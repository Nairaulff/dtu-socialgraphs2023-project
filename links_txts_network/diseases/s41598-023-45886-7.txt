Introduction People who have diabetes are more likely to develop diabetic retinopathy (DR), which is a degenerative disease of the retina. In the next few years, it is expected to affect an increasing number of individuals, as it is now the main cause of blindness among adults who are of working age worldwide. In 2017, a significant number of people were potentially susceptible to type 2 diabetes, and the number of people who fall into this category is also steadily growing around the globe. Most of these DR patients were between 35 and 59 years old, and 1 in 2 people among the 212 million were unaware of their disease. Numerous statistical studies conducted across the globe reveal the fact that diabetic retinopathy has acted as a significant public health issue in the present society. As per the data of 2023, the prevalence of diabetic retinopathy is estimated to be 34.6% 1 . The 74th World Health Organization (WHO) study revealed that more than 420 million people had diabetes in 2021, and 578 million were predicted to have the disease by 2030. The prevalence of diabetes is rising globally, which is further increasing the number of people who are afflicted by DR. It is also estimated that the number of DR patients worldwide is predicted to rise from 103.12 million to 160.5 million between 2020 and 2045, with 44.82 million individuals reporting visual issues. This establishes the role of DR in the potential development of a huge global, economic, and public health problem 2 . According to the International Diabetes Federation (IDF) 3 , a total of 537 million individuals in the world between the ages of 20 and 79 make up 10% of the world's population are estimated to have diabetes mellitus in 2021. The statistical data reveal that diabetes was responsible for a total worldwide health expenditure of USD 996 billion in 2021, further indicating growth of 316 percent over the course of the previous 15 years. In addition, it is also observed that in low and middle-income countries four out of every five people are diabetic patients. It is further projected that by 2030, the total number of people to likely suffer from diabetes will be 643 million which is further going to increase to 783 million by 2045 4 . An abnormal rise and fall in blood sugar levels are the initial symptoms of diabetes. Usually, glucose in the body is converted into energy, which lets people perform their daily tasks. But with the abnormal increase in blood sugar levels, the extra blood sugar produced has no choice but to build up in the blood vessels of various body organs such as the eye 5 , 6 , 7 acting as the root cause of the disease. Ophthalmologists classified DR into three categories based on its severity level: normal, NPDR (non-proliferative diabetic retinopathy), and PDR (proliferative diabetic retinopathy). The term "NPDR" refers to the initial phase of a disease wherein there are few or no specific symptoms, while it is subsequently classified into three categories: mild level, moderate level, and severe level. The most significant symptom of NPDR is blurred eye vision, night vision problems, small regions of inflammation in the retina's blood vessels, and sometimes a few retinal veins blocked by hemorrhages, leading to reluctant blood flow in the eye. PDR is an advanced form of diabetes. In this stage, the retina lacks oxygen due to circulation issues. Hence, fragile blood vessels get affected in the retina, and vitreous, which is a gelatinous substance located in the posterior segment of the eyeball. The center of the eye (vitreous), which contains new blood vessels, eventually starts leaking blood, resulting in vision impairment 8 , 9 . The severity levels of DR identification using fundus images as specified in Fig. 1 . Figure 1 Source: diaretdb1 (standard diabetic retinopathy database). Diabetic retinopathy sample fundus images with severity grading levels. Full size image Bioinspired optimization algorithms are developed considering ideas and inspirations acquired from the natural biological evolution process to produce new and resilient competing computational approaches. These are potential options for dealing with difficult optimization challenges 10 . An example of such an approach is the Firefly algorithm 11 , which is an efficient way to select features used to perform tasks pertaining to medical image analysis. These algorithms seek to find an optimal subset of features by simulating the natural processes of attraction and repulsion and are based on natural phenomena of the behavior of the fireflies. However, the algorithm requires high computational power during the search process. The study of diabetic retinopathy is a significant field of research and is a difficult and challenging topic, although there are many optimistic improvements in the works. The researchers are using new imaging techniques that utilizes Artificial intelligence as a part of the machine learning and deep learning models to detect diabetic retinopathy in early stages with enhanced accuracy. The present study thus proposes a method for identifying DR severity levels from retinal images that begins with image pre-processing and augmentation, followed by segmenting the optical disc (OD), the macula, blood vessels, exudates, and hemorrhages through an adaptive thresholding process. After the images are segmented, the model further implements a bio-inspired feature selection process which enables the most significant features to be fed into an ensemble learning model. In this process, multidomain features are extracted from the retinal images, including frequency, entropy, cosine, gabor, and wavelet components. Then, Novel Modified Moth Flame Optimization (MMFO) is used which is based on feature selection and contributes to the maximization of feature variance levels. The model is further trained using multiple machine-learning algorithms namely Naive Bayes (NB), k Nearest Neighbours (kNN), Support Vector Machine (SVM), Logistic Regression, Multilayer Perceptron (MLP), and Random Forests as part of an ensemble model. The experiments performed on an enlarged set of data samples reveal the advantageous aspects of the ensemble learning model in comparison to the conventional approaches achieving enhanced accuracy in determining the severity levels of DR. The distinctive contributions of the research are as follows: An extensive review of numerous applications of machine learning and deep learning implementations for DR detection and classification, emphasizing the contributions and related limitations. The implementation of image pre-processing and augmentation techniques being applied to the DR dataset from the retinal images, multidomain characteristics should be extracted. The process of implementing a modified moth flame algorithm of feature selection significantly cuts down on the number of features necessary for classification, thereby improving the effectiveness and interpretability of the model. The optimized features are classified by using machine learning algorithms NB, kNN, SVM, logistic regression, MLP, and random forests combined as an ensemble model, yielding optimized results in classifying the extent of complications of DR. The organizational structure of this article is as follows in the Literature Review, related to the state-of-the-art work implementations using various ML and DL (deep learning) techniques applied to DR, the “ Proposed methodology ” section provides detailed knowledge about the proposed framework and related methodologies, and the “ Result analysis ” section highlighted the experimental results and comparative analysis of the proposed model, followed by the Conclusion and future scope in the area of research. Literature review People who have diabetes are at an increased risk of developing DR, which is a leading cause of visual impairment. It is extremely important to identify DR at an early stage and treat it appropriately to prevent eyesight loss. Retinal fundus images, which can be evaluated using machine learning algorithms, are a method that can be utilized to determine the seriousness of DR 12 , 13 . This section highlights some of the models developed for evaluating DR intensity levels in this study. The authors in 14 have proposed a synergic adversarial label learning (SALL) framework to identify relevant retinal semantic labels and feature spaces. This framework is similar to the deep convolutional neural network model 15 . However, the model used limited data sources yet yielded improved results. Similarly, the proposed generative adversarial network model 16 was applied to higher-order fundus images for lesion segmentation wherein channel attention and multi-scale discriminator methods were used to identify large and small optimized retinal fields. CNNs are a specific kind of DL model that has seen significant application in the field of DR severity prediction use cases. In 17 , the authors proposed a hybrid detection and classification framework to detect DR using a voting method. This framework used both image segmentation and feature selection approach to design diversified optimal feature selection to identify the DR severity classes with enhanced outcomes. However, this task was quite tedious because considering the complexity of the disease, the existence of a large amount of variability in the degree of detail of the eye retinal images, and the requirement for accurate and reliable classification performance levels via the use of UNet and Multiple Scale Attention Network (MSA-Net) 18 , 19 . The authors in 20 proposed a deep graph correlation network (DGCN) that provides an innovative path for automated DR classification and other computer-assisted medical diagnosis systems. Similarly, the proposed technique utilized DenseNet169’s encoder and Convolutional Block Attention Module (CBAM) 21 to construct a visual embedding for automated DR diagnostics. Moreover, the authors in 22 presented a lightweight CNN model as an end-to-end DR-Net (EDR-Net) to reduce the computational cost of training large datasets. A two-stage framework 23 for automatic DR classification was proposed, which used two different U-Net models to separate the OD (optic disc) and BV (blood vessels) in the pre-processing step. These models could automatically learn the image characteristics of the retinal fundus and further accurately categorize the images into various intensity levels. The authors in 24 proposed a hybrid retinal image enhancement algorithm to improve image quality and further remove noise from the retinal fundus images. Moreover, the feature extraction method ResNet50 was applied to optimize the image features, yielding enhanced classification results. There have been many different iterations of CNNs developed, such as VGG, ResNet, and Inception, each of which achieved a different degree of effectiveness 25 , 26 , 27 . Thus, it is quite established that transfer learning models perform well and require significantly less data for training than models that learn from inception and other use cases 28 , 29 . The important aspects of an image can be brought to the viewer's attention through various attention techniques. To estimate the intensity of DR, deep learning models with attention mechanisms have been developed to enhance the performance of the models 30 , 31 . These models have produced interesting findings, but additional investigation is required to establish the possibility of their success in identifying the characteristics 32 . Deep learning models known as capsule networks are comparatively recent developments that have demonstrated significant in the field of image categorization in real-time applications 33 , 34 . The proposed framework, DenseNet121, and the Oculi technique 35 developed an optimized transfer learning model to detect DR severity levels. The framework affected the performance of the model in terms of the standardized data samples. The models are also intended to be more resistant to image transformations and aberrations than conventional CNNs because they have been developed to be more durable. The intensity of DR has been estimated using capsule networks, with studies reporting enhanced performance compared to conventional CNNs 36 . The authors 37 presented a detailed review of various deep and machine learning techniques, considering image enhancement techniques, to identify various complications in DR. In order to overcome issues pertaining to handling of imbalanced dataset, the authors in 38 presented a hybrid convolutional neural network involving a grey wolf optimization framework to extract and select the optimal features yielding an optimal classification of DR. Similarly, the authors in 39 proposed an improvised version of grey wolf optimization in association with the genetic algorithm to handle the diversified dataset population and perform optimal feature selection. These features are fed into the CNN classifier to classify the DR severity level. The authors in 40 considered a transfer learning approach wherein a two-stage U-Net architecture was proposed for DR segmentation and classification using the CNN-SVD (singular value decomposition) model. This framework included an Inception-V3 model to extract the most relevant features which was further trained using the CNN-SVD model generating enhanced performance and ensuring reduced model complexity. Proposed methodology Considering the review of the existing models that have been used to identify severity levels of diabetic retinopathy, it can be observed that these models use general-purpose deep learning classifiers, which have lower efficiency levels. The conventional models have higher complexity and cannot be applied to multi-institutional data samples. To conquer these problems, this section briefly explains the design of an augmented bio-inspired multidomain feature extraction and selection model for diabetic retinopathy severity identification using an ensemble learning process. The proposed approach in Fig. 2 , is observed that in order to identify DR severity levels from retinal images, it is initially necessary to segment the optical disc (OD), macula, blood vessels, exudates, and hemorrhages using an adaptive thresholding process 41 . Once the images are segmented, the model uses bioinspired feature selection and ensemble learning, wherein multidomain features 42 from the retinal images, including frequency, entropy, cosine, gabor, and wavelet components are extracted. These data features are fed into a novel Modified Moth Flame Optimization (MMFO) 43 feature selection model that assists in maximizing feature variance levels and identifying optimized features. These optimized features are trained using an ensemble model that includes various ML algorithms such as Naive Bayes (NB) 44 , k Nearest Neighbours (kNN) 45 , Support Vector Machine (SVM) 46 , Logistic Regression 47 , Multilayer Perceptron (MLP) 48 , and Random Forests 49 . The ensemble model combines the results of many different models to increase accuracy and robustness. Figure 2 Proposed model architecture for DR classification. Full size image Dataset description In this framework, two similar datasets are used, namely the Indian Diabetic Retinopathy Image Dataset (IDRiD) 50 and the standard diabetic retinopathy database (DIARETDB1) 51 . The IDRiD dataset has 516 authentic fundus images which are isolated from the ratio of training (413) and testing (103). This dataset contains images annotated with disease severity at the pixel level of diabetic retinal lesions. The DIARETDB1 dataset has 89 authentic color fundus images consisting of 5 healthy sign images and the remaining 84 having DR-related symptoms. Both the dataset images were captured using a 50-degree FOV (field of view) fundus camera. These datasets have grades ranging from 0 to 4 as healthy, mild, moderate, severe, and proliferative to classify DR severity grading levels. Table 1 provides a detailed description of the datasets. Table 1 A detailed description of the Dataset. Full size table Image augmentation and preprocessing The proposed model initially collects retinal images of different diabetic and non-diabetic patients. The image augmentation technique is used to increase the number of data samples to fit the training model efficiently. This technique is mainly applied to increase the number of image samples using rotation, zoom, and shear functions. During the training of the model, the use of these parameters produces images with the aforementioned characteristics. The images were collected for grade 0 (normal person), grade 1 (mild DR), grade 2 (moderate DR), grade 3 (high DR), and grade 4 (very high DR) cases. The collected images are then converted into the optical disc (OD), macula, blood vessels, exudates, and hemorrhages using multidomain feature extraction 42 and segmented through an adaptive thresholding process. This adaptive thresholding process 41 is used for image segmentation wherein a small set of nearest pixel intensities for a specific time is observed. This method is specifically used to decrease computational time consumption. It computes the threshold value (th) for every specific neighborhood region to perform the image segmentation process. In comparison to the global thresholding value, adaptive thresholding enables the segmentation process to become robust providing enhanced contrast and brightness to the fundus images. It acts as a powerful segmentation tool for segmenting the fundus image features accurately and effectively. Also, the process can easily be implemented on a wide variety of fundus image features encouraging researchers to use the same. However, there exist associated challenges pertaining to noise generation while segmentation of tiny image features. Adaptive thresholding is thus considered to be an extremely popular technique in image processing to segment images and extract specific regions of interest. The process of adaptive thresholding is elucidated as follows: Optical disc (OD) The optical disc, also known as the optic nerve head is the exit point for the ganglion cell axons that leave the eye. Since there does not exist any rods or cones overlying the optic disc, it can be identified as a small blind spot in each of the eyes. OD segmentation is usually based on shape and brightness. Equation ( 1 ) is used to extract OD as follows $$OD = {b}_{in}\left(I, th\left(I, 0.4,FP,dark\right)\right)$$ (1) where, ‘b in ’ and ‘th’ are binarization and thresholding operations, while ‘FP’ represents the foreground polarity of the image sets, ‘I’ represents the input grayscale image, the threshold value of 0.4, and the 'dark' polarity is chosen through the empirical analysis. Macula Macula is a region of high intensity in the central part of the retina and is estimated as follows $$Macula= {b}_{in}\left(I, th\left(I, 0.6,FP,bright\right)\right)$$ (2) where the threshold value of 0.6 and ‘bright’ polarity are chosen through the empirical analysis. Blood Vessels Blood vessels are thin, elongated structures with varying intensities, and are follows $$BV = {b}_{in}\left(I,th\left(I, 0.5,DP,right\right)\right)$$ (3) $$BV = close\left(BV, structure\left(disc, 5\right)\right)$$ (4) where the threshold value of 0.5 and ‘bright’ polarity are chosen empirically, and a closing operation in morphology that uses a size-structuring element in the form of a disc is 5 selected through the empirical analysis. Exudates Exudates are yellowish-white spots with high intensity and irregular shapes, which are identified as follows $$Exudates ={b}_{in}\left(I, th\left(I, 0.3, FP, bright\right)\right)$$ (5) $$Exudates = open\left(Exudates, structure\left( disc,10\right)\right)$$ (6) where in the threshold value of 0.3 and bright polarity are chosen empirically, and a closing operation in morphology that uses a size-structuring element in the form of a disc is 10 for different image sets. Hemorrhages Hemorrhages are bright red or dark spots with irregular shapes which are evaluated as follows $$Hemorrhages = {b}_{in}\left(I, th\left(I, 0.7,FP,bright\right)\right)$$ (7) $$Hemorrhages = open\left(Hemorrhages, structure\left(disc, 3\right)\right)$$ (8) where, the threshold value is 0.7 and bright polarity is chosen empirically. The closing operation in morphology using a size-structuring element in the form of a disc is 3 as considered in the case of different image sets. These images are represented in multiple domains by estimating frequency, entropy, spatial, approximate, and detailed features. The frequency features are evaluated using Discrete Fourier Transform (DFT), wherein ‘N q ’ is the number of input image pixels (m) used for the feature extraction process. $$DF{T}_{m}=\sum_{n=1}^{{N}_{q}}{p}_{n}*\left[\mathit{cos}\left(\frac{2*\pi *m*n}{{N}_{q}}\right)-\sqrt{-1}*\mathit{sin}\left(\frac{2*\pi *m*n}{{N}_{q}}\right)\right]$$ (9) Similarly, the entropy features are estimated using Discrete Cosine Transform (DCT) as follows $$DC{T}_{i}=\frac{1}{\sqrt{2*{N}_{q}}}*{p}_{n}\sum_{m=1}^{{N}_{q}}{x}_{i}*\mathrm{cos}\left[\frac{\sqrt{-1}*\left(2*m+1\right)*\pi }{2*{N}_{q}}\right]$$ (10) The spatial features are calculated using Gabor analysis as follows $$G{\left(p,s\right)}_{r}={e}^{\frac{-x{`}^{2}+{\partial }^{2}*{y}^{{\prime}2}}{2*{\varnothing }^{2}}}*\mathrm{cos}\left(2*\frac{pi}{\lambda }*{{p}^{\prime}}\right)$$ (11) where, p and s are indices and values of features, while ∂, \(\varnothing\) , and \(\lambda\) represent constants for angular and wavelength augmentation operations. In combination with these features, approximate and detailed wavelet components were also calculated as follows $${W}_{j}=\frac{{p}_{n}+{p}_{m+1}}{2}$$ (12) $${W}_{k}=\frac{{p}_{n}-{p}_{m+1}}{2}$$ (13) All these feature vectors are combined to form the Diabetic Retinopathy Feature Vector (DRFV), which could include redundancies that are reduced via the use of a feature selection approach. Modified moth flame optimization (MMFO) algorithm Moth Flame Optimization is a type of swarm intelligence-inspired algorithm. The algorithm solves numerous authentic problems in various provinces and was developed by Sayyad Mirjalili 43 . It represents a population-based mechanism to specify the navigation behavior of moths in nature. The artificial moth imitates the navigation technique used by actual moths, which is referred to as transverse orientation. This is accomplished by maintaining a stable angle with a distant source of flame in order to orient itself. This mechanism is initially generated randomly in solution space, determining each moth’s fitness function and setting the best position for the moth. Based on the spiral behavior mechanism, moths' positions are changed concerning the flame and updated to new positions. The bioinspired feature selection method significantly reduces the number of features required for classification, improving the interpretability and effectiveness of the model sets. The proposed Modified Moth Flame Optimization (MMFO) is observed to be robust and simplified while performing hyperparameter optimization for optimal feature selection wherein maximum class-level feature variance is considered. The traditional MFO, although has multiple advantages being simple, flexible, and validated across various applications has challenges of being constrained in generating local optimal solutions providing inferior convergence rates. The MMFO algorithm provides the ability to include maximum variance in the class-level features to achieve optimal feature selection. Also, it enhances the exploration capability of the MMFO algorithm in terms of minimizing the number of features and keeps a smaller selection of relevant features without impairing the system's performance and convergence cost. In this regard, MMFO-measured minimal fitness values are extracted from the dataset considering the diabetic retinopathy feature vectors (DRFV). The process is iterated until the optimal feature selection is achieved. Although the algorithm proves to be efficient as part of various ML and DL frameworks for optimal feature set selection but is found to be computationally expensive while handling larger volumes of dataset. The algorithm is based on the characteristic of moths which by nature fly in various directions, namely one-dimensional, two-dimensional, and three-dimensional views. These can be represented as follows $${M}_{th}=\left[\begin{array}{ccc}{mth}_{\mathrm{1,1}}& {mth}_{\mathrm{1,2}}\dots \dots & {mth}_{1,d}\\ \vdots & \dots & \vdots \\ {mth}_{x,1}& {mth}_{x,2}\cdots & {mth}_{x,y}\end{array}\right]$$ (14) Here x specifies the number of moths, and y specifies the dimensions of each moth in the solution area. These can be utilized to calculate the fitness function vectors represented as follows $${f}_{tn}=\left[\begin{array}{ccc}{ftn}_{\mathrm{1,1}}& {ftn}_{\mathrm{1,2}}\dots \dots & {ftn}_{1,d}\\ \vdots & \dots & \vdots \\ {ftn}_{x,1}& {ftn}_{x,2}\cdots & {ftn}_{x,y}\end{array}\right]$$ (15) Here ‘f tn ’ specifies the fitness value vector for each solution space. The position of the moths gets updated to calculate the global optimum values to solve the optimization problems as follows $$\mathrm{MMFO }= \left(\mathrm{L},\mathrm{M},\mathrm{P}\right)$$ (16) $${M}_{th} = (\mathrm{up}(\mathrm{m})-\mathrm{lw}(\mathrm{n}))*\mathrm{ random}()+\mathrm{lw}(\mathrm{m}))$$ (17) $$\mathrm{Flmno }=\mathrm{ round}(\mathrm{X}-1 *\mathrm{X}-1/\mathrm{M}))$$ (18) Here L, M, and P represent the moth’s random location, the movements of the moths in the search area, and finishing the search process, respectively. Where up and lw refer to upper bound and lower bound values to calculate the random distribution function. To achieve the best optimal values in the solution search space by updating the positions of the moths. Where M and X represent the number of iterations and flames at the maximum level respectively. Algorithm 1 The pseudo-code for the Modified Moth Flame Optimization Algorithm. Full size image Initially, a set of NM moths are generated by the selection of N features specified as follows $$N=STOCH\left(LM*N\left(DRFV\right), N\left(DRFV\right)\right)$$ (19) where LM is the moth Learning Rate, N(DRFV) represents several extracted multidomain features, and STOCH represents a stochastic number generation process. For each of these selected features, evaluate moth flame fitness (fm) as follows $$the \, {f}_{m}=\sqrt{\frac{\sum_{i=1}^{N}{\left({x}_{i}-\sum_{j=1}^{N}\frac{{x}_{j}}{N}\right)}^{2}}{N}}$$ (20) Similarly, generate NM different moths, and find the fitness threshold as follows $${f}_{th}=\frac{1}{NM}\sum_{i=1}^{NM}f{m}_{i}*LM$$ (21) $${f}_{New}={f}_{Old}\bigcup_{i=1}^{fm>{f}_{th}}STOCH\left(f\left(i\right)\right)$$ (22) moths with f m < f th are discarded, and their features are updated using Eq. ( 22 ). Where ‘f’ represents features of the current set of moths and the movement of the other moths is directly passed to the next set of iterations. This process is repeated for ‘NI’ iterations, and their fitness and internal configurations are modified in each set of iterations. Once all iterations are completed, the initial feature sets are estimated $${f}_{Initial}=\bigcup_{i=1}^{fm>{f}_{th}}f\left(i\right)$$ (23) These features are further processed using other iterations of Moth Flame Optimization (MFO) and a set of NM moths gets generated again by the selection of N features from the f(Initial) sets through Eq. ( 23 ). $${N}_{New}=STOCH\left(LM*N\left({f}_{Initial}\right), N\left({f}_{Initial}\right)\right)$$ (24) For each of these selected features, inter-class moth flame fitness is evaluated f m (in) as follows $${f}_{m}(in)=\sqrt{\frac{{\sum_{a=1}^{m}{(x}_{a}-\frac{\sum_{i=1}^{m}\sqrt{\frac{\sum_{j=1}^{n}{{(x}_{j}-\frac{\sum_{k=1}^{n}{x}_{k}}{n})}^{2}}{n-1}}}{m})}^{2}}{m-1}}$$ (25) where, m represents features of one class, while ‘m’ represents features of other classes. Similarly, generate ‘NM’ different moths and the fitness threshold is determined as follows $${f}_{th}=\frac{1}{NM}\sum_{i=1}^{NM}{f}_{m}{(in)}_{i}*LM$$ (26) $${f}_{New}={f}_{Old}\bigcup_{i=1}^{{f}_{m}(in)>{f}_{th}}STOCH\left(f\left(i\right)\right)$$ (27) Moths with \({f}_{m}\left(in\right)<{f}_{th}\) are discarded, and their features are updated through Eq. ( 27 ). Where f represents features of the current set of moths and the movement of other moths is directly passed to the next set of iterations. This procedure is performed until ‘NI’ iterations are completed, and the relevant fitness and internal configurations are modified in each set of iterations. Once all iterations are completed, the final feature sets are estimated as follows $${f}_{final}=\bigcup_{i=1}^{{f}_{m}(in)>{f}_{th}}f\left(i\right)$$ (28) All these features are fed into a set of classifiers including Naive Bayes (NB), k Nearest Neighbours (kNN), Support Vector Machine (SVM), Logistic Regression (LR), Multilayer Perceptron (MLP), and Random Forests which are combined using boosting operations. Ensemble learning Naive bayes (NB) The Naive Bayes classifier 44 is a supervised machine learning method to classify training data members that are independent of each other’s specific occurrences. It is one of the most efficient algorithms that produce faster outcomes. This classifier depends on the Bayes theorem to find the probability of the conditional hypothesis. kNN (k-nearest neighbours) The kNN 45 is a commonly used and simple form of classification in machine learning algorithms. This classifier defines the new data points by considering the nearest data points to calculate the equal value of the earlier data. Support vector machine (SVM) The SVM 46 is a supervised learning algorithm, one of the most implemented algorithms to solve regression and classification problems. This classifier generated the extreme boundary values to create hyperplanes for the best solutions. Suppose that the dataset has two different data features and is labelled. These data features are categorized based on labelling to draw a baseline between them and classify them easily. Logistic regression (LR) Logistic Regression (LR) 47 is among the simplest ML techniques, and it can be used to forecast continuous variables. This algorithm specifies the relationship between dependent and independent values and determines its effect on the resultant dependent variable. The objective is to calculate the best prediction in order to decrease the error rate between the dependent and independent values. The mean square error cost function average is calculated to minimize the error rate. Multilayer perceptron (MLP) A multi-layer perceptron 48 contains Input, output, and hidden layers the three types of layers, and is generally called a feed-forward neural network. These input layers are combined to send the information to each hidden layer in the network, and these hidden layers generate one single output. This algorithm mainly uses the back-propagation technique to train the model as well as image detection and analysis. Random forests (RF) The Random Forest algorithm 49 helps to solve regression and classification problems on the basis of ensemble learning. This algorithm depends on the various decision trees and takes the average of the given data to improve the classification performance. Random forests use two approaches to ensure that no two trees’ behaviours are too similar: bagging and feature randomness. This causes significant heterogeneity among the trees in the model, resulting in decreased correlation among trees and greater diversity. The final ensemble boosting method is as follows $$\begin{aligned} C_{out} & = C\left( {NB} \right)*A\left( {NB} \right) + C\left( {kNN} \right)*A\left( {kNN} \right) + C\left( {LR} \right)*A\left( {LR} \right) \\ & \quad + C\left( {SVM} \right)*A\left( {SVM} \right) + C\left( {MLP} \right)*A\left( {MLP} \right) \\ \end{aligned}$$ (29) where A and C represent the testing accuracy and output class for the given classifier, while C out is the final output of the ensemble classification process. The use of ensemble classification enables improvement in classification accuracy at different DR grade levels. This accuracy, in association with metrics namely precision, recall, and delay are needed for classification. It is evaluated for different dataset samples and compared with the existing models. Result analysis The proposed framework for identifying DR severity levels from retinal images is described in this section. At the outset, the retinal image classes, namely optical disc (OD), macula, blood vessels, exudates, and hemorrhages, are segmented using an adaptive thresholding process. After segmenting the images, the multidomain features namely frequency, entropy, cosine, gabor, and wavelet components are extracted from the retinal images. To maximize the feature variance and optimized feature selection, a novel modified moth flame optimization (MMFO)-based feature selection method is employed. The optimized features are trained using multiple machine-learning algorithms combined as an ensemble classification mechanism to classify the DR severity levels. These algorithms include Naive Bayes (NB), k Nearest Neighbours (kNN), Support Vector Machine (SVM), Logistic Regression (LR), Multilayer Perceptron (MLP), and Random Forests. The integrated results generated from the various models justify the superiority of the ensemble model in terms of its enhanced reliability and precision. The proposed framework is implemented on the Windows 11 operating system with an i7 processor, 16 GB of RAM, 1 TB of SSD memory, and 4 GB of NVIDIA GPU resources using NumPy and TensorFlow libraries in a Python environment. The proposed framework has yielded superior results when compared to the existing models, namely, the Mixed Model-DR Ensemble model 17 , the Deep U-Net architecture 18 , the DGCN model 20 , and the Hybrid Retinal-DL model 24 . The performance metrics that are used to calculate the performance of the training and testing data are Accuracy, Precision, Recall and F1-Score based on the true positive ( T p ) rate, true negative ( T n ) rate, false positive ( F p ) rate, and false negative ( F n ) rates of the classes. The equations of the considered metrics are presented in Eqs. ( 30 )–( 33 ). $$Acc\left(Accuracy\right)=\frac{{T}_{p}+{T}_{n}}{{T}_{p}+{T}_{n}+{F}_{p}+{F}_{n}}$$ (30) $$Pr\left(Precision\right)=\frac{{T}_{p}}{{T}_{p}+{F}_{p}}$$ (31) $$R\left(Recall\right)=\frac{{T}_{p}}{{T}_{p}+{F}_{n}}$$ (32) $$F1-Score=\frac{(2*Pr*R)}{(Pr+R)}$$ (33) Experimental analysis The proposed framework analyses the various DR grade classes with high degrees of precision as it uses high-density feature extraction models and MMFO integrated with an ensemble learning framework. The proposed framework yielded prominent results in comparison to the conventional DR detection and classification models, namely, the Mixed Model-DR Ensemble model 17 , the Deep U-Net architecture 18 , the DGCN model 20 , and the Hybrid Retinal-DL model 24 . Empirical studies reveal the fact best outcomes are achieved when 20–30% of the data are used for testing and 70–80% of the data are used for the purpose of training. Similarly, in case of machine learning algorithms, adjustment of the training—testing data ratio have significant influence on the performance of the model. Considering the same rule of thumb and to reduce chances of overfitting in the present study 80% of the data is used for training and the remaining 20% is used for the purpose of testing the model. The confusion matrix is generated from the ensemble classification model considering varying severity levels (0-Normal, 1-Mild, 2-Moderate, 3-Severe, 4-Proliferated). In this regard, Fig. 3 represents the heatmap as part of confusion matrix wherein the data points are divided into actual and predicted severity levels. The heatmap highlights the highest achieved accuracy of 96% for all the severity levels. Figure 3 A heatmap that represents the confusion matrix of the ensemble learning model for predicting DR severity levels. Full size image The model is further evaluated by varying the ratio of training and testing data and the resultant accuracy is generated. It is observed that the best accuracy is achieved when the training—testing data is of 80:20 ratio. The comparative analysis of generated accuracy measure of all the models are illustrated in Fig. 4 wherein it is observed that all the existing models generated enhanced accuracy considering 80:20 training—testing data ratio. More so, the proposed framework further generated superior accuracy in comparison to the other state-of-the-art models. Figure 4 The Accuracy of severity identification for different models. Full size image Due to the utilization of high-density feature extraction models and MMFO with ensemble learning, the proposed model evaluated various DR grade types with high levels of precision. The proposed model improved the DR grade classification precision value in comparison to the conventional models, namely, the Mixed Model-DR Ensemble model 17 , the Deep U-Net architecture 18 , the DGCN model 20 , and the Hybrid Retinal-DL model 24 , by varying the training data, as shown in Fig. 5 . The precision was also enhanced by the application of Gabor and wavelet analysis, which aided in enhancing classification performance even with smaller data samples. Figure 5 The Precision of severity identification for different models. Full size image Figure 6 reveals the fact that the proposed model yields enhanced recall measure in comparison to the conventional models, namely, the Mixed Model-DR Ensemble model 17 , the Deep U-Net architecture 18 , the DGCN model 20 , and the Hybrid Retinal-DL model 24 . The recall value achieved is also superior when measured considering varying training and testing data ratios. Figure 6 Recall of severity identification for different models. Full size image Figure 7 shows the computational time utilized in the training of the model wherein lower computational time is observed, which also justifies its enhanced performance in comparison to the conventional models, namely, the Mixed Model-DR Ensemble model 17 , the Deep U-Net architecture 18 , the DGCN model 20 , and the Hybrid Retinal-DL model 24 . Figure 7 The Computational time for Training the Model in comparison to the existing models. Full size image Performance analysis The research community has been immensely focused on studying aspects pertaining to automatic DR classification, especially using advanced ML and DL techniques. The proposed framework in this study has yielded superior performance in comparison to the Mixed Model-DR Ensemble model 17 , the Deep U-Net architecture 18 , the DGCN model 20 , and the Hybrid Retinal-DL model 24 , and conventional models considering the aforementioned metrics. The comparative results of the performance of Mixed Model-DR Ensemble model, Deep U-Net architecture, DGCN model, and Hybrid Retinal-DL model in contrast to the proposed model considering Accuracy, Precision, Recall and F1-Score are presented in Fig. 8 . Moreover, the proposed framework was evaluated considering computational time and Accuracy measures and further evaluated against the conventional models for DR classification. Table 2 represents such evaluation measures of Precision, Recall, F1-Score, and Accuracy that enabled the comparative analysis of the conventional models with to the proposed model. Figure 8 Evaluation of performance measures of the proposed framework with other conventional models. Full size image Table 2 The performance analysis of evaluation metrics of various models. Full size table Conclusion The proposed framework for identifying DR severity levels from retinal images includes an image pre-processing technique followed by the optical disc (OD), macula, blood vessels, exudates, and hemorrhages, which are segmented by utilizing an adaptive thresholding procedure. After segmenting the images, an ensemble learning model involving bio-inspired feature selection is used to extract multidomain features namely frequency, entropy, cosine, gabor, and wavelet components from the retinal images. A novel modified moth flame optimization (MMFO)-based feature selection method is employed to maximize the feature variance for achieving optimal feature selection. These optimized features are trained using various machine-learning algorithms employed during the ensemble model process. The algorithms included are Naive Bayes, k-Nearest Neighbors, support vector machine, logistic regression, multilayer perceptron’s, and random forests. The aggregated combination of the results generated from the multiple models propels the ensemble model to generate results with increased levels of reliability and precision. Due to the use of high-density feature extraction models and MMFO with ensemble learning, the proposed model further evaluates various DR-grade classes with high levels of accuracy. The proposed model is further evaluated considering computational time and accuracy metrics compared against the conventional models for DR classification by varying the training data. It is observed that the application of low-complexity feature analysis aided in accelerating the process and helped to achieve improved categorization success despite the constraint of using lesser data. The study directs the potential outcomes of the proposed approach in improving clinical decision-making and management of DR. The same framework can also be applied to predictions involving medical image analysis in other healthcare domains as well. The results generated from the model yield enhanced Accuracy, Precision, Recall and F1-Score justifying the superiority of the model in predicting diabetic retinopathy. But in practicality, often healthcare providers fail to rely on the generated predictions of the model as the output does not map with the input attributes fed in to the model failing to establish the contribution of the attributes leading to the prediction results. It is almost like a “black box” framework wherein optimized output is getting generated from the input, but users fail to get clarity on how the input impact on the resultant output. Hence, as part of the future research work, explainable AI can be applied additionally to the framework to achieve enhanced transparency and explainability to the generated prediction leading to confident decision-making in real-time healthcare scenarios.