Introduction Multi-objective optimization problems (MOPs) 1 are very common in real-world problems such as electrical engineering 2 , logistics scheduling 3 , and robotics 4 , which often have two or more objectives that need to be optimized simultaneously. The mathematical form of the MOPs can be expressed as follows: $$ \begin{array}{*{20}c} {{\text{minimize}}\;\left\{ {f_{1} \left( x \right),f_{2} \left( x \right), \ldots ,f_{k} \left( x \right)} \right\}} \\ {subject\;to\;x \in X,} \\ \end{array} $$ (1) where X is the search space of decision variables, x is the decision vector with D decision variables, and f 1 ( x ),…, f k ( x ) are k (≥ 2) objective functions to be optimized 5 . Usually, due to the conflict between objectives, it is difficult to obtain a single value that can satisfy all objectives, so we can only coordinate among multiple objectives to make them as optimal as possible 6 . The solution obtained by MOPs is not unique, but an optimal solution set composed of a set of optimal solutions, namely Pareto set (PS) in decision space and Pareto front (PF) in the objective space 7 . Multi-objective evolutionary algorithms (MOEAs) have been popular in solving MOPs due to numerous advantages 8 , 9 . For instance, MOEAs can efficiently obtain a set of optimal solutions in a single run even in the presence of irregular or noisy fitness functions. Various MOEAs have been developed, which can be roughly divided into three categories. The first category is Pareto or dominance-based MOEAs 10 . For example, NSGAIII 11 used the dominant relationship as a criterion for selection. The second includes indicator-based MOEAs 12 , such as HV 13 adopted in HypE 14 as the indicator. The third category is decomposition-based approaches 15 , which apply a series of vectors to decompose the MOP into multiple single-objective problems. For instance, MOEA/D 16 and RVEA 17 solved MOPs based on decomposition and reference vectors respectively. It is worth noting that the majority of MOEAs typically involve more than 10,000 function evaluations (FEs) in the process of optimizations. But for some expensive multi-objective optimization problems (EMOPs) 18 , 19 (such as computational electromagnetics 20 , fluid dynamics 21 , and finite element analysis 22 ) whose evaluation might take hours or even days. In such cases, the time consumption and computational cost can be burdensome. Therefore, how to reduce the computational cost or the number of evaluations for EMOPs is a significant concern. Surrogate-assisted evolutionary algorithms (SAEAs) 23 are a representative method to solve EMOPs 18 . The surrogate model (also known as meta-model) is built by machine learning to replace the computationally expensive real fitness function, enabling the evaluation of individuals at a lower cost during each iteration 24 . A variety of machine learning methods, including the Kriging model 25 , radial basis function (RBF) 26 , and support vector machines (SVM) 27 , have been introduced as surrogate models in SAEAs. On MOPs, SAEAs also have demonstrated their effectiveness in significantly reducing the number of expensive FEs 28 . According to the modeling method, SAEAs can be roughly categorized into approximation-based and classification-based, which can be summarized below: Approximation-based SAEAs: In the field of evolutionary computing, fitness approximation can employ various strategies, e.g. approximate fitness value or Pareto rank 29 . Among these SAEAs, the most typical ones are the Kriging and RBF 30 . In AB-MOEA 31 , an adaptive Bayesian method was proposed to determine which candidate solutions require evaluation. In K-RVEA 32 , a Kriging-assisted RVEA used the approximation ability of the Kriging model to assist optimization in selecting individuals. Besides, several machine learning methods are employed in surrogate modeling. For example, EDN-ARMOEA 33 , 34 utilized a dropout neural network to achieve a good balance between convergence and diversity. Classification-based SAEAs: The classification-based surrogate model does not evaluate individuals based on their approximate fitness values, but compares the individuals by classifiers 35 . As a classifier, the surrogate model compares the quality between the reference solution and other individuals and assigns a label to facilitate subsequent selection 36 . CSEA 37 constructed an artificial neural network to predict the dominant relationship between the candidate solution and the reference solution. And CPS-MOEA 38 classified the candidate solutions into positive and negative data sets by a pre-selection method. Although the application of surrogate models is widespread, numerous challenges still remain. First, which surrogate model to choose 39 . At present, mainstream surrogate models include Kriging, RBF, SVM, etc. But there is no standard in place to determine which surrogate model should be used. The second is how to use the surrogate model 40 , 41 . As mentioned above, the surrogate model can be applied to approximate the fitness value or estimate the rank of the individual. The way in which surrogate models are employed greatly influence the final result. Last but not least, how to update the surrogate (i.e. selection of individuals for re-evaluation) is also an important issue. Various approaches are described in the literature, e.g. selecting a set of optimal solutions 42 , non-dominant solutions 43 , or reference solutions based on the predicted results of the surrogate model 44 . Furthermore, SAEAs proposed in recent years have primarily focused on low-dimensional EMOPs with less than 30 decision variables. This limitation is primarily attributed to the scarcity of training samples for building accurate surrogate models and the excessive time required to train high-dimensional models. However, the critical problem of the number of decision variables has gained increasing attention. There are two important factors to consider when using the surrogate model to solve high-dimensional EMOPs. First, how selecting and building a surrogate model can minimize the extra computational cost caused by dimension increase. The efficiency of establishing and updating the surrogate model is strongly related to the dimension of the problem. Taking K-RVEA as an example, this algorithm performed well in scenarios with 10 decision variables, but its performance deteriorated significantly when the decision variable increased under the limited FEs. The second is how to find individuals with a balance of diversity and convergence. In SAEAs, such individuals are not only used for re-evaluation, but also play a crucial role in improving the accuracy of the surrogate model. Inspired by the aforementioned concepts, we propose a two-stage dominance-based surrogate-assisted evolution algorithm (TSDEA) for high-dimensional expensive multi-objective optimization. In the algorithm, the RBF model is employed to replace a portion of the FEs and guide individual evolution. The proposed algorithm designs a reference vector based two-stage selection strategy, which convergence considers the diversity and convergence of the population during the selection process. Besides, we develop a novel archive updating strategy to limit the number of update samples for retraining the RBF model. during the selection process, the reference vector assumes a crucial role an indispensable part. The main contributions of this paper can be summarized as follows: (1) To maintain the convergence and diversity within the population, a two-stage selection strategy is proposed. In the two-stage selection strategy, individuals are selected using the dominant relationship and angle-penalized distance (APD) proposed in RVEA, respectively. By employing this approach, we can thoroughly explore both the decision space and objective space, leading to the selection of individuals with exceptional convergence and diversity. (2) To limit the computing time of model training, an archive updating strategy is designed in this paper to make the maximum number of samples of model training limited. If the total number of samples exceeds, redundant individuals will be removed from the archive. This approach ensures that only the most relevant and informative samples are retained, optimizing the efficiency of the model training process. The rest of the paper is organized as follows. In Section “ Preliminary ”, we provide a relatively brief description of the non-dominant sorting method, APD, and RBF models so that the paper is self-contained. Section “ Proposed algorithm ” gives a detailed description of the proposed algorithm. The experimental results and analysis are given in Section “ Numerical experiments ”. Finally, we draw a conclusion and prospect in Section “ Conclusions ”. Preliminary In this section, we begin by presenting NSGAIII and angle-penalized distance (APD), which serve as the prototype and foundation of the two-stage selection strategy in this paper. Subsequently, we briefly describe the RBF model, including a comparison of other alternative models. NSGAIII The TSDEA proposed builds upon the concept of non-dominant sorting in NSGAIII and incorporates some improvements. a detailed explanation of the NSGAIII algorithm is provided in this part. In NSGAIII, a set of structured reference points is initially constructed. Next, NSGAIII continues to iterate through the operations of genetic, recombination, evaluation, non-dominant sorting, and selection until the maximum iterations are reached. At the t -th generation, the merger of the current population (population size is N ) and its offspring (population size is N ) will form a new population P t . N individuals need to be selected in the population P t . P t is initially into several non-dominant layers ( F 1 , F 2 , …, F n ) based on the non-dominant sorting. Individuals are then selected from F i to join a new population (denoted as S t ) until the number of selected individuals reaches or exceeds N for the first time, and this critical layer is denoted as F L . If the number of individuals in S t exceeds N , individuals in F 1 − F L−1 are accommodated in P t + 1 , followed by a niche operation to select the remaining individuals from F L . The selection strategy is based on a set of predefined reference vectors and the vertical distance between the individuals and the reference vectors. Objective values and reference points are initially normalized to align them on the same hyperplane 45 . Each individual is associated with a reference vector based on the minimum vertical distance. Next, select individuals for each reference vector. Referring to Fig. 1 a, if the number of individuals ( ρ ) in S t corresponding to the reference vector is 0 and no individuals in F L belong to this reference vector (such as V 1 and V 2 ), this reference vector is no longer considered. But in cases where ρ ≥ 1(as shown in Fig. 1 b), randomly select an individual from individuals of F L belonging to this reference vector. This iterative process continues until the number of individuals in S t reaches N . Figure 1 Description of selecting individuals for each reference vector. Full size image Angle-penalized distance The primary difficulty of high-dimensional EMOPs is achieving convergence to PF while simultaneously preserving solution diversity. Several studies have been proposed to address such questions, including the aforementioned RVEA algorithm. RVEA introduces an angle-penalized distance as a selection criterion, which can effectively balance diversity and convergence according to the experimental results in 17 . APD relies on a set of reference vectors that partition the objective space into multiple subspaces, the selection of each subspace is carried out independently. First, all individuals will be converted to objective vectors according to the following formula. $$ f^{\prime}_{i} = f_{i} - Z_{\min } $$ (2) where f i represents the objective value of the i th individual and Z min is the set of the minimum objective value of f . The translation of the objective function is to ensure that the initial point of the reference vector is always the origin, and all the translated objective values fall within the positive orthant. After the translation, APD adopts the acute angle between individuals and the reference vectors, as well as the length of the objective vectors to assess the overall performance of solutions by using the following formula: $$ d^{i} = \left( {1 + P\left( {\theta^{i} } \right)} \right) \cdot \left\| {\overline{v}^{i} } \right\| $$ (3) where P ( θ i ) and || i || measure the diversity performance and convergence performance, respectively. v i represents the objective vector corresponding to the i th individual. θ i represents the angle between the individual and the reference vector. $$ P\left( {\theta^{i} } \right) = M \cdot \left( {\frac{t}{{t_{\max } }}} \right)^{\alpha } \cdot \frac{{\theta^{i} }}{{\gamma_{v} }} $$ (4) where M represents the number of objectives, t represents the current generation, and t max represents the maximum generation. The angle γ v is used to normalize the angle, which is important when the distribution of reference vectors is too dense or too sparse. The value of α controls the changing rate of P ( θ i ) and a larger α means that more emphasis will be allocated to the convergence performance compared to the diversity performance. Radial basis function Radial Basis Function (RBF) 8 , 46 , 47 is a discrete multivariate data interpolation model. The value of the function depends on the Euclidean distance from the sample point to the measured point. RBF model is constructed by linearly stacking the basis function values. The basic expression of the basis function is as follows: $$ \hat{y}\left( x \right) = \sum\limits_{i = 1}^{n} {\lambda_{i} \Phi } \left( {\left\| {x - x_{i} } \right\|} \right) $$ (5) where λ i is the weight coefficient of the i th basis function; || x - x i || is the Euclidean distance between the measured vector point and the sample point x i ; n is the number of variables, and Φ (·) is the radial basis function. The critical steps of using the RBF model are involve selecting the basis function and calculating the weight coefficient. The choice of basis functions and coefficients directly impacts the fitting accuracy and local characteristics of the surrogate model 48 . In this paper, an RBF model with multi-quadratic functions is adopted to assist the search work. According to various research, each surrogate model has its unique characteristics and applications. For example, Kriging and SVM are suitable for low-dimensional problems, but when the dimension of the problem is increasing, the training process becomes computationally expensive 29 . Comparatively speaking, RBF is less sensitive to dimensionality and offers fast modeling speed, which is advantageous for high-dimensional EMOPs. Proposed algorithm In this section, the details of the proposed TSDEA will be given. The overall framework of TSDEA is presented first, followed by its two-stage selection strategy. Finally, the archive updating strategy is introduced. Algorithm framework Algorithm 1 outlines the primary framework of the proposed algorithm TSDEA. The algorithm composes of five components: initialization, establishment and updating of the surrogate model, generation of candidate offspring, reference vector based two-stage selection strategy, and finally an archive updating strategy. Reference vector based two-stage selection strategy is comprised of Algorithm 2 and Algorithm 3, which select individuals according to their dominant relationship and APD, respectively. Algorithm 4 is primarily applied for archive management, which is ultimately employed to update the surrogate model. (1) Initialization During the initialization phase, an initial population of size N is generated using Latin hypercube sampling (LHS) and evaluated using the original fitness function. The initial population will be included in the archive D s and D respectively, where D s is for subsequent surrogate model updates, and D is the final returned solution set. In addition, a set of uniformly distributed reference vectors is generated. (2) Building and updating the RBF Model In the first iteration, the individuals in D s are used to construct the RBF model for the evaluation of offspring individuals. In each subsequent iteration, new individuals that exhibit a balance between diversity and convergence are selected and added to the D s for retraining models. (3) Candidate offspring generation In each generation, N offspring solutions are generated using the simulated binary crossover (SBX) 49 and the polynomial mutation 50 . The selection of parents is based on a tournament strategy that considers dominant relationships and crowding distances, ensuring a higher chance of selecting optimal individuals. (4) Reference vector based two-stage selection strategy At this stage, we apply two sub-selection strategies, the dominance-based and the APD-based selection strategy. For the first stage, an improved dominance-based NSGAIII based on predefined generations is applied to search the decision and objective spaces exhaustively. The second stage involves selecting individuals based on either their APD value or crowding distance. (5) Deleting redundant individuals in the archive D s After the selected solutions are evaluated, they are added to D s and D . To prevent an increase in model retraining time due to an excessive number of individuals, the total number of individuals in D s is limited. To control the number, we introduce the extreme point. Whenever the number of individuals in D s exceeds the limit, all individuals are re-selected by the uncertainty calculated by the Euclidean distance from the extreme point. Reference vector based two-stage selection strategy As shown in Algorithm 1, individuals need to be selected from population P and its offspring for re-evaluation after offspring generation. In the algorithm, a reference vector based two-stage selection strategy is adopted. The following is a detailed introduction to the two-stage algorithm. Dominance-based selection strategy For high-dimensional EMOPs with extensive decision space, we need to explore the decision space thoroughly and find the optimal solutions that can balance diversity and convergence. In this stage, this paper utilizes an improved NSGAIII to search the entire space. As described in 9 , NSGAIII demonstrates excellent convergence and diversity maintenance in the population iteration process, and maintain uniform distribution of solutions on the non-dominant layer to avoid the algorithm falling into the local optimum. Besides, we have made appropriate enhancements to NSGAIII to help the selected individuals distribute more evenly. As explained in “ Preliminary ”, NSGAIII adopts a niche operation to select individuals, but when multiple individuals are associated with the same reference vector, the results become random. Based on this, we propose a new method that takes the angles between individuals and the reference vector as the selection criterion. Smaller angles indicate the proximity of individuals to the reference vector in space, resulting in a more uniformly distributed solution set. For instance, consider the two situations depicted in Fig. 2 . Figure 2 Different cases while selecting individuals. ( a ) Shows that the angle between the individual and the reference vector is small. ( b ) Shows that the angle between the individual and the reference vector is uneven. Full size image In Fig. 2 a, when the angle between an individual and its corresponding reference vector is small, a uniform individual distribution can be obtained by selecting any individual. However, when some individuals are distant from the reference vector, random selection may make the selected individuals gradually concentrate. As shown in Fig. 2 b, if s 2 and s 3 are selected, the gap between the selected individuals is minimal, and the diversity of the population cannot be improved. If individuals are selected according to the angle, such as s 1 and s 4 , a relatively more balanced distribution among individuals can be achieved. Therefore, selecting individuals according to the angle is more conducive to maintain population distribution. Although the improved NSGAIII has better performance, it cannot fully explore the whole space in the limited FEs. Therefore, prefixed generation is incorporated into the algorithm, allowing the evolutionary algorithm to search enough on the fitness landscape until neither convergence nor diversity can be further enhanced. In the dominance-based selection strategy proposed in this paper, the number of prefixed generations is determined by sensitivity analysis of parameters. The pseudocode of the algorithm is shown in Algorithm 2. The population P and Off evaluated by the surrogate model are merged into a new population P t of size 2 N . In this step, we need to select N individuals as the parent for the next iteration. First, individuals are adaptively normalized and assigned (lines 2–5). Subsequently, individuals are selected from the subspace associated with each reference vector to proceed to the next iteration (lines 7–9). The selection operation is no longer random, but the angles between the individuals and the reference vector. The individuals with smaller angles are preferentially selected. APD-based selection strategy After the first stage of selection based on the approximation of the surrogate model, we need to further screen the individuals. The selected individuals are evaluated using the original fitness function and used to enhance the accuracy of the surrogate model, which is important for optimizing the overall performance of the algorithm. At this stage, we utilize two criteria of APD and crowding distance to select individuals. Through massive simulation experiments in RVEA, APD can well adapt to the changes in the number of objectives and dimensions, thereby ensuring an optimal balance between convergence and diversity. However, it is hard to guarantee that all reference vectors have associated individuals in the optimization process. To tackle this problem, we take the crowding distance as another selection criterion. The specific application of the two criteria is based on the number of empty reference vectors V e . When V e surpasses a certain threshold ɛ , it indicates a concentrated distribution of individuals. Continuing to select individuals from these densely distributed areas would result in the population gradually converging towards a small region 23 . In this case, we employ the crowding distance to select individuals. Crowding distance is an indicator describing the degree of crowding between an individual and its neighboring points. A larger crowding distance signifies a more dispersed distribution of individuals within the population. Selecting individuals with larger crowding distances can help us search for regions with higher uncertainty and better maintain the diversity of the population. As demonstrated in Algorithm 3, the crowding distance (line 1) is first calculated. The objective function is then translated to guarantee that the initial point of the reference vector is always the origin and that the objective values for all translations are in the positive quadrant (line 2). Next, individuals are assigned and APD values are calculated according to the APD calculation method described in “ Preliminary ” (lines 3–4). Finally, the number of empty reference points is counted. If V e doesn’t exceed the threshold ɛ , the individual with the smaller APD value is selected, otherwise, the individual with the larger crowding distance is selected (lines 7–11). Archive updating strategy The solutions selected in the reference vector based two-stage selection strategy will be evaluated by the actual fitness function and used for the model update. However, the growing number of samples during iterations introduces another challenge known as archive management. It is widely acknowledged that the cost of training the surrogate model is positively correlated with the number of samples. Though we have chosen the RBF model which is relatively unaffected by the number of samples, additional samples may still cause unnecessary computation costs and accuracy reduction. To avoid this problem, we implement an archive updating strategy to eliminate inferior solutions from the archive. As mentioned above, we always keep two archives ( D and D s ) in the process of optimization. The size of D s for updating the surrogate model is limited. If the total number of newly added individuals in D s surpasses N , then redundant individuals need to be deleted. In the archive updating strategy, the retained individuals need to satisfy two requirements: (1) fulfill convergence and diversity; (2) fulfill the accuracy of the RBF model. To achieve this, we employ the dominant relationship and the Euclidean distance between individuals and the extreme point as the criteria. Individuals with better fitness values are selected according to the dominance relation, which can accelerate convergence to PF, and the Euclidean distance was introduced as a measure of uncertainty. $$ \begin{array}{*{20}c} {z_{i}^{extreme} = \left( {f_{1} \left( x \right), \ldots ,f_{i} \left( x \right), \ldots ,f_{k} \left( x \right)} \right),} \\ {x = \arg \min (f_{i} ),} \\ {f_{i} \in PF,1 \le i \le k} \\ \end{array} $$ (6) Extreme points consist of minimum values for all objectives. There are k extreme points for a MOP with k objectives. The definition of the i th extreme point is given as shown in Eq. ( 6 ). The individuals which are distant from these extreme points exhibit higher uncertainty to improve the diversity and the accuracy of the models. Consequently, we choose individuals with the maximum Euclidean distance from the extreme point. Next, we will introduce the specific usage of the two criteria. First, all the individuals are non-dominant. Individuals before the last layer are added to the next generation (line 3). For the individuals in the last layer, calculate the Euclidean distance between the individuals and the extreme points (lines 4–6). A larger distance indicates a higher likelihood of an individual being distant from the Pareto Front (PF), thereby avoiding the trap of local optima during the optimization process. Numerical experiments In this section, we examine the performance of the algorithm by comparing TSDEA with five state-of-the-art algorithms, namely AB-MOEA, EDN-ARMOEA, CSEA, K-RVEA, and CPS-MOEA. This experiment is performed based on objective number M = {2, 3} and decision variables D = {20, 50, 100}. The Wilcoxon rank sum test is utilized to compare the results obtained at a significance level of 0.05 for TSDEA and the other compared algorithms in 30 independent runs. The symbols "+" and "−" indicate that the performance of this algorithm is significantly better or significantly lower than that of the comparison algorithm, while "≈" indicates that there is no statistically significant difference between the comparison algorithms. For comparisons, the inverted generational distance (IGD) 51 and the modified IGD (IGD+ 52 ) metrics are adopted for evaluating the performance of the compared algorithms. Both IGD and IGD+ are comprehensive measures of diversity and convergence. More details about both indicators can be found in Supplementary Information A. Experimental settings (1) Problem settings In this experiment, we mainly employ three types of test problems, namely DTLZ (DTLZ1-7), WFG (WFG1-9), and ZDT (ZDT1-4, ZDT6) 53 . For the 3-objective problem, we choose the DTLZ and WFG problems. Since the WFG problem can only be applied to the problem of 3 objectives and above, we choose the ZDT benchmark problems in the 2-objective problem. (2) Comparison algorithms Five comparison algorithms are selected for the comparison test, among which the approximation-based SAEAs include AB-MOEA, K-RVEA, and EDN-ARMOEA, and the classification-based SAEAs include CSEA and CPS-MOEA. All algorithms used for comparison in this experiment are from the PlatEMO platform. AB-MOEA The parameter controlling the rate of change of penalty α = 2, number of generations before updating Kriging models w max = 20, Number of re-evaluated solutions at each generation u = 5; K-RVEA the penalty control parameter α = 2, the frequency of reference vector adaptation fr = 0.1, u = 5, δ = 0.05N, and w max = 20 for parameters to manage Kriging models; EDN-ARMOEA a diversity threshold parameter δ = 0.08, the maximum number of generations for AR-MOEA iteration = 20, the number of FEs at each generation k = 5; for ANN parameters, J = K = 40, wd = 10 –5 ; CSEA the number of hidden neurons of FNN H = 10, the number of reference solutions K = 6, and the number of solutions evaluated by surrogate model gmax = 3000; CPS-MOEA the number of generated offspring for each solution M = 3; (3) Experiment parameter The initial population size and data size N = 100, The maximum number of expensive function evaluations FEs = 500. The number of independent runs Run = 30. The number of generations before updating the Kriging models p max = 20. The parameter determining which criteria ɛ = 0.1. The parameter of the RBF model: The type of basis function is multiquadric. The range of input variables is [− 1, 1]. Comparison results and analysis To assess the efficiency of the proposed algorithm in handling high-dimensional EMOPs, TSDEA is compared with AB-MOEA, EDN-ARMOEA, CSEA, K-RVEA, and CPS-MOEA with varying numbers of dimensions and objectives. In addition to the DTLZ benchmarks, we set ZDT for the 2 objectives problem and WFG for the 3 objectives problem separately. To adequately present the dominance and quality of the obtained solutions from all compared SAEAs, we take IGD and IGD+ as the performance indicator in the following experiments. To further illustrate the advantage of the proposed algorithm, the non-dominant solution set obtained by the six algorithms on DTLZ2, DTLZ5, and ZDT1 are visualized. The results clearly demonstrate the outstanding performance of our algorithm. We compare the proposed algorithm with other algorithms in terms of both 2 and 3 objectives. The statistical results of IGD+ values are shown in Tables 1 and 2 , and IGD results are in Supplementary Tables 1 and 2 . As indicated in the tables, TSDEA outperformed the other algorithms in 20 (in Table 1 ) and 29 (in Table 2 ) test problems respectively, accounting for more than half of all test problems. These results show the competitiveness of TSDEA over its compared algorithms. However, the IGD+ values of TSDEA for DTLZ1, DTLA3, and DTLZ6 with different decision variables are not the best, which is similar to the 3-objective problems. This observation can be attributed to the fact that DTLZ1 and DTLZ3 have multi-modal fitness landscapes with multiple locally optimal solutions, while DTLZ6 has a large number of separated Pareto optimal regions in the decision space. In conclusion, the proposed algorithm shows the best overall performance. Table 1 Statistical results for IGD+ values obtained by AB-MOEA, EDN-ARMOEA, CSEA, K-RVEA, CPS-MOEA, and TSDEA for 2 objectives with the same number of real FEs. Full size table Table 2 Statistical results for IGD + values obtained by AB-MOEA, EDN-ARMOEA, CSEA, K-RVEA, CPS-MOEA, and TSDEA for 3 objectives with the same number of real FEs. Full size table To further compare the advantages of TSDEA, we visualize the non-dominant solution sets acquired by the six algorithms on 3-objective DTLZ2 and DTLZ5 in Figs. 3 and 4 . Additionally, Fig. 5 illustrates the distribution of non-dominant solutions of the six algorithms for the 2-objective ZDT1 problem. Upon reviewing Figs. 3 and 4 , non-dominant solutions obtained from K-RVEA and AB-MOEA are much closer to the true PF and exhibit a more balanced distribution the other three comparison algorithms, but they are weaker than TSDEA. Figure 5 reveals that none of the non-dominant solution sets can cover the true PF perfectly except for TSDEA. This reaffirms that TSDEA algorithm can obtain a set of non-dominant solutions with the best convergence and the most uniform distribution in the above problems. Therefore, the performance of TSDEA is better than the other five comparison algorithms. Figure 3 The non-dominant solutions obtained by each algorithm on 3-objective DTLZ2 in the run associated with the median IGD value. Full size image Figure 4 The non-dominant solutions obtained by each algorithm on 3-objective DTLZ5 in the run associated with the median IGD value. Full size image Figure 5 The non-dominant solutions obtained by each algorithm on 2-objective ZDT1 in the run associated with the median IGD value. Full size image Runtime comparison For the currently widely used surrogate model, the training time is closely related to the number of objectives and decision variables. Moreover, the training sample will also influences the computing time of the surrogate model. For the TSDEA proposed in this paper, we utilize the RBF model which is less insensitive to dimension and sample sizes. To assess the computational efficiency of TSDEA, we compare the running time of six algorithms AB-MOEA, CPS-MOEA, CSEA, EDN-ARMOEA, K-RVEA, and TSDEA for DTLZ2 problem with 3 objectives, and the results are shown in Fig. 6 . Figure 6 Runtime over the number of evaluations in AB-MOEA, CPS-MOEA, CSEA, EDN-ARMOEA, K-RVEA, and TSDEA. Full size image Observing Fig. 6 , it becomes apparent that the running time of the six algorithms increases linearly with the increase of the number of evaluations, where the runtime of EDN-ARMOEA increases more rapidly and AB-MOEA, CSEA, and K-RVEA have a slower growth rate. Conversely, CPS-MOEA and TSDEA show the slowest growth. From the details, the speed of CPS-MOEA is lower than that of TSDEA. The main reason is that CPS-MOEA uses KNN to predict the candidate solutions, and the computational complexity of KNN is much lower than that of the RBF method. In a word, the computational efficiency of TSDEA exceeds that of most algorithms. Sensitivity analysis of parameters TSDEA mainly contains two parameters, namely ɛ and p max . In Algorithm 3, ɛ is utilized to determine whether to update the surrogate model with APD or crowding distance. p max specifies how often the surrogate should be updated, that is, when the surrogate should be updated. We analyze the sensitivity of parameters in TSDEA through the experiment of DTLZ5. When p max = 20, We set ɛ to 0.1,0.3,0.5,0.7,0.9 for comparison. Figure 7 a summarizes the average IGD values with different values of ɛ . As you can see from the figure, the IGD value is minimal when ɛ = 0.1, so set ɛ to 0.1 as a general setting for all test instances. Figure 7 Average IGD profile plots over the different parameter values in TSDEA on the 3-objective DTLZ5 based on 30 independent runs. a Is the performance profile plots of parameter ɛ. b Is the performance profile plots of parameter p max . Full size image Next, we will test the effect of p max by setting different parameters. In this experiment, we set p max to 20, 40, 60, 80, and 100. The experimental results are shown in Fig. 7 b. When p max is 20, the average IGD value obtained is the smallest, so 20 is taken as the final value of p max . Effects of the individual selection criteria In the APD based selection strategy, we employ two individual selection criteria. To assess the efficiency of these criteria, we compare TSDEA with two variants: TSDEA (APD) and TSDEA (CD). TSDEA (APD) solely utilizes the APD criterion for individual selection, while TSDEA (CD) solely employs crowding distance for individual selection. The experiment is conducted on WFG problems and the statistical results are shown in Supplementary Table 3 . The results demonstrate that TSDEA outperformed the two variants on all benchmark problems. In WFG3 and WFG6, TSDEA is significantly better than the two variants and TSDEA also achieved comparable or superior results in other test questions, which indicates that the combination of the two selection criteria is superior to any single criterion. Therefore, the validity of the two individual selection criteria cannot be ignored. Effects of the two-stage selection strategies To further investigate the effectiveness of the two selection strategies proposed in this paper, TSDEA is compared with the two variants, as shown below. TSDEA(D): only use the dominance-based selection strategy TSDEA(A): only use APD based selection strategy The experiment is conducted on DTLZ1-7 with 3 objectives and 20 dimensions, and the statistical results can be found in Supplementary Table 1 . As can be seen from the table, except for DTLZ4, TSDEA obtained the best results on the other six test problems. On the problem of DTLZ4, TSDEA (A) performs slightly better than TSDEA. The reason may be that the point density on the real PF of DTLZ4 has a large deviation. To obtain better results, the algorithm must maintain the proper distribution of candidate solutions. However, the dominance-based selection strategy primarily prioritizes solution convergence, thus not delivering a noticeable improvement for DTLZ4. Nevertheless, when considering overall performance, the combination of both selection strategies outperforms any single-strategy algorithm. Conclusions In this paper, a two-stage dominance-based surrogate-assisted evolution algorithm for solving high-dimensional expensive multi-objective optimization (TSDEA) is proposed. The RBF model is applied in the algorithm to approximate the objective function to reduce the actual evaluation cost. To enhance diversity and convergence, we employ a reference vector based two-stage search method in the algorithm. The dominance-based selection strategy and the APD-based selection strategy are used to select individuals with better diversity and convergence, respectively. These individuals are re-evaluated through the actual fitness function and utilized to update the surrogate model. When updating the surrogate model, considering the cost of model retraining, we keep the number of individuals for updating limited. We evaluate the proposed algorithm on benchmarks with 20, 50, and 100 decision variables. Comprehensive results show that TSDEA outperforms five state-of-the-art algorithms (AB-MOEA, EDN-ARMOEA, CSEA, K-RVEA, and CPS-MOEA) with the same parameter settings and fixed evaluations. Although the proposed algorithm is competitive on most test problems, this work is preliminary and we will further improve the predictive accuracy of the surrogate model with more than 3 objectives and 100 dimensions in future work. Moreover, the application of the proposed algorithm to some real-world high-dimensional EMOPs will be considered in our future work.