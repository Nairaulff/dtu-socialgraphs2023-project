introduction last decade various deep learning model developed inferring bounding box object natural image achieved remarkable performance object localization however perspective data efficiency work used fully-labeled dataset respect localization regarded major limitation construction dataset time-consuming labor-intensive leading limited applicability practice meanwhile weakly supervised object localization wsol method employ class label without using target bounding box label wsol therefore attracted considerable attention potential training data-efficient manner main idea wsol detect class-discriminative region via object recognition task utilize region localization identified object class activation map cam one representative method wsol estimate class-specific discriminative region based inferred class score however various study addressed cam-based method capable capturing overall object region finer way focus class-discriminative region disregarding non-discriminative region reason many output bounding box either over-sized under-sized respect target object effort tackle challenge via diverse network architecture learning strategy among diverse wsol strategy corruption approach commonly used corruption method intentionally corrupt e.g. erase part input image feature map corruption method two different strategy exploited random corruption network-guided corruption random corruption approach remove small patch within image random corrupted image learn richer feature representation approach help trained network discover diverse discriminative representation thus detecting object-related region network-guided corruption approach adaptively corrupts feature map dropping discriminative region based integrated activation map corrupted feature map include non-discriminative region enables localization modifying original feature map making activation map additional layer network figure overview moana method generates fine-grained attended map wsol incorporating triple-view attention channel height width classifier full attention map generated outer sum triple-view attention comparison cam moana respect activation map left localization right localization red green box denote ground-truth predicted bounding box respectively green-masked region indicates activation map applying threshold map generated using python 3.6.0 available http full size image method improve performance limitation considered first random-corruption approach potentially disrupts network learning due unexpected information loss example object-characteristic part removed input image network enforced discover part remaining region exists discriminative region anymore network would trained incorrectly second network-guided corruption approach introduces additional hyperparameter e.g. corrupting threshold determine discriminative region also network-guided corruption method use specially designed module generate attention map discriminatory region hidden capture integral extent object however mainly exploit coarse information channel spatial attention applies attention value unit feature map paper propose novel module axis-based nexus attention moana accurately localizes object-related region image specifically propose new mechanism generate fine-level axis-based attention map utilizes series information distributed channel height width attention mechanism towards calibrating feature fine-level axis-based attention map size input feature map thus attention assigned unit across feature map channel compared existing method need mask patch image method require additional hyperparameter corrupting threshold select discriminative region reason proposed method regarded relatively simple algorithm requires one layer unlike wsol study reported performance single object localization applied method weakly supervised semantic segmentation task since requires generating pseudo mask multiple class multiple object process allowed evaluate effective method multi-object segmentation based result proposed method used single-object work also multi-object work demonstrating generalizability method main contribution work three-fold propose novel module axis-based nexus attention moana allows utilize feature representation various view tensor thus localizing object accurately proposed calibration feature map fine-grained attention map adaptively concentrate activated region along class-discriminative region accordingly likely focus informative region entire object image moana achieved best object localization performance metric top-1 loc err. top-5 loc err. gt-known loc err maxboxaccv2 two datasets i.e. cub-200-2011 ilsvrc additionally segmentation mask generated employing moana method best segmentation performance pascal voc dataset related work weakly supervised object localization existing wsol research address corruption method categorized two approach depending strategy corrupting region random corruption network-guided corruption method random corruption strategy singh lee devised hide-and-seek approach randomly drop patch input image encourage network find relevant region rather focusing discriminative part object yun introduced cutmix randomly erased e.g. cutting patch filled patch another class corresponding label also mixed although method considered efficient data augmentation method since require parameter random corruption negatively affect localization performance due brute-force elimination input image network-guided corruption method discriminative region original image feature map dropped corrupting threshold zhang proposed adversarial complementary learning acol find complementary region adversarial learning two parallel-classifiers one erase discriminative region learn discriminative region except erased region choe introduced attention-based dropout layer adl generates drop mask importance map utilizing self-attention mechanism randomly selects one thresholding feature map mai proposed erasing integrated learning eil train non-discriminative corrupting e.g. erasing feature original feature shared cnn layer however require corrupting threshold parameter masking proposed moana discovers region class-discriminative region non-discriminative object-related region using novel axis-based attention module without need erasing treshold several wsol approach spg generated self-produced guidance spg mask use pixel-level supervision attention map danet employed divergent activation learning complementary discriminative visual pattern nl-ccam combined low-probability high-probability class activation map dgl exploited two kind gradient target class classification loss rcam alleviated fundamental problem e.g. global average pooling instability thresholding reference existing cam method several technique ^2\text leveraged pixel-level similarity high activation value two image category mcir utilized two self-attention module attention-based fusion loss get better feature representation gao proposed token semantic coupled attention map ts-cam employ self-attention mechanism visual transformer mitigate long-range dependency problem cnns avoid partial activation generating long-range dependency attention map vitol employed patch-based attention dropout layer p-adl architecture utilized visual transformer self-attention expanding localization map best knowledge above-mentioned wsol method focused expanding activated region excessive activated region often generated coarsely localized moana elaborately naturally expand activation domain leveraging various type discriminative information based different view feature map weakly supervised semantic segmentation like wsol aim predict exact pixel-level object mask using weak annotation process requires expensive labeling conventional method trained classification network image-level class label estimate object localization map employed pseudo mask semantic segmentation method generated pseudo mask using cam however cam based intermediate feature down-sampled classifier issue poor object localization incorrect boundary alleviate problem focused expanding incorrect object region i.e. seed area attempted generate better seed area regarding introduced seed refinement method modify initial seed obtained cam kolesnikov refined cam exploiting seed expand constrain sec principle ahn developed inter-pixel relation network irnet generates transition map boundary activation map deep seeded region growing dsrg network introduced huang found small subtle discriminative region object interest using image label produced pixel-level label hand jointly conducted pseudo mask generation segmentation task generate better seed wang proposed self-supervised equivariant attention mechanism seam narrow gap fully weakly supervised semantic segmentation zhang designed context adjustment approach conta construct structural casual model remove confounding bias image-level classification generate better pseudo-masks ground truth also concentrated generating better seed area however moana computes fine-level axis-based attention therefore simple efficient attention based deep neural network moana based attention mechanism therefore reviewed existing attention method even devised wsol attention mechanism widely used enhance representational power feature among various attention mechanism focused context fusion based mechanism strengthens feature map meaningful aggregating information every pixel instance proposed squeeze-and-excitation network senet simple efficient gating mechanism consider channel-wise relationship among feature map basic architecture likewise woo devised convolutional block attention module cbam sequentially combine two separate attention map channel spatial dimension unlike senet cbam considered spatial attention involves focus moreover alleviate limitation senet utilizes fully-connected layer wang introduced efficient channel attention network eca-net deploys convolutional layer obtain cross-channel attention maintaining lower model complexity however since method emphasized meaningful feature multiplying attention value different information corresponding spatial i.e. height width channel dimension might ignored unsuitable wsol fine location information demanded meanwhile moana generates fine-grained attention map different attention value across region inferring connection channel height width axis-based attention method section present detail proposed module axis-based nexus attention moana moana applied output feature map fed classifier fig induce model learn entire region object hereafter regard output feature map feature tensor without loss generality moana generates self-attention tensor derived three type view-oriented attention map projecting input feature tensor channel height width dimension respectively moana-generated attention tensor present fine-grained characteristic sense assigning different attention value element tensor interaction complementary information axis-based attention matrix moana lead attention tensor focus discriminative region also discriminative region object regard final output feature tensor enriched representation resulting better object localization output overall architecture proposed moana illustrated fig detailed description given figure illustration module axis-based nexus attention moana input feature processed using triple-view attention transformed three kind pooled feature fed expansion function generated fine-grained attention map combined input feature referred combination obtain fed classifier full size image axis-based attention let c\times h\times input feature tensor denote dimension channel height width respectively condense global distribution input feature tensor triple view applied average pooling dimension tensor i.e. channel height width follows aligned avgpool _\text aligned aligned avgpool _\text aligned aligned avgpool _\text aligned avgpool average pooling operator respect dimension three pooled feature c\times 1\times c\times h\times c\times 1\times regarded summary extracted feature different viewpoint surely three view carry different information distributed input feature tensor capture feature representation highly activated reflect discriminative feature distributed vertically horizontally across channel independently subsequently order utilize local interaction among unit pooled feature applied convolution kernel size zero-padding without bias thus keeping dimensionality batch normalization non-linear activation function applied follows aligned _\text _\text aligned aligned _\text _\text aligned aligned _\text _\text aligned sigmoid function indicates convolutional layer respective pooled feature _\text c\times 1\times _\text c\times h\times _\text c\times 1\times corresponds resulting triple-view attention attention expansion expanded triple-view attention _\text _\text _\text generate attention map c\times h\times size input feature map mean outer sum function follows aligned _\text _\text _\text aligned aligned z_\text i,1,1 +z_\text j,1 +z_\text i,1 aligned aligned aligned z_\text i,1,1 z_\text j,1 z_\text i,1 denotes element tensor _\text _\text _\text represent index channel height width dimension value attention map likely different resulting fine-grained attention map fine-grained attention map representation method different previous attention-based method learn coarse attention map value across element within channel provide illustration tensor-form element example supplementary facilitate better understanding method figure illustration conventional context fusion attention approach moana moana calibrates feature employing fine-grained attention map generated axis-based complementary information full size image feature calibration applied attention tensor estimated input feature tensor considered computational approach follows aligned =\textbf aligned denote hadamard product element-wise summation respectively proposed approach employ fine-level attention map enabling detailed feature calibration element-level unit approach advantageous perspective feature representation learning axis-based attended feature sum discriminative feature mined various viewpoint rich feature representation additionally element-wise summation add input feature already contains information discriminative feature help activate region scaling term discriminative thus attention module described section attention expansion trained focus discriminative feature also relatively degraded feature consequently moana increase activation object-related region relatively lower activation non-object-related region interpretable phenomenon clearly observed experimental result fig distinction conventional context fusion attention figure show distinction process method context fusion attention method existing work primarily considers channel-wise spatial-wise attention ignoring spatial channel characteristic distributed different map feature tensor example cbam one representative context fusion attention method used calculate two attention map spatial attention map shape 1\times h\times channel attention map shape c\times 1\times channel height width attention value multiplied ignoring different information spatial channel dimension therefore still remains limitation context fusion attention mechanism meanwhile moana method generates three attention map c\times 1\times c\times h\times c\times 1\times generates triple-view attention map using outer sum triple-view attention map different provides complementary information found one axis considered allowing attention paid fine-grained feature found existing spatial channel therefore moana method calibrate feature complementary relation inherent input feature tensor thereby achieving best performance alleviating limitation context fusion attention mechanism experiment experiment setup datasets validated moana using three public datasets cub-200-2011 ilsvrc wsol pascal voc cub-200-2011 includes total image bird category divided image training image evaluation ilsvrc consists 1.2 million image category training image validation pascal voc contains total class composed training image validation image test image experiment used training image generated validation image competing method compared moana existing state-of-the-art wsol method cam acol spg cutmix adl nl-ccam rcam dgl eil ^2\text order observe effectiveness method compared five method sec dsrg irnet conta seam figure qualitative comparison proposed method moana cam wsol task cub-200-2011 ilsvrc datasets red box bounding box green box predicted bounding box green area segmented region extract bounding box threshold applied moana generate exact localization map tightly bounding entire region object image map generated using python 3.6.0 available http full size image evaluation metric quantitative evaluation used top-1 loc err top-5 loc err gt-known loc err metric top-n loc err fraction image iou predicted bounding box ground truth bounding box target class doe exist class highest class prediction probability gt-known loc err fraction image iou predicted bounding box ground truth bounding box regardless classification result additionally used recently proposed metric maxboxaccv2 iou threshold 0.3,0.5,0.7\ optimal activation map threshold threshold activation map set 0.01 interval final result maxboxaccv2 measured various localization performance threshold activation map various level semantic segmentation quantitative evaluation performed using miou score table quantitative result compared wsol method using top-1 top-5 gt-known localization error cub-200-2011 ilsvrc datasets lower value indicator better performance.the best performance highlighted bold second-best performance underlined full size table table quantitative result comparing wsol method maxboxaccv2 using resnet-50 backbone higher value indicator better performance full size table implementation detail weakly supervised object localization used resnet-50 pre-trained ilsvrc backbone network order obtain localization map used 1\times convolutional layer similar acol kernel size axis-based attention used according input image training resized 256\times 256\ cropped 224\times 224\ patch randomly resized image flipped horizontally probability 0.5 test image resized 224\times 224\ ilsvrc dataset trained moana using stochastic gradient descent sgd optimizer momentum 0.9 weight decay 0.0005 mini-batch size epoch learning rate decreased initial value 0.002 feature extractor 0.02 remaining module multiplying 0.1 every epoch cub-200-2011 dataset set mini-batch size epoch initial learning rate 0.01 learning rate decay rule multiplying 0.1 every epoch weakly supervised semantic segmentation used irnet base model generate pseudo-mask trained feeding moana classification network irnet used pseudo-masks generated using irnet train segmentation network deeplab input image transformed process irnet horizontal flipping random cropping color jittering classification model trained input image cropped 512\times 512\ 16-sized batch used weight decay coefficient 0.0001 sgd optimizer momentum 0.9 activation map threshold 0.16 total iteration trained starting initial learning rate 0.1 using polynomial decay lr_ init lr_ init 1-itr/\max itr 0.9 every iteration setting deeplab except segmentation model setting used pseudo-mask label implemented method pytorch trained titan gpu code available http experimental result weakly supervised object localization visualize predicted localization bounding box activation map cam moana method fig also indicate iou value predicted bounding box box upper left corner observed moana elaborately localized entire part object cub-200-2011 ilsvrc datasets cam focused partial object covered outside exact object region moana tightly bounded entire region object image thereby achieving best localization performance table summarize localization performance competing method table observed effectiveness reliability moana localization task consistently achieving best second-best performance various evaluation localization metric cub-200-2011 ilsvrc table moana achieved best maxboxaccv2 71.4 cub-200-2011 65.8 ilsvrc evaluated optimal activation map threshold figure qualitative comparison proposed method moana irnet task pascal voc dataset multi-label region segmented similar irnet full size image table quantitative result method using miou pascal voc dataset full size table table wsol result moana combination approach cub-200-2011 ilsvrc datasets full size table weakly supervised semantic segmentation visualize semantic segmentation result pascal voc shown fig specifically fig illustrates pseudo-mask generated classification model fig show segmentation mask obtained segmentation model trained pseudo-mask segmentation label fig analysis outcome produced irnet illustrates pseudo-masks confined distinct section object challenge reminiscent issue inherent cam wsol however distinct transformation observed proposed method applied mask scope extends covering entirety object case point observed 6th row fig traditional approach centered prominent feature facial region person contrast technique expands mask cover entire bodily structure fig influence enhanced pseudo-masks accuracy segmentation mask demonstrated segmentation model learned irnet-based pseudo mask shown fig identify problem segmenting certain part object segmenting wrong class segmentation model learned pseudo mask generated applying method expands object area accurately classified particularly evident 5th row fig specific section cow initially misclassified correctly identified area confined however integration method corrects misclassifications also augments segmented mask area align precisely ground truth word compared baseline method moana effectively identifies corrects missed segment region resulting representation closely aligned actual ground truth table summarizes result moana competing method fully weakly supervised setting pascal voc employed moana method module irnet although performance exceed advanced method notable enhancement miou observed result underscore potential applicability method context involving multi-label multi-object task detailed miou result class show supplementary analysis ablation study effect feature combination approach order investigate combination feature map effect compared result without combination approach term localization segmentation task based understanding combination operation note lead function learn information input feature tensor may missed emphasized ablation study conducted dividing investigation three case original feature calibration feature scaling attention value calibration feature combination scaling feature input feature table demonstrated effectiveness combination approach observing proposed method performed best three case figure left visualization activation map bounding box cam moana comparison right plotted triple-view attention map z_h z_w moana normalizing range indicates expansion pooled feature input feature size also plotted normalized difference show moana give attention column name left right figure input image map generated using python 3.6.0 available http full size image visualization attention map get insight working moana visualized axis-based attention map combined attention map input feature map resulting output feature map difference fig transformed expanded attention map z_h z_w matrix channel-wise average pooling visualization however attention map _c\ omitted difference value map channel-wise average pooling performed normalized matrix range fig localization result observed activation map cam focus part object region wing hand moana generates sophisticated activation map paying additional attention activated object region wing inactivated object-related region body furthermore observed body wing region calibrated region row spatial feature map column fig viewpoint attention map generation role interpreted excite activated region target task-related information inherent shown fig validated effectiveness fine-grained calibration feature wsol conclusion paper proposed novel module axis-based nexus attention moana accurately localize object image moana consists three component triple-view attention expansion attention iii calibration feature proposed method utilizes complementary information axis-based attention calibration sophisticated object-related region within feature map moana therefore doe require additional hyperparameter corrupting threshold masking discriminant region corrupting method proposed method achieved highest performance localization segmentation task term top-1 loc err. top-5 loc err. gt-known loc err. seg mask miou macboxaccv2 metric three datasets experimental result show validity three component interpreted inner working feature calibration proposed method plugged cnn architecture without modifying original network architecture sense applied moana final output feature extractor classifier applied algorithm task multi-object localization sense would forthcoming research issue generalize application various cnn task e.g. object detection