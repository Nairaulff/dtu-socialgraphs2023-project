introduction basal cell carcinoma common form skin cancer human incidence high incidence cancer combined number bcc case increasing globally although metastasis death rare bccs cause significant morbidity due aggressive destructive local growth bccs heterogeneous group tumor different growth pattern internationally bccs classified two broad category based histopathologic feature low-risk high-risk subtypes category classified subclass swedish pathologist example classify bccs according sabbatsberg model includes three risk category low-aggressive subtypes divided superficial type nodular type medium-aggressive type includes aggressive infiltrative subtypes grow well-defined manner superficially compared high-aggressive tumor high-aggressive type iii aggressive infiltrative morphea form subtypes correct assessment subtype crucial planning relevant treatment however significant inter-pathologist variability grading tumor reporting subtype moreover given time-consuming process evaluating histological slide combined increasing number sample delay diagnosis increase cost reduce diagnosis time inter-observer variation deep learning approach actively investigated deep learning enables implementation computational image analysis pathology provides potential increase classification accuracy reduce interobserver variability interestingly even unknown morphological feature associated metastatic risk disease-free survival prognosis may revealed early research work computational histology method required pixel-wise annotation i.e. delineating specific region wsi pathologist using pixel-wise annotation however time-consuming approach generalize real-world data alternative weakly supervised learning framework widely adopted method wsi classification common technique within weakly supervised learning multi-instance learning mil approach use wsi-level label i.e. label associated specific region without losing performance technique treat set instance patch wsi bag mere instance positive case patch make bag wsi positive otherwise treated negative mil requires wsi partitioned set patch often without need data curation later work increasingly added self-supervised contrastive learning paradigm extracting better feature vector paradigm pre-trained cnn model tuned using contrastive learning framework contained manner adding component mil approach proven provide better performance however mil framework fundamentally assumes patch independently identically distributed neglecting correlation among instance neglecting correlation affect overall performance classification model instead spatial correlation captured using graph neural network turn increase model performance recently transformer made great leap front introducing capability incorporate context among sequence token natural language processing task e.g gpt-3 inspired success transformer natural language processing dosovitskiy proposed vision transformer vit method image classification task take patch image input enables capturing sequence patch token considers position image context using positional embeddings consideration positional relationship contextual information show vit perform better cnn especially using feature obtained self-supervised contrastive model addition vision transformer require substantially fewer data compute resource relative many cnn-based approach relative resilience noise blur artifact semantic change out-of-distribution sample could contribute better performance medical image transformer applied image classification segmentation detection reconstruction enhancement registration task specifically histological image vision transformer successfully applied different histological image related task including detection breast cancer metastasis classification cancer subtypes lung kidney colorectal cancer given success vision transformer many medical application capability graph neural network capture correlation among patch adopt combination graph neural network transformer detect classify bccs result accuracy ensemble comprised graph-transformer model test set 93.5 86.4 72.0 two-class three-class five-class classification task respectively moreover sensitivity detecting healthy skin tumor reached 91.9 respectively performance ensemble model test set summarized table associated confusion matrix shown fig figure show average roc curve separate cross-validation model test set heatmaps used visualize region wsi highly associated label figure show tumor region different bcc subtypes correctly identified graph-transformer model table model performance bcc grade test set based ensemble model comprising cross-validation model split full size table figure confusion matrix ensemble model three different classification task test set binary classification tumor tumor three class classification tumor two grade tumor five class classification tumor four grade tumor full size image figure mean roc curve five-fold cross-validation model based test set different classification task binary classification three class classification five class classification full size image figure visualization class activation map row corresponding image row class activation map built binary classification task tumor tumor area tumor emphasized representative example shown four bcc grade superficial low aggressive nodular low aggressive medium aggressive high aggressive row represent close image area marked black box slide cropped focus tissue running model full size image discussion paper used graph-transformer detection classification wsis extraction bcc developed deep-learning method showed high accuracy tumor detection grading use automated image analysis could increase workflow efficiency given high sensitivity tumor detection model could assist pathologist identifying slide containing tumor indicating tumor region slide possibly reduce time needed diagnostic process daily practice use high-accuracy automated tumor grading could save time potentially reduce inter- intra-pathologists variability study among first apply two four grading bcc wsi using deep learning approach method reached high auc value 0.964–0.965 0.932–0.975 0.843–0.976 two three two grade five class grade classification respectively previously campanella used significantly larger dataset totally 44,732 wsis including 9,962 slide wide range neoplastic non-neoplastic skin lesion 1,659 bccs achieved high accuracy tumor detection suggested slide could safely removed workload pathologist interestingly gao compared wsis smartphone-captured microscopic ocular image bccs tumor detection high sensitivity specificity approach however tumor grading applied study best knowledge open-source dataset grading bcc make difficult compare result work baseline one advantage study data available open data set enable progress area another study regarding bcc detection attention pattern compared attention pattern pathologist observed neural network distribute attention larger tissue area integrating connective tissue decision-making study used weakly supervised learning label assigned slide level approach instead focusing small pixelwise annotated area give algorithm freedom evaluate larger area including tumoral stroma furthermore slide-wise annotation significantly time-consuming pixel-wise annotation limitation study somewhat limited size dataset number class increase performance reduced significantly could attributed reduced number wsi per class training set example difficult model differentiate bcc subtype subtype class classification task relatively easier differentiate low high aggressive class class classification task fig availability data performance would likely increase even though work make systematic inter-observer variability analysis two pathologist involved annotation dataset different grade 5-class classification differed 6.7 wsis annotation wsis corrected consensus along third senior pathologist case real life situation using tool one proposed work would likely reduce inter-pathologist variability study subject warranted limitation study imbalance dataset different task included several 1–18 slide per tumor slide classified individually even though aimed include many wsis tumor group difference group aggressive tumor bigger thus slide also fact within tumor several bcc subtypes presented affected number wsis group since included several slide tumor slide showed tumor thus totally included slide represented healthy skin shown table caused imbalance dataset especially task largest group healthy skin furthermore fact bcc case show tumor slide could slide needed removed due low quality scanning table distribution bccs wsis different class full size table furthermore many wsis composite subtypes sometimes present slide case typical bcc admix multiple type i.e. case one pathologic pattern proportion mixed histology case reach case mixed bcc case contain one aggressive subtypes despite characteristic mixed pattern per wsi model able detect worst bcc subtype per slide accuracy 86.4 three-class classification 72.0 five-class classification task shown table slide pen mark indicate extraction index corresponding extraction case large tissue wsi since dataset split based patient index pen mark training set different test set model affected similarity handwritten character pen mark identified tissue tiler therefore included training patch moreover wsis different color artifact slice edge inconsistency scattered small tissue spot hole despite variation among wsis model treated handwritten character background variation noise work best knowledge first approach transformer grading bcc wsi result show high accuracy tumor detection grading bccs successful deployment approach could likely increase efficiency robustness histological diagnostic process method dataset dataset retrospectively collected sahlgrenska university hospital gothenburg sweden time period 2019–2020 complete dataset contains labeled wsi bcc excision glass slide per tumor table slide scanned using scanner nanozoomer s360 hamamatsu 40x magnification slide label removed using open-source package called anonymize-slide dimension wsis ranged 71,424 207,360 size ranging 1.1 5.3 total 5.6 moreover almost sample multiple sectioning level per glass slide scanning glass slide marked letter digit indicating slide represented tumor scanned slide annotated wsi-level class no-tumor grade bcc tumor accordance swedish classification system several growth pattern tumor detected wsis classified according worst possible subtype annotation performed two pathologist separately case two main annotator differing opinion 6.7 wsis third senior pathologist brought final annotation decision made consensus three pathologist dataset set use classification task first task detecting presence tumor binary classification tumor tumor second task classified three class tumor low-risk high-risk tumor line grading system third task classing dataset class tumor grade bcc low aggressive superficial low aggressive nodular medium aggressive highly aggressive line swedish classification system two-grade classification task label converted case low aggressive high aggressive iii figure show patch bccs corresponding class three classification task indicated figure sample bcc subtypes used three classification task tumor tumor tumor two grade tumor tumor four grade tumor arranged pathologist accordance sabbatsberg model depending classification task hand sample row assigned different grade tumor full size image feature extraction overview method shown fig given wsis large conventional machine-learning model could ingest directly hence wsis first tiled patch wsis tiled patch 10x magnification overlap using openslide patch least tissue area kept others discarded number patch ranged 22–14,710 patch per wsi total 5.2 million patch generated training set stated variability among wsis including color difference artifact etc despite difference among patch image processing made tiling figure method overview adapted zheng wsi first tiled patch feature extracted via self-supervised learning extracted feature become node graph network become input graph-transformer classifier full size image patch tiled feature extracted using self-supervised learning framework simclr using contrastive learning approach data augmented sub-images used generate generic representation dataset algorithm reduced distance image increased distance different image negative pair step using resnet18 backbone patch training set except patch hold-out test set feature vector patch extracted training simclr adam optimizer weight decay batch size epoch used initial learning rate scheduled using cosine annealing graph convolutional network construction feature generated self-supervised contrastive learning used construct graph neural network using contrastive learning feature vector patch extracted since patch connected nearest neighbor patch edge corner tiling break correlation among patch correlation among patch typically captured via positional embeddings since histological patch spatially correlated space positional embeddings could better captured via graph network patch connected neighboring patch side corner hence total edge set 8-node adjacency matrix used create graph representation wsi positional embedding captured via adjacency matrix used construct graph convolutional network feature vector patch became node graph zheng showed result using fully connected graph single tissue per slide work show approach work disconnected graph representing multiple tissue per wsi worth noting almost wsis dataset multiple tissue per slide i.e. correlation among separate tissue due non-tissue region result disconnected graph shown fig worth noting distance component disconnected graph well position space effect performance model figure example wsi graph network wsi six tissue section six disconnected component graph network disconnected component randomly placed space node represents patch patch shown figure better visualization full size image vision transformer graph convolutional network built network fed vit generally transformer applies attention mechanism mimic way human extract important information specific image text ignoring information surrounding image text self-attention introduced function query key value vector mapped input feature using vector applies multiple-head self-attention extract refined feature allowing understand image whole rather focusing individual part self-attention function accompanied multilayer perceptron mlp block used determining class work used standard vit encoder architecture along graph convolutional network classification bcc subtypes moreover computational cost training vit high depending input size number patch large depending size image tissue size relative wsi resulted large number node computationally hard applied directly input transformer reduce number node extent vit digest input pooling layer added training graph-transformer extraction wsis combined training validation set additional dataset extraction wsis scanned separately comprise hold-out test set test set handled separately held simclr graph-transformer model training validation slide relating specific extraction always placed set avoid data leakage similar slide necessitated dividing dataset extraction level resulting uneven split cross-validation hence fivefold cross-validation used training output model cross-validation fold combined one ensemble model majority vote provide final prediction test set step performed two- three- five-class classification task separately supplementary table training model hyperparameters used task model configured mlp size self-attention block trained batch size epoch adam optimizer weight decay learning rate decay step training performed gpus dgx a100 training simclr model took around day training graph transformer took around min average converge given wsi test set tiling inference took around visualization visualize interpret predicted result graph-based class activation mapping used method computed class activation map class label graph representation wsi utilizing precomputed transformer graph relevance map using method heatmaps overlayed region wsi associated wsi label