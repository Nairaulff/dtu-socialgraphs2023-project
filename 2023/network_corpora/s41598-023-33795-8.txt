introduction world autism awareness month celebrated april worldwide people organisation alike entire month dedicated raising awareness sharing understanding shedding light global south african health crisis parent battling year autism spectrum disorder asd defined developmental disability affect social interaction communication learning skill spectrum reflects wide range symptom child present autism therapy intervention attempt lessen deficit problem behaviour associated asd child worldwide diagnosed asd higher rate child united state center disease control abnormality characterise social interaction pattern communication restricted stereotyped repetitive repertoire interest activity however treatment intervention service asd tricky since time-consuming treatment conducted asd symptom typically appear first year child life developing specific period many type treatment available including behavioural developmental educational social-relational pharmacological psychological one south african group quest school sowetan live proposed child diagnosed young year age norm overemphasise impact asd adult child common sign adult include finding hard understand others thinking feeling getting anxious social situation young child includes responding name avoiding eye contact repetitive movement flapping hand flicking finger rocking body sign asd older child include seeming understand others thinking feeling unusual speech repeating phrase talking others finding hard say feel asd sometimes different girl woman boy mean harder spot especially girl woman woman may learnt hide sign asd fit coping people asd girl may hide sign asd copying child behave play recently explosion asd case worldwide increasing alarming rate centre disease control world health organisation wolff piven argued every child asd certain percentage people disorder shown live independently whilst others would require life-long care support asd trait difficult trace due test diagnosis requiring significant time cost however several treatment therapy intervention help child asd improve ability reduce symptom topic asd therapy enhancement interest researcher decade effect robot-enhanced intervention child asd lot research work sphere machine learning statistical pattern recognition spc community discussing combine model model prediction furthermore much research work community shown ensemble learning classifier effective technique improving predictive accuracy due variance reduction benefit ensemble learning classifier development successful fielding significantly lagged behind bio-medical health science research activity yet prominent field central concern application need increase predictive accuracy early asd diagnosis test decision basic idea behind ensemble learning train multiple classifier learning system achieve objective combine prediction different way ensemble developed resulting output combined classify new instance popular approach creating ensemble include changing case used training technique bagging boosting stacking changing feature used training introducing randomness classifier due nature asd impact society improvement predictive therapy enhancement accuracy even fraction per cent translates significant future saving time cost even death furthermore economic effect asd individual disorder family society whole poorly understood updated light recent asd prediction detection finding enormous effect family warrant better therapeutic prediction detection method machine learning statistical pattern recognition community supporting development child asd multi-profile therapeutic work disturbed area especially understanding linguistic expression used social communication development mutual social contact functional symbolic play recent year robot learning robot-assisted asd therapy ret grown popularity key research finding ret shown effectiveness child asd particular communication common attention imitation undertaking communication behaviour recognizing understanding emotion developing sensitivity physical contact chernyak tool embraced therapist counsellor teacher parent child help asd better communicate connect others virtual reality augmented reality several research study examined suggest promising finding effectiveness virtual augmented reality-based treatment promotion support protection health well-being child adolescent asd also used help without asd understand living condition mean using variety machine learning technique one could analyze parent age socio-economic status medication predict child asd diagnosis predictive algorithm could also useful identifying factor may contribute asd example machine learning algorithm helped find association asd parent use substance caffeine certain antidepressant machine learning also used better understand classify asd trait vary nature severity person person another machine learning study stevens analyzed behavioural data found two overarching behavioural profile asd subgroup based severity different trait scholar investigated clinical application robot diagnosis treatment asd diehl others created machine-learning algorithm could help robot understand autistic child need help several study predicting asd trait individual carried asd research data science analytics community using several machine learning statistical modelling technique include screening detection identification classification prediction asd trait individual screening detection alternating functional decision tree support vector machine red flag used support vector machine used detection identification kosmicki investigated logistic model tree logistic regression detecting non-asd asd among child predict asd trait support vector machine naïve bayes classifier random forest applied prediction asdt response baseline fmri using random forest tree bagging proposed dvornek learning pipeline method achieving higher accuracy compared standard method bala investigated identification asd among toddler child adolescent adult using several machine learning algorithm k-star classification regression tree -nearest neighbour support vector machine bagging random tree svm achieved best performance prediction asd different age level deep learning neural network used heinsfeld predict asd patient using imaging brain follow-up research work classification hemodynamic fluctuation empirical comparison adaboost flexible discriminant analysis fda decision tree c5.0 boosted generalised linear model glmboost linear discriminant analysis lda mixture discriminant analysis mda penalised discriminant analysis pda support vector machine svm classification regression tree cart early stage detection asd toddler child adult good performance observed svm toddler adaboost child glmboost adult recently kanchana predicted early phase asd adult using naïve bayes logistic regression random forest random tree random forest achieving highest predictive accuracy review evident researcher used single classifier detecting predicting classifying asd general yet ensemble model stable importantly shown predict better single classifier also known reduce model bias variance study assessed ethical social implication translating embodied artificial intelligence application mental health care across field psychiatry psychology psychotherapy furthermore despite limitation single classifier include able make prediction new data seen historical information must provided advance overfitting problem i.e overfitting data looking none research study looked predicting asd therapy asdt way improve asdt predictive accuracy yet proactive corrective action taken well advance prediction asdt even accurate slight increase therapy predictive accuracy positive impact foreseeing asd toddler also improve outcome child asd thereby reducing symptom due early behavioural intervention research work proposes modelling using ensemble classifier approach help show effectiveness predicting asdt term robot-assisted intervention group robot-enhanced-therapy control group receiving intervention human standard-human-treatment condition respectively investigation aim find use artificial intelligence algorithm help identify reliable method identifying asd child likely benefit specific intervention program advance solid foundation establishing personalised intervention program recommendation system asd child ensemble learning approach used overcome precariousness prediction enhance accuracy efficiency prediction mcl system architecture resampling process also considered word research work focus predicting effectiveness asd-enhanced therapy using social robot human end first significant contribution paper investigation five single-classifier learning system identify best performing term predicting therapy enhancement autistic child using social robot type therapy one hand standard human treatment hand second contribution proposal multiple-classifier learning system ensemble learning approach predict asd therapy enhancement idea ass using multiple classifier learning system mcls approach worthwhile overcome limitation single classifier learning system scls term predictive accuracy due inability handle complex tracking situation high accuracy analyse performance mcls scls unique model must accurate individually need sufficiently diverse reason possible combination number classifier per ensemble explored i.e two classifier per ensemble five classifier finally feature selection decision tree-based approach used identify physical characteristic significant asdt treatment best knowledge study one first study investigates application artificial intelligence asdt rest paper organised follows sect single-classifier learning system give background single-classifier learning system used asdt prediction multi-classifier learning system examined intelligibility viewpoint improve effectiveness asdt predictive accuracy sect multiple classifier learning system section experiment present experimental design set-up result drawn dream dataset supporting data-driven study asd robot-enhanced therapy finally paper concluded critical research finding remark sect remark conclusion single-classifier learning system several approach single-classifier learning however five base method classifier construction considered paper i.e mixture regression tree-based net instance-based bayesian-related include artificial neural network ann decision tree -nearest neighbour -nn logistic discrimination lgd naïve bayes classifier nbc brief description five classifier use classification prediction task given logistic discrimination logistic discrimination lgd supervised learning classification algorithm used predict probability target variable example class initially developed cox later modified day kerridge lgd related logistical regression due dependent variable dichotomous word two possible value taken example either non-detection asd detecting asd lgd probability density function class modelled like supervised learning classification method rather ratio i.e partially parametric unknown instance new element classified using cut-off point score error rate lowest cut-off point 0.5 slope cumulative logistic probability function steepest 0.5\ 0.5\ 0.5\ halfway point i.e logit function transforms continuous value range necessary since probability must lgd approach generalised two class also called multinomial logit model multinomial logit model mlms derived similarly lgd model detail mlms modified versins lgd interested reader referred jolliffe hosmer lameshow referred interested reader k-nearest neighbour -nearest neighbour -nn instance-based learning approach one venerable easy-to-implement machine learning algorithm supervised sometimes unsupervised learning -nn solve classification regression prediction problem assuming similar thing exist near thus -nn hinge assumption true enough algorithm valid essentially -nn work assigning classification regression prediction nearest set previously classified predicted occurrence unknown instance memory storage entire training set classify new example distance measure hamming cosine similarity chebychev euclidean manhattan minkowski computed trained unknown instance paper cosine similarity distance measure used stored training unknown instance assigned class nearest neighbouring instance nearest neighbour first computed new example given frequent class among neighbour select value right data algorithm run several time different value reduces number error encountered maintaining algorithm ability make prediction given data seen accurately paper process supervised learning focused artificial neural network like state-of-the-art classification method neural network artificial neural network anns non-parametric i.e assumption data made case model linear regression instead computational model inspired animal nervous system represented connection layer many simple computing processor element neuron used various classification regression problem economics forensics pattern recognition ann trained supplying many numerical observation pattern trained input data pattern whose corresponding classification desired output known final sum-of-squares error sse validation data network calculated training network sse value used select optimum number hidden node resulting trained neural network new unknown instance carried sending attribute value network input node weight applied value finally value output unit activation computed weight bias optimised running network multiple time significant output unit activation determines classification new instance decision tree decision tree classifier supervised machine learning algorithm used regression classification task start single node subsequently series decision branch possible outcome giving tree-like diagram training best attribute selected using information gain measure total attribute list data root node internal node leaf terminal node classifier simple understand interpret visualise according safavian landgrebe classifier four primary objective classifying training sample correctly much possible generalising beyond training sample unseen sample could classified high accuracy quickly updating training sample become available similar incremental learning simple structure possible despite classifier strength objective highly debatable extent conflict objective also classifier concerned objective dts non-parametric valuable represent logic embodied software routine take input case example described set attribute value output boolean multi-valued decision making easy build automated predictive model paper boolean case considered classifying unknown instance easy tree constructed starting root node applying certain test condition would eventually lead leaf node class label associated class label associated leaf terminal node assigned instance naïve bayes classifier naïve bayes classifier nbc perhaps superficial widely studied supervised probabilistic machine learning method bayes theorem strong independence assumption feature procure result nbc assumes input attribute variable independent training data considered naïve assumption real-world data conditional probability attribute given class label learnt training data strength nbc lie ability handle arbitrary number independent numerical categorical attribute feature solid often controversial primary assumption due naivety attribute independent given value class classification bayes rule applied determine class unknown instance computing probability given selecting class highest posterior probability naive assumption conditional independence collection random variable important result otherwise would impossible estimate parameter without assumption relatively strong assumption often applicable however bias estimating probability may make difference practice order probability exact value determine probability nonetheless nbc shown solve many complex real-world problem effectively also requires small amount training data estimate parameter frequency table created attribute target class calculate posterior probability classifying unknown instance nbc used calculate posterior distribution prediction outcome class highest posterior probability multiple classifier learning system multiple-classifier learning system mcls defined set classifier whose individual prediction combined way classify new example produce one optimal predictive model common type mcls includes ensemble classifier function parallel classifier input combination furthermore significant number method used create combine individual classifier including ensemble method committee classifier fusion combination aggregation etc mcls built aggregation determined one design mcls architecture three type mcls architecture namely—static parallel multi-stage design three dynamic classifier selection one famous mcls architecture static parallel zhu two classifier developed independently executed parallel output generated base classifier combined determine final classification decision selected set possible class label many combination function available architecture including majority voting weighted majority voting product sum model output minimum rule maximum rule bayesian method averaging mainly used regression problem voting used classification problem two category sp-related mcls single algorithm used base learning homogenous parallel multiple algorithm used base learning heterogeneous parallel paper former category used second type mcls architecture design classifier usually overlap organised multiple group iteratively constructed stage iteration parameter estimation process depends classification property classifier previous stage design benefit processing input parallel ensures label assigned using necessary feature addition number composition stage used model proven significant impact overall performance approach used generate model applied parallel using combination rule used method example boosting strategy shown create weak classifier tend form stronger one dynamic classifier selection ensemble learning architecture developed applied different region within problem domain technique involves training mcls dataset selecting best prediction model -nn approach sometimes used determine instance closely related unknown instance predicted see sect single-classifier learning system one classifier may shown outperform others based global performance measure may necessarily dominate classifier entirely weaker competitor sometimes beat best across region kittler research shown performs better single classifier even better combining base classifier furthermore kuncheva approached problem global local accuracy perspective promising result ensemble learning classifier classified three stage generation selection integration objective first stage obtain pool model followed selection single classifier subset best classifier finally base model combined obtain prediction new unknown instance aspect multiple classifier system determining number component classifier final ensemble also known ensemble size cardinality important impact ensemble size efficiency time memory predictive performance make determination critical problem furthermore one assume diversity among component classifier another influential factor accurate ensemble however explanatory theory reveals diversity among component contributes overall ensemble accuracy therefore possible ensemble size respective diversity considered paper recently multi-classifier-based boosting introduced clustering classifier training performed jointly method applied object detection entire training set available beginning related work include multiple instance learning multiple deep learning architecture former algorithm learns bag example need contain least one positive example positive case thus training data doe aligned mellema developed system using anatomical functional feature diagnose subject autistic healthy ensemble method offer several advantage single model improved accuracy performance especially complex noisy problem also reduce risk overfitting underfitting balancing trade-off bias variance using different subset feature data furthermore provide confidence reliability measuring diversity agreement base model providing confidence interval error estimate prediction despite pro ensemble method drawback challenge computationally expensive time-consuming due need training storing multiple model combining output additionally difficult interpret explain involve multiple layer abstraction aggregation obscure logic reasoning behind prediction experiment experimental set-up main aim randomized controlled experiment evaluate effectiveness five machine learning algorithm predicting asdt robot-assisted intervention group autistic child control receiving intervention human investigate asdt predictive accuracy could improved using ensemble learning investigation conducted using dataset behavioural data robot-enhanced therapy recorded child diagnosed asd dataset cover therapy session treatment half child interacted social robot supervised therapist half used control group i.e interacting directly therapist word class attribute type intervention social robot-enhanced therapy condition i.e interaction autistic child social robot social human therapy condition i.e interaction autistic child human attribute follows ability child wait turn social interaction communication outcome engagement eye contact verbal utterance behavioural outcome stereotype behaviour maladaptive behaviour adaptive behaviour emotional outcome functional dysfunctional negative emotion positive emotion furthermore group followed applied behaviour analysis aba protocol aba scientific observation principle behaviour improve change behaviour social interest ret sht session child participated randomised manner avoid ordering effect participant group went protocol initial assessment eight intervention final assessment effect treatment assessed using autism diagnostic observation schedule ado term difference initial final assessment therapy session recorded using sensorized therapy fang session recorded three red–green–blue rgb camera two red–green–blue-depth rgbd kinect camera providing detailed information child behaviour therapy dataset comprises body motion head position orientation eye gaze variable specified data joint frame reference metadata attribute include participant age participant gender numeric target ability task therapy condition response elaboration training substitutive hormonal therapy date therapy complete list sensor primitive associated method provided table table sensor primitive extracted sensorized intervention table full size table public release dataset doe include footage child instead processed feature recorded data provided according source data informed consent obtained subject and/or legal guardian data collected experimental protocol approved university vde sweden main source data information reader contact billing addition metadata including participant age gender asd diagnosis variable skeleton comprising joint position upper body head position orientation eye gaze vector therapy condition therapy task including joint attention imitation turn-taking data time recording initial ado score included secondary data ethic committee approve study within environment furthermore method carried following relevant guideline regulation simulation five base classifier modelled using default hyper-parameters respective classifier approach utilises different form parametric estimation learning example generate various form linear model density estimation tree network classifier among top influential popular algorithm data mining practically applicable asd known example application within robotics-enhanced therapy industry first state-of-the-art classification method base classifier constructed using matrix laboratory matlab software base classifier later used assessed benchmark various mcl system evident benefit using ensemble could achieved simply copying individual model combining individual prediction reason possible combination number classifier per ensemble explored i.e two classifier per ensemble five classifier ensemble defined multiple classifier learning system mcl two classifier per ensemble multiple classifier learning system mcl three classifier per ensemble multiple classifier learning system mcl four classifier per ensemble multiple classifier learning system mcl five classifier ensemble ass performance base classifier training set—validation set—test set methodology employed first dataset split randomly training set run validation set testing set test effectiveness classifier dataset split randomly 5-folds smoothed error rate i.e smoothing normal error count using estimate posterior probability posterior probability using bayesian estimation conjugate prior used performance measure experiment rate used primarily variance reduction benefit dealing effectively tie two competing class f-measure score also used performance measure single classifier empirical comparison experiment benefit f-measure considers model ability two class attribute make robust gauge model performance feature factor ranking selection method implemented two basic step general architecture experiment subset generation subset evaluation ranking feature every dataset filter method used evaluate subset overall mutual information-based approach single classifier exhibit lowest error rate utilised task mutual information calculates reduction entropy transformation dataset technique summarised classifier implicit feature selection model-building process identifies rank feature factor significantly impact contribute asd set feature available form input algorithm output purpose technique discard irrelevant redundant feature factor given vector paper feature factor selection used evaluating mutual information gain variable context target variable robot-child human-child therapy fixed-effect model kirk used test statistical significance main effect i.e five single classifier twenty-three multiple classifier system three multiple classifier architecture five resampling procedure versus respective interaction experiment randomly replicated five time 5-fold making total experiment experimental result experimental result asdt predictive performance single classifier one hand mcls hand described behaviour multiple classifier explored different mcls architecture resampling procedure result presented three part first part compare performance robustness five single-classifier learning system predicting asdt autistic child second part investigates performance mcls i.e ensemble resampling procedure architecture determine improvement asd therapy predictive accuracy overall result mcl system averaged ensemble learning combination resampling procedure architecture experimental comparison mcl system possible ensemble combination presented finally behavioural factor ranking order contribute critical addressing asd problem identified figure plot smoothed error instance learned target domain averaged five-fold cross-validation run one method fold used evaluate method main effect i.e base single classifier system mcl system resampling procedure mcl system architecture significant level f-ratios 131.7 71.4 513.6 1132.6 respectively figure single classifier system full size image figure multiple classifier system full size image figure resampling procedure full size image figure multiple classifier system architecture full size image figure multiple classifier learning system overall result full size image figure multiple classifier learning system full size image figure multiple classifier learning system full size image figure multiple classifier learning system full size image figure multiple classifier learning system full size image fig follows best base classifier exhibiting smoothed error rate 35.7 1.7 0.643 accuracy f-measure 0.631 second-best base classifier ann followed -nn lgd smoothed error rate 36.2 2.2 0.625 accuracy f-measure 0.6035 38.5 1.6 0.618 accuracy f-measure 0.603 41.7 1.9 0.583 accuracy f-measure 0.575 finally worst performance nbc smooth error rate increase 43.3 1.4 0.567 accuracy f-measure 0.531 relevant attribute predicting asd therapy communication non-verbal eye contact social interaction single classifier fig performance single baseline model taken reference point appears performance mcl system statistically significant confidence level compared single-classifier learning system mcl system ensemble size composed three classifier achieve least smoothed error rate 21.4 1.9 ensemble two classifier exhibit second-best performance smoothed error rate 30.7 1.8 four classifier take third spot worst performance ensemble comprises five classifier smoothed error rate 36.5 2.2 difference performance four ensemble statistically significant significance level eye contact social interaction relevant feature predicting asd using multiple classifier system ensemble classifier bagging achieve lowest error rate 23.3 1.9 followed boosting 25.9 1.5 feature selection 31.4 1.7 randomization 34.7 1.5 respectively stacking ensemble classifier achieve lowest accuracy rate 37.2 2.1 accuracy point view performance difference ensemble classifier statistically significant 0.95 degree confidence fig fig appears multiple classifier system significant robust effect multi-stage design used architecture accuracy rate 73.5 1.8 followed static-parallel dynamic classifier selection accuracy rate 71.8 1.3 67.5 1.7 respectively difference performance architecture significant level result presented fig show mcls performing worse dynamic classifier selection error rate 32.5 1.7 compared single parallel multi-stage hand mcls performs slightly better multi-stage architecture design used 26.5 1.5 single parallel 28.2 2.3 thus difference performance three architecture significant significance level following similar pattern fig result three-way interaction effect multiple classifier learning system architecture resampling procedure found statistically significant level mean interaction two attribute different across level third attribute word two-way interaction resampling method multiple classifier learning system varying across architecture two-way interaction architecture resampling method varying across multiple classifier learning system two-way interaction architecture multiple classifier learning system varying across resampling method result summarised fig follows mcls perform differently predicting asd therapy significant error rate increase observed ensemble five four classifier compared three two classifier per ensemble ensemble three single classifier achieve highest accuracy rate ensemble five single classifier achieving lowest accuracy ensembling boosting outperforms resampling method ensembling stacking achieving lowest accuracy rate case across three architecture static parallel multiple classifier learning asd therapy prediction achieves highest accuracy followed multi-stage dynamic classifier stability multiple classifier system respectively ensembling bagging achieves highest accuracy rate poor performance ensembling stacking case across multiple classifier learning system performance multiple classifier system term predicting asdt significantly different across three architecture major difference noticeable multi-stage design single parallel minor difference observed multi-stage design dynamic classifier selection result show mcls built bagging best technique predicting asdt followed boosting feature selection randomisation stacking respectively fig effect resampling procedure multiple classifier learning system mcls transparent mcls exhibit worst performance stacking closely followed feature selection randomisation best overall performance static parallel architecture come bagging used contrast best performance observed decision tree logistic discrimination two component ensemble ensemble artificial neural network decision tree logistic discrimination naïve bayes classifier exhibit worst performance fig bagging exhibit minor error rate increase tight competition boosting mcls multi-stage architecture used one striking outcome artificial neural network logistic discrimination ensemble performance compare favourably decision tree logistic discrimination ensemble however ensemble artificial neural network decision tree logistic discrimination naïve bayes classifier exhibit one worst performance mcls another poor performance -nearest neighbour naïve bayes classifier used ensemble component primarily randomisation used dynamic classifier selection system observed time stacking continues struggle achieves worst performance especially artificial neural network decision tree one hand logistic discrimination naïve bayes classifier hand component ensemble fig best-performing ensemble artificial neural network logistic discrimination decision tree logistic discrimination component performance method multiple classifier learning mcl3 follows similar pattern one observed mcl2 fig figure also show smaller increase error rate resampling procedure static parallel architecture mcl2 best-performing ensemble decision tree -nearest neighbour logistic discrimination component hand poor performance observed artificial neural network decision tree k-nearest neighbour artificial neural network -nearest neighbour naïve bye classifier component ensemble case feature selection stacking resampling procedure method multi-stage design fig nearly identical observed mcls2 ensemble achieving higher accuracy rate bagging boosting used otherwise average performance method worsens stacking used best-performing ensemble decision tree -nearest neighbour logistic discrimination primarily feature selection randomisation stacking stacking ensemble method composed artificial neural network -nearest neighbour naïve bayes classifier prof worst-performing impact mcls predictive accuracy shown fig bagging yield best performance closely followed boosting severe competition randomisation best-performing ensemble artificial neural network decision tree naïve bayes classifier component ensemble -nearest neighbour logistic discrimination naïve bayes classifier drop third-best performing stacking multi-stage design used one worst stacking dynamic classifier election used overall mcls system perform better static parallel used followed multi-stage dynamic classifier selection figure follows using static parallel build mcls boosting best technique dealing asd spectrum disorder problem artificial neural network -nearest neighbour logistic discrimination naïve bayes classifier component ensemble hand ensemble artificial neural network decision tree -nearest neighbour logistic discrimination component achieves worst performance case resampling procedure level i.e bagging boosting feature selection randomisation stacking follows fig best technique handling asd spectrum disorder multi-stage design across various resampling procedure boosting closely followed bagging however poor performance observed feature selection randomisation stacking method also ensemble artificial neural network decision tree -nearest neighbour logistic discrimination component exhibit worst performance mcls bagging using dynamic classifier selection show superior performance resampling procedure fig best-performing ensemble across bagging boosting feature selection component artificial neural network decision tree k-nearest neighbour naïve bayes hand randomisation stacking ensemble artificial neural network k-nearest neighbour logistic discrimination naïve bayes perform best kind problem seems building mcls using static parallel architecture performs better compared architecture dynamic classifier selection multi-stage design fig a–c additionally ensembling learning boosting appears effective especially dynamic classifier selection multi-stage design used bagging appears effective static parallel used outperforming resampling method like feature selection randomisation stacking situation another good performance static parallel multi-stage design ensemble learning used randomisation overall ensemble learning stacking worst-performing method across three architecture social difficulty core asd one many psychological factor lack low level joint attention interaction partner given attention use social robot received asd intervention important investigate significant attribute contribute asd therapy i.e raat vs. sht rank accordingly ranking help investigate ret produce similar pattern comparison sht feature selection one several ranking approach used dealing high dimensionality data improving classification accuracy one goal feature selection machine learning find best feature build applicable model studied phenomenon example removing non-informative redundant asd predictor model many feature selection algorithm including filtering encapsulation embedded one tang pen many feature selection technique classified supervised wrapper filter intrinsic embedded unsupervised learning unlabelled data goal feature selection technique artificial intelligence find best set feature allows one build optimised model studied phenomenon asdt case many feature selection algorithm paper use classic method constructing decision tree process feature selection decision tree algorithm supervised learning embedded approach used select feature ranking order according mutual information criterion whereby node impurity decision tree utilised strength decision tree algorithm high classification accuracy strong robustness feature selection process algorithm result modelled obtain feature considered relevant asd therapy enhancement merit value rank feature analysed summarised fig figure asd therapy feature sorted relevance full size image term ranking result show eye contact yielding slightest cross-validation error 7.51\ 0.14\ followed social interaction 13.23\ 0.34\ non-verbal speech 16.07\ 0.28\ respectively otherwise social touch stereotype two feature exhibiting error rate i.e 22.86\ 0.19\ 24.52\ 1.45\ respectively addition feature significantly different level significance word eye contact autistic child appears impact asd-enhanced therapy compared say stereotype social touch remark conclusion paper novel research performed regarding exploration prediction intervention use autistic child using asd-specific characteristic open question related predicting confidence addressed include asdt data utilised effectively achieve efficient confidence-based prediction using ensemble classifier end significant contribution paper include showing robustness single classifier predicting asdt enhancement using social robot human therapist additionally show mcls provides therapy enhancement performance improvement single base classifier including best-performing one tree-based approach used quantitatively determine importance physical attribute according mutual information-based ranking additionally conclusion single training classifier obtain influential ensemble several different way still high average individual accuracy much diversity would generate influential ensemble several notable takeaway work first ensemble built combination three classifier using bagging achieve perfect fit good performance ensemble could attributed stable nature nearest neighbour linear threshold algorithm core component ensemble ensemble built dynamic classifier selection segmenting population several sub-regions consistently perform poorly however performance static parallel multi-stage combination ensemble strategy provides statistically significant improvement single best classifier understand large datasets randomisation expected better say bagging boosting given size asdt data bagging achieved best result eye contact interactive communication appear critical behavioural factor considered dealing asd therapy however argued inability child disorder communicate use language depends heavily intellectual social development word child asd may able communicate using speech language may minimal speaking skill therefore joint attention child could another factor need consideration dealing asdt previous study provide clear conclusion predictive accuracy multiple classifier system intervention use autistic child study first kind focusing predictive intervention use asdt using single classifier multiple classifier system creating confidence-based predictor using conformal prediction several open question regarding knowledge extracted data using ensemble learning study utility researcher clinician parent alike affords potential learn become socially fluent matter strong autism impairment may although cure asd found yet accurate prediction asdt could lead improved outcome even complete cure additionally study pave way investigating artificial intelligence device could programmed notice react verbal non-verbal response could include facial expression body movement vocal physiologic reaction autistic child i.e could artificial intelligence replace therapist assertion based study application asdt prediction show promising result study based child age year subsequent study datasets child age critically analysed train therapeutic prediction model focus collect data various source age group improve proposed classifier enhance accuracy furthermore state-of-the-art classification method including single classifier like support vector machine considered experiment also considered focus study child asd next research autistic child autistic adult additionally study purely focused behaviour future work investigate specific cognitive mechanism might targeted affected robot vs. human interaction sum research provides effective efficient approach predicting detecting asd trait child three year test diagnosis asd trait costly lengthy difficulty detecting asd child adolescent doe help another cause delay diagnosis thus help accurate asd spectrum disorder predictive accuracy individual guided early prevent situation getting worse reduce cost associated delay