ubiquitous method audio signal classification particularly speech recognition however machine learning suffers several drawback hinder wide dissemination internet thing iot first machine learning especially deep neural network dnns rely cloud infrastructure conduct massive computation model training inference state-of-the-art sota deep learning model gpt-3 billion parameter training requirement 3.14 10^ flop floating operation per second training sota speech transcription model whisper used word library many word one person would continuously speaks year none mentioned technical requirement could fulfilled edge device iot thus cloud infrastructure necessity dnn task second reliance cloud computing machine learning pose great security privacy risk previous security breach happened raw data communication cloud edge machine learning breach carry average 4.24 million loss number continuously growing privacy concern cause distrust among smart device user drive abandonment smart device third environmental impact implementing dnn cloud infrastructure often overlooked neglected training transformer model million parameter generate carbon dioxide emission equaling four time manufacturer vehicle whole lifespan therefore next generation smart iot device need posse sufficient computational power operate machine learning even deep learning edge among effort bring machine learning edge device reservoir computing especially physical reservoir computing generated early success last two decade originating concept liquid state machine echo state network researcher demonstrated sound-induced ripple surface bucket water could used conduct audio signal recognition nutshell reservoir computing exploit intrinsic nonlinearity physical system replicate process nodal connection neural network extract feature time series signal machine perception reservoir computing directly conduct computation analog fashion using physical system largely eliminates necessity separate data storage organization machine learning perception notably reservoir computing naturally suited audio processing task subset time series signal researcher explored many physical system operate reservoir computer temporal signal processing system include field-programmable gate array fpga chemical reaction memristors superparamagnetic tunnel junction spintronics attenuation wavelength laser special medium mem microelectromechanical system others though study demonstrated reservoir computing could handle audio signal processing physical system computing usually cumbersome require preprocessing original audio clip using method mel spectrum largely cancel benefit reducing computational requirement machine learning via reservoir computing importantly boost computational power conventional reservoir computing technique use time-delayed feedback achieved digital analog conversion time-delayed feedback hamper processing speed reservoir computing drastically increasing envelope energy consumption computing suggest less-than-satisfactory performance physical reservoir computing largely caused insufficient computational power computing system chosen previous work recently discovered hopf oscillator common model many physical process sufficient computational power conduct machine learning although simple physical system computing achieved without need additional data handling time-delayed feedback auxiliary electrical component interestingly nonlinear activation neural network also sometimes captured physical reservoir simplify physical reservoir computer architecture e.g. shape memory alloy actuator physical reservoir computer performance hopf oscillator reservoir computer set benchmarking task e.g. logical task emulation time series signal prediction task exceptional compared much complex physical reservoir paper extension previous work demonstrate outstanding capability hopf reservoir computer audio signal recognition task hopf oscillator act nonlinear filter also portion computational task off-loaded hopf physical reservoir computer based previous work hopf oscillator performs computation store information dynamic state fundamentally nonlinear response oscillator type nontraditional computing unlocked machine learning oscillator dynamic state act type local memory additional memory introduced delay line previous work hopf oscillator single readout layer trained perform battery task single readout layer replaced relatively shallow neural network difficult task sound recognition result point efficacy using type reservoir computer edge computing could pave way obtaining edge artificial intelligence decentralized deep learning foreseeable future hopf oscillator reservoir forced hopf oscillator represented aligned aligned x^2+y^2 x^2+y^2 aligned aligned equation refer first second state hopf oscillator respectively _0\ term resonance frequency hopf oscillator parameter affect radius limit cycle motion example without external forcing hopf oscillator would limit cycle radius would oscillate frequency _0\ parameter also loosely correlate quality factor oscillator amplitude sinusoidal force oscillator classify audio signal external forcing signal contains audio signal constructed shown used input hopf oscillator modified hopf oscillator reservoir represented aligned aligned aligned x^2+y^2 aligned aligned x^2+y^2 aligned external signal composed offset audio signal offset ensures radius parameter non-negative external signal injected radius parameter sinusoid a\sin hopf oscillator dynamically responds audio signal state corresponds audio feature machine learning audio classification task state although explicitly used classification task depicted fig likely store information aid computational task unlike original form hopf oscillator reservoir computer use hopf oscillation extract audio feature classification instead directly using two state output time series signal prediction several change made computational scheme hopf oscillator reservoir computer first formulation reservoir doe include typical procedure multiplication input masking function masking function included conventional reservoir computing preset mask multiplying reservoir output create neuron reservoir system training mask equates updating parameter training digitally realized neural network however method memory expensive inefficient audio signal processing since length mask sufficient cover length audio clip nodal connection necessary signal classification instead training mask use efficient multiple layer convolutional neural network readout directly feed forward reservoir output train connection layer parameter second gaussian noise multiplied audio signal audio signal already background noise noise mask used previous hopf reservoir computer study highlight robustness third instead using pseudo-period guide training machine learning readout use number sample collected classification control nodal connection within collected feature point generated reservoir processing audio data virtual node mean sampling point original audio reservoir generate n-1\ nodal connection reservoir state classification example virtual node sampled audio data point processed physical node i.e. fig n-1\ time creates feature point one audio sample n-1\ nodal connection feature point current paper set audio processing method hinders sampling speed audio signal thus resample original full resolution audio data ensure operate experiment within relatively short period time worth noting length audio clip classification event effectively build pseudo-period traditional context reservoir computing via time-delayed feedback loop i.e. fixed length audio produce one classification result detail provided later eventual nodal connection hopf reservoir computer output handling could conceptualized fig figure schematic showing nodal connection within hopf oscillator reservoir computing original signal sent two state oscillator i.e. two physical node physical node generates virtual node time series digital readout layer i.e. machine learning algorithm read sample node oscillator note use one node audio classification present paper n_0\ corresponds number sample original audio signal refers number virtual node controlled readout mechanism signal reservoir sent neural network indicated blue dashed arrow neural network described fig digital readout classify sample corresponding one audio clip class full size image hopf reservoir computer used compute feature map several representative example shown fig refers virtual node number time scale axis defined step size reciprocal sampling rate value feature map rescaled consecutive convolutional layer followed flattened layer fully-connected layer depicted fig construct machine learning readout processing audio signal output reservoir described method section note similar approach applied sota urban sound recognition edge device though eliminate computationally expensive preprocessing mel spectrogram offloading feature extraction reservoir computer importantly approach could use coarse sampling used instead mel spectrogram applied capture granularity audio signal detailed comparison provided subsequent section demonstrate superior feature extraction hopf reservoir computer figure sample feature map generated hopf oscillator corresponding different audio event audio clip length sec sampled -axis follows arithmetic order virtual node -axis time reservoir set node test grayscale value pixel corresponds signal strength data point i.e. feature point audio signal air conditioner car horn child playing dog barking drilling engine idling gunshot jackhammer siren street music full size image result result urban sound recognition dataset first present result hopf reservoir computer urban sound recognition task shown fig left column audio feature mel spectrum operation calculated audio clip 44.1 khz sampling rate show drastic difference three example using top example reference average pointwise euclidean distance reference two higher comparison audio feature hopf shown right column fig three example much higher similarity three example e.g. euclidean distance average euclidean distance sample class aligned c_i -c_j number second sampling rate sample class sample class aligned amplitude hopf reservoir computer time virtual node number indexed class indexed class indexed value indexed value average euclidean distance presented fig diagonal minimal value column row demonstrates hopf oscillator capable separating class even without neural network figure mel spectrum compared hopf urban sound recognition task top bottom three example siren class presented left column energy mel spectrum shown horizontal axis time vertical axis frequency mel spectrum operation conducted upon sample four second long 44.1 khz sampling rate total number frequency band set time step set 0.025 second right column audio feature extracted hopf reservoir computer sample second audio clip downsampled number virtual node set notably mel result hopf reservoir result look similar information conveyed process internally consistent highlighted classifier performance full size image figure average euclidean distance presented symmetric matrix ten urban sound class average euclidean distance calculated sample within single class diagonal element sample two class off-diagonal element full size image robustness audio classification also high importance real-world application highlight mel spectrum result compared hopf result three different noise level using example top row fig white noise added original signal create different signal-to-noise ratio snrs audio feature three new signal computed mel spectrum using 44.1 khz audio sampling rate hopf reservoir computer using audio sampling rate output audio feature shown fig clearly shown mel spectrum-based audio feature lose low frequency information snr reduced feature generated hopf reservoir computer maintain similar structure original audio counterpart euclidean distance snr figure robustness hopf audio extraction compared mel spectrum various signal-to-noise ratio snrs visualization siren example shown top fig used different level noise top bottom three different amount noise added original siren audio example left column energy mel spectrum shown note result start lose low frequency information snr drop right column audio feature extracted using hopf shown note result remains largely noise level even snr equal full size image confusion matrix urban sound recognition task shown fig proposed audio recognition approach based hopf reservoir computer 96.2 accuracy account accuracy improvement compared reduction flop floating operation per second high sampling rate readout mel spectrum computation 90\ audio piece training figure urban sound recognition task confusion matrix presented recognition accuracy labeled ten different audio event note class label figure class label fig full size image result qualcomm voice command dataset using machine learning model trained previous test case i.e. urban sound recognition task baseline test qualcomm voice command dataset demonstrate reconfigurability hopf reservoir computer audio recognition system experiment purposefully reduce number epoch freeze cnn portion machine learning model reconfigure process audio recognition system urban sound detection task voice command task left portion fig representative audio feature four class shown significant difference compared feature urban sound event fig audio recognition yield accuracy confusion matrix depicted right portion fig note number parameter trained experiment 35,000 account dynamic memory 8-bit input batch size demonstrating feasibility running training machine learning readout low-level edge device consuming li-po battery level power figure summary result hopf reservoir computer qualcomm voice command task left example feature map different wake word generated hopf reservoir computer right confusion matrix proposed sound recognition system processing qualcomm wake word label corresponds galaxy lumia snapdragon android full size image result spoken digit dataset spoken digit dataset used compare performance hopf reservoir computer audio recognition reservoir e.g. shown fig hopf reservoir computer produce approximately accuracy spoken digit classification task result retains state-of-the-art recognition accuracy dataset using one physical device i.e. one consolidated analog circuit two physical node state comparison best performing reservoir employed memristors preprocessing original audio clip yield similar accuracy suggest vibratory nature reservoir largely contributes simplicity proposed sound event detection system activation reservoir using sinusoidal signal boost feature extraction audio signal using hopf oscillation detail described later figure summary result hopf reservoir computer conduct spoken digit recognition task confusion matrix proposed sound recognition system processing spoken digit dataset original activation strength inverse hyperbolic tangent machine learning readout full size image increase strength activation signal term discard inverse hyperbolic tangent activation machine learning readout yielded result shown fig accuracy compared case using sending state machine learning readout suggests hopf reservoir computer reconfigured digital readout similar physical reservoir computer additionally hopf oscillator computational power could also drastically enhanced changing oscillator internal physical condition figure summary result hopf reservoir computer conduct spoken digit recognition task confusion matrix proposed sound recognition system processing spoken digit dataset time increase activation strength without inverse hyperbolic tangent machine learning readout full size image conclusion hopf physical reservoir computer architecture proposed real-world edge computing application audio recognition although speech recognition relatively simple task deep neural network running cloud difficult task edge computer due limited computational power proposed architecture effectively strength analog digital device splicing analog oscillator digital neural network moreover hopf oscillator readily fabricated commercial shelf electrical component hopf physical reservoir computer architecture discussed paper several distinct difference similar physical reservoir computer prominently hopf oscillator paired neural network rather using simple ridge regression increasing complexity neural network hopf physical reservoir computer able perform difficult task neural network straightforward easily implemented architecture employed paper doe use preprocessing original audio data significantly reduces computational cost recognition task instead follows activation signal construct feature map matrix reshape inverse tanh usually mel spectrum used type task account half computational load nonlinear oscillator-based physical reservoir computer must use time-delayed feedback cumbersome would require digital-to-analog analog-to-digital converter however hopf oscillator capable storing enough information dynamic state avoid moreover presented architecture robust noise hopf oscillator nonlinearity important real-world audio processing application proposed architecture several key advantage first computational load proposed approach significantly reduced computation involved construction feature map matrix reshape normalization inverse tanh operation consume around computational power compared mel spectrogram sampling rate 4,000 estimate computational load draw conclusion similar operation cortex-m4 arm san jose california edge device yield latency running algorithm second proposed method paired different machine learning model though paper cnn machine learning readout feature map yielded proposed method replaced common image processing method including limited transformer structure similarity index feedforward neural network euclidean distance etc third compared mel spectrogram physically implemented limit cycle generate feature robust noise low audio quality worth noting audio used experiment downsampled version half sampling rate used mel cnn approach still achieving audio recognition accuracy approximately higher example robustness feature map generated audio additional noise fig retains distinctive feature even extremely low signal-to-noise ratio summary result paper present result sound signal recognition using reservoir computing technology consisting hopf oscillator instead employing computationally expensive preprocessing e.g. mel spectrum commonly used study directly take output hopf circuit process normalized audio signal machine learning recognition anticipate hopf reservoir computing directly implemented microphone achieve future processing-on-the-sensor result section systematically demonstrate hopf reservoir computing approach yield accuracy improvement diverse 10-class urban sound recognition compared state-of-the-art result using edge device whereas use surprisingly simple preprocessing normalizing original signal wake word recognition result accuracy using exact readout machine learning algorithm retraining mlp implies hopf reservoir computer enable inference reconfiguration edge sound recognition system additionally compared reservoir computing system e.g. spoken digit dataset yield superior performance without need using complex preprocessing multiple physical device mask function addition also conducted benchmarking experiment far realistic datasets i.e. 10-class urban sound recognition dataset 4-class wake word dataset demonstrate boosted performance audio signal processing changing activation signal strength hopf oscillator implies degree freedom reconfiguring physical reservoir computer compared reservoir implementation lastly carefully crafted algorithm preprocessing data sound recognition task keep overall energy consumption including digital readout based flop operation analog sampling rate computational load sound clip 10-class dataset training machine learning model well envelope computational resource possessed consumer electronic device sound recognition device using hopf reservoir computer could effortless integration device untraceable computational load increase analysis physical mechanism hopf reservoir computer sound recognition three element play important role audio signal recognition limit cycle system creates oscillation signal temporal domain sinusoidal form continuously convolves incoming audio signal convolution reminiscent fourier transform hopf oscillator generates unique pattern audio recognition e.g. fig interestingly process largely replicates process cochlea extracting sound signal feature perceptible neuron nonlinear oscillation hopf oscillator temporal direction creates nodal connection reservoir computer corresponding neuron connection dnn additionally nonlinearity hopf oscillator cause respond differently signal possessing various characteristic feature audio broadband fashion produce clean separation feature fig .it worth noting recent study demonstrated cochlea directly-connected neuron create limit cycle system using previous audio signal activation dynamically enhance performance cochlea performing audio signal feature extraction physical model inner ear modeled hopf oscillator time-delayed feedback loop using signal previous time instant activate limit cycle oscillation audio signal recognition actually happens inner ear instead brain interesting future extension work explore different activation signal create artificial ear capable on-membrane audio recognition meantime two state hopf oscillator affect time delay enhances memory effect essential time series signal processing discussion future work unique advantage hopf reservoir computer demonstrated paper pave way next generation smart iot device exploit unused computational power sensor network specifically physical mechanism backing reservoir computing also happen microphone membrane carefully crafted activation signal one could imagine future microphone directly operate sound signal recognition using sensor mechanism instead dedicated processing rig addition shown fig feature map sound signal consists unique pattern recognized convolutional neural network commonly used visual signal processing extension present work explore correlation audio signal feature map visual signal feature map type time series data feature reservoir computing could used backbone multi-modal machine learning smart iot paradigm including sensor fusion audio video signal combination decentralized machine learning extremely small amount training data required machine learning operation clear feature separation described result section could offer surprisingly satisfactory result essential many use case without luxury unlimited size datasets e.g. soft user identification noisy environment e.g. mix different signal one example shown fig eight-second long audio signal consisting multiple different i.e. car horn drilling siren used demonstrate proof-of-concept hopf reservoir computer mixed signal processing first four second audio clip car horn drilling sound last four second siren sound added higher amplitude shown figure audio feature generated hopf reservoir computer clearly dominant class second half data exhibit visually high correlation audio feature generated clean siren sound hopf reservoir computer euclidean distance anticipate pattern matching algorithm originating computer vision application could employed type audio event separation processing figure noise resistance test using audio feature generated urban sound recognition task first four second eight second clip drilling car horn sound mixed last four second contains siren sound high amplitude two time larger compared two audio class added mixed data shown figure latter four second audio feature show high similarity compared reference siren sound full size image implementation convolutional neural network adopts machine learning approach proposed using urban sound recognition task allows direct comparison feature extracted physical reservoir computer well spectrogram technique normally applied using machine learning readout without computationally expensive preprocessing audio physical reservoir computing architecture employed paper achieved accuracy improvement compared realistic application internet thing machine learning method applied using dedicated neural processor syntiant nd101 particular chip could deploy approximately 60,000 neural core well requirement machine learning model used paper 40,000 neural core alternative approach feature generated reservoir computer could engineered compress amount data audio recognition model deployed low-level edge processor still limit reservoir computing method using hopf oscillator current form first high accuracy sound event recognition requires many virtual node generate diverse feature machine perception however increasing virtual node lead exponential growth sampling rate read high quality audio data actively seeking solution separate audio feature original signal recognition recording could decrease required sampling rate second current circuit-based physical reservoir separate process signal mixing activation circuit redesigning circuit necessary simplify signal reading future system deployment however ultimate version hopf reservoir using mem solve problem since computing happen audio sensing mechanism lastly signal processing still relies digital readout though algorithm remarkably simple microcontroller unit needed anticipate short-term solution deploying optimized machine learning model firmware consuming size static memory without optimization dynamic memory training upgraded machine learning model future goal using analog circuit could detect spike signal audio recognition similar neuron achieve fully analog computer edge device method hopf physical reservoir computer realized proprietary circuit design proposed following schematic given fig circuit implemented using tl082 operational amplifier ad633 multiplier input audio signal first normalized range -1\ +1\ mixed sinusoidal forcing signal matlab sent circuit national instrument cdaq-9174 data i/o module output circuit referred state hopf oscillator collected sampling rate 10^5\ samples/s cdaq-9174 later machine learning processing figure simplified circuit schematic hopf reservoir computer full size image three datasets employed sound recognition experiment consist urban sound recognition qualcomm voice command spoken digit urban sound recognition dataset consists audio clip class high quality urban sound clip recorded new york city audio clip four second long sampling rate least 44.1 khz compared commonly available datasets extremely small number sample demonstrate reconfigurability hopf reservoir computer audio processing qualcomm voice command dataset also used dataset consists audio clip clip lasting second four wake word collected speaker diverse speaking speed accent dataset use clip experiment compared previous urban sound recognition case difference processing algorithm retraining output portion i.e. convolution layer machine learning readout detail discussed later part methodology section result section paper compare proposed hopf reservoir reservoir also conduct experiment spoken digit recognition serf standard benchmarking test reservoir computing spoken digit dataset consists audio clip spoken five different speaker qualcomm voice command dataset total number audio clip experiment set sake processing speed resample audio clip sampling rate normalize data range -1\ +1\ sending analog circuit output circuit used training machine learning model remaining used testing fig nodal connection hopf physical reservoir computer shown although collect data stream hopf circuit data stream consists input signal response virtual node defined sampling speed signal follow principle arranging manipulating signal virtual node output circuit reservoir first activated using inverse hyperbolic tangent function aligned feature aligned subsequently activated output rearranged order virtual node feature map machine perception sample feature map rendering consisting different class urban sound shown fig hopf reservoir computer produce feature map described hopf oscillator reservoir section used input neural network shown figure effectively hopf reservoir computer offloading cost computationally expensive mel spectrum swish activation employed boost performance machine learning model processing sparse neuron activation i.e. dead neuron problem overall accuracy machine learning model processing audio data note future version machine learning software using skipped connection generating residual network boost robustness software large set data second clip output skip-sampled number time sample number virtual node machine learning processing labeled fig machine learning algorithm implemented using kera tensorflow backend training conducted nvidia rtx 2080ti gpu adam optimizer default learning rate 0.001 loss function cross entropy batch size training epoch urban sound recognition dataset qualcomm voice command dataset spoken digit figure schematic showing convolutional neural network-based machine learning readout classification audio event using hopf reservoir computer light blue box figure correspond feature map generated machine learning operation arrow different machine learning operation number light blue box depth feature map bottom number length width feature map respectively max pooling size 2,2 also operated two consecutive convolution reduce dimension feature map note length width label dimension changed machine learning operation full size image