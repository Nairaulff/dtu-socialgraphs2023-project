introduction digital image become ubiquitous daily life taken various device smartphones digital camera drone provide significant visual information diverse field quality image however always optimal due various factor lighting condition color distortion camera setting photo retouching common practice enhance appearance low-quality image removing unwanted element improving overall aesthetic however manually retouching image demand specialized expertise training making difficult everyday user accomplish even professional photo editor retouching large batch image time-consuming monotonous therefore drastic demand automated photo retouching solution recently deep learning-based photo retouching method proposed appropriate solution improve image quality visual fidelity leveraging power convolutional neural network cnns furthermore pioneering study involved gathering vast collection input image corresponding retouched image edited expert resulted establishment mit-adobe fivek dataset facilitated advancement supervised learning approach one challenge deep learning-based photo retouching efficiently accurately represent color information image generally straightforward way capture color representation image required retouching involves increasing either number layer network number filter layer however previous photo retouching method focused method solely image presented network rgb color space although information obtained rgb space valuable editing image incorporating diverse cue different color space facilitate process deep learning task address issue aim improve photo retouching performance considering various color space first step examined image converted rgb space various alternative color space ycbcr hsv lab xyz shown fig input image show completely different histogram color space word transforming image alternate color space result generation new image effectively employed neural network perspective leverage image multiple color space global prior enhance visual quality image paper propose dual-color space network operates two color space provides robust color information compared single color space network network take rgb image input color representation extracted color space obtain global prior representation utilize guide retouching process towards natural realistic result also network designed adopt sequential processing framework resembles step-by-step workflow human figure histogram input image different color space full size image contribution summarized follows introduce dual-color space network leverage global prior different color space enhance overall quality image moreover network employ straightforward sequential process simplify architecture color prediction module cpm color space converter csc serve integral component network introduced extract feature diverse color space transition color space present extensive analysis ablation study highlight benefit proposed method show intriguing property guide future research direction related work color space conversion color space play crucial role several deep learning task including image classification salient object detection image segmentation various color space used task several approach proposed learn feature different color space exploiting strength color space approach improve performance accuracy colornet proposed architecture learn classify image using different color space show certain space lab hed improve classification performance compared rgb space mcsnet transformed image hsv grayscale color space capture additional information saturation luminance vgg-16 backbone network used extract feature parallel rgb channel color information channel information saturation luminance scene abdelsadek investigated effect using different color space image segmentation four different color space including rgb ycbcr xyz hsv compared using various image segmentation method study demonstrate selection color space notable influence result color transform-based method typical approach method involves extracting feature low-resolution image using predict parameter predefined local global color transformation predicted color transformation applied initial high-resolution image common color transformation technique comprises several function curved-based transforms affine transforms lookup table transformation function learned method adjust various image content computationally efficient however effectiveness limited predetermined color transformation may sufficient accurately represent complex non-linear color mapping input retouched image sequential processing method method belong category imitates retouching workflow human representing process sequence color operation implementing approach challenging demand additional supervision identify suitable editing sequence csrnet explored commonly used retouching operation showed operation expressed multi-layer perceptrons layer affected 32-dimensional conditional vector obtained input image global feature modulation shi proposed operation planning algorithm produce synthetic ground-truth sequence facilitate training network neurops replicated conventional color operator acquired knowledge color transformation pixel level intensity determined scalar approach involve converting image different color space instead utilize original rgb image performing photo retouching figure overview proposed dual-color space network method consists two separate network operates different color space full size image method dual-color space network shown fig proposed framework includes transitional network base network transitional network take low-quality image input produce transitional image transitional image fed base network structure allows proposed method utilize global prior multiple space single image enhancement transitional network study driven two key concept neural network perceive image numerical value therefore conversion color space image interpreted network completely new image color space complete correlation one another image better represented different color space rgb space expanding concept two thing concluded firstly single image transformed multiple representation color space conversion thus achieving similar effect using multiple input mean obtain multiple global prior single image secondly combination global prior lead better result implement idea field photo retouching incorporating transitional network since consider quantitative measure perceptual quality chosen use ycbcr color space transitional network channel denotes brightness luminance image channel represent chrominance standard photo retouching dataset tends feature image under-exposed condition utilize channel enhance visual result chrominance channel employed together modify color information illustrated fig bottom left network consists three cpms two cscs explained carefully sect 3.2 3.3 network first convert input image rgb ycbcr next ycbcr input processed series cpms sequentially improve input last csc transitional ycbcr image saved compute reconstruction loss approach allows network carry retouching operation using global prior color space rgb finally network generates transitional image base network base network take input rgb color space shown fig bottom right base network composed three cpms network utilizes global prior rgb space contrary transitional network network produce final retouched image i'\ computes reconstruction loss figure left overview color prediction module cpm right process obtaining control value full size image color prediction module cpm followed sequential image retouching pipeline build cpm map input pixel output pixel via pixel-wise manner goal produce retouched image input image implementing pixel-wise mapping sequential manner set transitional base network illustrated fig cpm take image input generates intermediate image aligned cpm n-1 aligned transitional network base network specifically utilize equivariant mapping build simple translation fig left show n-1 converted 64d feature vector perform straightforward translation feature space control value determines magnitude translation lastly modified feature vector z'\ converted back rgb space resulting output i'\ aligned aligned denote mapping 64d feature vector vice versa respectively obtain illustrated fig right incorporate global image statistic downsample rgb image denoted n-1 use kernel size represent prediction mapping function denoted aligned n-1 aligned feature space dimension consists downsampling layer two convolution layer pooling layer fully connected layer firstly rgb image downsampled two convolutional layer used extract 32d feature map next three different pooling function utilized determine maximum average standard deviation channel three 32d vector concatenated 96d vector refer global prior described sect 3.1 method employ global prior two color space finally fully connected layer map 96d global prior 64d control value color space converter csc obtain comprehensive set color information two separate type global prior proposed method utilizes rgb ycbcr space enhanced retouching process rgb represents color combining different intensity red green blue commonly used color space digital image ycbcr represents color information using luminance chroma blue chroma red conversion rgb ycbcr color space represented using conversion matrix follows aligned bmatrix bmatrix bmatrix 0.299 0.587 0.114 -0.169 -0.331 0.500 0.500 -0.419 -0.081 bmatrix bmatrix bmatrix bmatrix bmatrix aligned rgb ycbcr color transformation also achieved using conversion matrix matrix follows aligned bmatrix bmatrix bmatrix 1.000 0.000 1.403 1.000 -0.344 -0.714 1.000 1.773 -0.000 bmatrix bmatrix cb-128 cr-128 bmatrix aligned shown fig bottom left utilize cscs convert color space rgb ycbcr implement beginning end stage transitional network training objective given rgb image refer ground truth image retouched image predicted model i'\ also referring ycbcr converted image image denoted total loss total composed rgb reconstruction loss ycbcr reconstruction loss total variation loss color loss reconstruction loss train model using rgb ycbcr color space two distinct reconstruction loss employed loss measure difference predicted image aligned chw aligned aligned chw aligned total variation loss also include total variation loss encourage smoother continuous image output aligned chw aligned refers gradient operator color loss implement color loss considers rgb color vector computes angular difference aligned aligned operator calculates average cosine angular difference value pixel total loss function therefore complete training object network aligned total aligned balancing hyper-parameters table quantitative comparison state-of-the-art method mit-adobe fivek dataset full size table experiment dataset metric conduct experiment mit-adobe fivek dataset widely-used set raw image corresponding retouched version manually edited five expert a/b/c/d/e follow common practice utilizing retouched image expert experiment splitting training testing set image image respectively image resized reducing longer edge 500px maintaining aspect ratio use psnr ssim delta metric evaluate performance color difference metric defined cielab color space demonstrated consistent human perception unlike psnr ssim smaller indicates better performance implementation detail implement model using pytorch framework experiment conducted single nvidia rtx gpu training mini-batch size set run iteration use adam optimizer 0.9 0.99 initial learning rate weight balancing hyper-parameters 0.01 0.1 base network contains three cpms transitional network contains three cpms two cscs comparison state-of-the-arts compare model state-of-the-art method including white-box distort-and-recover dupe pix2pix hdrnet csrnet neurop demonstrate effectiveness white-box distort-and-recover dupe pix2pix hdrnet refer result previous work top two state-of-the-art method csrnet neurop retrained model experimental condition ensure fair comparison quantitative comparison result presented table demonstrate proposed model outperforms previous state-of-the-art method mit-adobe fivek dataset specifically white-box distort-and-recover show low performance 20db psnr necessitate million parameter reinforcement-learning-based method directly supervised image one reason method use reinforcement learning receive direct supervision image dupe hdrnet exhibit fairly decent performance require several hundred thousand parameter similarly pix2pix performs reasonably well relies ten million parameter top two state-of-the-art method csrnet neurop proposed model outperforms term metric model requires relatively parameter csrnet neurop ten thousand still light-weighted result show proposed method outperforms existing method exhibit lightweight architecture figure visual comparison state-of-the-art method mit adobe fivek dataset zoom better visibility full size image visual comparison visual comparison state-of-the-art method shown fig compared csrnet neurop show stable performance model display poor quantitative metric contain unpleasing artifact produce image unrealistic color area compared two model retouched image demonstrate effectiveness method specifically first second third row show method enhance input image vividly naturally fourth fifth sixth row result obtained method show realistic image resemble image seventh row human photo lower resemblance three method image result demonstrate realistic natural skin color fewer color shift figure test ranking result rank closely represents image indicates result preferred participant full size image user study conducted mean opinion score test present user study selected total participant randomly chose image test set participant asked rank retouched result three version csrnet neurop based similarity image visual appeal assigning 1st 2nd 3rd place ranking shown fig result achieve better visual ranking csrnet neurop image ranked first image ranked third result indicate retouched result visually favorable participant compared method table evaluation psnr ssim channel ycbcr space using mit-adobe fivek dataset full size table ability capture luminance since used ycbcr color space transitional network utilize luminance feature presented quantitative qualitative result channel table demonstrates proposed method outperforms existing method psnr ssim channel specifically model achieves higher psnr/ssim csrnet 0.53db/0.003 neurop 0.22db/0.002 additionally fig illustrates result show highest psnr/ssim value histogram closely resemble image result indicate method effectively extract luminance feature image utilizes generate final retouched image ablation study validate choice ycbcr color space transitional network conducted ablation study training model using three additional color space hsv lab xyz comparing performance fair comparison rgb space employed process color space result obtained using entire network including base network transitional network cscs removed maintain number parameter quantitative result shown table demonstrate using multiple color space generally effective using one rgb color space lab color space utilized metric showed best performance term addition present visual comparison result fig model using different color space generated pleasing result without artifact unnaturalness however retouched image produce vivid closest-to-gt result result suggest possible conduct research exploring different color space various combination figure visual comparison channel ycbcr space using mit-adobe fivek dataset better understanding psnr value histogram provided full size image table quantitative comparison different color space transitional network mit-adobe fivek dataset full size table figure visual comparison different color space transitional network mit-adobe fivek dataset zoom better visibility full size image conclusion paper introduces novel dual-color space network provides robust color information operating two distinct color space surpassing capability single-color space network employing transitional network base network color representation extracted color space approach allows proposed network incorporate global prior color space guiding retouching process toward producing natural realistic result experiment demonstrated proposed method achieves higher accuracy generates retouched image natural visually striking compared existing state-of-the-art method future work aim investigate alternative color space explore different combination enhance modeling capability network approach yield promising result still limitation need addressing although proposed method outperforms previous method across metric retains lightweight model process involved converting color space could elevate computational cost high-resolution image addition cpms cscs transitional network primarily operate ycbcr color space emphasizing channel luminance capture choice influenced commonly used mit-adobe fivek dataset contains under-exposed image exceptional test set case relatively low-exposure image contains overall dark pixel result deviate image although result realistic aesthetically pleasing hope future research introduce practical application real-world situation various image condition