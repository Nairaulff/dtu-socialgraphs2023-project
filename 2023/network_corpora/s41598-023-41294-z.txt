introduction influenza virus infection mostly presented self-limited respiratory infection immunocompetent people however influenza virus could lead life-threatening infection elderly risk group patient hemagglutinin glycoprotein located surface influenza virus act attaching ligand host cell insert virus cell escape immune response virus alter antigenic feature hemagglutinin protein point mutation phenomenon known antigenic drift mutation gene influenza virus could cause antigenic drift changing protein structure result new strain virus effectively recognized immune system making virus spread easily causing epidemic influenza virus classified orthomyxoviridae family family three important human pathogen including alphainfluenzavirus betainfluenzavirus gammainfluenzavirus influenza virus member alphainfluenzavirus important human pathogen due wide host range higher rate drift shift mutation main part virus attachment host cell receptor globular head domain critical neutralizing antibody generation host immune system one potent genomic location mutation influenza virus divided two different group based globular head domain type placed one group type considered member second group four important antigenic site domain amino acid residue number important residue evolutionary antigenic feature ha1 role ha1 mutation adequacy influenza vaccination made collaborating center vaccine related biological product advisory committee vrbpac responsible functional monitoring report decision new season vaccine despite delicate process shortage strain mismatch vaccine strain circulating strain current study also evaluated sars-cov-2 spike mutation extra evaluation demo future consideration field sars-cov-2 severe acute respiratory syndrome coronavirus etiological agent covid-19 coronavirus disease-2019 pandemic sars-cov-2 betacoronavirus member sarbecoviruses sublineage virus genome ssrna single strand rna 34kb length sars-cov-2 contains different gene including orf1a/b spike envelope membrane nucleoprotein accessory orfs virus bind cell using protein attachment cellular receptor ace-2 angiotensin-converting enzyme protein important antigenic part virus recent year artificial intelligence algorithm achieved human even super-human performance different task image classification text classification action recognition etc anomaly detection sub-domain responsible learning normal representation space detecting anomalous sample test time exploiting learned representation due different challenge labeling anomalous sample high cost rareness sample method domain use normal sample training called unsupervised alternatively one may use limited number labeled anomalous sample training process called semi-supervised unsupervised semi-supervised anomaly detection method recently achieved satisfactory result variety domain image text time-series video deep semi-supervised anomaly detection deepsad recently proposed semi-supervised method made clear semi-supervised anomaly detector significantly superior compared supervised training classification algorithm specifically training dataset complex number normal sample much higher anomalous one anomaly detector attempt find compact representation space normal sample maximizing margin exists normal abnormal one help learn general unique feature normal sample rely overly contrast exists normal anomalous sample classify since mutation prediction task number unmutated sample much higher mutated one problem formulated anomaly detection task formulation unmutated mutated sample considered normal anomalous sample respectively benefit approach two-fold firstly semantically meaningful representation could learned even small number training sample make generalization unseen test time sample possible secondly finding labeling procedure mutated virus expensive time-consuming process anomaly detector could work fine without limited number anomalous mutated training sample motivation propose first anomaly detection framework predicting virus mutation use long short-term memory lstm neural network combination deep semi-supervised anomaly detection deepsad loss learn long-term input dependency also find semantic representation space mutated unmutated training sample figure show overall architecture proposed method conduct extensive experiment show effectiveness method improving average recall f1-score precision area curve auc three different publicly available influenza datasets figure overall architecture method first raw data processed output prepared time step embedding dimension denotes time pre-processing phase lstm cell used produce hidden state h_i\ time point attention function take h_i\ cell state t-1 output next using softmax function weight produced weighted sum hidden state obtained using mentioned weight output weighted sum c_t\ hidden state used produce encoded vector _t\ last step deepsad loss function applied _t\ decide whether input data in-class normal out-class anomaly full size image background sake clarity discus important prerequisite deep learning literature section first recurrent neural network architecture lstms discussed brief introduction anomaly detection method presented recurrent neural network rnn rnns broadly used model data sequential dependency sequence could formed based temporal spatial arrangement initial architecture rnns vanilla rnn suffer memorizing long-term well short-term dependency address issue alternative architecture lstm network bi-directional rnns gated recurrent unit gru introduced approach attempt summarize previous input hidden state updated time step mentioned information regulated using parameter gate instance lstm network consists lstm cell cell contains state h_t\ memory s_t\ two updated based three different gate called input gate i_t\ forget gate f_t\ output gate o_t\ input gate selects memory dimension modify forget gate decides memory cell dimension ignored next time step output gate decides dimension memory transferred state cell state vector updated based gate activation value produced tanh activation specifically memory constitutes previous memory dimension forgotten plus input activation value input gate selects finally state constitutes memory activation value selected output gate equation parameter w_f w_i w_o w_s\ b_f b_i b_o b_s\ shared cell learned training process recurrent behavior lsmt model h_t\ s_t\ function t-1 t-1 model ability take input varying length length sequence doe need fixed note sigmoid activation function used gate map gate output zero one model selection i.e. gate output represents complete selection embedding value corresponds complete non-selection tanh activation function used cell state update rule produce activation value aligned t-1 aligned aligned t-1 aligned aligned t-1 aligned aligned t-1 tanh t-1 aligned aligned tanh aligned despite huge effort making different lstm architecture improve performance architecture proposed yet generally better original one therefore proposed method based lstm network improvement ability maintain long-term information interpretability anomaly detection mentioned anomaly detection sub-branch artificial intelligence seeking solve one-class classification problem one-class method access label one category dataset called normal class method seek design classifier distinguish normal class vs. unseen class also referred anomaly class instance mutation prediction problem anomaly detection method assumes access unmutated sample setup could adopted reason large cost data-gathering process kind mutated unmutated class even impossibility gathering kind mutation training dataset issue make classification setup ineffective classifier may get biased towards accurate prediction known mutation reflected training set deep support vector data description dsvdd one basic anomaly detection method trained unsupervised manner try find latent space compact hyper-sphere contains normal training sample space pre-assumption dsvdd anomalous sample layout circle contrast normal one could make detectable recently chong shown vulnerability method mode collapse i.e. convergence data point single point latent space due unsupervised training process alleviate issue dsad suggests using limited number anomalous training sample train dsvdd achieved satisfying result shown limited number anomalous sample enough prevent mode collapse also enhance supervised classifier accuracy specifically training sample significantly imbalanced toward normal class different point view autoencoder another dominant framework used field owing unsupervised training process intrigued formulating anomaly detection problem based ability trained normal training sample pre-assumption would reconstructed well test time compared abnormal input primary version autoencoders shown deficiency performance training dataset becomes complex variant ae-based method proposed based generative adversarial network adversarial robust training self-supervised learning method experiment result dataset experiment used dataset provided tempel data hosted http dataset includes influenza subtypes h1n1 h3n2 h5n1 sequence length respectively number available sequence year three subtypes provided table table number sample subtypes full size table experiment sars-cov-2 selected rbd domain spike nucleotide sequence length united kingdom january last day december number available sequence month provided table current study used one year period time sars-cov-2 introduction future research data result seem promising limited completely validated mutation prediction sars-cov-2 spike gene need future study study performed accordance declaration helsinki carried accordance relevant guideline regulation table number sequence sample january december full size table implementation use pytorch scikit-learn implementation experiment performed h1n1 h3n2 h5n1 similar previously proposed method tempel first sample per year chosen training testing first sample year selected training set remaining set test set model since validation also needed finding best threshold first training set used validation remaining training use batch size learning rate 0.001 gradient descent optimization also similar tempel hidden layer size dropout percentage set 0.5 respectively fig show validation curve used good hint stop training process 50th epoch model converged therefore trained model training epoch bioinformatics pipeline suggested amino acid alteration location amino acid alteration location suggested algorithm evaluated simple alignment analysis model training possible amino acid alteration location influenza h1n1 h3n2 h5n1 listed based highest recall precision influenza virus sequence obtained ncbi influenza database random full-length sample influenza circulating strain used sample amino acid alteration location evaluation addition alteration evaluated based suggested vaccine strain 2016–2017 season stain include a/california/7/2009 h1n1 pdm09-like virus a/hong kong/4801/2014 h3n2 -like virus b/brisbane/60/2008-like virus b/victoria lineage sampling influenza sequence aligned alignment amino acid location visualized clc workbench major epitope marked based previous study h1n1 h3n2 h5n1 influenza reported human host hence mutation assessment dataset use host mostly avians baseline section compare method recently proposed anomaly detection method easily adapted task although approach golan bergman achieve top performance anomaly detection problem use self-supervised learning method specialized image processing task consequently reach weak performance datasets table includes performance bergman al. called goad compared method parameter represents time-series sequence length ending year sake equality comparison chosen similar tempel besides repeating experiment different value give comprehensive intuition sensitivity method algorithm domain-specific autoencoder-based approach reported performance arae stable domain-agnostic high-performance approach arae trained fully unsupervised training manner using unmutated training sample result competitive semi-supervised learning method besides aes effective facing complex datasets moreover report performance similar semi-supervised anomaly detection method proposed recently esad ae-based approach employ kind negative unmutated positive mutated sample loss function finally performance original vanilla deepsad method without proposed modification reported table table precision recall f1-score h1n1 h3n2 h5n1 datasets 5,10,15\ full size table result report mean standard deviation metric used evaluate method different experiment model trained trial table show performance method compared tempel recently proposed sota datasets experiment area curve auc f1-score recall precision reported related work report tempel result use original implementation publicly available reported link paper following experiment also conducted similar experiment sars-cov-2 dataset 5,10\ unlike experiment experiment present time-series sequence length month rather year comparison auc f1-score recall precision shown method achieves competitive significantly superior result standard criterion auc recall precision averaged across value datasets good notice method consistently better temple parameter small i.e training set different measure could effect using anomaly detection loss train model since deepsad loss attempt find shared representation space unmutated sample given training set efficiently best scenario extract general feature table auc comparison h1n1 h3n2 h5n1 datasets 5,10,15\ full size table table f1-score prediction h1n1 h3n2 h5n1 datasets 5,10,15\ full size table table recall prediction h1n1 h3n2 h5n1 datasets 5,10,15\ full size table table precision prediction h1n1 h3n2 h5n1 datasets 5,10,15\ full size table stopping criterion training process mentioned use validation data find best point cut training process figure show f1-score curve validation test test depicted validation curve almost always follow corresponding test curve show usability determining point stop training process note smaller value parameter complexity finding good representation space therefore larger number training sample needed approximately make validation test distribution similar consequently validation curve completely follow test curve comparison roc curve figure show roc curve method compared tempel obvious method always lesser value false-positive rate high true positive rate value value test datasets justified margin exists normal abnormal distribution hsc loss attempt make margin large possible classification-based approach tempel try minimize cross-entropy loss doe consider maximizing margin explicitly help model robust noise exist training datasets typical considering difficulty dataset-making process moreover sars-cov-2 dataset method setup lower false-positive rate show higher true-positive rate compared tempel ablation study result also conducted experiment using different model called transformer predicting mutation result experiment shown table detail mechanism transformer provided ablation section method table recall f1-score auc h1n1 h3n2 h5n1 datasets 5,10,15\ full size table mutation prediction result real-world dataset assessment evaluation possible amino acid alteration mutation exhibit top recall precision rate listed assessed based random sample reported influenza sequence 2016–2017 season vaccine strain table represents model result different possible amino acid alteration location presence random sampling data reported stain noted based model result reported alteration amino acid number associated previous next amino acid proposed alteration algorithm sampling data evaluated separately regardless algorithm roc curve mutation furthermore proposed alteration position depict mutation fig table sampling aligned data year express mutation year data set particular position mutation particular location appear current random sampling due low stability frequency mutation h1n1 influenza evaluation antigenic site influenza h1n1 amino acid sequence proposed model highlight important alteration amino acid number three important site meanwhile many missed important amino acid alteration especially detail provided fig comparison current anomaly detection method suggested method tempel three difference alteration position difference refer amino acid number tempel model residue represent important alteration located h3n2 influenza evaluation antigenic site influenza h3n2 amino acid sequence model proposed important alteration amino acid number antigenic site amino acid receptor binding site alteration location illustrated fig mentioned important alteration antigenic site lower site site missed comparison model tempel model proposed two position model detect residue suggested tempel model current model residue represents variable position sequence epitope amino acid number epitope location missed model model suggests alteration amino acid number tempel model amino acid doe reflect epitope high prevalence variation true mutation site h5n1 influenza influenza h5n1 amino acid sequence evaluated reported sequence human host due lack report particular year evaluation model multiple sequence alignment important alteration position table used avian sequence h5n1 due nature virus amino acid number seem important study antigenic evaluation moreover comparing current model tempel model two different mutation location tempel comparison conducted study reveals two important mutation position sars-cov-2 data collected june proposed mutation position amino acid location amino acid number represents alpha variant-specific mutation n501y date dataset preparation another proposed mutation position represent particular association variant except omicron variant s477n noted time database preparation clue omicron variant mutation position reflect particular result discussion every year hundred thousand death reported influenza disease despite many effort develop new treatment vaccine due high genetic diversity influenza virus complete success achieved yet extended genetic diversity due rna genome virus protein encoded genome hemagglutinin among important protein play key role infectivity propagation virus glycoprotein play paramount role binding sialic acid ligand virus surface host cell well fusion cell fact pathogenicity depends efficient cleavage hemagglutinin precursor ha1 ha2 protein former responsible receptor-binding activity latter anchor ha1 also responsible ph-dependent fusion reason along increased resistance currently available class drug inhibit ion channel neuraminidase made inhibition hemagglutinin one attractive goal development anti-influenza drug recent year addition medication immune system target response infection infection established adaptive immune system trigger strong response virus neutralizing antibody produced virus major target neutralizing antibody since antibody strain specific mutation epitope targeted antibody may change antigenicity virus lead emergence antibody- vaccine-escape strain entrance virus body production neutralizing antibody immune cell antibody-escape virus evade host immune system phenomenon called selection antibody escape variant influenza virus highly prone antigenic change change often caused two main mechanism called antigen shift drift cell infected two different genotype new strain may develop due placement different part two strain new viral particle phenomenon lead generation new pandemic strain called antigen shift influenza virus highly prone point mutation due lack proofreading ability rna genome accumulation point mutation called antigen drift occurrence phenomenon gene encoding cause alteration structure function protein result immune system longer able detect virus therefore jeopardizes risk future pandemic body resistance since critical role replication cycle occurrence change greatly contributed evolution virus series mutation effect antigenicity finally lead intense antigenic drift phenomenon called cluster transition characteristic evolution study shown change amino acid sequence ha1 tremendously alter antigenicity virus thereby tracking change essential predict future behavior virus thyagarajan bloom mutagenized gene wild-type create codon-mutant library gene used library make pool mutant reverse genetics using illumina deep mutational scanning found 10,000 different probability mutation protein also cultured mutant investigated mutated virus concluded mutation mostly occur region protein recognized antibody otherwise receptor-binding domain frequently subject mutation possible reason still target sialic acid spite extensive mutation protein determining new antigenic variant critical order develop efficient flu vaccine collaborates number laboratory around world identify circulating influenza virus human population traditionally hemagglutination inhibition test used evaluate antigenic variant virus time-consuming hand-operated method however advance computer science bioinformatics led invention development faster accurate method using scoring regression method sequence collected h3n2 flu virus liao proposed method predicting variant virus according proposed method influenza virus variant predictable agreement rate 91.67 also identified amino acid position whose change significantly contribute development new variant yang developed learning sparse algorithm called antigenco ha1 protein h3n2 virus identify superior determinant property antigenic profile serological data addition single mutation method also used multiple simultaneous mutation co-evolved site order predict antigenicity prediction accuracy method studied work 90.05 łuksza developed model based mapping sequence viral fitness according mutation epitope region considered positive fitness effect induce cross-immunity flu strain conversely incidence mutation outside epitope site regarded fitness cost using system viral clade involved future epidemic predicted yin developed computational method predict suitable strain vaccination generating time-series training sample splittings embeddings method recurrent neural network rnn help performing sequence-to-sequence prediction using h3n2 flu strain identified suggested strain method similarity recommended vaccine strain current work study anomaly detection-based approach predicting influenza mutation study result suggest important alteration position influenza h1n1 h3n2 h5n1 multidisciplinary study show promising reliable result mutation prediction influenza virus comparison mentioned previous study based nature anomaly detection approach seems appropriate mutation prediction analysis viral genome study considering complete gene roc curve current model represents great performance however assessment important antigenic site optimization would critical study furthermore one major limitation current study limited available sequence different year limitation reflects minor problem current research considering parameter meanwhile great effort time sars-cov-2 pandemic availability great amount primary sequence data could promising study considering advancement high throughput sequencing technique limitation sequence solved future another limitation current study evaluation lineage clade type influenza different clade lineage h1n1 unique evolution need focus future study light improving primary sequence limitation addition another limitation analysis h5n1 mutation need mentioned lack h5n1 report human host furthermore need considered another limitation current study theory mutational pressure prediction position could lead future developed model could also noted using model differentiate mutation-prone gene location positive pressure natural selection sequence could challenging perspective future study developing accuracy model recently rnn model used predict antigenic change severe respiratory syndrome coronavirus sars-cov-2 sawmya used pipeline method predict mutation region sars-cov-2 gene first gene classified according country phylogenetic tree obtained next step using algorithmic method method used machine learning position gene distinct term characteristic obtained finally occurrence mutation site predicted using cnn-rnn network considering sars-cov-2 current study data preliminary perspective study preliminary data represents low productivity potential position mutation sars-cov-2 gene highlight important position mutation amino acid number represents n501y mutation alpha variant method influenza virus sars-cov-2 rbd database amino acid sequence influenza virus sequence obtained ncbi influenza database http amino acid sequence obtained without limitation time report amino acid sequence human host north hemisphere referring h1n1 strain downloaded full-length sequence region used multiple sequence alignment msa msa performed mafft algorithm experiment sars-cov-2 used covid-19 data portal provided european covid-19 data platform embl european bioinformatics institute embl-ebi proposed method mutation prediction problem formulated time series anomaly detection getting time series data raw amino-acid sequence preprocessing method employed firstly ambiguous amino acid replaced one common amino acid amino acid sequence clustered primary time series sequence obtained lastly amino acid represented feature space using prot2vec method order formulate problem anomaly detection selected temporal attention-based rnn backbone trained deepsad loss function let preserve sequential aspect input also benefit anomaly detection algorithm temporal attention-based rnn shown significantly better performance compared lstm network preserving long-term dependency besides owing use attention mechanism focus important feature input helpful complex problem mutation prediction task addition deepsad loss function help model focus important part input sequence also encapsulate compact representation space exactly look mutation prediction problem code made publicly available http sake reproducibility preprocessing preprocessing similar yin includes three major step replacing obscure amino acid acquiring time series sequence representing amino acid feature space protein consist common amino acid due error reading protein sequence stated datasets might ambiguous amino acid letter site needed replaced probable amino acid step randomly replaced one amino acid one one amino acid replacement obtaining time series sequence sample year divided cluster using -means algorithm experiment similar yin al. set k=3\ similarity metric euclidean distance cluster year closest cluster next year selected finding closest cluster pair two consecutive year multiple sequence cluster formed example assume year cluster closest cluster year t+1\ cluster year t+2\ closest cluster make cluster sequence cluster cluster sequence protein sample randomly selected hence sequence time series sequence data created feature space representation amino acid converted vector using protvec representation calculated following equation aligned x^t_i i+j 2d+1 aligned v_i^k\ vector output protvec -th amino acid sample gathered year show number amino acid neighbor like yin al. representation evaluated 3-grams set step specific site position also known epitope selected protein sequence rnn model trained tested site generate label position sequence assuming dataset sequence year t+1\ nucleotide value position time t+1\ compared nucleotide value position time value differ indicates mutation hence labeled anomaly otherwise data labeled afterward training testing sequence year given input model temporal attention given specific time series sequence x_1 x_2 x_t temporal attention mechanism used encoding sequence architecture lstm gru performance decay input length increase applying temporal attention mechanism mentioned architecture able consider element sequence final encoding sequence overcome issue mechanism order calculate attention weight first attention function take hidden state time cell state j-1 time j-1\ lstm cell output scalar value aligned j-1 h_i aligned attention function defined aligned j-1 h_i attn j-1 h_i attn aligned attn attn learned training process using softmax function weight calculated applied hidden state aligned k=1 j-1 aligned aligned z_j k=1 j-1 h_k aligned z_j\ context vector time last step using following equation encoded vector _j\ time calculated aligned tanh aligned learned training process next step deepsad loss discussed next section applied encoded vector length input time series sequence deepsad loss mentioned earlier use deepsad loss function temporal attention rnn capture normal feature deepsad loss function defined aligned i=1 c\vert j=n+1 m+n c\vert l=1 aligned neural network temporal attention-based rnn denotes parameter also hyper-parameter set training process minimizing loss function normal sample centralized minimum volume hyper-sphere center abnormal sample forced also hyper-parameter assign extra weight abnormal sample mitigate imbalanced training sample issue finally denote number normal abnormal training sample respectively mentioned ruff use radial basis function deepsad loss produce better result therefore called hyper-sphere classifier hsc loss function used experiment aligned i=1 m+n aligned hsc force normal data mapped near origin center set zero since data dataset label dataset assumed set pair number training sample y=1\ show normal data case unmutated virus y=0\ show mutated sample ablation described rnns one mechanism produce satisfactory result case sequence transduction however efficiency problem capturing long-term dependency mainly fact input sequence passed step chain chain becomes longer probable information get lost unlike rnns transformer efficient retaining long-term dependency transformer kind neural network architecture become popular due performance various field introduced perform sequence transduction dependency input element architecture consists encoder decoder encoder layer together generate encoding summarize element relation element sequence self-attention mechanism layer consists self-attention mechanism feed-forward neural network input sequence fed encoder input part flow two layer encoder first self-attention mechanism learns three weight matrix query weight key weight value weight input element input multiplied three vector produce query vector key vector value vector attention weight input element input element obtained applying dot product attention weight divided dimension key vector lead stable gradient advantage rnns pas result softmax function order normalize weight next multiply value vector softmax score end sum weighted value vector follows aligned attention softmax aligned resulting vector would sent along feed forward neural network decoder function similar way decoder module contains layer take encoding use generate output sequence decoder layer component encoder layer also attention layer two component help decoder focus relevant part input sequence conclusion future work research shown effectiveness anomaly detection approach predicting influenza mutation conducting extensive experiment due extreme imbalance training sample problem anomaly detector extract useful information efficiently find shared robust feature unmutated sample also result parameter small advocate mentioned merit approach future work want extend experiment provide result sars-cov-2 severe acute respiratory syndrome coronavirus mutation prediction helpful understanding behavior application