introduction knowledge graph organizes store knowledge real world multi-relationship-directed graph node represent name people thing place entity edge represent relation entity belonging attribute knowledge graph also seen collection fact composed triple instance triple bill gate founder microsoft bill gate microsoft serve head tail entity respectively founder serf semantic relation gradual evolution artificial intelligence perceptual intelligence cognitive intelligence recent years.kgs playing increasingly important role many domain information retrieval question-answering system recommendation system incompleteness two aspect one hand due incompleteness people cognition real world limitation data extraction algorithm existing large-scale knowledge graph often fail capture define entity relation hand knowledge graph ever-evolving new entity emerging every moment shi weninger performed statistical analysis dbpedia late early found new entity emerged daily common knowledge graph completion method embedding-based method transe complex rotate learn embeddings entity relation known triple predict missing entity relation unseen entity refer entity included training set emerge testing set fig entity fig entity fig unseen entity different fig meanwhile relationship entity fig aâ€“c learn graph structure semantic information fig apply model fig predict relationship unseen entity shown fig obtain representation entity henry helen training representation contains latent information henry husband helen representation used infer missing relation fig however entity fig unseen fig get representation entity training conventional embedding method predict missing relation fig way obtain corresponding representation novel entity retrain whole knowledge graph containing unseen entity however retraining frequently extremely space-consuming time-consuming solution avoiding costly retraining desirable figure example relation prediction full size image approach doe need retraining used unseen entity adopt rule father son husband rule capture entity-independent semantic information directly applied new entity however rule mining method implemented based path traversal number rule exponentially related scale knowledge graph meanwhile rule dependent graph structure semantics expressiveness lower representation learning another research unseen entity representation learning use external resource entity description category information approach benefit inductive learning additional computation massive resource required process time-consuming always feasible inspired generalization graph neural network gnn method inductive link prediction emerged grail related method task inductive link prediction method challenging since aim predicting missing link entity knowledge graph entity training inference different.these method first extract subgraphs knowledge graph use topological structure information among entity relation subgraphs predict missing relation achieve good result however method consider topological structure ignore semantic information entity subgraph type entity one kind semantic information knowledge graph posse entity-type information type constructed hierarchical structure different granularity semantic concept considered sub-types different layer xie propose relation two entity constrained type entity triple helen mirren graduated harvard university head entity belong category person tail entity belong category educational institution motivated phenomenon propose model type information entity learn semantic information entity-type integrate structure semantics learn inductive representation study propose novel inductive representation method tgrail improves generalization ability representation learning incorporating category information structured information based subgraph following list paper main contribution introducing tgrail novel integrated inductive knowledge graph embedding model model integrates topological information subgraph semantic information entity-type combination two kind information enhances generalization knowledge graph embedding introducing entity hierarchical type information coding method address different role different hierarchical type increasing weight abstract type decreasing weight concrete type model outperforms baseline approach evaluating tgrail several previously benchmark model two datasets fb15k-237 wn18rr related work transductive embedding model knowledge graph embedding kge method aim learn distributed representation entity relation projecting element knowledge graph continuous vector space word kge convert symbolic representation knowledge numerical representation maintaining knowledge graph internal structure semantic information embeddings improve calculation efficiency complex semantic association entity relation significant constructing reasoning applying knowledge base moreover extensively applied task relation extraction question-answering recommendation system typical knowledge graph embedding model based fact alone translational distance tensor decomposition model transe transd transr translational distance model evaluate rationality triplet modeling relation translation operation entity vector space tensor decomposition model consider knowledge graph third-order tensor head entity tail entity relation index mode-1 mode-2 mode-3 vector tensor respectively value tensor element used indicate whether corresponding fact triple hold example model include rescal distmult complex addition relying triplet information alone model use additional information improve accuracy representation type information one kind additional information hierarchical-type information found entity frequently constructed artificially contains rich semantic information regarded accurate prior knowledge important learning representation knowledge graph meanwhile type information generalized rather specific certain entity introducing hierarchical type relation prediction task improve accuracy relation prediction especially entity fewer training sample instance relation place birth generally connects two distinct type entity category head tail entity correspond personality location type respectively several model proposed add type information entity existing embedding model instance tkrl model add explicit entity type transe joie model represents knowledge graph ontology view i.e. type information instance view i.e. entity information encodes two view jointly tarp model encoded type information instance-level information prior probability likelihood relation respectively combined bayes rule transductive embedding model learn vector representation updating initial random vector entity relation contrast new entity target knowledge graph initial vector training process inferred entity therefore transductive embedding-based representation solve problem new emerging entity representation knowledge graph inductive embedding model several kind inductive embedding model proposed solve problem new emerging entity representation graph neural network-based subgraph-based description information-based rule-based approach textual description information-based method entity description involve abundant semantic information utilized auxiliary information improve accuracy embedding learning existing embedding-based model information integrated shown success zhen proposed jointly embedding entity word aligning wikipedia anchor entity name vector space dkrl model suggests using convolutional neural network continuous bag-of-words model encode textual information concatenating text vector structure vector acquired trans model wang proposed constructing co-occurrence network combined entity annotating corpus achieve text-enhanced knowledge representation although method achieve representation unseen entity knowledge graph limitation one representation heavily rely presence textual description information two element triple new entity located must knowledge graph therefore method applied knowledge graph meet condition graph neural network-based method graph neural network-based approach acquire representation unseen node aggregating neighbor node information lan however method need information node around unseen node applied entire new graph composed unseen node subgraph-based method subgraph-based approach grail tact compile extract enclosing subgraph surrounding target relation firstly annotates relative position entity subgraph design score function using gnn annotated subgraph subgraph paper composed important node selected node around target relation several approach estimating importance node method grail tact compile assume distance target relation reflects importance node work ppr take probability node wandering randomly graph importance score recently graph neural network-based method geni proposed applies attentive gnn predication-aware score aggregation capture relation importance node compile emphasizes directed nature edge enclosing subgraph message interaction edge entity tact address semantic correlation relations.these method processed inside enclosing subgraphs neglecting situation subgraphs sparse relation prediction subgraphs solve problem snri proposes fully using complete neighboring relation neighboring relational feature node neighboring relational path sparse subgraph dekg-ilp predicts link two subgraphs using relation feature based contrast learning gnn-based subgraph feature training testing set model disjoint set entity mean method learn representation unseen entity without restriction seen entity however consider topological structure node subgraphs ignoring semantic information node type rule-based method rule-based method learn set rule training data rule entity-independent used task contain unseen entity avoiding trouble retraining according different strategy mining process rule learning method divided path traversal-based method representation-based learning method differentiable rule mining method rulen one path traversal-based method first find triple containing target relation search path graph depth-first search strategy path body form rule tensorlog neurallp drum differentiable rule learner model tensorlog establishes connection first-order rule inference sparse matrix multiplication compiles specific logical reasoning task series numerical matrice operation differentiated based tensorlog neural propose rule-learning framework combine parameter structure learning first-order logic rule end-to-end differentiable model neural num-lp extension neurallp method add numeric property rule body based neurallp drum learns logical rule establishing connection confidence score rule low-rank tensor approximation however rule limitation expressing complex semantic correlation meanwhile number rule limited scale knowledge graph consideration search cost compared aforementioned work work mostly devoted problem entity representation entirely new knowledge graph propose knowledge graph inductive representation method incorporating subgraph structural feature entity-type semantic information tgrail inductive representation learning problem definition knowledge graph defined denotes set entity containing head tail entity set relation entity set triple inductive knowledge graph embedding given source knowledge graph target knowledge graph source knowledge graph defined _s\ _s\ _s\ _s\ _s\ set entity including head tail entity _s\ set relation entity _s\ denotes set triple fact target knowledge graph _t\ _t\ _t\ _t\ _s\ _t\ _t\ _s\ conventional knowledge graph representation method first embed entity relation low-dimensional continuous vector space define corresponding scoring function measure rationality triple obtaining vector representation maximizing score known fact goal inductive knowledge graph representation learning learn representation entity relation _s\ generalize target _t\ use solve inference problem completely unseen entity _t\ paper evaluates representation triple classification link prediction overall architecture model model tgrail discussed section figure depicts architecture whole model consists two part type representation module topology representation module type representation module encodes hierarchical type entity constructing projection matrix based tkrl model topology representation module first extract directed subgraphs around target relation node topology subgraphs obtain subgraph representation based rgcn model training score function created tgrail integrates two part unified framework model explained detail figure overview tgrail full size image structure representation subgraph extraction relation triple related also node edge surrounding quantity node edge around particular relation huge large-scale knowledge graph considered equivalent aggregating node information whole knowledge graph may enhance effect expense impractical time memory consumption majority actual network model seal suggests high-order characteristic graph learned subgraph feature within small range around target relation therefore paper considers extracting graph composed node edge within two hop around relation enclosing subgraph subsequent work based subgraph existing wlnm seal grail model assume graph undirected extracting subgraphs relation undirected graph symmetric however relation practice symmetric instance triple mike parent lisa mike lisa parent lisa mike parent relation parent doe satisfy symmetric incorrect result produced relation parent edge treated undirected accordingly considering node around edge extracting subgraphs enough direction also considered similar concept in- out-degrees directed graph present study introduces incoming outgoing node define directed enclosing subgraphs definition node directed graph edge length one node called first-order ingoing node first-order outgoing node similarly referred second-order ingoing node referred second-order outgoing node edge length two definition given triple let collection lst-order in-going node node collection lst-order outgoing node node directed closed subgraph regarding close node representation similar grail adopt drnl initialize node embedding depicts topological position node subgraph target relation head tail entity linked relation seen target node topological structure node enclosing subgraph represented tuple denotes shortest distance node head node denotes shortest distance node tail node representation node obtained vectorizing tuple subgraph representation enclosing subgraph close subgraph node embedding trained using rgcn model calculation formula shown follows aligned h_i^ v_j nv_i^ w_r^ h_j^ w_o^ h_i^ aligned denotes extracted subgraph set relation nv_i^ denotes set neighbor whose relation node used normalization _r\ weight parameter corresponding neighbor relation _o\ weight parameter corresponding node activation function _i^ represents embedding representation node _i\ lth level pooling average node subgraph used represent subgraph aligned close v_s close v_s close h_i aligned v_s close set node enclosing subgraph target node vector edge vector subgraph representation vector concatenate structured representation aligned close h_u h_v r_t aligned h_s close denotes subgraph h_u h_v denotes node denotes edge type representation type entity knowledge graph hierarchical structure actor/award winner/person reflects varying level abstraction across different type entity embedding learning subtypes different hierarchy level play different role transductive learning detail category offer richer information representation learning however inductive representation learning emphasizes generalization abstract category information provides significant aid representation learning paper hierarchy-based weighted encoding approach type representation capture exploit hierarchical structure suppose hierarchical type subtypes granularity fine coarse e.g. actor/award winner/person specific type actor subtype hierarchical type use projection matrix m_t represent subtype represent weight subtype projection matrice hierarchical type formalized aligned m_t m_t aligned number layer hierarchy m_t^ projection matrix i-th subtype weight corresponding assumed precise type lower weight introduce novel approach decrease equal proportion increasing value subtype aligned aligned 0.5 entity multiple different type project matrix entity obtained weighted summation several different type triple project matrix head entity relation defined aligned t_i array t_i t_i array aligned number entity type denoted t_i denotes i-th type entity t_i projection matrix t_i weight t_i obtained frequency entity belonging c_i denotes relation set head entity relation framework tgrail order make full use hierarchical type structure information designed score function combine two part unified framework score function aligned h\oplus close w_s aligned close embedding vector hierarchical type module structure representation module respectively model training loss function transe used objective optimization function training model binary classification task performed given triple goal maximize distance closest positive negative example negative sample constructed randomly replacing triple head tail uniformly sampled entity aligned aligned regularization parameter represents set triple knowledge graph denote positive negative triple respectively experiment section evaluates model effectiveness link prediction triple classification first experimental dataset configuration evaluation metric described second experiment result tgrail several benchmark datasets shown datasets perform experiment two benchmark datasets wn18rr fb15k-237 type information entity fb15k-237 category information provided literature wn18rr dataset currently doe dedicated category information hypernym entity used category information statistical data show entity hypernym word information accounting total entity order ensure integrity dataset triplet involving entity preserved missing entity category filled mode data processing inductive representation mainly focus model performance unseen entity representation number unseen entity evaluation dataset powerful model evaluation ability result experiment adopts grail dataset division method several node randomly selected root node graph composed k-hop neighborhood node around root node used training graph test graph generated similarly removing training graph datasets divided four part corresponding test set v1_ind v2_ind v3_ind v4_ind order verify inductive characteristic model duplicate entity training test set relation test graph taken train graph detailed information training set test set shown table table statistic inductive benchmark datasets used denote number entity relation triple respectively full size table evaluation metric keep consistent baseline model perform triple classification link prediction task adopt auc-pr hit evaluation metric triple classification binary classification task determine whether given triple exists knowledge graph task score triple scoring function set threshold score score exceeds threshold triple considered correct otherwise considered wrong classification task requires negative triplet publicly released negative triplet current dataset construct negative triplet randomly replacing triplet head entity tail entity adopt auc-pr evaluation metric triple classification experiment emphasizes model discriminative ability positive sample link prediction predict third element triple based existing two element entity prediction refers predicting missing entity triplet relation prediction predict missing relation two given entity experiment link prediction refers relation prediction experimental setting pytorch used implement model experiment conducted gtx ram capacity adam optimizer utilized batch size learning rate 0.001 number training epoch embedding vector dimension entity relation hierarchical type set default value parameter result table demonstrate experimental result auc-pr hit wn18rr fb15k-237 better compare performance different model hit auc-pr plotted performance curve model two datasets shown fig several phenomenon observed among three rule-based method rulen performs best two end-to-end differentiable method neurallp drum achieve similar performance.it indicates rule acquired path-based mining inductive hit pr-auc result grail better neurallp datasets wn18rr fb15k-237 compared two method note sampling subgraph rulen similar enclosing subgraph grail difference rulen method performs rule mining based subgraph grail method graph neural network method feature learning result demonstrates grail learns topological structure node neighborhood also distribution node feature neighborhood tgrail outperforms inductive baseline metric wn18rr fb15k-237 suggests integration type information beneficial inductive representation table inductive result pr_auc full size table table inductive result hit full size table figure performance variation different model full size image comparison experiment comparison different type encoding scheme order analyze influence different entity type coding scheme inductive representation model introduce tgrail-whe type coding adopts whe method tkrl hierarchical type weight change proportionally according type inclusion range specific category greater weight taking example hierarchical type observed artist specific entity assigned largest weight however tgrail greater emphasis given type generalization subtype artist specific type assigned smaller weight illustrated table effect tgrail_whe unseen entity good tgrail show different hierarchical weight calculation method different effect inductive representation model excessively detailed category information affect accuracy prediction comparison descriptive information type information compare different effect description information hierarchical type inductive knowledge graph embedding design baseline model grail_des entity description information vectorized bert table show result two model benchmark dataset fb15k-237 illustrated table compared grail performance grail_des incorporates description information drop indicates detailed description information limit representation capability model unseen entity influence type information far better description information inductive knowledge graph representation table hit pr_auc result tgrail_whe tgrail fb15k-237 full size table table hit pr_auc result grail_des tgrail fb15k-237 full size table conclusion transductive embedding model generate representation unseen entity may emerge subsequently inductive method recently proposed realized inductive learning based subgraph extraction gnn method account structural characteristic related node neighborhood overlooking expressive semantics encapsulated within hierarchy type node address semantic information propose novel inductive knowledge graph embedding method paper incorporates subgraph structure information around relation integrates category feature experimental result indicate proposed tgrail performs better several current state-of-the-art technique benchmark datasets however tgrail method still limitation capture structure semantics subgraph ignoring topology structure global graph future work explore extract global feature graph enhance generalization ability inductive representation learning