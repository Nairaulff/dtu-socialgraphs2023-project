introduction pu-erh tea highly distinctive tea product yunnan province china quality pu-erh tea affected packaging production processing storage different region variety processing technique result different value pu-erh tea pu-erh tea classified pu-erh raw tea pu-erh ripe tea based processing technology furthermore finished pu-erh tea left loose leaf compressed cake brick facilitate transportation storage typically longer pu-erh tea stored higher value many unscrupulous enterprise individual sell second best quality price seriously affect pu-erh tea sale market mislead consumer negatively affect economic benefit consumer improve traceability combat counterfeiting various technological solution proposed instance traceability system bound quick response code near field communication nfc chip could trace every link supply chain digital id-based solution completely solve problem counterfeiting counterfeiter still copy code nfc chip fit cheaper product original packaging one important way enhance product traceability extract use information unique natural characteristic product case pu-erh tea different unique natural texture formed tea compressed cake used basis tea face image computer vision technology made possible use deep learning image processing method biometric identification including face recognition many face recognition model method developed deepface sphereface central loss state-of-the-art face recognition model localface similar method also used animal feature recognition task automatic identification individual cow goat pig face recognition cow face recognition individual egg identification therefore speculated biometric approach could also applied pu-erh tea face recognition task tea face recognition task divided two type tea face verification tea face recognition improve traceability pu-erh tea product proposed pu-erh tea face verification model teafacenet based improved mobilenetv3 model attention mechanism module eca block lightweight network mobilenetv3 feature extraction express texture feature reducing number parameter triplet loss softmax used loss function experimental result showed validation accuracy model higher classical convolutional neural network cnns model constructing verification model improve traceability pu-erh tea help avoid adulteration material method data acquisition image data study collected pu-erh tea cake production plant puer city yunnan province china 22.78°n 100.91°e two type equipment used photograph tea cake mobile phone honor high-speed photographic apparatus eloam high-speed portable docscanner s820a3af purpose simulate real-world scenario schematic diagram image acquisition process shown fig eloam high-speed portable docscanner s820a3af cmos autofocusing technology million pixel main camera capture image resolution honor mobile phone released honor june equipped million pixel quad camera resolution image acquired mobile phone total piece pu-erh raw tea piece pu-erh ripe tea collected piece used training dataset piece test dataset tea cake photographed front back image shooting standard follows set white background keep background clean tidy without debris shoot distance directly tea cake ensure tea cake center image make tea cake maximally filled picture ensure clear texture figure schematic diagram image acquisition full size image preprocessing data acquisition completed tea cake image processed uniformly resolution tea cake map adjusted image expanded using data enhancement technique operation following three training datasets established pu-erh raw tea face dataset pu-erh ripe tea face dataset mixed tea face dataset three datasets include front back image pu-erh raw tea pu-erh ripe tea pu-erh tea face datasets shown fig figure example pu-erh tea face datasets pu-erh raw tea face image front pu-erh raw tea face image back pu-erh ripe tea face image front pu-erh ripe tea face image back example data acquired different recording device high-speed sortable scanner mobile phone full size image amount data training data set shown table training dataset pu-erh raw tea face contains front back image pu-erh raw tea cake captured using two type equipment resulting total image applying data augmentation technique total number image increased similarly training dataset pu-erh ripe tea face contains front back image pu-erh ripe tea cake taken using two different device resulting total image data augmentation total number image increased mixed tea face dataset contains raw ripe pu-erh tea face previous datasets resulting total image data augmentation total number image increased 16,000 training process dataset split training set validation set 9:1 ratio training set validation set pu-erh raw tea face dataset pu-erh ripe tea face dataset contained image respectively mixed tea face dataset contained 14,400 image respectively table training dataset data full size table test dataset shot shooting method piece pu-erh raw tea pu-erh ripe tea containing front back image shown table among test pair pair tea face pair different tea face selected pu-erh raw tea face test dataset pu-erh ripe tea face test dataset test pair pair tea face pair different tea face selected mixed tea face dataset table test dataset data full size table data enhancement photographing tea cake difficult determine fixed direction due round shape improve robustness deep neural network tea face recognition various scene used rotation flipping random contrast brightness adjustment image noise random erasing enhance data data augmentation technique enriches dataset improves generalization model allowing learn enough feature enhance performance data enhancement technique illustrated fig figure data enhancement method original image 45° clockwise rotation 90° clockwise rotation 135° clockwise rotation 180° clockwise rotation 225° clockwise rotation 270° clockwise rotation 315° clockwise rotation mirror flip salt-and-pepper noise gaussian noise random brightness adjustment random adjustment chroma contrast sharpness random erasing full size image image rotation firstly image enhancement performed using rotation rotate original image 45° 90°,135° 180° 225° 270° 315° performing one mirror flip done model could learn feature angle improve rotation invariance model image noise term image noise salt-and-pepper noise gaussian noise used enhance image data salt-and-pepper noise important noise mainly change pixel black white randomly compared noise image sensitive salt-and-pepper noise gaussian noise noise whose distribution obeys normal distribution superimposed every point image using two method enhance image could improve ability model mine deep feature image enhance recognition performance model complex scene image brightness chroma contrast sharpness term image brightness adjustment following measure used enhance data adjusts brightness original image selecting three random value three random value constrained range namely value min =0.5\ value min =0.5\ value max =2.0\ value max =2.0\ value max =2.0\ value max =2.0\ image chromaticity contrast sharpness adjustment measure taken enhance data enhancement adding image training set main purpose enhancement method simulate situation different light intensity tea face taken also data processed method could make shortcoming neural network make robust testing data different light intensity image random erasing zhun zhong proposed random erasure method training cnns randomly selects rectangular region image modifying pixel using random value using method image different occlusion level could generated could reduce risk overfitting make model robust occlusion lightweight network mobilenetv3 mobilenet lightweight network designed mobile device embedded device nowadays available version include mobilenet mobilenetv2 mobilenetv3 mobilenetv3 combine structure mobilenet mobilenetv2 introduces squeeze-and-excitation block firstly mobilenetv3 used depthwise separable convolution designed reduce amount computation improve computational speed network depthwise separable convolution mainly includes depthwise convolution pointwise convolution depthwise convolution change convolution kernel standard convolution single-channel convolution kernel input number channel single-layer convolution kernel channel convolved separately finally superimposed pointwise convolution used expand channel using convolution comparison standard convolution shown fig figure traditional convolution depthwise separable convolution residual block inverted residual linear bottleneck full size image secondly mobilenetv3 used linear bottleneck expansion layer inverted residual linear bottleneck used reduce loss feature information inverted residual used learn feature expanding channel residual block descending ascending inverted residual block ascending descending figure show residual block fig show inverted residual linear bottleneck finally mobilenetv3 placed lightweight attention model squeeze excitation structure depth filter extension order facilitate application attention largest representation figure show structure mobilenetv3 block new activation function swish\left used swish\left shown swish\left x\frac relu6 figure mobilenetv3 block symbol indicate connection operation sum element full size image attention mechanism module attention mechanism essentially set weighting coefficient learned autonomously network dynamically weighted emphasize region interest suppressing irrelevant background region mainstream attention mechanism include channel attention spatial attention firstly squeeze excitation block main representative channel attention attention mechanism module used mobilenetv3 block shown fig mainly composed two part squeeze excitation secondly convolutional block attention module cbam used experiment based original channel attention bridged spatial attention module sam figure show structure cbam module figure block cbam block eca block width height channel dimension i.e. number filter full size image structure efficient channel attention eca block shown fig used 1-dimensional sparse convolution operation optimize fully connected layer operation involved block significantly reduce number parameter maintain comparable performance order compress number parameter improve computational efficiency block adopts dimensionality reduction-then dimensionality increase strategy using two multilayer perceptrons learn correlation different channel i.e. current feature map interacts feature map intensive connection eca module simplifies connection making current channel interact domain channel aggregated feature obtained global average pooling gap eca generates channel weight performing fast 1d\ convolution size determined adaptively mapping channel dimension shown log_ odd represents odd number nearest set proposed model architecture tf-bottleneck block paper teafacenet bottleneck tf-bottleneck block proposed module improved mobilenetv3 block figure show inverted residual block block mainly relu activation function figure show tf-bottleneck block attention block eca module placed depth filter extension facilitate application attention maximum representation figure inverted residual block tf-bottleneck block full size image backbone feature extraction network teafacenet feed batch data redesigned deep convolutional neural network performs l2\ normalization produce embeddings tea face triplet loss softmax loss used training data eventually used tea face verification task training structure teafacenet model shown fig figure training structure teafacenet model full size image specification backbone feature extraction network paper shown table initial input size adjusted final output feature vector entire backbone network consists module layer1 layer2 layer3 layer4 layer5 layer18 layer1 includes convolutional regularization activation layer activation function using h-swish layer2 layer3 layer4 linear bottleneck layer eca module added relu used activation function layer5 layer6 layer7 linear tf-bottleneck layer eca module added three layer also using relu activation function layer8 layer9 layer10 layer11 linear bottleneck layer eca module added four layer h-swish used activation function layer12 layer13 layer14 layer15 layer16 linear tf-bottleneck layer eca module added h-swish used activation function layer17 flatten layer main purpose layer flatten feature transition convolutional layer fully-connected layer layer18 fully-connected neural network layer whose main purpose fully connect input 128-dimensional feature vector table structure backbone feature extraction network full size table loss function triplet loss chosen main loss function main objective minimize euclidean distance anchor positive image maximize euclidean distance negative image shown fig minimized triplet loss function shown triplet f\left f\left increase distance gap positive negative pair set possible triple training set base figure triplet loss full size image meanwhile softmax loss added training using triplet loss convergence model slow due fact using triple select data generates large number data set random sampling method used selection lead reduced model training speed softmax loss function shown softmax log\frac among denotes deep feature belonging class feature dimension denotes column weight last fully connected layer bias term size mini-batch number class tea face verification process tea face verification mainly involves inputting two image recognized trained teafacenet network extract depth feature image finally form two feature vector mapped compact euclidean space l2\ distance directly represents similarity gap two tea face verification result derived based similarity gap threshold i.e whether tea face specific process tea face verification described process shown fig crop dataset image resizing image expand dataset using image enhancement technique including rotation noise brightness chroma contrast sharpness adjustment random erasing divide training data training validation set ratio 9:1 make test pair tea face data using new tea face data train teafacenet model using training dataset record validation set loss value save model epoch training image test pair tested trained teafacenet model calculate distance get best threshold verification result test pair obtained achieve tea face verification figure tea face verification process full size image evaluation metric evaluate performance network tea face verification datasets precision recall f1-score accuracy used performance evaluation tp\ represents data pair correctly recognized tn\ represents different data pair correctly recognized fn\ represents different data pair incorrectly recognized fp\ represents data pair incorrectly recognized calculation method given precision 100\ recall 100\ score precision recall precision recall 100\ accuracy 100\ result discussion experimental environment parameter setting experiment conducted python code mainly based kera deep learning framework tensorflow used backend hardware software configuration piece information shown table hyperparameters model training shown table table hardware software configuration information full size table table hyperparameters model training full size table tea face recognition result test dataset used evaluate teafacenet model table show tea face verification result teafacenet compared several mainstream network model including resnet50 vgg16 inception-resnet-v1 mobilenet mobilenetv3 among mobilenetv3 best recognition effect among mainstream network model recognition accuracy raw tea face dataset ripe tea face dataset mixed tea face dataset teafacenet network 97.58 98.08 98.20 respectively teafacenet network add eca attention mechanism module use depthwise separable convolution linear bottleneck accuracy achieves better result three datasets improving 1.92 2.42 0.54 three datasets respectively recognition accuracy improved replacing attention mechanism module redesigning network structure term size model teafacenet second mobilenet recognition accuracy improved three datasets table tea face verification result full size table teafacenet best accuracy raw tea dataset mature tea dataset mixed dataset also converged first model training better result could achieved model trained epoch variation loss value validation set accuracy different network model raw tea dataset ripe tea dataset mixed dataset shown fig fig fig respectively figure loss accuracy raw tea dataset full size image figure loss accuracy ripe tea dataset full size image figure loss accuracy mixed dataset full size image test deal two main type problem i.e. distinguishing similar tea face dissimilar tea face therefore model need tested optimal threshold experiment focus determining optimal threshold model used ten-fold cross-validation table show optimal threshold model role threshold determine whether two tea face similarity greater optimal threshold mean two tea face dissimilar optimal threshold mean two tea face similar figure show validation case teafacenet model validation result obtained model trained using raw tea face dataset validation result obtained model trained using ripe tea face dataset validation result obtained model trained using mixed dataset table model optimal threshold full size table figure validation case teafacenet model full size image model performance analysis teafacenet improved feature extraction performance reduced computational effort introducing eca module using depthwise separable convolution linear bottleneck compared traditional cnns network network achieved better result performance precision recall f1-score raw tea dataset 97.34 97.83 97.58 compared mobilenetv3 increased 3.29 0.33 1.84 respectively precision recall f1-score ripe tea dataset 98.98 97.16 98.06 compared mobilenetv3 increased 1.91 3.00 2.47 respectively precision recall f1-score mixed dataset 98.82 97.58 98.20 compared mobilenetv3 increased 1.00 0.08 0.54 respectively table show precision recall f1-score model test set raw tea face dataset ripe tea face dataset mixed dataset experiment showed teafacenet could implemented achieved excellent result pu-erh tea face verification task table model performance analysis full size table analysis receiver operating characteristic roc curve quality network model could better determined area roc curve auc value size part area roc curve auc value 0.5 1.0 larger auc representing better performance higher upper left corner better performance figure show roc curve model three datasets roc curve teafacenet model upper left corner auc value 0.996377 raw tea face dataset 0.996377 ripe tea face dataset 0.997269 mixed tea face dataset figure roc curve raw tea face dataset roc curve ripe tea face dataset roc curve mixed tea face dataset full size image effect attentional mechanism module model investigate effect attention mechanism module model experiment conducted replacing eca module model module cbam module table show result tea face recognition different attention mechanism module shown experimentally better result achieved using eca module least number model size accuracy increased model using module 0.83 0.33 0.25 three data set model size volume reduced 5.8 accuracy improvement model using cbam module 1.25 4.92 three data set model size volume reduced 72.1 feature channel tea face recognition task large impact result proven eca module could effectively improve accuracy network verification table comparison tea face recognition result different attention mechanism module full size table discussion work propose pu-erh tea face verification approach called teafacenet based improved mobilenetv3 enhance pu-erh tea traceability identification construct three type pu-erh tea face datasets establish pu-erh tea face verification network achieve comprehensive verification pu-erh raw tea pu-erh ripe tea teafacenet network achieved recognition accuracy 97.58 98.08 98.20 raw tea face dataset ripe tea face dataset mixed tea face dataset respectively however several issue remain area tea face recognition currently publicly available dataset pu-erh tea face dataset used experiment need expansion work solely address pu-erh tea face verification problem exploration required pu-erh tea face recognition problem practical application transportation breakage also pose challenge discussion needed verification identification pu-erh tea face breakage conclusion primary objective study address challenge tracing pu-erh tea cake facilitate detection counterfeit substandard tea product paper proposed pu-erh tea face verification model teafacenet based improved mobilenetv3 architecture teafacenet model extract 128-dimensional feature pair pu-erh tea face image calculates distance determine whether tea face based similarity image determined best threshold experimental result demonstrated teafacenet model outperformed model pu-erh tea face dataset eca block reduced model size extracting feature thereby improving recognition rate network proposed model exhibited better robustness generalization ability achieved excellent result individual class tea face verification task also mixed datasets approach could serve empirical basis subsequent pu-erh tea face recognition task aid enhancing traceability pu-erh tea product