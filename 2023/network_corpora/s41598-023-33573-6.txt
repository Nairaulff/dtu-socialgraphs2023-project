introduction biopsy important tool monitoring kidney allograft finding kidney allograft biopsy guide clinical management provide prognostic information banff classification renal allograft pathology first published widely applied diagnosis kidney allograft rejection importance interstitial inflammation emphasized since establishment classification according recent banff classification update diagnosis acute t-cell mediated rejection requires minimum moderate tubulitis moderate interstitial inflammation non-scarred cortex similarly diagnosis chronic active t-cell mediated rejection requires minimum moderate tubulitis moderate total cortical inflammation moderate inflammation scarred cortex reproducibility quantified inter-rater intra-rater reliability one important attribute classification scoring/grading scheme given importance interstitial inflammation diagnosis kidney allograft rejection good reproducibility essential many study already confirmed therapeutic prognostic relevance banff classification however publication reproducibility especially inter- intra-rater reliability interstitial inflammation scoring scarce reliability coefficient reported publication quite varied range 0.33 0.65 general understanding well poorly renal pathologist perform interstitial inflammation scoring assessment well established reported reliability coefficient obscured transplant practitioner reason good poor reliability investigated furthermore extent variation interstitial inflammation scoring may impact clinical practice unknown address issue current study undertaken investigate inter-rater intra-rater reliability interstitial inflammation scoring according banff classification addition traditional kappa statistic approach conditional agreement calculated improve transparency increase understandability inter- intra-rater reliability nephrologists transplant surgeon renal pathologist finding provided comprehensive picture reproducibility interstitial inflammation scoring call attention possible clinical implication result inter-rater reliability inflammation scoring suboptimal wide range table summarizes pairwise inter-rater reliability interstitial inflammation scoring raters pair total inflammation non-scarred cortex score pairwise weighted kappa value ranged 0.14 slight agreement 0.44 moderate 0.27 fair average confidence interval 0.24 0.29 total cortical inflammation score pairwise weighted kappa value ranged 0.08 0.52 inflammation scarred cortex i-ifta score pairwise weighted kappa value ranged 0.05 0.47 inter-rater reliability three scoring significantly differ 0.27 vs. 0.30 vs. 0.26 0.147 linear mixed model lmm figure show pairwise inter-rater reliability interstitial inflammation scoring grouped rater pair order kappa value lower moderate agreement rater pair showed consistently better worse inter-rater reliability three scoring confirmed one-way anova 0.063 table pairwise inter-rater reliability interstitial inflammation scoring full size table figure pairwise inter-rater reliability interstitial inflammation scoring grouped rater pair order upper dashed line indicates kappa value 0.4 regarded lower limit moderate agreement lower dashed line indicates total average kappa value red blue purple box whisker indicate score score i-ifta respectively error bar confidence interval full size image conditional agreement probability scoring table show conditional agreement probability rater inflammation score example rater assigned specific case probability random rater would also assign case 49.1 similarly rater assigned ti0 specific case probability random rater would also assign ti0 case 53.9 average conditional agreement ranged 38.6 61.3 score 36.7 58.6 score 37.8 61.8 i-ifta score many individual score chi-squared test confirmed raters performed differently data shown however single rater significantly better worse agreement raters 0.712 data shown table conditional agreement probability rater inflammation score full size table given critical interstitial inflammation threshold definite diagnosis acute t-cell mediated rejection chronic active t-cell mediated rejection ti2 i-ifta2 dichotomized score two group none/mild score 0/1 moderate/severe score 2/3 inflammation table taking top left cell rater score 0/1 52.3 example indicates 52.3 time random rater would also assign score case rater assigned score word 47.7 1–52.3 time random rater would disagree rater assigned case score average conditional agreement score 0/1 57.2 indicating 42.8 1–57.2 time second random rater would assign score 2/3 case first rater considered score 0/1 average conditional agreement general 47.2 score 50.0 score 47.1 i-ifta score therefore overall disagreement rate among scoring similar original 4-tier scoring raters performed differently individual group single rater significantly better worse agreement raters 0.983 data shown table conditional agreement probability rater dichotomized score full size table intra-rater reliability better inter-rater reliability table show descriptive statistic intra-rater reliability inter-rater reliability three interstitial inflammation scoring intra-rater reliability generally better inter-rater reliability 0.37 vs. 0.27 0.49 vs. 0.30 0.44 vs. 0.26 score score i-ifta score respectively table kappa statistic intra-rater reliability inter-rater reliability full size table pathologist practicing pattern scoring varied figure show distribution score assigned case raters raters displayed different tendency extent inflammation assigned case noticeable dichotomizing score clinically relevant group none/mild score 0/1 moderate/severe score 2/3 inflammation example rater tended give lower score rater preferred higher score interestingly although exact proportion varied individual pathologist tendency scoring shared common pattern across score score i-ifta chi-squared test confirmed difference score distribution 4-tier 2-tier categorization 0.001 supplementary table scoring post hoc test bonferroni correction confirmed rater consistently assigned lower score compared raters score assigned rater also significantly lower rate figure distribution score assigned case raters score score i-ifta score note similar pattern across i-ifta score distribution none/mild 0/1 vs. moderate/severe 2/3 group highlighted broken line full size image discussion interstitial inflammation scoring i-itfa routinely carried essential part diagnostic criterion t-cell mediated rejection banff classification renal allograft pathology given important role scoring reproducibility essential however time reproducibility scoring overlooked good reproducibility usually taken granted contrast study showed inter-rater reliability interstitial inflammation scoring good even remotely reasonable found pairwise inter-rater reliability interstitial inflammation scoring fair general varied widely kappa value ranging simply acceptable 0.05 moderate 0.52 pathologist perform better worse particular scoring individual pathologist perform significantly different overall inter-rater reliability interstitial inflammation scoring unsatisfactory showed identifiable pattern could use predict performance pair raters inflammation non-scarred cortex score included banff classification establishment inter-rater reliability study revealed suboptimal result kappa intraclass correlation coefficient 0.26 0.42 although compared directly finding banff score mean weighted kappa 0.27 concurred study interstitial inflammation routinely assessed allograft kidney biopsy well native kidney biopsy therefore finding poor inter-rater reliability surprising also alarming banff classification continuously evolves according newly found evidence concept total cortical inflammation score inflammation scarred cortex i-ifta score subsequently introduced meeting score play important role diagnosis chronic active t-cell mediated rejection inter-rater reliability score investigated study preimplantation biopsy intraclass correlation coefficient reported 0.44 fair surprisingly high reliability i-ifta score pairwise kappa value 0.60 0.65 reported paris group latter study included three pathologist study group might reason unusually high agreement found inter-rater reliability banff score i-ifta unsatisfactory banff score however finding validated future study study used different reliability coefficient cohen kappa fleiss kappa intraclass correlation coefficient investigate inter-rater reliability although result except one paris group equally considered suboptimal standard hard directly compare finding due different coefficient construct different sample population also important bear mind intraclass correlation coefficient kappa statistic depend scoring distribution extent agreement differs across different location continuous explanatory variable scale across different category using kappa statistic infer reliability another population requires scoring distribution sample case similar population hand conditional agreement probability given sample representative compared generalized population importantly unlike kappa statistic intraclass correlation coefficient obscured nephrologists transplant surgeon renal pathologist conditional agreement probability give clear view well poorly raters agree represent encounter daily practice expressed percentage example sentence like 57.2 chance another pathologist agree extent interstitial inflammation case. understandable kappa statistic inter-rater reliability interstitial inflammation 0.27. similar approach proposed field pathology expected concordance kappa statistic value found pathologist agree frequently interstitial inflammation scoring pathologist perform equally poorly three kind scoring single pathologist performed better others even dichotomizing score none/mild score 0/1 moderate/severe score 2/3 inflammation group clinically relevant disagreement rate still given interstitial inflammation prerequisite diagnosis t-cell mediated rejection poor agreement scoring might result difference pathological diagnosis potentially impact clinical practice accordingly future study warranted investigate effect irreproducible pathological scoring clinical decision comparing intra-rater reliability inter-rater reliability found pathologist much consistent could reconcile intriguing illuminating finding evidently chart statistically proven contrast generally poor inter-rater reliability raters consistent intrinsic practice pattern distribution score assigned individual raters different time general intra-rater pattern visually evident across three inflammation scoring chi-squared test post hoc two proportion test bonferroni correction confirmed observation indicating pathologist tendency scoring extent interstitial inflammation tendency i-ifta scoring example rater consistently assigned higher score three scoring raters finding partially explained poor inter-rater reliability across raters time better intra-rater reliability within individual fixed practice pattern could double-edged sword one hand would reassured good internal consistency single institution one pathologist read biopsy hand score across different center study unlikely comparable general practice real world might hampered poor inter-rater reliability concur marcussen first study inter-rater reliability banff classification precise criterion semiquantitative score needed visual analog scale banff score provided recent reference guide might example however also shown international study inter-rater reliability banff score along many histological feature kidney biopsy doe improve persistent feedback therefore potential benefit educational action also need evaluated future work conclusion concordance previous study confirmed inter-rater reliability banff scoring moderate addition found pathologist performance inter-rater reliability banff score i-ifta equally poor conditional agreement probability clearly showed average agreement interstitial inflammation score two pathologist better chance poor inter-rater reliability least partially rooted pathologist individual preference scoring extent interstitial inflammation finding current study alert nephrologists transplant surgeon pathologist uncertainty inflammation score well banff classification encourage investigation reason possible remedy poor inter-rater reliability method datasets kidney allograft biopsy performed linkou chang gung memorial hospital used fifty case representing full spectrum interstitial inflammation selected archive one senior renal pathologist t.c participate subsequent scoring process assessment inter-rater intra-rater reliability slide scanned converted whole-slide image nanozoomer s360 digital slide scanner c13220-01 400x magnification study approved chang gung medical foundation institutional review board irb 202200101b0 experiment performed accordance relevant guideline regulation written informed consent waived chang gung medical foundation institutional review board study adhered declaration helsinki interstitial inflammation scoring pathologist eight renal pathologist different hospital taiwan carried scoring independently participating pathologist specially trained field renal pathology one two year age pathologist wide range independent sign-out experience kidney allograft pathology year mean 7.6 working different class institution primary district hospital tertiary medical center pathologist provided whole-slide image hematoxylin eosin- periodic acid-schiff- periodic acid-methenamine silver- trichrome-stained section case performed interstitial inflammation scoring according usual practice following banff classification scoring reported using banff classification inflammation non-scarred cortex absent/minimal non-scarred cortex inflamed mild 10–25 moderate 26–50 severe total cortical inflammation ti0 absent/minimal ti1 mild 10–25 ti2 moderate 26–50 ti3 severe inflammation scarred cortex i-ifta0 absent/minimal non-scarred cortex inflamed extent cortical ifta i-ifta1 mild 10–25 scarred cortex inflamed i-ifta2 moderate -50 scarred cortex inflamed i-ifta3 severe scarred cortex inflamed five case excluded subsequent analysis due missing score least one rater remaining case scored twice interval least three month evaluation intra-rater reliability one rater might assign different score first second round evaluation inter-rater reliability score first second round pooled together get score used obtain balanced interpretation simplicity refer score case manuscript conditional agreement probability conditional agreement probability calculated observed concordant score case different score assigned raters conditional agreement particular rater specific score calculated count specific score divided count score assigned raters case particular rater assigned specific score example regarding inflammation non-scarred cortex score case scored rater case raters case score assigned raters score score score conditional agreement rater score 49.1 meaning 49.1 time random rater would also assign case scored rater see raters representative sample entire renal pathologist population taking one rater first rater case neglectable influence entire population therefore first rater score removed numerator denominator statistic inter-rater intra-rater reliability evaluated pairwise linearly weighted cohen kappa weighted kappa coefficient among different scoring i-ifta compared using linear mixed model lmm included two random effect intercept subject case random slope scoring lmm able deal dependency pairwise kappa coefficient scoring distribution score among eight raters compared using chi-squared test comparison proportion carried 2-proportion test data analysis conducted using spss ibm spss inc chicago illinois value 0.05 considered statistically significant ethical approval study involving human participant reviewed approved chang gung medical foundation institutional review board written informed consent waived chang gung medical foundation institutional review board