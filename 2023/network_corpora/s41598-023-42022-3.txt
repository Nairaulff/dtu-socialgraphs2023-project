introduction blood tissue convenient accessible source alteration blood gene expression study reflecting progression disease progression make transcriptomics data important type omics data type diagnostic investigation human disease however lack reliable blood-based biomarkers non-invasive diagnosis either alzheimer disease parkinson disease α-synuclein dj-1 protein investigated blood biomarkers demonstrated high potential used clinic however validation failed study blood biomarkers used clinically date research identifying aβ42/40 ratio level neurofilament light chain nfl blood concentration future potential blood gene biomarkers neurodegenerative disease particularly interesting high accessibility relatively cheap perform however identifying gene expression biomarkers blood good reproducibility difficult past due small sample size available datasets use statistical learning particular interest investigating blood gene biomarkers due high dimensionality gene expression data machine learning algorithm used feature selection identify gene panel subsequently used distinguish disease control patient panel gene used train classification model identify predict disease status long applied support vector machine svm small dataset returned good result later worked larger dataset using least absolute shrinkage selection operator lasso feature selection approach svm classifier discovered good classification model receiver operating characteristic roc area curve auc 0.87 recently lee lee used multiple feature selection together classification algorithm multiple datasets identified model worked well within different datasets performed poorly datasets shamir conducted largest gene expression analysis tissue whole blood including patient health patient used svm approach classify patient healthy control using gene signature achieved roc auc performance 0.79 wang reanalysed dataset taking random forest approach classify patient healthy control achieved lower roc auc 0.74 limited classification approach used relatively large dataset great potential investigating methodology improve classification performance study collected largest publicly available blood transcriptomics datasets built robust replicable model study respectively applying range feature selection classification approach methodology data processing full workflow study shown fig publicly available peripheral venous whole blood datasets downloaded gene expression omnibus database geo http accession identifier gse63061 gse63060 two independent datasets generated addneuromed cohort study sample collection analysis protocol used independent training test datasets respectively study processed separately using methodology described previously however mild cognitive impairment mci patient removed dataset reduce study complexity additionally since low-expression gene shown important feature previous machine learning-based microarray analysis bottom probe average expression value datasets discarded meanwhile publicly available peripheral figure workflow identification blood biomarkers training test datasets standardized separately feature selection applied training data generate feature set gene using different approach feature set used train five different classification model distinguish control disease patient linear regression support vector machine svm xgboost random forest multilayer perceptron mlp feature set classification model combination evaluated test datasets additionally vae convolutional neural network cnn model trained evaluated separately full size image venous whole blood dataset comprising healthy control sample downloaded geo accession identifier gse99039 dataset processed using previous methodology without removing bottom probe average expression value dataset randomly divided training testing dataset sample training testing process done using train_test_split function python sklearn library datasets scaled using standardscaler sklearn transforms feature distribution mean value standard deviation done training testing datasets separately t-distributed stochastic neighbor embedding t-sne used visualise local structure high-dimensionality data identify clear group dimensionality reduction t-sne created using tsne package sklearn run perplexity set run iteration visualized using tsneplot function bioinfokit v0.9 feature selection following multiple feature selection approach considered model training process knowledge-based feature selection variable step size recursive feature elimination vssrfe logistic regression lasso variational autoencoder vae five-fold cross-validation performed optimise precision-recall auc prauc feature selection process done using bayessearchcv scikit-optimize python library prauc used optimisation sensitive unbalanced class selected subset feature used later training test datasets apply different algorithm knowledge-based feature selection investigate whether feature selection within context existing biological knowledge improve classification performance yield better-classifying model set gene based previous knowledge disease included addition gene high variance across sample included well dataset following source used identify knowledge-based gene degs identified previous meta-analysis gene gene control network module preserved network described previous paper gene gene network module preserved control network described previous paper gene genetic risk gene genome-wide association study gwas gene gene kegg pathway 'kegg parkinson disease gene addition top gene median absolute deviation mad training dataset included well dataset following source used identify knowledge-based gene degs identified previous meta-analysis frontal cortex gene gene control network module preserved network described previous paper gene gene network module preserved control network described previous paper gene gwas gene gene gene kegg pathway 'kegg alzheimers disease pathway gene risk gene alzgene database gene addition top gene mad training dataset included recursive feature elimination variable step size variable step size recursive feature elimination vssrfe work recursively eliminate unimportant feature feature set remains described briefly estimator trained find importance feature dataset least important feature removed number feature removed first step determined initial step size number feature dataset halved step size also halved step size one repeated recursively feature set data pruned desired number feature usually number give best performance evaluation score estimator sample included datasets relatively similar initial step size set feature weight used vssrfe confirmed using linear regression parameter controlling strength regularization tuned whole training datasets vssrfe using bayesian optimization fivefold feature reduction using lasso lasso elastic net reduce number feature using regularisation regularisation approach feature selection shrink coefficient feature zero remove feature model lasso algorithm applied sklearn python library reduce dimension data constant multiplies term optimized full feature set reduced best subset feature variational autoencoder vae microarray data generally high dimensionality large number feature relatively low sample number vae great potential reduce dimensionality data basic vae architecture applied based vae proposed zhang encoder reduces number feature latent space used classification algorithm vae built using kera module python layer using rectified linear unit relu activation function compiled using adam optimiser categorical cross-entropy loss function early stopping loss function doe improve across epoch training stopped optimum vae architecture confirmed using five-fold cross-validation 5-fold identifying model best average accuracy softmax classifier three architecture vae tested basic vae architecture based vae zhang basic vae architecture including batch normalization layer vae basic vae architecture including batch normalization layer vae dropout layer prevent overfitting machine learning classification optimization classification algorithm performed training datasets using bayesian optimization fivefold optimize prauc supplementary table show classification algorithm used various feature set training datasets also show base python code run algorithm parameter tuned optimize algorithm training data algorithm tuned trained feature training datasets feature set found using four feature selection method discussed identify feature set classification method performs best addition approach neural network approach built-in dimensionality reduction classification used vae architecture used reduce feature softmax classifier assign sample disease control convolutional neural network cnn model built well based cnn application computer vision cnns similar multilayer perceptrons mlps however change make effective using multiple layer good reducing data dimensionality start gene expression data reshaped two-dimensional space like image data two-dimensional convolutional layer relu activation function applied data passed maxpooling layer flattened passed dense layer relu activation function softmax used classifier cnn compiled using stochastic gradient descent sgd optimizer categorical cross-entropy loss function python kera package supplementary table summarize parameter used approach datasets information respectively performance classification model assessed using roc-auc plotted using roc curve function sklearn python package prauc plotted using precision recall curve function sklearn relevant python code used study available http result data processing pre-processing gse99039 dataset randomly split training dataset control test dataset control initially 20,183 feature gse63061 dataset used training dataset study included control sample test dataset gse63060 included control initially 19,147 feature local structure datasets outlier sample identified reducing dimensionality using t-sne t-sne plot perplexity shown supplementary figure indicating outlier data perplexity chosen gave clearest visualization data feature selection four approach feature selection used training datasets identify best biomarker panel gene used classification model number feature identified approach shown table table number feature identified using feature selection approach full size table knowledge-based feature selection investigate whether yield better classification model set feature based existing biological knowledge used dataset combination knowledge-based feature highest mad feature returned unique feature mapped dataset dataset combination knowledge-based feature highest mad feature returned unique feature mapped dataset recursive feature elimination variable step size feature weight used vssrfe discovered using training data vssrfe identified panel gene gave prauc roc-auc accuracy 1.00 see fig training data vssrfe identified panel gene dgkk ptgds lsp1 pdlim7 kir2dl3 gave maximum prauc 0.686 roc-auc 0.704 accuracy 0.690 see fig figure evaluation score different number gene selected using vssrfe vssrfe identified panel gene data panel gene data gave best prauc roc-auc accuracy score full size image feature reduction using lasso number feature reduced regularization using lasso lasso identified gene set gene ndufs5 rpl36al gave best model prauc 0.8191 dataset using dataset lasso identified gene set gene gave best poor model prauc 0.5861 variational autoencoder vae number feature reduced using vae model training data basic vae architecture performed best accuracy 0.623 vae batch normalization accuracy 0.537 dropout layer accuracy 0.560 learning rate vae reduced 0.00001 model converge 0.001 training data vae batch normalization dropout layer gave best accuracy 0.554 though much better either vaes without dropout accuracy 0.548 machine learning classification optimization classification algorithm performed using bayesian optimization approach fivefold five classification algorithm svm radial kernel xgboost mlp optimized run using gene set identified feature selection approach additionally vae cnn optimized used reduce dimensionality classify data dataset evaluation score classification algorithm shown table result classification approach using feature set identified feature selection shown 20,183 gene dataset knowledge gene feature set vssrfe feature selection selected feature dgkk ptgds lsp1 pdlim7 kir2dl3 lasso selected feature vae reduced feature representative feature cnn vae classifier inherently reduce feature dimension require feature selection roc curve classification algorithm shown fig model except one mlp using vae feature selection accuracy higher proportion largest observed class non-information rate test data 0.519 model trained using gene gave best accuracy 0.702 roc auc 0.743 prauc 0.762 however much lower sensitivity 0.571 specificity 0.824 table evaluation classification algorithm data full size table figure roc curve classification algorithm data full size image may advantageous biomarkers false negative diagnosis much preferred false positive cnn model performed well consistently high score across evaluation approach evaluation score classification algorithm dataset shown table roc curve classification algorithm shown fig model except two mlp svm using vae feature selection accuracy higher non-information rate test data 0.579 model trained using 159-feature panel identified vssrfe gave best accuracy 0.810 roc auc 0.889 prauc 0.919 supplementary table demonstrated confusion matrix summarising performance study respectively table evaluation classification algorithm data full size table figure roc curve classification algorithm data full size image confusion matrix best model datasets shown supplementary table respectively confusion matrix model shown supplementary figure datasets respectively ethical approval ethical approval needed discussion diagnosis still challenging task clinical practice partly due lack accessible accurate blood biomarkers different classification algorithm applied transcriptomics data identify panel gene optimal model potential prediction model using diverse variety feature selection approach best-performing model identified respectively best-performing model gene included accuracy 0.702 roc auc 0.743 prauc 0.762 best model using model gene panel performed better model accuracy 0.810 roc auc 0.889 prauc 0.919 many previous study using identify biomarkers utilised small datasets recent study lee lee tested various feature selection classification approach three datasets highest roc auc 0.874 identified using deep neural network degs high convergent functional genomics score many model built work outperformed previous study model trained feature set identified vssrfe algorithm gave promising result best accuracy 0.810 roc auc 0.889 prauc 0.919 model relatively balanced sensitivity specificity 0.818 vs. 0.798 high specificity found model well several model specificity 0.913 however came cost lower sensitivity set feature potential diagnosis panel need validation various previous study identified blood-based gene expression variation signature associated jiang performed feature selection blood transcriptomics data identifying degs reducing dimension using lasso performing recursive feature addition svm remaining feature identified panel gene ptgds gpx3 slc25a20 cacna1d lrrn3 polr1d arhgap26 tnfsf14 vps11 used svm decision tree model classifier ptgds lrrn3 gene feature set feature selection method used study former identified feature selection approach latter present gene based previous knowledge identified best classification approach roc auc 0.777 however study many limitation limited approach feature selection involved using degs likely removed many key feature early lasso could applied largest limitation study small size test dataset introduce bias result performance estimation reflect true quality model work shamir achieved roc auc greater found study using dataset also limitation falchetti used much larger test datasets performing meta-analysis four blood datasets feature selection selected top degs absolute effect size used rfe identify gene set gene used classification algorithm using training test split data balanced split data previous study best model identified svm radial kernel achieved roc auc 0.791 although many model outperformed created study datasets used falchetti combined merging re-scaling gene dataset although made sample size much greater may introduced covariates data especially high level technical noise present microarrays study large sample size train test data come study avoided many limitation previous study although model underperform compared previous result larger sample size increase likelihood result reproducible extremely important diagnostic study addition model low sensitivity high specificity mean patient disease misdiagnosed over-diagnosed study revealed vae feature selection approach performed relatively poorly capturing representation gene expression pattern used classification previous research also shown vae approach lose important information study likely due complex nature gene expression pattern blood however solid tissue study impacted tissue directly biopsied skin cancer vae demonstrated effective way reducing feature dimensionality retaining feature information practical study traditionally applied imaging data cnns work well many layer making suitable reducing data dimensionality classification previously shown work well classifying various cancer type blood-based gene expression study cnn high sensitivity make good detecting actual case disease however also high rate false positive case early detection high sensitivity important patient missed false positive often ruled testing healthcare professional result study describe potential diagnostic application however limitation study identify gene expression biomarkers require large sample size identify reliable signature diagnosis datasets used study largest publicly available give comprehensive result however would likely require validation thousand sample information patient disease history symptom would make possible investigate effect disease progress develop prognostic biomarkers could make possible create biomarkers predict risk developing certain symptom moreover would beneficial phenotypic data individual including age gender smoking status variable could influence development disease furthermore information could impact data collection processing relative abundance blood cell type sample would also valuable misdiagnosis rate high instance misdiagnosis rate range pathologically confirmed study diagnosis generally based clinical examination ruling potential cause symptom using brain imaging blood test result also potential patient cohort model trained tested actually misdiagnosed misdiagnosed patient included initial study likely model continue misdiagnose patient similar condition datasets used study diagnosis criterion stricter minimum requirement diagnosis clinical setting reduce impact result work study aimed build blood-based gene expression prediction model additionally aimed ass whether feature selection context existing biological knowledge contribute improving classification performance feature selection classification approach used study thorough dataset date classification model successfully classified patient control good evaluation metric show potential promise clinical practice potential deep learning particularly cnns also investigated improved refined study still potential data-driven approach including feature weighting would likely improve feature selection classification additionally ensembled model could potentially enhance predictive capability combining strength leverage diversity multiple algorithm future work particularly larger datasets ensembled model approach could taken conclusion study pursued blood-based biomarkers using machine learning gene expression profiling research yielded promising result best model achieving accuracy roc auc 0.889 precision-recall auc 0.919 best model reached roc auc 0.743 notably deep learning algorithm specifically cnns exhibited consistent performance across datasets highlighting potential gene expression biomarker detection study underscore potential non-invasive blood-based biomarkers revolutionize early diagnosis management though research larger datasets patient history integration needed robust validation deeper insight disease progression