introduction growth computational capability statistical model becoming increasingly complex make prediction various design condition model often contain uncertain parameter must estimated using data obtained controlled experiment method parameter estimation matured significantly remain notable challenge statistical model estimated parameter considered reliable one challenge practical identifiability model parameter defined possibility estimating parameter high confidence given different form uncertainty parameter model-form measurement present low practical identifiability statistical model lead ill-posed estimation problem becomes critical issue parameter physical interpretation decision made using estimated value identifiability deficit also lead unreliable model prediction therefore statistical model suitable practical application therefore reliable parameter estimation process model prediction significant interest practical identifiability evaluated controlled experiment parameter estimation study conducted frequentist statistic problem practical identifiability examine possibility unique estimation model parameter consideration method examining identifiability broadly classified local global identifiability method former examines possibility =\theta ^k\ unique parameter estimate within neighborhood parameter space latter concerned uniqueness ^k\ considering entire parameter space local sensitivity analysis widely used find parameter produce large variability model response analysis parameter resulting large variability considered relevant therefore assumed identifiable parameter estimation however parameter associated large model sensitivity could still poor identifiability characteristic another class frequentist identification method based analysis property fisher information matrix fim staley proposed positive definiteness fim necessary sufficient condition parameter considered practically identifiable similarly rothenberg showed identifiability parameter equivalent non-singularity fim however subsequent finding reported model singular fim could also identifiable weijers extended classical fim analysis showed even individual parameter low identifiability belong identifiable subset subset practically identifiable parameter within subset functional relationship thus resulting combined effect model response shown identifiable subset found examining condition number -criterion determinant -criterion selecting parameter pair smallest condition number largest determinant similarly machado considered ratio examine practical identifiability find identifiable subset another popular identification technique likelihood profiling method based finding likelihood profile parameter maximizing likelihood respect rest parameter parameter likelihood profile shallow deemed low practical identifiability addition evaluating practical identifiability likelihood profiling could also used find functional relationship parameter helpful model reparameterization however due several re-optimizations required obtain likelihood profile method doe scale well parameter space could quickly become computationally intractable method based fim likelihood profiling gained significant popularity examine local identifiability mean estimate practical identifiability dependent ^k\ analysis conducted valid within neighborhood overcome limitation local identifiability global identifiability method using kullback-leibler divergence identifying function proposed however method computationally complex suitable practical problem moreover since method based frequentist statistic unable account parametric uncertainty therefore unable provide honest representation global practical identifiability study examining global practical identifiability bayesian framework early attempt based global sensitivity analysis gsa apportions variability either derivative variance model output due uncertainty parameter unlike local sensitivity analysis gsa-based method simultaneously vary model parameter according distribution thus providing measure global sensitivity independent particular parameter realization however global parameter sensitivity doe guarantee global practical identifiability pant capellari formulated problem practical identifiability gaining sufficient information model parameter data information-theoretic approach used quantify information gained larger information gain would mean larger practical identifiability however assumption structure parameter-data joint distribution made developing estimator similar approach used ebrahimian change parameter uncertainty moving prior distribution estimated posterior distribution used quantify information gained pant proposed information sensitivity function combining information theory sensitivity analysis quantify information gain however joint distribution parameter data assumed gaussian framed bayesian setting information-theoretic approach identifiability provides natural extension include different form uncertainty present practical problem work novel estimator developed information-theoretic perspective examine practical identifiability statistical model expected information gained data model parameter used metric quantify practical identifiability contrast aforementioned method based information theory proposed approach following novel advantage first estimator information gain used priori analysis data required evaluate practical identifiability second framework account different form uncertainty model-form parameter measurement third framework doe make assumption joint distribution data parameter previous method fourth identifiability analysis global rather dependent particular realization model parameter another contribution work information-theoretic estimator highlight dependency parameter pair emerge posteriori however priori manner combining knowledge information gained parameter parameter dependency using proposed approach possible find parameter subset estimated high posterior certainty controlled experiment performed broadly dramatically reduce cost parameter estimation inform model-form selection refinement associate degree reliability parameter estimation manuscript organized follows bayesian parameter inference bayesian paradigm parameter estimation presented quantifying information gain differential entropy mutual information presented information-theoretic tool quantify uncertainty associated random variable information gain respectively estimating practical identifiability priori estimator developed quantify global practical identifiability bayesian construct estimating parameter dependence problem estimating parameter dependency addressed priori estimator developed quantify parameter dependency developed posteriori practical identifiability framework applied linear gaussian statistical model methane-air reduced kinetics model result presented numerical experiment concluding remark presented concluding remark perspective quantifying practical identifiability bayesian setting section first present bayesian framework parameter estimation next utilize concept differential entropy mutual information information theory quantify information contained data uncertain parameter statistical model thereafter extend idea mutual information develop priori estimator quantify practical identifiability bayesian setting statistical model low practical identifiability due insufficient information model parameter may often case identifiable subset exist parameter within subset functional relation exhibit combined effect statistical model subset practically identifiable find identifiable subset develop estimator highlight dependency parameter pair emerge posteriori bayesian parameter inference consider observation/data y\in physical system realization random variable distributed set possible realization random variable herein use lower-case upper-case symbol notation represent realization random variable set possible observation respectively consider another real-valued random variable distributed denotes uncertain parameter model data assumed generated statistical model given aligned y\triangleq +\xi aligned forward model map parameter model input d\in prediction space simplicity consider input model known random variable additive measurement noise uncertainty measurement observation collected using controlled experiment prior belief parameter distribution updated obtain posterior distribution via bayes rule aligned y\mid y\mid aligned y\mid called model likelihood y\mid called evidence quantifying information gain updating parameter belief prior posterior associated gain information data gain quantified change uncertainty parameter example consider gaussian prior posterior distribution information gain quantified change variance measure uncertainty parameter distribution greater reduction parameter uncertainty consequence information gained data general change parameter uncertainty prior posterior distribution given input model d\in defined aligned aligned operator quantifying amount uncertainty lack information given probability distribution thus expected information gained parameter defined aligned aligned one popular choice operator differential entropy defined average shannon information given probability distribution mathematically continuous random variable distribution support differential entropy defined aligned -\int aligned using differential entropy quantify uncertainty probability distribution change uncertainty expected information gain evaluated aligned aligned aligned y\mid aligned aligned -\int y\mid aligned aligned y\mid y\mid y\mid aligned aligned y\mid aligned quantity called mutual information random variable given model input =d\ case discrete random variable mutual information measured bit whereas case continuous variable unit nats remark mutual information y\mid always non-negative mean updating parameter belief prior posterior increase parameter uncertainty estimating practical identifiability bayesian framework parameter treated random variable practical identifiability determined examining information gained model parameter parameter data uninformative estimated high degree confidence therefore practically unidentifiable mutual information useful quantity study information gained data entire parameter set doe apportion information gained parameter therefore examine practical identifiability define conditional mutual information aligned y\mid y\mid aligned parameter except _i\ denotes expectation using conditional mutual information practical identifiability based intuition average high information gained _i\ mean high practical identifiability thus present following definition identifiability bayesian setting definition local identifiability given statistical model parameter parameter _i\in said locally identifiable sufficient information gained particular realization definition global identifiability given statistical model parameter parameter _i\in said globally identifiable sufficient information gained average respect distribution expectation possible realization therefore provides statistical measure global practical identifiability contrary evaluating fixed result local identifiability measure mean information gained _i\ implicitly depend typically doe closed-form expression must estimated numerically using definition differential entropy conditional mutual information written aligned y\mid y\mid _i\mid y\mid aligned aligned y\mid y\mid y\mid aligned aligned y\mid y\mid y\mid aligned remark term differential entropy conditional mutual information defined aligned y\mid _i\mid _i\mid aligned aligned y\mid y\mid aligned case parameter uncorrelated aligned y\mid _i\mid y\mid y\mid aligned formulation doe involve conditional distribution involving parameter data requires joint distribution namely y\mid y\mid typically joint distribution closed-form expression must approximated special case _i\ perfectly correlate realization provides sufficient information _i\ term inside logarithm becomes identically unity case data informative _i\ effective parameter dimensionality eff becomes general case monte-carlo integration used approximate high dimensional integral aligned y\mid y\mid k=1 outer aligned drawn distribution drawn likelihood distribution y\mid outer number monte-carlo sample typically conditional evidence y\mid doe closed-form expression therefore y^k\mid must numerically approximated one approach rewrite conditional evidence y^k\mid mean marginalization aligned _i\mid aligned simplicity assume parameter uncorrelated prior observing data also independent model input result re-written aligned aligned result low-dimensional integral univariate prior distribution evaluating using classical monte-carlo integration dramatically increase overall cost estimating conditional mutual information especially likelihood evaluation computationally expensive special case prior normally distributed cost reduced considering -point gaussian quadrature rule using quadrature approximation give aligned =n_ inner aligned quadrature point weight respectively inner number quadrature point use gauss-hermite quadrature rule order hermite polynomial exact polynomial order 2t-1\ much general case prior distribution non-gaussian however still evaluated cost estimating reduced using importance sampling proposal distribution using importance sampling rewrite aligned aligned importance sampling weight case proposal distribution gaussian quadrature rule applied aligned =n_ inner _i^ aligned combining estimator conditional evidence result biased estimator conditional mutual information variance controlled numerical accuracy estimating high-dimensional integral bias governed accuracy approximating conditional evidence mean variance controlled outer monte-carlo sample bias inner quadrature point practice estimating conditional evidence become computationally expensive especially variability output forward model high respect _i\ given large =\theta statistical model conditional evidence become near zero numerical approximation mean vanilla monte-carlo integration gaussian quadrature challenging using estimator based importance sampling conditional evidence shown alleviate problem carefully choosing density proposal example consider case additive measurement noise normally distributed likelihood model distributed y\mid =\mathcal sampled according case model prediction large variability respect parameter _i\ given =\theta model likelihood become small case importance-sampling-based estimator given used constructing proposal around sample =\mathcal ^2_ proposal ^2_ proposal variance proposal distribution result robust estimation conditional evidence prevents infinite value conditional mutual information consider estimate conditional evidence remark assessing practical identifiability bayesian framework dependent prior distribution although framework presented article entirely priori analysis practical identifiability prior selection affect estimated identifiability prior selection extensive area research considered part work physical interpretation identifiability information-theoretic framework assessing practical identifiability using conditional mutual information described provides relative measure many bit nats information gained particular parameter practical application information gain vary disparate scale useful associate physical interpretation identifiability following pant consider hypothetical direct observation statistical model given ^2_ additive measurement noise given observation model define information gain equivalent variance measurement uncertainty direct observation model given y\mid large would mean information gained _i\ using statistical model would lead higher measurement uncertainty parameter observed directly prior distribution approximated mean equivalent normal distribution ^2_ given aligned ^2_ ^2_ aligned aligned ^2_ ^2_ y\mid aligned information gain equivalent variance depends information gained model parameter thus used metric compare different model parameter estimating parameter dependence statistical model unknown functional relationship dependency may present parameter multiple parameter combined effect statistical model parameter form identifiable subset individual parameter exhibit low identifiability however subset collectively identifiable mean data uninformative weakly informative individual parameter within subset whereas informative entire subset example consider statistical model _1\theta individually identifying _1\ _2\ possible combined effect statistical model however clear _1\ _2\ belong identifiable subset pair identifiable thus considering statistical model given _3=\theta _2\ better identifiability characteristic statistical model traditional method examining correlation parameter often insufficient reveals linear functional relation random variable highlight parameter dependency consider statistical model given interested examining relation _i\in _j\in emerge posteriori conditional mutual information presented estimating practical identifiability provides information practical identifiability individual parameter doe provide information dependency developed pair parameter quantify dependency define conditional mutual information parameter pair aligned _j\mid _j\mid y=y =\theta aligned evaluates average information variable _i\ _j\ obtained posteriori defined parameter statistical model except _i\ _j\ closed-form expression typically available therefore numerical approximation required integral form given aligned aligned y\mid _j\mid aligned aligned aligned _j\mid y\mid y\mid aligned 21a aligned y\mid _i\mid y\mid aligned 21b aligned y\mid _j\mid y\mid aligned 21c via bayes theorem remark term differential entropy conditional mutual information defined aligned _j\mid _i\mid _i\mid aligned 22a aligned y\mid y\mid y\mid y\mid aligned 22b formulation requires evaluating joint distribution namely y\mid y\mid y\mid y\mid typically joint distribution closed-form expression must approximated sake illustration assume parameter uncorrelated prior observing data consequence assumption relation developed _i\ _j\ discovered solely data furthermore also reasonable assume prior knowledge parameter independent input model substituting 21a 21c obtain aligned aligned y\mid y\mid y\mid y\mid y\mid aligned aligned similar estimating practical identifiability estimate conditional mutual information using monte-carlo integration _j\mid _j\mid aligned aligned _j\mid k=1 k=n_ outer _j^ _j^ aligned aligned _i^ _j^ drawn prior distribution respectively drawn likelihood distribution y\mid _i^k _j^k conditional evidence obtained mean marginalization aligned aligned 25a aligned aligned 25b aligned aligned 25c similar estimating practical identifiability conditional evidence 25a 25c efficiently estimated using importance sampling along gaussian quadrature rule however noted 25a integral two-dimensional space therefore requires inner quadrature point numerical experiment section present numerical experiment validate information-theoretic approach examine practical identifiability estimate obtained global identifiability compared variance-based global sensitivity analysis mean first-order sobol index computed using salib see supplementary material first linear gaussian statistical model considered practical identifiability analytically examined proposed information-theoretic approach model computationally efficient therefore ideal conducting estimator convergence study next practical identifiability reduced kinetics model methane-air combustion considered reduced kinetics model widely used numerical analysis chemically reactive flow since embedding detailed chemistry combustion often infeasible reduced kinetic model often parameterized constructing model practically identifiable parameter desirable improve confidence model prediction application linear gaussian model identifiability framework applied linear gaussian problem closed-form expression available conditional mutual information see supplementary material consider statistical model aligned aligned n\times called feature matrix prior distribution given m\times model likelihood therefore given y\mid n\times constant considered known evidence distribution model given +\gamma model-form error exists consider feature matrix aligned pmatrix pmatrix aligned i\mid i=1 linearly-spaced point interval m=3\ mean statistical model uncertain parameter assume uncorrelated measurement noise =\sigma 0.1\ purpose parameter estimation synthetic data generated using assuming ^t\ n=100\ figure convergence variance practical identifiability estimator linear gaussian statistical model left number quadrature point inner 50\ considered number monte-carlo integration sample outer varied bias convergence practical identifiability estimator case linear gaussian statistical model right outer 10^ considered inner varied given inner increasing outer reduces variance whereas increasing inner given outer decrease bias estimate full size image figure convergence variance practical identifiability estimating parameter dependency linear gaussian statistical model left number quadrature point inner 50\ considered number monte-carlo integration sample outer varied bias convergence estimating parameter dependency case linear gaussian statistical model right outer 10^ considered inner varied given inner increasing outer reduces variance whereas increasing inner given outer decrease bias estimating parameter dependency full size image parameter identifiability goal framework developed estimating practical identifiability ass practical identifiability statistical model controlled experiment conducted consider using uncorrelated prior distribution identifiability study ensures information obtained due observation data discussed estimating parameter dependence using historical parameter estimate improve prior remark affect identifiability analysis however considered prior refinement figure illustrates convergence error estimating information gain parameter using estimator developed estimating practical identifiability expected fixed number quadrature point increasing number monte-carlo integration point decrease variance estimation however fixed outer increasing number quadrature point reduces bias estimate figure illustrates variance bias convergence error estimating parameter dependency described estimating parameter dependence expected observed variance error controlled accuracy monte-carlo integration outer bias controlled quadrature approximation inner figure first-order sobol index left information gain center information gain equivalent variance right linear gaussian model sobol index show output statistical model largest variability due uncertainty _1\ followed _2\ _3\ variable exhibit largest gain information therefore highest practical identifiability followed _2\ _3\ direct observation model variable _1\ lowest measurement uncertainty followed _2\ _3\ full size image figure first-order sobol index left estimated information gain right vs. measurement noise variance ^2\ linear gaussian model increasing measurement noise covariance doe affect variability output respect parameter therefore first-order sobol index remain unchanged however information gain decrease increasing measurement noise covariance full size image first-order sobol index estimated information gain information gain equivalent variance shown figure estimated first-order sobol index see supplementary material convergence study show considered linear gaussian forward model largest output variability due uncertainty _1\ followed _2\ _3\ implies forward model sensitive parameter _1\ followed _2\ _3\ surprising since i\mid i=1 point interval thus according first-order sobol index relevance parameter follows order _1\ _2\ _3\ estimated information gained agrees well truth obtained trend suggests data informative _1\ followed _2\ _3\ discussed estimating practical identifiability practical identifiability follows trend furthermore reported previous work seen parameter good identifiability characteristic also exhibit high model sensitivity using hypothetical direct observation model described estimating practical identifiability smallest measurement uncertainty obtained variable _1\ followed _2\ _3\ parameter high practical identifiability associated low measurement uncertainty direct observation model figure illustrates variability first-order sobol index estimated information gain measurement noise variance ^2\ first-order sobol index account parameter uncertainty therefore remain unchanged increase measurement noise however estimated information gain thereby practical identifiability decrease measurement noise observation corroborates intuition large measurement uncertainty lead large uncertainty parameter estimation figure show second-order sobol index true estimated dependency parameter pair linear gaussian model examining second-order sobol index see supplementary material convergence study show negligible interaction parameter pair estimated parameter dependency agree well truth trend preserved bias observed due error approximating conditional evidence shown figure clearly seen parameter _1\ _3\ high dependency mean parameter compensate one another combined effect output statistical model parameter associated feature i\mid i=1 i\mid i=1 ^3\ fact similar effect statistical model i\mid i=1 observation also show low practical identifiability _3\ mainly due underlying dependency _1\ pair combined effect statistical model figure second-order sobol index left true parameter dependency center estimated parameter dependency right linear gaussian model second-order sobol index show negligible interaction parameter pair obtained estimate parameter dependency agrees well true value trend preserved _1\ _3\ largest dependency one another therefore expected combined effect output statistical model full size image figure correlation plot sample obtained true posterior distribution left obtained aggregate posterior prediction right linear gaussian model negative correlation observed _1\ _3\ whereas _2\ uncorrelated parameter aggregate posterior prediction agrees well data exhibit high certainty full size image parameter estimation linear gaussian model joint distribution written aligned pmatrix bmatrix bmatrix bmatrix bmatrix pmatrix aligned analytical posterior distribution given post post post y-\mu post a\sigma using gaussian conditioning sample posterior distribution aggregate posterior prediction shown figure variable _1\ _3\ negative correlation whereas _2\ uncorrelated parameter mean parameter variable _1\ _3\ linear dependency _2\ doe dependency dependency suggested priori analysis conducted statistical model illustrated figure aggregate posterior prediction agrees well data exhibit high certainty figure change parameter variance ^2_ vs. measurement noise covariance ^2\ linear gaussian model increasing measurement noise result smaller change parameter variance prior posterior largest reduction variance observed _2\ followed full size image figure illustrates change variance parameter _i\ defined ^2_ ^2_ ^2_ post versus ^2\ parameter _2\ exhibit smallest posterior uncertainty followed _1\ _3\ ^2\ _1\ largest estimated information gain figure center exhibit dependency _3\ figure right thereby resulting larger posterior uncertainty comparison _2\ practical application model selection parameter selection critical examining information gain parameter dependency therefore aid finding parameter estimated high certainty increasing measurement noise result smaller change parameter variance parameter exhibit larger posterior uncertainty also shown variation estimated information gain measurement noise figure right contrary first-order sobol index remain unchanged measurement noise figure left application methane chemical kinetics accurate characterization chemical kinetics critical numerical prediction reacting flow although significant advancement computational architecture numerical method embedding full chemical kinetics numerical simulation almost always infeasible primarily high-dimensional coupled ordinary differential equation solved obtain concentration large number involved specie result significant effort made develop reduced chemical kinetics model seek capture feature ignition delay adiabatic flame temperature flame speed observed using true chemical kinetics reduced mechanism typically formulated using combination theory intuition leaving unresolved chemistry resulting uncertainty relevant rate parameter selecting functional form modeled reaction rate term lead reliable parameter estimation highly desirable mean high confidence parameter estimation thereby model prediction underlying parameterization reaction rate term must exhibit high practical identifiability shock tube ignition canonical experiment used develop validate combustion reaction mechanism experiment reactant mixture behind reflected shock experience elevated temperature pressure followed mixture combustion important quantity interest experiment time difference onset reflected shock ignition reactant mixture defined ignition delay ign ignition delay characterized time maximum heat release steepest change reactant temperature therefore key physio-chemical property combustion system figure temperature evolution stoichiometric methane-air combustion t_o\ p_o\ kpa mean 2-step mechanism comparison gri-mech 3.0 ignition delay time ign mixture release maximum heat under-predicted nearly order magnitude 2-step mechanism full size image illustrate practical identifiability framework consider stoichiometric methane-air combustion shock tube adiabatic ideal-gas constant pressure ignition assumption typically chemical kinetics capturing detailed chemistry methane-air ignition computationally expensive due hundred associated reaction model reaction chemistry consider classical 2-step mechanism proposed westbrook account incomplete oxidation methane reduced mechanism consists total specie reacting inert specie namely n_2 reaction reversible thus drastically reducing cost evaluating chemical kinetics reaction involved reduced chemical kinetics model aligned aligned aligned aligned overall reaction rate temperature-dependent modeled using arrhenius rate equation aligned k_1\triangleq ae^ -48400 -0.3 1.3 aligned aligned 3.98\times 10^ -40000 _2o 0.5 0.25 aligned aligned 5\times 10^ -40000 aligned a=2.8\times 10^9\ pre-exponential factor ideal gas constant temperature kelvin solve resulting reaction equation cantera v2.6.0 used figure illustrates temperature evolution using 2-step mechanism gri-mech 3.0 initial temperature t_o\ initial pressure p_o\ kpa stoichiometric ratio =1\ gri-mech 3.0 mechanism consists detailed chemical kinetics specie reaction noticed 2-step mechanism under-predicts ignition delay nearly order magnitude improve predictive capability 2-step mechanism functional dependency pre-exponential factor introduced t_o aligned t_o t_o aligned _2\ _3\ uncertain model parameter similar parameterization used -dodecane reduced chemical kinetics noted expressive functional form pre-exponential factor chosen goal framework ascertain practical identifiability parameter estimation consider detailed gri-mech 3.0 exact solution combustion problem used generate data consider logarithm ignition temperature =1.0\ p_o\ kpa available data model calibration assume uncorrelated measurement noise =\sigma 0.1\ parameter identifiabiliy practical identifiability framework applied methane-air combustion problem examine identifiability model parameter controlled experiment conducted consider uncorrelated prior distribution model parameter _1\sim _2\sim _3\sim prior result pre-exponential factor order similar previously reported therefore considered suitable study similar application linear gaussian model historical estimate model parameter considered examining identifiability figure first-order sobol effect index left information gain center information gain equivalent variance right methane-air combustion model sobol index show largest variability output statistical model uncertainty _1\ _2\ _3\ exhibit similar variability variable exhibit information gain therefore highest practical identifiability _2\ _3\ similar information gain variable _1\ exhibit lowest measurement uncertainty direct observation model followed similar uncertainty _2\ _3\ full size image first-order sobol index estimated information gain information gain equivalent variance shown figure information gain estimated using outer =12000\ monte-carlo sample inner =5\ quadrature point examining first-order sobol index see supplementary material convergence study output forward model exhibit largest variability due uncertainty variable _1\ followed similar variability model output respect _2\ _3\ largest information gain observed variable _1\ followed similar gain _2\ _3\ mean _1\ highest practical identifiability followed much lower identifiability _2\ _3\ using hypothetical direct observation model described estimating practical identifiability variable _1\ largest practical identifiability exhibit lowest measurement uncertainty followed similar uncertainty _2\ _3\ figure second-order sobol index left estimated parameter dependency right methane-air combustion model trend suggests underlying interaction parameter _2\ _3\ pair _1\ _2\ _1\ _3\ nearly dependency one another pair _2\ _3\ exhibit low dependency full size image figure show second-order sobol index estimated parameter dependency second-order sobol index see supplementary material convergence study follow trend suggesting underlying interaction parameter _2\ _3\ observed low identifiability _2\ _3\ suggested figure primarily due underlying dependency pair estimate parameter dependency outer =12000\ monte-carlo sample inner =5\ quadrature point used single two-dimensional integration space respectively similar magnitude parameter dependency obtained pair addition similar information gain _2\ _3\ also suggest underlying symmetry respect _1\ mean interchange _2\ _3\ affect output statistical model clearly seen =1\ also evident second-order sobol index suggest combined effect output statistical model due interaction _2\ _3\ figure correlation plot sample obtained posterior distribution left obtained aggregate posterior prediction right methane-air combustion model correlation plot reveal relation among variable aggregate posterior prediction agrees well data exhibit high certainty full size image parameter estimation let consider parameter estimation problem seek posterior distribution typically closed-form expression posterior distribution available due non-linearities forward model chosen family prior distribution alternative sampling-based method markov chain monte carlo mcmc seek sample unnormalized posterior gained significant attention method construct markov chain stationary distribution posterior distribution metropolis-hastings algorithm mcmc method used generate sequence sample given probability distribution adaptive metropolis algorithm powerful modification metropolis-hastings algorithm used sample posterior distribution figure illustrates correlation sample obtained using adaptive metropolis algorithm obtained aggregate posterior prediction ignition delay time linear correlation observed variable however joint distribution pair show similarity similarity also observed priori analysis quantifying parameter dependency shown figure figure aggregate temperature evolution methane-air combustion model aggregate prediction agrees well gri-mech 3.0 detailed mechanism full size image figure aggregate specie concentration evolution methane-air combustion model aggregate prediction agrees well gri-mech 3.0 detailed mechanism full size image obtained aggregate prediction show dramatic improvement 2-step mechanism predicting ignition delay time wide range temperature using functional form pre-exponential factor also improved mixture temperature evolution shown figure however adiabatic flame temperature defined mixture temperature upon reaching equilibrium still over-predicted improvement prediction evolution specie concentration time also noticed shown figure concluding remark perspective examining practical identifiability statistical model useful many application parameter estimation model-form development model selection estimating practical identifiability prior conducting controlled experiment parameter estimation study assist choice parametrization associated high degree posterior certainty thus improving confidence estimation model prediction work novel information-theoretic approach based conditional mutual information presented ass global practical identifiability statistical model bayesian framework proposed framework examines expected information gain parameter data performing controlled experiment parameter higher information gain characterized higher posterior certainty thereby higher practical identifiability adopted viewpoint practical identifiability parameter doe binary answer rather relative practical identifiability among parameter useful practice contrast previous numerical approach used study practical identifiability proposed approach following notable advantage first controlled experiment data required conduct practical identifiability analysis second different form uncertainty model-form parameter measurement taken account third framework doe make assumption distribution data parameter previous method fourth estimator provides knowledge global identifiability therefore dependent particular realization parameter provide physical interpretation practical identifiability context examining information gain parameter information gain equivalent variance direct observation model also presented practical identifiability framework extended examine dependency among parameter pair even individual parameter exhibit poor practical identifiability characteristic belong identifiable subset parameter within subset functional relationship one another parameter within identifiable subset combined effect statistical model collectively identified find subset novel priori estimator proposed quantify expected dependency parameter pair emerge posteriori illustrate framework two statistical model considered linear gaussian model non-linear methane-air reduced kinetics model linear gaussian model shown parameter large information gain low parameter dependency estimated high confidence variance-based global sensitivity analysis gsa also illustrates parameter sensitivity necessary identifiability however conclusively shown inability variance-based gsa capture different form uncertainty lead unreliable estimate practical identifiability information gain equivalent variance obtained using direct observation model show parameter high practical identifiability associated low measurement uncertainty observed directly case methane-air reduced kinetics model shown parameter large dependency low information gain therefore low practical identifiability proposed estimator capture non-linear dependency reveal structure within parameter space performing controlled experiment non-linear dependency observed considering posteriori parameter correlation linear relation well understood