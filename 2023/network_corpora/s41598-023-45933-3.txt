introduction image synthesis natural language description field research focusing generating visual content image illustration based textual description prompt involves training machine learning model typically deep learning technique understand connection text corresponding visual output text-driven image synthesis aim develop system generate meaningful accurate image based text feature various application include creative design generation visual content various design purpose illustration book magazine website virtual world gaming automatically generate visual asset landscape character object virtual world video game based textual description procedural generation data augmentation creating synthetic image training machine learning model computer vision task helping expand size diversity available training data storytelling visualization aid generation visual representation storytelling helping illustrate scene concept described written narrative text-to-image synthesis typically involves training variational autoencoder vae generative adversarial network gan large dataset paired text corresponding image model understands map text visual feature capturing underlying pattern relationship training data significant progress prompted visual content generation text highly detailed realistic image accurately capture nuance textual description remain challenging however recent advancement deep learning technique including larger model improved training methodology shown promising result generating visually coherent contextually relevant image text prompt unique text-based image stylization system several step unsupervised style image initially divided foreground background image primary foreground colour gathered binarized spatial shape like text symbol icon assigned create content image picture style transfer applies foreground picture style content image researcher proposed technique stylizes shape text symbolic representation pattern binary image using input-style image styled geometric shape backdrop image combined legibility-preserving structure texture transfer method employed reduce discrepancy image followed architecture proposed model may draw necessary outcome creating higher-quality image synthesis synthesising simple complicated easy difficult generative adversarial network gans proposed ian good fellow eminent idea play various role every computer vision application unsupervised model act generative model synthesizing novel image similar image generating new tune existing one model proposed researcher work better natural scene face work aim bring robustness gan apart performance yanhua worked synthesizing dressing image given input image termed fitting gan model learns input image output generated according fitting model used regularization adversarial loss function jezia created model help synthesis realistic image story text using spatial relation word followed using two-stage model generator discriminator low-resolution image converted high-resolution image knn used compare image quality score valuable progress made computer vision image synthesis application researcher concentrated preserving semantic information image super-resolution gan used enhancing resolution quality low-resolution image advantageous upscale image without losing much detail introducing artifact basic idea behind super-resolution gan train generator network produce improved-resolution image low-resolution counterpart bert bidirectional encoder representation transformer well-trained language model transformer architecture basic block overtaken natural language processing tool trained using massive corpus text data understand context meaning word sentence critical feature bert bidirectional training considering context end word training allows capture deeper semantic understanding handle task require understanding closeness across different sentence part model trained large amount text mean like book article website enables learn broad range language pattern nuance pre-training bert trained task-specific datasets minimal adjustment model architecture fine-tuning process allows adapt specific task improve performance paved way advancement nlp inspired development several transformer-based model gpt-3 roberta albert achieved remarkable result comprehensive understanding language generation task hand language model acquired various field application researcher worked bert model news classification enormous data combined spark performance bert prof outstanding even extensive data study nmt bert work better contextual embedding fine-tuning downstream language understanding task inspires improve bert nmt use bert-fused model first bert uproot depiction input sequence attention mechanism fuse representation every layer encoder decoder nmt model related work many application include various language model researcher proposed language model using relational feature text represented feature type including n-grams word character n-grams etc. method analysis distance available token across document concentrate binary feature whereas model doe consider longer-range relation feature second approach followed using keyword detection vectorization corresponding keywords word various field work attempted various application language however researcher developed pre-trained model extractive summarization biomedical domain challenging approach trained sentence using biobertsum language model follows sentence position embedding mechanism working embedding mechanism model taken hand researcher unified model identify multiple paraphrase input sentence pair preprocessing method generates sentence embedding vector using sentence-bert model many researcher proposed multiple stream methodology processing text input arrive better information processing survey done author lining various word representation model starting raw text meaningful vector includes preprocessing tokenization noise removal segmenting word followed stemming lemmatization end tagging even though application may vary primary task involves text input record need understanding statistical property sentence word analyzed incorporated methodology ensemble model instead continuous bag word skip-gram etc publication bert subsequently gtp-3 represented significant advancement nlp provided overview significant language representation learning model developed nlp discussed development model time addition provides summary comparison contrast various model sentiment analysis proceeds evaluate primary benefit drawback researcher proposed two parameter-reduction method reduce bert memory usage training speed method scale better bert self-supervised loss model inter-sentence coherence reliably improves preliminary task multi-sentence input top model achieves state-of-the-art score glue race benchmark parameter bert-large bert all-purpose language representation model allows computer use rich two-way context contained natural language text sequence-transduction model transformer used attention mechanism approach classification carried parallel word input word sequence determine whether word function antecedent machine-readable text requires language model linguistic model predict likelihood context-related term language model research based unidirectional training seems daunting bert bidirectional unlike elmo transformer encoder-based word embedding used fine-tune classify patent model technique outperforms cnn word embeddings two million patent datasets concentrated patent claim alone indicating patent claim alone yield state-of-the-art classification result contrary popular belief fine-tun pre-trained bert much text yielding rich text information image production position embeddings proposed reflect word order transformer-based system like bert formal framework exists investigate empirically-driven high-performing model translation invariance monotonicity symmetry capture word distance vector space feature formalise behavior enable principled sinusoidal reinterpretation proposed work offer new probing test identical word probing indicator using mathematical function objectively detect general attention pattern related quality described multi-perspective fusion introduced improve image synthesis generator dynamic selection approach match text image feature contrast discriminator multi-class discriminant method using mask segmentation image different type improve discrimination joint probability image token related layout token observed using joint-decoding transformer give extra observed data describe complicated scenesâ€”added layout-vqgan invested encoding decoding extra information concerning complicated scenario attention approach object generator may provide fine-grained feature targeted object using effective dual generator initial image properly formed fuzzy image content refined help dynamic memory module introduced proposed method researcher developed novel approach called multi-perspective fusion improve text-to-image synthesis approach generator incorporates dynamic selection mechanism match text feature image feature enabling accurate synthesis meanwhile discriminator utilizes multi-class discriminant method mask segmentation introduced additional type enhance discrimination capacity proposed framework called raseedgan randomly-seeded super-resolution gan designed evaluate field quantity randomly sparse sensor without relying full-field high-resolution training utilizing random sampling algorithm gain fragmentary perspective high-resolution underlying distribution even sparse noisy finding promising author considered methodology generating statistical property text hand synthesizing corresponding image text input challenging synthesising high-quality image computer vision application challenging task overcome disadvantage single-stage gan network author brought two-stage network resulting enhanced resolution image work proposes keyframes selection strategy video description using boundary-based method allows system encode visual information picking small subset keyframes construct video description without considerable degradation text-to-image synthesis model architecture designed synthesizing image corresponding tamil text description architecture proposed work well based statistical information since tamil morphologically rich language necessary look language model synthesizer network new dataset created applying google translator translate english text caltech ucsd -birds oxford-102 datasets tamil language image synthesis architecture shown fig figure text image synthesis architecture full size image model leverage ability tbertbasecase generate meaningful sentence embedding model fused tbertbasecase basegan introducing language model word embedding proposed method generates improved resolution realistic image tamil text two demanding datasets dataset oxford flower dataset cub text collected tamil sentence corresponding english text translated using google translate create corpus trained oxford-102 contains class set image file description figure show google translate translated english sentence tamil text file probably sentence cub dataset also developed experimentation figure show translation figure text translation using google translate full size image tbert basecase model language model preliminary work focus understanding statistical property input text result generation text vector bert model initial transformer framework developed processing text enhanced various version masked unmasked cased uncased depending upon corpus learning language taken training proposed language model tried use bert basecase model trained tamil text corpus fine tuning last layer processing sentence feature study done using bert named bert basecase model proposed model tbertbasecase model trained tamil input text aim study property sentence generate corresponding text vector bert model advantageous language model like glove embedding etc since algorithm work bi-directional left right unique processing text feature proposed tbert base case model take input text sentence followed hidden layer tbert basecase model layer hidden unit process data hyperparameters around tamil morphology language challenging task token embeddings initial token representation feed bert transformer block transformer block start self-attention let token recognise value token input sequence self-attention compare token creates weighted sum token embeddings calculate attention weight method help model grasp local global input sequence dependency self-attention transformer block residual connection residual connection let model preserve token embedding information avoid vanishing gradient problem training self-attention output added element-by-element token embeddings transformer block refines token input sequence contextualized embeddings combine static token embeddings contextual information self-attention ffn bert numerous transformer block stacked model capture complicated relationship refines token representation layer passing output block next block bert word embeddings last transformer block token representation schematic representation text processing using tbertbasecase presented fig embedding vector text depicted table figure tbertbasecase language model full size image table feature vector representation input text full size table consider given set sentence text token value fed input token input layer result pas various hidden layer customized according given tamil input feature token generate feature vector 2\dots employing concatenation summing last layer vector hidden layer transformer depicted objective function tbert base case model represented h\left h\left logt_ bertbasecase log\left embedding_ text elemetwise\ sum denotes number token given text token given text represents various text token text concatenation vector hidden layer represented equation represents objective function tbert base case model hidden layer consists token embeddings â€”contextualised embeddings elementwise sum drafted basegan model image generation generator discriminator network gan proposed base image synthesis model deployed using tamil text-to-image synthesis network earlier many image synthesis model proposed work using encoder output image caption model study work receiving latent vector previous language model named tbert base case model latent output vector fed generator network noise function preprocessed image feature vector similarly output generator network fed discriminator along generator noise function two noise function sent along text feature vector minimax adversarial loss function architecture represented fig figure basegan image synthesis network full size image basegan model input image vector image text feature vector image vector transformed tensor value size size image vector generic objective function gan network represented minmaxgd\left d\right x\sim\ pdata loglog d\left x\right z\sim\ loglog\left 1-d\left g\left z\right noise function supplied random value generator discriminator let text vector corresponding image vector gan model trained fashion generator maximizes loss discriminator minimizes generator loss minimizing maximizing equation given t\right pdata loglogd t\right log 1-d\left g\left z\right t\right z\sim log d\left g\left z\right t\right g\left z\right â€”noise function generator d\left x\right â€”discriminators probabilistic value real instance real x\sim pdata -expected overall real data â€”discriminator loss function â€”generator loss function t\right pdata â€”expected over-all real data image text vector z\sim â€”expected overall random input generator input image text vector equation represents loss function discriminator maximizing minimizing objective function pdata\ refers distribution feature vector naturalistic image pz\ refers data distribution latent space concerning discriminator first term denotes expectation logarithm discriminator output given real sample discriminator aim maximize term correctly classifying real sample close second term represents expectation logarithm discriminator output given generated sample represents random noise vector sampled prior distribution discriminator aim minimize term classifying generated sample close 0.eq represents generator loss function.the expectation logarithm generated sample random noise vector sampled prior distribution generator maximises term make discriminator classify generated sample real hybrid super resolution gan hsr gan hybrid super resolution gan hsr gan work similarly two-stage gan model super-resolution gans proved better image synthesis model various application conventional gan model two-stage model work super-resoluting synthesised image stage many application work single-stage gan network still lack minute information essential part synthesised image model work residual block super resolution gan two-stage model work similarly base gan model considered stage output fed stage improving resolution model work like residual block splitting transforming aggregating function vector representation image vector provided form latent vector essential feature vector latent space pointed generate image generator image size fed input generator stage along word embeddings tbert basecase language model model architecture two-stage hybrid super resolution gan network described fig figure architecture hybrid super resolution gan hsr gan model full size image stage gan receives output image stage improve resolution hybrid super-resolution gan work wasserstein loss function employed generator discriminator wasserstein function significant advantage bringing difference original fake image generated two component involved natural distribution value real generated distribution value image generated mathematical form minimum distance follow earth mover distance calculated considering transfer plan data converted authentic generated image gain experiencing wasserstein loss function create large gap across real fake image generated intends solve problem understanding realness image generated moreover also help stabilizing model training model wasserstein loss function creates notion discriminator critic try bring important gradient information everywhere training model representation hsrgan follows refers high resolution image generated representation low-resolution image generated stage stage network objective function represented minmax d\right x\sim pdata log\mathrm log loglog\left 1-d\left g\left loss function corresponding stage wasserstein loss represented loss wdg =e\left c\left real g\left z\right clear wasserstein loss function aim evaluate critic value real image distribution fake image generated denotes critic value loss function critic value number discriminator output determined critic output depends lipschitz constant depicted c=1-lipschitz\ continuous distance emd i=1 j=1 real g\left z\right â€”being representation low-resolution image generated stage-i stage network â€”refers high resolution image generated stage-ii network expected overall real data high-resolution image generated stage-ii network â€”expected overall real data low-resolution image generated stage network d\left g\left â€”probabilistic value fake instance low-resolution image actual câ€”the critic value number discriminator output determined critic output distance emd â€”earth mover distance real fake distribution result discussion model evaluated using score fid calculates kullbackâ€“leibler divergence conditional distribution y|x marginal distribution inceptionscore.f1 score calculates precision recall value synthesised image resolution image tends lower grade enhanced two-stage gan explained forthcoming model image obtained resultant convincing still lack high-resolution feature pave way enhancing output basegan model using hsrgan model testing training set represented table table dataset cub-200 oxford-102 full size table figure show image generated result basegan resolution improvement hsrgan fig resolution improvement better level dealt mean squared error mse structural similarity index measure ssim across epoch training value ssim mse considered evaluate minimal similitude natural fake image score resembles image provides better reconstruction image initial epoch mse value higher rate gradually decreasing help reconstruct image mse figure deviation estimated feature image generated term square difference pixel value given case discrepancy image stage generated stage term similar pixel value prof enhancement feature two level figure generated image using basegan hsrgan network oxford-102 dataset full size image figure generated image using basegan hsrgan network cub dataset full size image figure mse score generated image quality using hsrgan ssim similarity index generated image quality using hsrgan full size image similarly ssim also used measuring perceived image quality measure brightness contrast image also symbolizes higher value ssim quality image generated formulation mse ssim mse ssim 2\mu_ 2\sigma_ mean standard deviation hrlr cross-covariance generated image real image input sequentially inception score represented follows exp y|x p\left produced imagery analysis pre-trained inception network image label higher produce higher-quality image classified another frÃ©chet distance metric fid fid predicts feature space picture using pre-trained inception network equation show fid score fid=|| +trace\left mean covariance real synthesised image contrast fid minimum value show realistic image distribution alike measure provides combined way represent precision recall capture property equation represents measure f1\ measure=\frac precision recall precision+recall gan proved outstanding practice image synthesis application model hand image synthesis tamil two level performance base gan model hsrgan model primary concept proposed work novel idea brought limelight tamil language development stage long way explore proposed architecture starting point enhancement tamil language support various application regional language initial stage language model aim generate vector representation tamil text input rear end gan model synthesize image corresponding text vector strength model lie far generate image application english language par various model proposed model proposed author work text-to-image reversal vice-versa format model employed author image-text-image model using gan model method used calligraphy casia-hwdb dataset chinese database handwritten character tested model transfer model gave convincible accuracy character compared english much done pre-trained english text vector like wordtovec skip thinking vector glove embeddings others preprocess text gan model match attngan gan image text encoders using common ms-coco dataset bidirectional lstms processed text data white top pillow table group evaluation scored using blue-1 blue-2 however past study generated photo english text description required much technology methodology proposed challenging relevant tamil text description primary model work brought lime light tamil language previous work research done english language comparative performance evaluation done embedding vector generated tbertbasecase language model along pre-trained gan network like attngan stack gan proposed architecture evaluated existing architecture performance assessed figure show valuation metric cub-200 oxford-102 test set among proposed model hsrgan outperforms basegan pre-trained gan architecture basegan comparatively better along pre-trained model figure portrays performance concerning fid score proposed hsrgan outperforms trained architecture score convincing satisfactory next run fig prof performance architecture score among provided model projected work prof better evaluation despite tamil text processing complexity proposed model outcome match stackgan thus quantitative comparison indicate persuasible performance synthesising realistic high-resolution image conditioned tamil text accomplished figure inception score evaluation full size image figure fid score performance estimation full size image figure f1-score valuation full size image conclusion synthesis image text intriguing stream research computer vision image synthesis tamil text critical since rich morphology tbertbasecase language basegan model early stage combining tamil language well-known gan model however still performance basic architecture convincible need improvement incorporated using super-resolution gan architecture basegan model enhanced using two-stage gan model named hybrid super resolution gan hsrgan revamp resolution image model improved using enhanced pattern high-resolution gan model autoregressive model