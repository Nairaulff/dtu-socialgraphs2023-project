introduction rise mobile internet internet thing iot complex software find application kind new device number architecture running program multiplied cot software component increasingly integrated closed-source product brings security risk challenge terminal example extensive use open source software resource sharing lead increased security risk large number terminal insecure physical environment likely cause leakage user business sensitive information sumap pointed cve vulnerability trend security analysis report number cve statistic ranked first number reached astonishing 13,000 therefore automatic analysis software artifact compiled form binary code great significance time finding similar function compiled code segment get attention bcsd technique used measure similarity relationship two binary program component depending detection granularity program component basic block granularity function granularity entire program binary code similarity applied scenario software plagiarism detection malware detection analysis vulnerability detection one main challenge bcsd source code compiled different binary code using different version compiler selecting different compilation option etc shown fig modifying gray box figure make source code compiled different semantically equivalent binary program happen time example order improve efficiency program version compiler may changed compiler may changed completely order suitable different architecture target platform changed possible deliberately apply obfuscating transformation generate polymorphic variant source code ideal goal bcsd identify similarity binary code corresponding source code undergone different conversion figure extended compilation process full size image paper propose novel architecture mffa-net detect binary code similarity propose sff module introducing shallow feature mlp network learn global structural feature put forward aff module studying feature fusion method depth relationship feature captured attention matrix attention mechanism added feature feature fusion extract refined feature mffa-net aim extract overall structural feature finer feature without reducing efficiency related work traditional binary code similarity detection considering application challenge many binary code similar method proposed traditional method mainly include binhunt ibinhunt binclone multi_mh discovre etc binhunt employed new graph isomorphism technique symbolic execution theorem proving identify semantic difference ibinhunt utilized deep taint identify semantic difference control flow program still low accuracy high overhead binclone used hashing obtain fixed-length value variable-length instruction sequence represents piece binary code bit-vector compute similarity multi_mh first cross-architecture binary code search method indexed function based input output semantics example given function compiled cpu architecture x86 multi_mh find similar function compiled architecture discovre used number arithmetic instruction call instruction basic block feature backtracking algorithm repair incorrect match however algorithm time-consuming difficult deal large number function pair david developed tool called esh successor gitz used large-scale detection high accuracy chandramohan proposed scalable robust binary search engine called bingo captured full function semantics inlining related library user-defined function disadvantage false positive rate high cross-optimization option scenario dynamic analysis required cooperate static analysis deep learning-based binary code similarity detection method based deep learning divided end-to-end detection method multi-stage detection method end-to-end detection method mainly include Î±diff asm2vec codecmr etc order avoid manually selected feature method directly extract feature using instruction raw byte multi-stage detection method include feature selection feature encoding feng proposed bug search approach genius first used embedding vector feature selection proposed novel neural network-based approach gemini similarity detection gemini graph embedding model embed control flow graph cfg function zhu proposed similar detection method siminspector based neural machine translation nmt graph embedding validated siminspector higher gemini similarity detection accuracy rate zuo implemented prototype system innereye large-scale binary code analysis used embeddings natural language processing nlp encode categorical feature bindeep hybrid model proposed tian bindeep used rnn identify specific type two function used siamese neural network calculate similarity two function although embedding automatically learn feature embedding function doe provide information learning content massarelli proposed novel architecture safe directly extracted function feature based assembly instruction achieves high performance added application scenario based article published safe architecture doe incur computational overhead building manipulating control flow graph lead considerable speed advantage general work stripped binary multiple architecture still need improved model latter word greater impact result previous word used capture semantics entire function efficiency reduced effect worse problem definition solution overview problem definition source code changed gray part shown fig similar binary file disassembled obtain similar binary function paper considers similar function different compiler similar binary function result compiling original source code different compiler compiler map source code corresponding binary function specific software considered compiler paper use represent assembly instruction list composes function represents number instruction data processing represented vector embedding vector obtained mapping retains similarity structure binary function mffa-net overview process identifying similarity two binary function shown fig mffa-net-based embedding model take pair binary function input computes similarity score output two step embedded model structure used first step assembly instruction embedding component convert sequence assembly instruction sequence vector second step mffa-net convert sequence vector single embedding vector assembly instruction embedding instruction mapped vector real number using instruction2vec i2v model trained large corpus instruction sequence vector final output step mffa-net two module network first semantic feature fusion sff module concatenating input feature advanced semantic feature remedy lack overall semantic information caused incomplete feature information captured rnn advanced semantic feature compute summary vector taking account instruction context using bi-directional recurrent neural network attention feature fusion aff module designed find useful information various feature research relationship feature figure process identifying similarity two binary function full size image detail mffa-net model based safe input model binary code function instruction overall structure model shown fig advanced semantic feature extraction module model take word embedding input safe extract function embedding ssf module model concatenates advanced semantic feature word embedding feature learn multi scale feature fully connect layer maxpooling\ layer extract ssf feature aff module matrix computed advanced semantic feature ssf feature present interaction feature model interaction attention compute weight feature finally concatenates weighted feature compute function embedding figure overall framework mffa-net full size image semantic feature fusion module sff module concatenate word embedding help obtain overall information function high-level feature extracted bi-directional recurrent neural network help capture context function shown fig sequence instruction vector achieved training i2v model large corpus instruction fed bi-directional neural network obtaining summary vector size rnn rnn concatenation operand rnn rnn represent forward backward rnn cell respectively forward backward state rnn state rnn cell size u/2\ instruction embedding size concatenating input instruction vector get summary vector size obtain matrix summary vector mlp network constructed matrix transformed fusion feature embedding using layer tanh\ activation global maxpooling\ layer compute size maxpooling tanh fully connected layer learn overall semantic information function perform maxpooling\ operation reduce information loss retain characteristic information attention feature fusion module aff module in-depth study relationship feature extract cross matrix point cross matrix record interaction factor feature firstly used compute feature embedding size self-attentive network safe method cross matrix size computed sff module qp^ attention weight compute follow aligned softmax softmax aligned weight matrix size weight acted weight acted normalization cross matrix finally fusion feature attention weight get embedding vector size concatenation operand attention weight represent degree weakening increasing feature input feature vector added attention weight obtain weighted feature vector make feature vector expression accurate goal make sure source code higher similarity score others safe use siamese network embedding model reduce loss use cosine distance compute similarity two binary function obtained using i2v mffa-net model cosine similarity calculated following formula sim -th component similar sim otherwise dissimilar sim experiment experiment implemented tensorflow python version 3.6.9 optimizer adam dimension function embedding size train model epoch optimal setting model learning rate 0.001 batch size parameter set safe detailed configuration information follows computer configuration ubuntu 18.04 64-bit memory intel core i7-6700t cpu 2.80ghz gpu geforce gtx 950a tensorflow version 1.5.0 datasets two datasets used verify effectiveness method one amd64armopenssl dataset 95,535 function compiled cross-platform amd64 arm amd64multiplecompilers dataset 452,598 function compiled single platform amd64 amd64armopenssl dataset generated using one compiler gcc-5.4 optimization level 0-3 amd64multiplecompilers dataset generated using three compiler clang-3.9 gcc-5.4 gcc-3.4 optimization level 0-3 basic statistic datasets shown fig figure datasets analysis full size image two pair similar pair dissimilar pair created function two datasets total number pair finally obtained twice total number function similar pair labeled dissimilar pair labeled generate training test pair described literature function amd64multiplecompilers dataset divided 14:3:3 training validating testing set i.e. training validating testing function amd64armopenssl dataset divided 4:1 training testing set i.e. training testing evaluation metric receiver operating characteristic roc curve chosen key performance index area curve auc higher auc better area roc curve also chose another important precision-recall curve evaluation index curve first used raghavan information retrieval become popular recent year area curve called average precision comparing prediction performance two new old model roc curve curve new model better old model time performance new model considered better old model experimental result compared method safe method used two evaluation metric auc verification first reproduce effect safe method two datasets effect amd64armopenssl dataset lower literature use cross-validation training quantitative comparison multi result time time consumption model also considered experimental result shown table result amd64multiplecompilers dataset single-platform case model mffa-net get high score two metric 99.6 auc 99.6 table auc value safe model 98.8 98.8 respectively mffa-net model 0.8 higher term auc safe model training time mffa-net model min much min safe model 127,076 pair function test set need embedding inference time mffa-net model longer safe model result amd64armopenssl dataset cross-platform case term auc considered crucial metric binary classification mffa-net outperforms safe one percentage point auc value safe model 97.1 97.3 respectively auc value model 98.3 98.1 respectively training time mffa-net model min much min safe model time taken mffa-net model infer 19,140 pair function test set longer time taken safe model table comparison result using different model two datasets full size table fig see roc curve mffa-net model completely cover safe model indicating mffa-net performs better safe figure show comparison result training loss two model seen fig convergence speed mmfa-net faster safe also prof training speed mffa-net faster figure performance comparison test set roc curve amd64multiplecompilers dataset curve amd64multiplecompilers dataset roc curve amd64armopenssl dataset curve amd64armopenssl dataset full size image figure training loss comparison full size image regardless whether single-platform case cross-platform case auc value mffa-net model better safe model compared safe total consumption training time inference time mffa-net model much smaller seems ability bcsd model efficient conclusion propose new approach mffa-net better capability bcsd single-platform cross-platform case mffa-net learn overall structural feature also deeply dig relationship feature evaluate method proposed two datasets used experiment experimental result fig table demonstrate mffa-net model valid bcsd mffa-net method high score overall auc compared safe mffa-net achieve better performance different metric seen table mffa-net great advantage training time future research continue optimize strive make inference time shorter also try apply mffa-net application scenario advanced persistent threat apt classification semantic classification etc