introduction art representation human specifically visual art manifestation idea feeling way life social context present throughout humankind history ancestral cave painting found continent different artistic style prevailed historical period painting century main mean documenting reality expressing emotion generating good artistic sample using deep learning technique significant importance several reason firstly enables exploration new possibility artistic creation leveraging capability artificial intelligence intersection art open avenue novel innovative artistic expression pushing boundary traditional artistic practice moreover generating high-quality artistic sample hold potential democratize art automating creation process ai-based system make art accessible wider audience irrespective artistic skill training inclusivity foster creativity allows individual engage art meaningful way promoting cultural appreciation expression furthermore deep learning model capture essence renowned artist claude monet recreate style remarkable accuracy preservation artistic heritage pay homage past master also allows contemporary artist build upon legacy leading continuous evolution artistic practice result distance priori abysmal art artificial intelligence narrowing recent year human gone deeper specific branch expressive artificial intelligence eai branch focus development intelligent algorithm capable generating work art essence eai substantially different research field since artistic ability creativity represents subjective quality doe allow define theoretical set rule evaluate algorithm output therefore design technique capable establishing interaction art challenge scientific community recent year envisioning possibility developing artistic world use branch computer science relation applied visual art numerous work carried recent year among aaron project initiated harold cohen currently still progress stand aaron algorithm engine combined database artistic technique capable generating creative version given canvas beyond generation new artistic image based concept creativity much effort scientific community recent year focused generation image mimic given artistic style particular evolution neural network last decade meant great advance aspect thus two essential element considered work style content style conceived way artist express idea canvas surface hand refer concept content work art semantic part representation object recognised style work art made algorithm sold auction first time piece question portrait edmond belamy inspired 18th century aesthetic project developed french multidisciplinary collective called obvious formed pierre fautrel hugo caselles-dupré gauthier vernier artist computer scientist economist respectively methodology used neural network whose training performed using dataset 15,000 portrait painted fourteenth twentieth century characteristic feature style particular period extracted context outlined far must completed mention french painter claude monet essential figure work since work unique style essential approach take eai claude monet 1840–1926 considered greatest exponent impressionist movement work characterised palpable obsession express emotion effect light produce nature going exile algeria avoid military service stay europe led growing interest study light different time different season gradually accentuated luminous effect point sometimes blurring form even fusing together common among contemporary paint seclusion studio gallery claude monet art based opposite intention capture canvas idea perfect landscape faithfully reflect nature surrounded therefore work made outdoors becoming one forerunner painting plein air outdoors furthermore conclude oil painting beyond condition moment doe follow prevailing line romanticism classicism realism place focus sens nature among important work highlight one shown fig figure water lily pool japanese bridge twilight venice full size image characteristic style monet work subject study scientific community repeatedly trying generate image mimic artist style article creating art deep learning published december applies compare different type architecture transfer style artistic painting photograph hand may see publication paper art2real unfolding reality artwork via semantically-aware image-to-image translation various architecture used generate landscape snapshot work different artist recently study carried kotovenko published march stand develops neural network architecture aim transform input image work painted different well-known artist kandinsky van gogh gauguin cézanne picasso monet among others another recent work vivek ramanujan propose new approach style transfer parameterised brushstrokes represent style image addition work recent work explored use stable diffusion model image style transfer importance study lie two key aspect novel training methodology applied art generation propose novel training methodology cycle gan model based top- approach inspired work unique training scheme potential enhance convergence performance model leading improved result term loss function image quality quantitative qualitative evaluation expert group provide comprehensive evaluation proposed methodology quantitative qualitative perspective latter performed expert group remainder paper follows following structure next section provides overview related work detail result following provide comprehensive discussion finally present method employed study related work rendering-based precedent prior analysis technique used generation artistic image necessary mention area knowledge included within graphic art known non photorealistic rendering npr area encompasses technique starting real image try simulate non-photorealistic representation example imitating style pencil drawing watercolor color canvas main limitation npr methodology whole lack flexibility algorithm thus algorithm specialise transferring specific style generalizable style therefore particular convolutional neural network cnns offer different strategy overcome limitation neural style transfer order overcome restriction exposed previous section particularly relevant experimental study convolutional neural network conducted led gatys became clear cnns able extract information style feature image based pattern detection key work discovery image produce content style activation well ability differentiate thus application style given image achieved iteratively updating weight relative content style present cost function disruptive work since presented restriction different style labelled training set needed study initiated current known neural style transfer nst whose technique establishes starting point two image content image includes semantic part i.e represented beach tree several people style image one containing texture aim achieve objective generate new image generated image semantic information content image style style image line study carried later johnson included open source implementation system proposed gatys al. consisted training vgg-19 proposed initial study result obtained similar gatys al. limited lack method ensure addition achieving style transfer generated image semantic content initial image preserved moreover computational cost required high sense worth mentioning work carried later team dimitry ulyanov proposed use feed-forward convolutional network image pattern recognition subsequent classification main difference work comparison one proposed gatys mainly based use efficient loss function involves shorter processing time thus managed considerably reduce time cost whole process hand rujie yin published january work attempted perform texture transfer aim preserving much possible semantic information starting image although also used vgg-19 starting point key system segmentation content image several part corresponding object semantic field fragmentation performed texture transfer carried individually part finally proposing union thus ensuring much accurate higher resolution transfer even though quality style transfer using nst gradually increasing result study carried regard present work opted technique different reason one hand computational cost training network subsequent implementation high hand previously analysed approach start single style image style image greatly reduces possibility term transferring impressionist feature define claude monet work likewise starting point present work single picture painter complete dataset large part work wide range feature texture characterise style shown subsequently apply input image lead reject use technique based use single image recent work include liu learn spatial attention score shallow deep feature adaptive attention normalization module adaattn alleviate content leak reversible neural flow unbiased feature transfer module artflow recent research effort explored contrastive learning approach image style transfer language-driven artistic style transfer ldast utilizing contrastive language visual artist clva consistent content structure analogous style pattern well zero-shot contrastive loss diffusion model enabling high-quality image generation without additional fine-tuning auxiliary network surpassing existing method task like image style transfer image-to-image translation manipulation generative adversarial network generative adversarial network gans gaining popularity recent year among scientific community since provide additional value traditional model consisting ability create content vanilla version gans described study goodfellow based definition model two antagonistic network generator discriminator vanilla version gans present several difficulty term network training collapse mode consisting fact generator verified set image useful fooling discriminator tends always create set losing variability output image consequently losing creativity oscillating loss meaning training gans loss generator discriminator become excessively large without converging iii lack ex-post control content generated image may result generated content meeting user requirement quality generated image unsatisfactory order overcome aforementioned obstacle vanilla version several version gans designed last decade first so-called wasserstein gan wgan successor wasserstein gan gradient penalty wgan-gp improvement vanilla version seek increase stability training model reducing collapse mode problem end replace binary cross-entropy loss function loss function correlate quality generated image hand conditional gans cgans address problem poor control content vanilla version purpose use external information guide image generation process thus cgan model always combine basic gan source external information discrete class label text description semantic map conditional image object mask attention map better control content generated image using cgans basis study known pix2pix great interest scientific community since publication key model transformation source image belonging one domain output image belonging another domain study show model able translate example domain image taken day image taken night day night fig image edge shown domain complete image shown edge photo fig figure example pix2pix model image-to-image translation cgans full size image view result obtained pix2pix model could seem priori good solution challenge posed present work allows conversion photograph domain monet frame domain however pix2pix model conceptual obstacle based supervised learning approach i.e training model requires labelled pair example word would need element domain order subsequently label introduce training process requirement impossible case given photograph corresponding landscape monet recreated work likewise able obtain work would painted author snapshot taken today limitation starting point study published month pix2pix work constitutes turning point gans paradigm since introduces concept cycle-consistent adversarial network cycle gans approach allows cross-domain conversion without requiring direct correspondence individual image domain needed labelled image belonging domain image need paired example illustrated previously would necessary pair photograph landscape day night photograph landscape taken day domain photograph landscape taken night domain beyond advantage cycle gan outperforms pix2pix approach given offer bidirectional conversion i.e allows image converted domain domain vice versa particular case use cycle gan model make possible convert photograph monet painting turn monet painting photograph way recreate landscape monet actually saw produced work generate work art today reality impressionist painter would done reason given far cycle gan model one chosen basis development present work architecture model composed four neural network two generator two discriminator d_x\ d_y\ transforms image domain domain hand transforms image domain domain d_y\ try discern whether input image real image fictitious image try resemble domain hand d_x\ try discriminate whether input image real image fake image try resemble domain applying scheme challenge posed present work image domain correspond photograph monet painting respectively therefore see fig generator try convert photograph monet painting generator transform work artist photograph hand discriminator d_y\ try discern input image really work painted monet fictitious image generated finally discriminator d_x\ decides whether input really photograph image generated painting figure cycle gans scheme applied present work—image adapted full size image work leveraging gan architecture include chen apply internal-external scheme learn feature statistic mean standard deviation style prior iest zhang learn style representation directly image feature via contrastive learning achieve domain enhanced arbitrary style transfer cast batziu introduces novel approach combine cyclegans fast adaptive bidimensional empirical mode decomposition fabemd effectively adopt specific artist style image proposed method modifies cycle-consistency loss incorporate texture information estimating corresponding bidimensional intrinsic mode function bimfs experimental result show approach outperforms state-of-the-art method artistic neural style transfer application top- gans approach continuing advance developed scientific community relation gans essential mention work carried sinha published october innovative methodology training gans addressed study argued order update generator weight gan dummy image created generator used image able best fool discriminator word realistic fake image produced lowest adversarial loss would used update weight generator author demonstrate work modification substantially improves result without increasing computational cost way shown fig batch image produced generator indicated blue bar left illustration similar real image used weight update process experiment performed different variant gans vanilla gan cgan wgan wgan-gp shown effectiveness top- approach lie discarding image created generator really similar output set way analysis carried show including image could cause gradient move wrong direction thus hindering convergence training quote abstract above-mentioned report ... gradient update computed using worst-scoring batch element sample actually pushed away nearest mode figure training process top- gans approach full size image date previous work taken advantage promising top- approach applied train cyclic structure like aforementioned cycle gans present work develops methodology evaluates result quantitative qualitative perspective transformer diffusion model besides cnn gan architecture visual transformer diffusion model based transformer also used recently style transfer task perform content-guided global style composition transformer-driven style composition module styleformer deng propose transformer-based method stytr2 avoid biased content representation style transfer taking long-range dependency input image account even recently diffusion model proven good alternative deal style content separately producing image art scope propose iterative latent variable refinement method applied denoising diffusion probabilistic model ddpm process generate high-quality image based reference image recently zhang proposed method able learn artistic creativity directly single painting guide synthesis another work leveraging difussion model chang introduce inst inversion-based style transfer method learns artistic style directly single painting enabling efficient accurate transfer without complex textual description achieving high-quality result across various artist style artificial intelligence art sum two recent review dealing artistic image generation artistic image style transfer former provides comprehensive analysis utilization artificial neural network deep learning visual art cover various application prediction classification evaluation generation identification field including photography pictorial art modeling video game architecture comic latter explores field ai-generated art discussing various deep neural network architecture model utilized creation classic convolutional network cutting-edge diffusion model provides overview structure working showcase milestone ai-generated art deepdream recent development like stable diffusion dall-e highlighting strength limitation work demonstrate ongoing evolution substantial growth artificial neural network visual art remarkable progress made deep neural network short period time showcase intersection art computer science field proposed approach section introduce data employed study also review proposed system based cycle gan architecture i.e composed two generator two discriminator d_x\ d_y\ unlike scientific community developing trained following top- approach proposed sinha data order develop evaluate proposed learning methodology cycle_gan/monet2photo dataset provided tensorflow used table summary table cycle_gan/monet2photo dataset full size table shown table composed photograph piece art monet proposed architecture work leverage cyclegan architecture train using top-k method show fig concretely generative network architecture adapted johnson known remarkable performance neural style transfer super-resolution task architecture consists three convolutional layer several residual block two fractionally-strided convolutional layer stride 1/2 final convolutional layer responsible mapping feature rgb output implementation perform experiment six nine residual block table table architecture size activation map implemented generator residual block using channel_last set-up full size table contrast discriminator network employ patchgans patchgans designed classify whether overlapping image patch real fake patch-level discriminator architecture boast fewer parameter compared full-image discriminator operates efficiently image varying size leveraging fully convolutional approach figure proposed approach implement cyclegan model patchgan discriminator train using top-k approach full size image resnet type generator generator model designed based upon resnet architecture resnet architecture similar u-net architecture mentioned study zhu incorporates skip-connections enable flow information non-consecutive layer also feature residual block encoder decoder component residual block allow addition input data block facilitating transfer relevant information output layer addition operation performed element-wise case dimension input output convolutional block match technique zero-filling convolution employed adjust dimension accordingly despite introduced resnet architecture remains widely used due effectiveness incorporation residual block promotes gradient back-propagation training effectively preventing issue gradient vanishing network depth increase additionally computational cost training resnet architecture increasing layer lower compared u-net architecture advantage led select resnet architecture work patchgan type discriminator structure chosen discriminator d_x\ d_y\ patchgan cnn whose purpose perform binary classification input image decide whether real fictitious however unlike cnns make decision patchgan architecture doe evaluate entire input image segment patch training phase patchgan network evaluates content patch decide whether real fictitious subsequently average result calculated generate final verdict complete image use patch-based analysis discriminator several advantage first allows localized style evaluation different patch may exhibit variation style within single image second encourages generator produce visually convincing result fine-grained level leading sharper realistic output lastly patch-based approach reduces computational complexity compared evaluating entire image making efficient training inference loss function cycle gans model generator loss calculated three component adversary loss cycle consistency loss iii identity loss first component adversary loss contains information answer following question image created generator manage deceive corresponding discriminator calculate enough use binary cross-entropy function since must compare tensor formed tensor prediction made discriminator second component cycle consistency loss evaluates goodness generator assumption complete cycle i.e. apply generator image source domain photograph afterwards apply generator generated fictitious image target domain getting back original image smaller difference source photograph reconstructed photograph effective generator mean absolute error mae used compare image source photograph reconstructed photograph finally third component identity loss try evaluate goodness generator following way generator fed image already belongs target domain keep unchanged realises already belongs target domain smaller difference input image output image efficient generator function also used compare two image correct weighting three component mentioned essential generation efficient model calculation discriminator loss simpler calculation generator loss vanilla gans calculate mean squared error mse real image fictitious image belonging domain final loss discriminator mean previous one top-k training proposed system discussed previously key study sinha use training image able fool discriminator effectively way generator weight updated using loss generated image value proposition present work consists applying training scheme cycle gans system consisting two generator two discriminator date approach applied linear gan-type scheme consisting one generator one discriminator update weight generator done taking account image created able confuse d_y\ discriminator effectively procedure applied training generator case taking account loss incurred d_x\ discriminator mentioned first iteration training prediction made discriminator random implies ability decide whether input image real image quite limited therefore make sense discard image batch first epoch proposed system training initiated using batch image update model weight however generator discriminator learn proportion batch image used gradually reduced following annealing schedule hand stated sinha al. recommended reduce value point selecting single item batch since would dilute effectiveness using sample training set initially set equal full batch size beginning training training progress systematically decrease constant factor epoch reach minimum value thus ensuring never progress point one element mini-batch equation show calculation epoch aligned max aligned represents decay factor minimum number element mini-batch value calculated used choose top- image effective deceiving discriminator explained previously component capture ability generator deceive discriminator known adversarial loss way discriminator issued verdict whether input image fictitious choose image higher probability real closer probability effective image fooling discriminator apply mask calculation adversarial loss take account loss calculation referred image result system evaluation cycle gan model described developed trained following two approach first one call basic vanilla one used scientific community date consists updating weight generator taking account sample batch second approach based proposed top- methodology take account update weight image able maximise deception respective discriminator quantitative evaluation section show quantitative qualitative result achieved training approach generator discriminator loss prior training cycle gan model using methodology pytorch ray tune library used detect optimal hyper-parameter combination case optimal understood combination minimises generator loss time maximises loss discriminator d_x\ d_y\ respect vanilla training methodology defined search space ray tune several hyper-parameters affect model performance see table table show optimal combination returned ray tune basic training methodology training epoch particular last row show hyper-parameter combination best satisfies min-max game table ray tune result vanilla training methodology full size table similarly table show best combination returned ray tune top- training methodology last row optimal choice hyper-parameters training epoch result prove top- methodology improves behaviour loss function offered vanilla training methodology since observe training model epoch proposed method reach lower loss level generator maintaining loss level discriminator d_x\ d_y\ vanilla version table ray tune result top- training methodology full size table validate result identifying optimal hyper-parameter combination trained vanilla top- methodology epoch figure show plot resulting loss curve obtained figure loss curve vanilla top- training epoch full size image training plot shown fig qualitatively support previous finding prove top- approach achieves lower level loss generator one charge creating monet frame basic training version regarding discriminator d_y\ one differentiating whether generated image really work monet system present similar level furthermore clearly observe top- training approach achieves uniform steady training loss evolving smother vanilla training approach lead conclusion choice top- image iteration training facilitates advance convergence training also cyclic model statement match finding sinha paper regarding training non-cyclic model structural similarity measure index ssmi structural similarity measure index ssmi technique used measure similarity two image specifically ssmi evaluates test image respect reference image quantify visual similarity metric first introduced work zhou wang early turning point scientific community following reason image comparison technique used based quantifying difference absolute value individual pixel two image using example mean square error however ssmi metric proposes ass similarity two image based following key characteristic luminance contrast structure formal definition define aligned =\frac 2\mu _x\mu _y+c_1 _x^2+\mu _y^2 c_1 aligned luminance similarity _x=\frac ^n_ i=1 x_i\ c_1\ constant aligned =\frac 2\sigma _x\sigma _y+c_2 _x^2+\sigma _y^2 c_2 aligned constrast similarity _x= n-1 ^n_ i=1 x_i ^\frac c_2\ constant aligned =\frac c_3 _x\sigma c_3 aligned structural information _x=\frac n-1 ^n_ i=1 x_i y_i c_3\ constant possible define ssim index aligned ssim aligned chose metric since attempt mimic human visual perception system first time visual perceptual system highly capable identifying structural information scene thus identifying difference information extracted reference sample scene thus metric replicates behaviour performs best task involve differentiating sample reference image present work employed ssmi compare luminance contrast input image photograph output image monet work aim compare whether transformation implemented proposed system respect structure semantic content transformed photograph closer index better proposed system succeeded transforming image respecting structure input image seen fig ssmi obtained comparing photograph monet artwork generated proposed system higher calculated comparison photograph artwork generated vanilla cycle gan approach show although model manage generate monet-style work quite satisfactorily proposed model respect semantic chromatic content input image greater extent figure ssmi comparison vanilla top- training full size image qualitative evaluation validate result obtained also carried visual assessment picture generated proposed method appraisal image created using vanilla cycle gan proposed method shown people validated section analysis question asked basic characteristic group surveyed main result obtained visual assessment result obtained indicated system evaluation hyper-parameter optimisation process carried methodology cycle gan model vanilla training version proposed cycle gan top- training method result process chose efficient approach quantitative term applied final version model large sample photograph aim qualitatively evaluating result obtained figure show several example transformation achieved picture monet method similarly fig contains sample transformation monet picture figure sample transformation picture monet full size image figure sample transformation monet picture full size image seen image model recreate monet artistic style quite well end include stroke imitate painter brushstrokes turn blur edge object give effect canvas tone photograph also replaced vivid colour frequently used artist work noted however top- approach successful maintaining chromatic luminous structure photograph also image generated proposed system pixelated vanilla system allows human eye fooled easily based qualitative observation formulate following hypothesis hypothesis image generated vanilla methodology proposed top- system capable mistaken real work monet hypothesis proposed top- system qualitative improvement basic training methodology cycle gan model hypothesis-testing survey order test above-mentioned hypothesis carried survey using image generated model vanilla top- survey designed google form tool consists five question distributed two clearly differentiated group general group expert group one hand general group composed individual varied socio-demographic profile variability age respondent level education place residence however characterises respondent group lack prior knowledge art sector aim make survey widely available possible shared various social network specifically link questionnaire published whatsapp facebook linkedin addition generated code pointing survey help distribution survey questionnaire available suppl annex following distribution survey general group indicated mean dissemination total response obtained example result obtained question respondent asked choose image opinion monet could painted visualising specific landscape respondent chose option image generated proposed top- system opposed option image generated vanilla cycle gan system allows validate veracity hypothesis i.e proposed system qualitatively improves vanilla system hand group expert consisted specialist visual art individual degree art history form part staff museo del prado museo reina sofía located madrid spain specifically respondent belonged visitor service department room assistant curator since profile defined case clearly unique survey distributed individually respondent sending unique link survey case expert response received case response obtained reveal respondent identified monet original among several fake image generated vanilla top- approach point reaffirms hypothesis hypothesis work generated system confused original work turn quality image generated proposed system mislead expert criterion discussion work proposed novel training methodology applied cycle gan model based updating weight generator taking account image able best fool respective discriminator result obtained vanilla version proposed methodology evaluated quantitative qualitative perspective qualitative appraisal particularly relevant given artistic nature image produced quantitative perspective showed use top- methodology facilitates convergence model turn improves level achieved loss function generator discriminator model also quantitative term ssmi served parameterise similarity image generated fulfilling initial objective generating image maintain semantic content imitating artist style sense found ssmi calculated image generated top- system closer calculated basic methodology show proposed system maintains semantic chromatic content input image greater extent qualitative perspective based initial visual assessment transformation achieved two hypothesis formulated first hypothesis stated basic methodology proposed top- methodology capable generating image could mistaken real work art second hypothesis stated proposed top- system qualitative improvement basic training methodology cycle gan model test hypothesis carried survey among two group general group expert group response two sample confirmed hypothesis conclude evidence affirm proposed methodology improves basic training model qualitative term however work based two key assumption one hand assume expert group representative criterion valid generalizing opinion hand specifically focus single painter style experiment required test method different artistic style additionally work limitation firstly resolution image used limited may result artifact easily noticeable human eye secondly second assumption regarding focus single style also serf limitation explored different pictorial style remains area future research finally important note model employed study intentionally basic model main objective demonstrate improvement achieved implementation top-k training approach investigation explore advanced powerful method domain final reflection noted ability deep learning model merge two distinct style photographer painter open door new form artistic creation however stressed artistic capacity eai doe detract creative capacity human doe seek replace reason simple implemented system imitate pictorial tendency photograph source exist beforehand way desirable society interprets artificial intelligence tool seek complement valuable human capacity generate new idea concept creativity