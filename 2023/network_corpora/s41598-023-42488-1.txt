introduction molecule central chemical science play important role many field material science application pharmaceutical light-emitting diode photovoltaic material molecular dye redox flow battery advancement technology requires thorough understanding principle chemical physical property assessment unexplored material experimental synthesis followed characterization candidate compound fundamental understanding quantitative structure-property relationship qsprs therefore highly desirable accelerate discovery new molecule superior property however traditional experimental approach insufficient efficiently examine vast chemical space potential candidate molecule due high cost time requirement associated synthesis characterization modern qspr approach therefore frequently relying physics-based prediction property data machine learning utilizing molecular fingerprint and/or quantum chemical descriptor key problem becomes create select reasonable i.e potentially synthesizable molecular structure sufficient chemical diversity target property calculated generative algorithm task previously rule-based automatic model builder utilized genetic algorithm recently advanced broad application machine learning algorithm include generative adversarial network gans deep neural network recurrent neural network transformer-decoder-type language model combination genetic algorithm masked language modeling mlm name predominant application area molecular structure generation methodology drug discovery area catalysis optoelectronics following suit example one largest molecular datasets drug discovery constructed enumerating organic molecule non-hydrogen atom based chemical stability synthetic feasibility comprised billion molecule measure performance generative algorithm molecular structure generation benchmark data set developed molecular set moses guacamol data set goal computational inverse molecular design involves optimizing chemical characteristic target property related molecular electronic structure property necessary employ computationally expensive quantum chemical calculation density functional theory dft initio correlated quantum chemistry method work focus inverse design molecule specific optoelectronic property particular gap highest occupied molecular orbital homo lowest unoccupied molecular orbital lumo so-called homo-lumo gap hlg useful electronic property exploited molecular electronic application estimate kinetic stability molecule e.g drug discovery application serve measure lowest electronic excitation energy latter usually transition electron homo lumo shown previously hlg directly proportional energy lowest excited state relevant design chromophore generative model provide million even billion new molecule short time computationally expensive component design workflow computation molecular property reliable quantum chemical calculation rapid prediction molecular property crucially important accelerating candidate screening inverse design process rapid increase number candidate molecule number type constituent atom represents combinatorial explosion problem challenge tackled recent advance surrogate model trained electronic structure calculation performed high-throughput workflow high-performance computing hpc architecture surrogate model developed prediction dft hlgs previously reported based variety algorithm random forest deep neural network graph convolutional neural network gcnns kernel ridge regression krr surrogate typically order magnitude faster relative quantum chemistry method used create training hlg data previously reported proof-of-principle study inverse design photoactive optoelectronic molecule low hlg purpose integrated hydragnn surrogate model trained quantum chemical hlgs mlm-based generative model developed drug discovery application despite fact mlm re-trained able obtain new organic molecule considerably lower hlgs 1.7 thereby demonstrated possibility generating screening new molecule user-specified electronic property hlg however since hydragnn surrogate trained hlgs computed molecule containing non-hydrogen atom gdb-9 dataset molecule surrogate model reliable predicted low-hlg organic molecule since contained atom strained structural unit three- four-membered ring hardly present training dataset concluded performance surrogate model need re-evaluated newly generated molecule since structural characteristic designed molecule different starting molecular structure distribution however envisioned ultimate molecular design workflow would comprise iterative sequence prediction new molecule approach target molecular property step iterative design process must ensured performance surrogate model remains consistently high level address problem applied deep learning workflow ensure high performance surrogate model iteration iteration examining generalization error providing additional molecular data training following report performance iterative inverse design workflow molecule derived original gdb-9 molecular dataset published ref low hlgs creating six generation new molecule workflow includes surrogate performance evaluation retraining generation method workflow iterative design surrogate deep learning previous proof-of-principle work reported inverse design low organic molecule reduced hlg single iteration producing molecule gap low 0.75 large quantity whereas lowest hlg original gdb-9 dataset 0.98 work also reported surrogate gcnn model prediction hlgs perform well newly generated molecule compared original molecule gdb-9 dataset mean absolute error mae increased 0.11 original molecule population 0.45 newly generated molecule error must viewed perspective even accurate quantum chemical method typical error order 0.1 prediction band hlgs mae significantly greater threshold affect accuracy inverse design workflow finding implied surrogate training hlgs molecule gdb-9 data set insufficient prediction general organic molecule particular molecule non-hydrogen atom highly strained cyclic structure three- four-membered ring and/or molecule high frequency functional group particular placed vicinal position important conclusion previous work surrogate model needed improved subsequent iteration generative process adding training data newly generated molecule cover larger chemical space surmised deep learning process hlg surrogate model would allow generally applicable unbiased inverse design workflow efficiently find novel molecule desired property share little similarity original chemical molecular structure space derived workflow fig starting molecular data gdb-9 data fed density-functional tight-binding dftb quantum chemical method compute molecular property case hlg dftb approximate dft method roughly two three order magnitude faster conventional dft comparable accuracy dftb-computed hlgs used ground truth hydragnn surrogate model featuring graph convolutional neural network gcnn trained predict hlgs purely based knowledge simplified molecular input line entry system smile string molecule data selection rule applied identify molecular structure surrogate retraining limit molecular size described training surrogate model used pre-trained validated masked language model mlm generate new molecule mutating selected molecular structure data iteration workflow concluded adding newly generated molecule molecular database noted surrogate training accomplished order hour depending available computational resource agnostic ground truth method chosen reasoning select dftb method explore sufficiently large chemical diversity initial generated molecular datasets proof-of-principles type work clearly appropriate computational resource available higher level theory first principle initio method could employed using exact workflow minimal change code figure deep learning iterative workflow inverse design molecule desired property namely specific value hlg high synthesizability starting molecular database work gdb-9 data set dftb hlgs taken ground truth molecular property gcnn surrogate trained accurately predict relationship molecular structure hlg data selection rule used identify newly generated molecule surrogate model show poor performance predicting property limit size molecule mlm mutated generated new molecule trained surrogate model full size image density-functional tight-binding method low computational cost dftb method coupled reasonably good agreement dft organic molecule make well suited generate large number electronic structure data training surrogate model work selected third-order self-consistent-charge scc dftb method often referred dftb3 conjunction so-called 3ob parameter dftb3 hlgs good agreement perdew berke ernzerhof pbe first principle dft method thus suitable purpose dftb calculation electronic energy converged scc tolerance 10^ hartree local geometry minimization molecule achieved using conjugate gradient driver maximum force atom 10^ hartree/bohr molecular database contains molecular data form smile string smile converted three-dimensional coordinate using merck molecular force field mmff94s implemented rdkit package geometry re-optimized using dftb3/3ob dftb calculation performed using dftb+ program interface atomic simulation environment finally three quantity electronic structure calculation collected homo lumo hlg energy optimized geometry molecule converted smile string procedure suggested kim graph convolutional neural network model surrogate model predict dftb3/3ob hlg given molecular structure hydragnn open-source gcnn implementation effectively leverage hpc resource achieve linear scaling distributed training using large volume data demonstrated gpus hydragnn architecture work composed stack gcnn layer feed set fully connected layer produce prediction hlg gcnn layer ensure topological structure molecule used construct effective deep learning descriptor provide fully connected layer sufficient information learn dependence hlg molecular structure data pre-processing i.e. conversion molecular structure graph composed node graph performed atom type atomic number aromatic hybridization type i.e. ^2\ ^3\ number hydrogen neighbor used feature node whereas type covalent bond e.g. single double triple aromatic used edge feature nodal feature 11-dimensional vector atom type hybridization type represented one-hot encoding others treated scalar important note gcnn node edge information construct graph based initial cartesian coordinate prior dftb re-optimization step since purpose surrogate avoid quantum chemical calculation especially case computationally expensive method could used instead ensured smile created dftb optimization identical different due bond breaking connectivity change molecule question discarded removed database specific hydragnn architecture used work composed six principal neighborhood aggregation pna layer hidden dimension fully connected layer neuron respectively relu used activation function trigger nonlinearity model adamw optimizer used stochastic mini-batched first order method training learning rate equal 1\times 10^ default parameter setting pytorch training performed epoch iteration workflow data whereas equally split validation testing training hydragnn model performed distributed data parallelism ddp across nvidia v100 gpus summit supercomputer oak ridge leadership computing facility olcf masked language model advance natural language processing nlp strategy large number unlabelled data trained unsupervised way build generalizable language model purpose text generation prediction process masked language model mlm training described occurs two step namely pre-training fine-tuning pre-training stage entirely unsupervised doe require labeling feature engineering thus applied large amount data build generalizable pre-trained model stage pre-training carried combination tokenization masking tokenization step vocabulary generated listing commonly occurring sequence converted sequence integer token used input mask prediction token randomly masked model trained predict original sequence token closely possible based given context consequently model predicts set alternative given masked token subsequent fine-tuning process pre-trained model trained specific task typically lower specific dataset time augmented labeled data case mlm utilized fine-tuning performed ligand-protein binding affinity described blanchard combining two process mlm achieve state-of-the-art result various application applied mlm context new molecule generation using smile text representation one represent molecule sequence character using smile representation taking account respective atom bond described tokenization scheme used convert given molecule commonly occurring sequence appropriate token masking scheme used mask part sequence model trained learn predict chemical structure molecule based particular context similar previous work applied technique use pre-trained model generating new molecule specific property summary mlm combination scoring value computed surrogate model performed iterative manner able generate new molecule uncharted chemical space user defined property hlgs used work newly generated molecule often larger size molecule contained initial molecule population indicating mlm capability exploration new chemical space work mlm pre-trained enamine real database augmented approximately billion molecule complete dataset trained using wordpiece tokenizer mentioned deepspeed fused lamb optimizer used using data parallelism mask prediction billion molecule node olcf summit supercomputer compute node summit nvidia v100 gpus data evenly partitioned amongst gpus 5\times 10^5\ molecule gpu mlm publicly available used directly hugging face transformer library data selection rule previous work surrogate model exhibited poor performance predicting hlg newly created molecule included original gdb-9 data training data straightforward way improve surrogate performance re-training adding newly generated molecule cover wider chemical space however since chemical space even low organic molecule vast task neither trivial efficient include generated molecule unclear best select novel molecular data training surrogate model define apply three rule data selection applied efficient training surrogate model expanding size molecular data larger molecule containing non-hydrogen atom rule outlined rule add molecule large prediction error general machine learning model larger error data distinct covered training data maximum error value train/validation/test data end surrogate model training utilized compare prediction error new molecule accepted molecule larger prediction error maximum error train/validation/test data new training data assuming surrogate model sufficiently learned new molecule lower prediction error rule retain unique molecule better train surrogate model data merged new molecule generated previous iteration database utilized training data surrogate model next iteration integrated database also utilized initial population generation molecule mlm believe integrated database allows one expand chemical space molecule mutation identical molecule new molecule different iteration despite low possibility mlm generate molecule already encountered previous iteration efficiently train surrogate without duplicate dropped duplicate structure kept unique molecule integrated database rule limit number atom mlm generate new molecule substituting small fragment large fragment insertion chain expansion ring size leading increase average molecular size unrestricted chemical space grow exponentially number atom chemical substructure estimated number molecule cover complete chemical space material discovery even larger 10^ case pharmacological application number clearly impossible tackle even computationally economical method dftb supercomputer architecture hence instead allowing explicitly exploration vast number possible new molecule must re-consider ultimate goal surrogate model understand predict qspr representative subspace possible chemical space hence desirable keep size re-trained molecule relatively low yet still allow coverage sufficiently large variety combinatorial assembly rule added new molecule containing non-hydrogen atom integrated dataset gdb-20 generated molecule larger non-hydrogen atom separately used test data monitor prediction capability surrogate model number based fact largest size molecule enamine database based gdb-9 database rule applied simultaneously iteration newly generated molecule adding integrated database successful dftb calculation shown fig simplicity trained surrogate model scratch every iteration using updated molecular dataset result discussion work aim demonstrate general applicability combined generative model surrogate deep learning workflow inverse design novel molecule target property case specific value hlg previous work describe result detail case hlg minimization i.e aim predict chemically reasonable molecule lowest possible hlg however also performed investigation aim maximize hlg unexpectedly turn rather uninspiring task molecule highest hlg tetrafluoromethane _4\ dftb-predicted hlg higher general expected fully saturated molecule comprised single bond associated highest hlgs structure doe leave much room chemical diversity respective data therefore presented analogous form low hlg study described supporting information deep learning iteration table show evolution number molecule deep learning iteration newly generated molecule indicate individual data iteration label gen-x generated iteration iteration number 1–6 iteration new molecule generated mlm molecule training data e.g 95,735 molecule gdb-9 seed population generate new molecule first iteration 143,204 molecule second iteration etc. generation aim collect around 100,000 new molecule cumulative number original newly generated molecule tabulated table generated data three rule method section simultaneously applied generated molecule 100,000 molecule calculating molecular property using dftb every iteration number generated molecule reduced result selection became 100,000 accepting chemically valid molecule appropriate valence coordination number atom new train data table number new molecule added training data next iteration applying data selection rule described section rest molecular data set aside test data test data includes molecule low prediction error rule restricted atom iterated design loop time deep learning process obtain surrogate model consistent performance expanded training data percentage new training data accepted rule largest first iteration decreased rest iteration implies chemical space significantly expanded iteration diversified molecular structure subsequent iteration table number molecule iteration low hlg deep learning full size table prediction capability surrogate model tracked comparing hydragnn hlg prediction versus dftb hlg calculation ground truth gdb-9 data gen-1–gen-6 fig show parity plot two surrogate model surrogate model iteration surrogate0 surrogate model iteration surrogate5 surrogate5 trained 191,557 molecule gdb-9 gen-1–gen-5 surrogate0 trained 95,735 molecule gdb-9 colored point fig prediction surrogate5 gray point plot prediction surrogate0 mean absolute error mae value surrogate0 first value mae1 surrogate5 second value mae2 included plot indicating deviation re-trained surrogate later iteration decreased mae surrogate0 increasing 0.12 gdb-9 0.91 gen-5 mae surrogate5 consistently around 0.12 generation utilizing surrogate5 molecule generated gen-6 98,118 used test data mae slightly higher 0.13 thus conclude surrogate5 represents good improvement surrogate0 generated molecular datasets increasing mae surrogate0 value later iteration indicates new molecule higher prediction error added instead generating comparable molecule figure parity plot gdb-9 iteration low gap design error plot surrogate model dftb prediction dataset colored point surrogate5 prediction gray point surrogate0 prediction surrogate5 trained gdb-9 gen-1–gen-5 dataset mae1 mae2 value plot corresponding prediction error surrogate0 surrogate5 respectively full size image inverse design molecular structure low hlg dftb-computed hlg distribution original gdb-9 dataset shown top panel fig distribution appears multi-modal corresponding different molecular class aliphatic molecule olefinic molecule conjugated molecule molecule double triple bond well strained ring distribution range 0.98 lowest hlg 19.8 highest hgl majority molecule gap goal inverse design workflow generate novel molecule population maximum shifted towards lower hlgs task selected demonstration inverse design workflow supporting information different exercise documented tasked inverse design workflow generate molecule high hlgs however since predicted molecule exercise rather uninspiring aliphatic molecule large number halogen decided focus main text discussion hlg minimization result larger variety molecular characteristic figure distribution density molecule generated iteration dftb hlg prediction full size image analysis generated molecule mlm-based generation process surrogate model instantaneously provides hlg new molecule based previous surrogate training inverse design molecular structure low hlg accomplished selecting new molecule based hlg value final low hlg molecule selected also based hlgs among 1,000,000 generated molecule generation sorting molecule ascending order hlg value top 100,000 molecule collected accepted new molecule next iteration figure show distribution dftb hlg iteration newly generated molecule tabulated table selecting lower gap molecule workflow gap distribution gradually shifted iteration gdb-9 iteration gen-6 toward lower value shown fig transition pronounced step gdb-9 gen-1 shift toward lower gap size observed increasing number iteration hlg distribution increased visibly iteration molecule hlg decreased molecule hlg average hlg value per iteration listed table evidence shift hlgs increasing number workflow iteration note molecule generation ensured unique rule even though distribution gap comparable iteration iteration shifted gradually worth noting new molecule gap lower lowest hlg gdb-9 data 0.98 created number increased higher iteration table average hlg calculated molecule dataset full size table due large number molecular structure iteration unpractical compare directly individual molecular structure iteration therefore resorted analyze different chemical space distribution dimension reduction using convolutional variational autoencoder cvae convert bit one-hot encoding feature extended-connectivity fingerprint ecfps three dimensional chemical latent space mapping better visualize understand distribution molecule reduced two dimension using principal component analysis pca indicating dimension reduction two-dimensional chemical latent analysis ecfp-cvae-pca visualized 550,380 molecule accumulated molecule train test dataset shown fig dataset visualized separately two dimensional scattering plot coloring based gap value fig molecule gdb-9 dataset distributed widely clear distinction occupied space low gap 0–5 middle gap 5–10 molecule fig distribution gen-1–gen-6 close origin pcas far comparable occupy space slightly deviate gap value color scatter quality chemical space exploration gen-1 gen-6 clearly similar indicating mlm generates similar type molecule time gradually enhanced target property rough visual inspection molecular structure fig associated generation indicates novel molecule feature conjugated bond functional group featuring amine well small strained ring anti-aromatic ring clearly iterative search molecule generating mutating molecule previous iteration lead fine-tuning molecular structure term molecular characteristic figure chemical space plot gdb-9 generated data gen-x 1–6 obtained three dimensional latent space dimension reduction using ecfp-cvae pca utilized visualize chemical latent space two dimension full size image fig show another straightforward statistical analysis molecular structure using structural property h/c ratio ratio aromatic atom aliphatic atom marked aromaticity double bond equivalent dbe number atom function dftb hlg hlg value plotted unfortunately significant relationship could identified hlg respective structural property one might expect weak relationship hlg value dbe number well number atom size molecule example molecule larger dbe number tend lower hlg value similar trend observed number atom molecule hlg inversely proportional number atom molecule however even molecular property strongly related structure connectivity elemental composition would remain non-trivial problem suggest molecule characteristic general guidance using quantity specific molecular structure prediction demonstrated workflow seems successful inversely designing molecule target property figure dftb hlg versus analysis molecular character h/c ratio aromaticity ratio double bond equivalent dbe number atom training test data gdb-9 gen-x 1–6 dataset normalized number molecule color bar counted colored based relative population point full size image selection novel molecule low hlg discus selected molecule gen-x datasets hlg lower lowest gap molecule hlg 0.98 gdb-9 data investigate molecular structure greater detail number molecule stringent condition iteration gradual shift lower gap molecule observed fig suggested larger number molecule listed table indeed number increased molecule iteration see fig believe molecule iteration successfully generating molecule low hlg molecule iteration table average hlg calculated molecule dataset full size table figure number generated molecule hlg 0.98 gen-x 1–6 data screened molecule number molecule five-member ring six-member ring component full size image new molecule included molecule generated mlm contains 4–9 member ring molecule note new molecule hlg 0.98 composed various substructure strained ring structure three- four-membered ring seven-membered ring substructure well commonly observed five- six-membered ring assumed molecule ring substructure 5-membered ring 6-membered ring experience high strain stable even observed nature regard subset molecule new data table deemed chemically stable indicated screened data fig molecule composed mainly 5-membered ring 6-membered ring well alkane chain functional group six molecule smallest gap provided together chemical latent space plot using ecfps-cvae-pca analysis 550,380 molecule collected gdb-9 gen-1–6 dataset fig molecule low gap fig show similarity contained single ring fused ring substructure often ketone functional group connected alkane chain ring substructure derived benzene cyclopentadiene indane naphthalene molecule molecule also heterocycle substitution carbon nitrogen oxygen note one low gap molecule generated work obtained gen-3 0.67 much lower lowest gap original gbd-9 data 0.98 confirming validity inverse design workflow also indicating may necessary perform six design iteration furthermore provide dataset molecule imported analyzed using chemiscope.org interactively visualize molecular structure relative chemical latent space position shown fig molecule table also included supplementary data smile gap information nevertheless since number chemically reasonable structure increase iteration increase number design cycle provide larger number viable suggestion chemically viable specie associated target property figure mapping two dimensional chemical latent space using ecfps-cvae-pca analysis low gap iteration data 550,380 molecule six lowest gap molecule demonstrated together gap value chemical latent space coordinate full size image conclusion work report iterative workflow design new molecule posse lower homo-lumo gap hlgs molecule contained starting gdb-9 molecular database workflow utilizes combination two model generative surrogate model paired data selection step limit size newly generated data iteration iterative workflow gradually increase number viable prediction molecular structure associated target property also ensures consistency surrogate model performance molecular structure changing one generation molecule next deep surrogate learning number molecule contained training data applying three data selection rule largest beginning workflow decreased later iteration well worsening performance surrogate newly generated molecule indicated gdb-9 data contain sufficient variety molecule train surrogate model newly generated molecule addition training data generated molecule improved surrogate performance iterative deep learning able search way new molecule low hlg targeting design low hlg molecule demonstrated workflow provided variety new molecule low hlg constructed combination alkane chain ring substructure molecule hlg 0.98 absent gdb-9 dataset number increased last iteration supporting information show workflow successfully used design molecular structure high hlgs work show presented workflow advantageous exploring vast molecular structure space analysis newly predicted molecule indicates difficult pinpoint precise molecular structure possessing target property employing statistical relationship number atom double-bond equivalent number aromatic atom etc therefore conclude inverse design workflow suggested offer effective pathway reliably predict molecular structure target property