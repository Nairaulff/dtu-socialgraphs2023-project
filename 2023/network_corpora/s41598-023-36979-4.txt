introduction pest management strategy used control living organism pose risk food fiber health security played essential role achieving current food supply role continue critical agricultural production system since beginning agricultural development grower compete harmful insect collectively called pest organism reduce crop yield fruit quality damage plant serve disease vector contaminate food crop different strategy developed control arthropod pest agriculture including chemical cultural biological e.g. plant resistance natural enemy etc mechanical method much concern use chemical pest control due cumulative non-sustainable adverse effect environment particularly non-target effect beneficial organism including natural enemy e.g. predator parasitoids microorganism pollinator potential development pesticide resistance valuable tool addressing threat integrated pest management ipm ipm developed early 1970s pest control strategy promotes sustainable agriculture strong ecological basis ipm approach incorporates various tactic control class pest e.g. insect pathogen weed vertebrate create ecologically economically efficient production system tactic include biological control cultural practice host-plant resistance genetic manipulation pesticide ipm tactic applied different crop including sorghum production sorghum sorghum bicolor moench fifth valuable cereal crop globally u.s. crop value billion planted 5.26 million acre sorghum production world used mainly human consumption animal feed u.s. used livestock feed turned ethanol however current production sorghum face significant pest management challenge since outbreak melanaphis sacchari zehntner hemiptera aphididae commonly named sugarcane aphid sca different tactic developed including scouting protocol pesticide treatment guide host plant resistance program prevent yield loss sorghum proper identification classification insect pest early stage important task crop pest management strategy i.e. pesticide cultural control method costly overused misidentification happens however insect pest factor affect understanding pest management agriculture sorghum farmer encounter beneficial insect need identified classified automatically better understand pest beneficial insect interaction i.e. predation pest scouting field one major community feeding sca lady beetle coleoptera coccinellidae common genus specie subfamily level coccinellids find sorghum plant include coccinella septempunctata coleomegilla maculata cycloneda sanguinea harmonia axyridis hippodamia convergens olla v-nigrum subfamily scymninae technological advance artificial intelligence machine learning related living organism efficiently identified classified smallest use labor time increase precision agriculture represent major focal point modern agricultural production research machine learning sub-field artificial intelligence labeled data used train model trained model subsequently used make inference prediction new incoming data without additional programmatic effort convolutional neural network cnn represent type machine learning model specifically deep learning model used analyze visual imagery cnns excel variety computer vision task image classification object detection localization among others object detection refers task identifying classifying instance object interest image video frame cnn-based approach object detection extract feature input image use feature perform two main task detect region interest roi bounding box contain instance object image a.k.a. object identification classify roi arbitrary number class a.k.a. object classification depending two task performed object detection approach classified one-stage detector two-stage detector one-stage detector perform task simultaneously one stage include model yolo family among others two-stage detector identify roi first stage subsequently classify roi refine bounding box second stage two-stage detector include model faster r-cnn cascade r-cnn fpn traditionally two-stage detector accurate one-stage detector one-stage detector faster suitable use practical application require real-time object detection remarkably combination faster r-cnn fpn network achieved competitive result popular benchmark datasets however recent yolo model produced state-of-the-art performance term accuracy speed benchmark datasets yolov7 known produce best result end year deep learning software object detection designed user-friendly manner allows training model applied solve agricultural challenge recent study using deep learning neural network object detection shown possible develop model automated disease identification insect recognition study focused use object detection approach identify classify pest based image yellow sticky trap type insect trap example salamut focused detecting cherry fruit fly based yellow sticky trap image several one-stage two-stage object detection approach compared including faster r-cnn yolov5 using dataset contains 1,600 annotated image best result overall obtained using faster r-cnn model lightweight mobilenet backbone network specifically faster r-cnn model average precision .50 0.88 compared best yolov5 model 0.50 0.76 wang published dataset called pest24 approximately 25,000 pest trap image contain field pest trained several object detection model dataset including faster r-cnn vgg-16 backbone network cascade r-cnn resnet-50-fpn yolov3 whose backbone called darknet-53 experimental result showed yolov3 best performance dataset overall mean average precision map 0.50 59.79 compared map 0.50 57.23 cascade r-cnn map 0.50 51.10 faster r-cnn used faster r-cnn model pre-trained coco dataset detect small pest whitefly thrip using dataset approximately 1,500 sticky trap image showed model transferred coco accurate corresponding model trained directly pest image wang adapted faster r-cnn model make easier find small pest light-trap image improved model used attention mechanism focus predictive feature together sampling strategy region proposal network address class imbalance also adaptive roi selection select best feature different level pyramid network experimental result dataset called agripest21 approximately 25,000 image type pest showed adapted model achieved map 78.7 significantly better map baseline model included comparison study one-stage e.g ssd two-stage model e.g. cascade r-cnn jiao also used adaptive feature fusion pyramid network identify richer feature pest detection together faster r-cnn network resnet50 backbone obtained competitive map value 77.4 agripest21 dataset zhang used strategy similar i.e. attention mechanism obtained better feature fusing feature pyramid network adapt yolo model small pest detection task experimental result pest24 dataset showed adapted yolo model called agripest-yolo better performance faster r-cnn cascade r-cnn several yolov4 yolov5 variant producing overall map 0.50 71.3 map 0.50 0.5 0.95 46.9 opposed abovementioned study focused image trapped pest study focused pest detection wild sava experimented faster r-cnn yolo model detecting brown marmorated stink bug i.e. halyomorpha halys tree image experimental result dataset image assembled maryland biodiversity project showed yolov5m variant produced best result map 99.2 compared faster r-cnn map 89.1 contrast takimoto showed faster r-cnn better yolov4 detecting herbivorous beetle specifically striped flea beetle i.e. phyllotreta striolata turnip flea beetle i.e. phyllotreta atra set image collected web fieldwork similarly ozdemir kunduraci also found faster r-cnn network inception-v3 backbone better yolov4 used detect classify insect according order level using dataset consisting 25,820 training image 1,500 test image butera also showed faster r-cnn mobilenet-v3 backbone represents effective model detecting beetle-type pest specifically popillia japonica also distinguishing type non-harmful similar looking beetle cetonia aurata phyllopertha horticola giving overall map 92.66 dataset used contained 36,000 image collected web photo sharing site ahmad also used web assemble dataset 7,046 image contain type pest experimented set yolo model showed yolov5-x gave best result overall map 0.5 value 98.3 map .50 0.05 .95 value 79.8 addition work deep learning automated pest identification recent study also focused identification beneficial insect pollinator natural predator including coccinellidae beetle ratnayake used hybrid approach combine object detection model specifically yolov2 background subtraction technique identify track honeybee wildflower cluster proposed approach called hydat track one insect time tested dataset consisting 22,260 video frame 17,544 bee visible detection rate 86.6 compared detection rate 60.7 yolov2 ratnayake extended hydat approach make suitable tracking multiple insect simultaneously proposed approach called polytrack yolov4 together foreground background segmentation identify track honeybee experimental result 39,909 video frame including 5,291 frame honeybee showed polytrack achieved value 0.975 0.972 precision recall respectively superior hydat yolov4 model used bjerge assembled dataset consisting 29,960 beneficial insect nine taxon bee hoverflies butterfly beetle used dataset study usability yolo model accurately detect classify insect experimental result showed yolov5 model best performance map 0.50 0.05 0.95 0.592 best f1-score 0.932 similarly spanier assembled dataset approximately 17,000 imaged pollinator insect eight type including bee wasp butterfly moth beetle etc retrieved inaturalist inaturalist.org observation.org database best performing model variant yolov5 achieved overall accuracy 0.9294 f1-score 0.9294 bjerge constructed dataset 100,000 annotated image containing small insect author experimented faster r-cnn model yolov5 model enhance detection proposed motion-informed-enhancement image experimental result showed yolov5 achieved map 0.50 value 0.924 faster r-cnn model achieved map 0.50 value 0.900 term coccinellid beetle detection venegas used traditional image processing technique based saliency map linear iterative clustering active contour identify roi bounding box potentially contain coccinellids subsequently used deep cnn classify roi coccinellids not-coccinellids approach evaluated dataset 2,300 coccinellid beetle image assembled inaturalist project ecuador colombia roi detection approach accuracy cnn model area curve auc 0.977 similarly vega used cnn together weighted hausdorff distance loss function detect beetle dataset 2,633 image similar one used venegas reported mean accuracy 94.30 work represent important first step towards automated identification coccinellid beetle considered natural pest controller realm deep learning object detection automatically detect classify coccinellids found sorghum largely unexplored conventional manual identification coccinellids requires expert skill identification key based coloration morphological characteristic contrast existing automated tool based digital technology imagery data employ state-of-the-art deep learning architecture may accurate thus vision-based automated system image processing using deep neural network need researched precise classification identification coccinellids advance integrated pest management area sorghum towards goal first assembled dataset consisting approximately 5,000 image retrieved inaturalist dataset assembled used study automated deep learning approach enable detection classification coccinellids trained variant popular two-stage faster r-cnn model enhanced fpn model referred faster r-cnn-fpn also trained variant yolov5 yolov7 model choose focus faster r-cnn-fpn model given model shown best performance prior related work backbone cnn explored resnet-50 resnet-101 given network commonly lead good trade-off accuracy speed similarly selected yolov5 another strong model experiment given best performance several prior work finally also choose include yolov7 study give best performance several benchmark datasets explored insect detection neither pest beneficial insect ipm area summarize research contributes dataset effective deep learning model trained detect classify coccinellids including faster r-cnn-fpn yolov5 yolov7 model best knowledge first study explore yolov7 insect detection classification best model potentially installed used unmanned vehicle automate detection classification coccinellids sorghum field field scouting model customized natural enemy encountered different crop automated field scouting method deep learning approach object detection generic architecture deep neural network object detection consists two main component backbone commonly pre-trained cnn network used generate feature map head used detect object bounding box defined coordinate bounding box prediction classify object one several category interest case different type coccinellids one-stage detector including yolo family detector dense prediction head achieves object detection classification task simultaneously two-stage detector including popular faster r-cnn detector decouple object detection classification task achieve two stage first stage use dense prediction head generate roi may contain object second stage sparse detection head used classify roi according different object category refine bounding box recent year become standard practice insert neck backbone head network collect mix feature different layer fpn network one example neck commonly used object detection network fpn top-down path lateral connection extract semantic feature map different scale resulting feature map enable model find object different scale path aggregation network panet another example neck used object detector enhances fpn bottom-up path help propagate low-level feature equipped also adaptive feature pooling panet shown improve object localization generic architecture one-stage two-stage detector shown fig study popular faster r-cnn representative two-stage approach two yolo variant yolov5 yolov7 task detecting classifying common coccinellid found sorghum model studied trained evaluated using image annotated labelbox tool http figure generic architecture object detection approach modern object detection network consists three main component backbone network performs feature extraction given input image neck collect combine feature different layer head used detect classify object interest one-stage detector use dense prediction head simultaneously address detection bounding box regression classification task two-stage detector decouple two task use sparse prediction head classify previously identified roi full size image faster r-cnn-fpn modern faster r-cnn model use pre-trained cnn backbone feature extraction combined fpn network neck obtain semantic feature map different scale extracted feature map provided input region proposal network rpn seen dense prediction head network rpn identifies region interest roi i.e. region may contain object interest case coccinellids corresponding location i.e. rectangular bounding box parameterized using box center coordinate height width precisely rpn sliding window generate three anchor different aspect ratio 1:2 1:1 2:1 respectively grid cell input feature map anchor labeled object/positive background/negative based overlap ground truth bounding box used train rpn network identify roi location highly overlapping region potentially corresponding object filtered using non-maximum suppression threshold subsequently resulting roi together feature map provided input sparse prediction head trained classify roi several category interest e.g. different coccinellid type refines location parameter network trained together using multi-task loss combine cross-entropy classification loss linear regression loss experiment two cnn network pre-trained imagenet cnn backbone specifically resnet-50 resnet-101 network given provide good trade-off accuracy speed fpn produce feature map different scale consequently 5x3 anchor generated location rezatofighi suggested standard loss used regress parameter bounding box corresponding object strongly correlated iou intersection union metric generally used evaluate object detection approach instead loss proposed use loss based iou metric specifically experimented iou loss loss based generalized iou giou showed optimizing giou loss help improve performance measured either using giou standard iou given result experiment iou giou regression loss bounding box regression task faster r-cnn yolov5 described two-stage detector faster r-cnn-fpn network re-purpose image classification perform object detection using rpn identify anchor contain object interest roi subsequently classifying roi specific category opposed one-stage detector use directly input image identify bounding box coordinate class probability object interest yolov5 released company called ultralytics evolved time used latest yolov5 v6.0/v6.1 architecture backbone yolov5 new csp-darknet53 combine original darknet53 network used yolov3 cspnet network darknet53 inspired resnet architecture specifically designed object detection cspnet address issue duplicate gradient information large backbone network truncating gradient flow speed computation current neck used yolov5 architecture consists two component sppf new csp-pan sppf variant spatial pyramid pooling spp help identify small object also object different scale sppf designed improve computation speed spp similar darknet53 backbone pan network panet also combined csp improve computation speed yolov5 dense prediction head inherited yolov3 addition component improve efficiency yolov5 make use variety augmentation technique input image among others mosaic augmentation used stitch together four image goal training model find object place center image large majority object generally located furthermore yolov5 automatically generated anchor different scale aspect ratio predict bounding box confidence score cell grid directly input image anchor generated using k-means clustering based bounding box training set genetic evolution algorithm optimizes initial k-means centroid based complete iou ciou loss ciou loss aggregate overlap area distance center point aspect ratio consistency two bounding box yolov5 head detection layer corresponding three different scale predicts bounding box different aspect ratio scale resulting total anchor bounding box predicted deviation anchor dimension faster r-cnn-fpn technique used filter bounding box representing object whole network trained using multi-task loss combine classification loss binary cross-entropy objectness loss binary cross-entropy location loss ciou yolov5 exponential moving average ema model checkpoint final detector yolov5 represents series object detection model compound-scaled variant architecture pre-trained coco dataset model yolov5 series different size application different need term trade-off accuracy speed study experiment five yolov5 variant vary size nano yolov5n small yolov5s medium yolov5m large yolov5l extra-large yolov5x whose specific architecture available official github repository .yaml file model directory yolov7 yolov7 architecture designed based bag-of-freebies idea introduced bochkovskiy refers fact important detector fast inference time training expensive help improve overall accuracy model acceptable training done offline idea mind yolov7 introduced several innovation network architecture training strategy one important innovation main component yolov7 architecture used backbone neck/head network block called extended efficient layer aggregation network e-elan elan stack computational block structure combined csp optimize shortest gradient path ensure scaling network doe result deterioration performance addition e-elan expand shuffle merge cardinality enables model learn diverse feature neck network structured based pafpn network combination pan fpn e-elan feature extraction fusion addition lead head yolov7 introduces auxiliary head somewhere middle network meant assist lead head may far network soft label assigned auxiliary lead head coarse-to-fine manner based prediction lead head ground truth coarse soft label used auxiliary head represent relaxed version fine soft label used lead head expected auxiliary head precise term anchor yolov7 leverage automated anchor selection approach proposed yolov5 aspect ratio feature map representing three different scale total anchor furthermore data augmentation technique similar used yolov5 also used yolov7 including mosaic augmentation commonly-used technique employed filter predicted bounding box achieve robustness module-level re-parameterization i.e. aggregating weight multi-branch module inference yolov7 gradient flow propagation path plan module benefit re-parameterization yolov7 trained scratch coco dataset using multi-task learning loss consisting classification loss binary cross-entropy objectness loss binary cross-entropy location loss ciou lead auxiliary head used loss includes similar component corresponding two head different weight final model used inference based ema model parameter different checkpoint training together innovation introduced yolov7 component reused prior work led state-of-the-art result standard benchmark datasets object detection time smaller inference time compared yolo model yolov7 also consist series pre-trained model various size study experiment four yolov7 variant standard yolov7 model designed standard gpus compound scaling variant yolov7-x smallest model yolov7-tiny deigned edge gpu larger model yolov7-d6 cloud gpu architecture dataset coccinellid imagery downloaded inaturalist web portal used inaturalist.org inaturalist citizen science project allows naturalist upload share observation i.e. image biodiversity worldwide web platform mobile app free submission observer include actual image location observed time group identification agreement taxon observation create research-grade label assigned observation inaturalist make archive research-grade observation data available environmental science community via global biodiversity information facility gbif used gbif assemble dataset training testing deep learning model detection localization classification coccinellids research-grade label family genus specie level considered dataset assembled dataset includes seven distinct category coccinellids corresponding important coccinellids found sorghum plant specifically coccinella septempunctata coleomegilla maculata cycloneda sanguinea harmonia axyridis hippodamia convergens olla v-nigrum subfamily scymninae three sample image seven category shown fig row corresponds one coccinellid type figure sample coccinellid image category included study full size image aimed select approximately image per category assembled dataset total number 4,865 image image contains one instance coccinellids type i.e. corresponding particular category dataset split train 3,053 image development dev 1,113 test subset table show distribution images/coccinellid instance seven category train/dev/test subset also whole dataset supplementary table show distribution image respect number instance per image category train/dev/test subset seen image one two coccinellid instance although image coccinellid instance table dataset statistic distribution image coccinellid instance seven category train/dev/test subset also whole dataset full size table also classified instance dataset according size information frequently used evaluating object detection approach specifically instance classified based area occupy image small area 32^2\ medium 32^2 area\le 96^2\ large area 96^2\ supplementary table show distribution small medium large instance train/dev/test subset whole dataset seen number small instance total dataset included training subset number medium instance instance test subset remaining instance large represent majority dataset given observation evaluation metric generic representing mostly large category opposed specifically focused small medium large category respectively implementation detail trained evaluated faster r-cnn-fpn yolov5 yolov7 model data flow diagram whole process depicted fig training image used train model development image used evaluate select hyperparameters performance final model estimated test data figure data flow diagram coccinellid image collected inaturalist labeled using labelbox set image split train dev test subset yolo faster r-cnn-fpn model trained fine-tuned train dev subset respectively performance model estimated test subset term average precision metric full size image faster r-cnn-fpn used detectron2 library object detection segmentation developed facebook research train evaluate faster r-cnn-fpn model coccinellids detection detectron2 pytorch deep learning framework successor detectron originally designed flexible order support rapid implementation evaluation novel research. default configuration base-r-cnn-fpn defined base-r-cnn-fpn.yaml file http hyper-parameters detectron2 available http train/test file adapted available http training model used default value hyper-parameters detectron2 faster r-cnn-fpn object detection model experimented resnet50/resnet101 backbone cnns iou/giou regression loss respectively term number iteration started training faster r-cnn-fpn model default 40,000 iteration however learning curve shown supplementary fig suggested training development loss still decreasing still increasing 40,000 iteration thus enable network learn give better performance ran experiment 400,000 iteration identified best iteration model based learning curve shown supplementary fig specifically best iteration identified point validation loss start increasing training loss still decreasing using criterion faster r-cnn-fpn resnet-50 best validation/training point observed around iteration 80,000 iou giou loss faster r-cnn-fpn resnet-101 best point observed around iteration 220,000 loss yolov5 used official pytorch yolov5 implementation provided ultralytics available http train evaluate yolov5 model used pre-defined model configuration yolov5 variant used experiment number class changed pre-defined configuration available http file yolov5n.yaml yolov5s.yaml yolov5m.yaml yolov5l.yaml yolov5x.yaml correspond five yolov5 variant used study respectively term hyper-parameters yolov5 provides three different hyper-parameter setting specifically hyp.scratch-low.yaml hyp.scratch-med.yaml hyp.scratch-high.yaml train smaller medium larger size model respectively three hyper-parameter setting found http training model yolov5 used default value hyperparameters except using epoch batch size best model identified yolov5 framework using validation data used evaluation example specific command line used train yolov5s model shown modified file non-default hyper-parameters highlighted red font similarly command lined used evaluate yolov5s model yolov7 also used official yolov7 pytorch implementation http train evaluate yolov7 model yolov5 used pre-defined model configuration yolov7 variant used experiment number class changed pre-defined configuration available http file yolov7.yaml yolov7-tiny.yaml yolov7x.yaml yolov7-d6.yaml correspond four yolov7 variant used study respectively term hyper-parameters yolov7 provides three different hyper-parameter setting edge gpu architecture yolov7-tiny standard gpu architecture yolov7 yolov7-x cloud gpu architecture including yolov7-d6 three hyper-parameter setting found http hyp.scratch.tiny.yaml setting yolov7-tiny hyp.scratch.p5.yaml setting yolov7 yolov7-x hyp.scratch.p6.yaml setting yolov7-d6 training model yolov7 used default value hyperparameters except using epoch batch size best model identified yolov7 framework using validation data used evaluation example specific command line used train yolov7 model shown modified file non-default hyper-parameters highlighted red font similarly command lined used evaluate yolov7 model ensure reproducibility make available train/test/dev data form inaturalist image annotation model configuration best trained model http model trained amazon web service aws p2.xlarge instance according aws configuration p2.xlarge instance follows gpu vcpus gib memory high network bandwidth training model specified number iterations/epochs took day evaluation metric used three standard average precision metric evaluate result model three metric defined using intersection-over-union iou measure capture overlap predicted bounding box instance ground truth bounding box instance specifically iou defined area overlap i.e. intersection divided area represented union metric used evaluate ability model correctly identify type coccinellid average precision iou=0.50\ denoted 0.50 average precision iou=0.75\ denoted 0.75 average precision iou=.50 .05 .95\ represents average precision across ten iou threshold varying 0.5 0.95 step size 0.05 denoted .50 0.05 .95 simply considers prediction correct iou detected instance ground truth instance annotation greater equal example 0.50 considers prediction correct correct corresponding iou greater equal 0.50 addition comparing model term average precision metric also compared model term number layer specific model architecture used includes number parameter network size model inference time per image characteristic used identify small model accurate fast embedded mobile device automated field scouting ethic statement result presented based solely experiment image data experiment involve live vertebrate and/or higher invertebrate experiment carried accordance relevant guideline regulation result discussion result model used study faster r-cnn-fpn yolov5 yolov7 whole test subset shown table specifically family model report 0.50 0.75 model variant considered best result term average value obtained range iou threshold 0.50 0.95 step 0.05 74.605 obtained yolov7 model best value yolov5 model 73.3 obtained yolov5x variant best value faster r-cnn-fpn model 65.6 obtained faster-r101-giou significant result given best value popular object detection benchmark microsoft coco dataset considers primary metric currently 65.4 february 4th term 0.50 primary metric pascal voc benchmark dataset best value 97.3 also obtained using yolov7 model best 0.50 value obtained yolov5 variant specifically yolov5m 96.0 best value obtained faster r-cnn-fpn variant faster-r50-giou 94.3 finally using stricter 0.75 requires least 0.75\ iou overlap comparing predicted bounding box ground truth bounding box object instance best result 82.6 obtained yolov7 model well yolov5x variant following closely result competitive term number reported literature similar problem show model considered study particular yolov7 model ability detect localize coccinellids real world image posted inaturalist overall test data standard yolov7 model best performance among model yolov7 family followed closely yolov5x model yolov5 family model significantly better best faster r-cnn-fpn model specifically faster-r101-giou evaluate performance model relation size inference time table also show number layer number parameter inference time size model faster r-cnn-fpn model average number parameter million resnet50 resnet101 respectively compared model relatively large size 165.8 242.1 resnet50 resnet101 respectively high inference time approximately per image thus despite fact two-stage detector large size high inference time faster r-cnn-fpn model accurate comparison yolov5 yolov7 model coccinellid image yolov5 model smallest size inference time overall seen performance increase size model yolov5x largest model best performance inference time per image size yolov7 variant overall larger size yolov5 variant however best yolov7 model standard yolov7 size 74.8 inference time 19.2 per image lower inference time best yolov5x model also worth noting standard yolov7 model large number layer specifically layes accordingly large number parameter comparable number parameter faster r-cnn-fpn resnet50 still fast inference time proof bag-of-freebies idea used yolov7 give intended result table faster r-cnn-fpn yolov5 yolov7 result network evaluated test subset using best model according development subset result reported term 0.50 0.75 faster r-cnn-fpn faster model using resnet-50 r50 resnet-101 r101 base model iou giou loss respectively best result model within family highlighted bold best result overall also shown italic model number layer number parameter inference time size also shown full size table gain insight model perform type coccinellids dataset table show result term averaged iou threshold seven type coccinellids included dataset seen standard yolov7 model give best result four coccinellid type specifically coccinella septempunctata coleomegilla maculata cycloneda sanguinea hippodamia convergens highly competitive result three type yolov5x model give best result harmonia axyridis olla v-nigrum subfamily scymninae thus based result also conclude standard yolov7 model good choice identifying coccinellids type included study closely followed yolov5x model yolov7 model performs best coccinellids type coccinella septempunctata ap=780.4\ followed coleomegilla maculata harmonia axyridis olla v-nigrum ap=76.4\ ap=76.2\ ap=75.5\ respectively model lower cycloneda sanguinea subfamily scymninae hippodamia convergens value 72.2 71.0 70.5 respectively fasterr-cnn\\fpn-r101-giou yolov7 yolov5x max iteration learning rate 0.0002 0.01 0.01 momentum 0.9 0.937 0.937 weight_decay 0.0001 0.0005 0.0005 warmup_epochs 1.0 3.0 3.0 warmup_momentum unused 0.8 0.8 warmup_bias_lr unused 0.1 0.1 iou_training_threshould 0.3 0.2 0.2 anchor p3/8 unused 12,16 19,36 40,28 10,13 16,30 33,23 anchor p4/16 unused 36,75 76,55 72,146 30,61 156,198 373,326 anchor p5/32 unused 142,110 192,243 459,401 116,90 156,198 373,326 confusion matrix constructed comparing type predicted yolov7 model manually annotated type shown fig generally type predicted correct accuracy higher case expected detected instance type incorrectly predicted furthermore instance missed background coccinellid instance detected coccinellid input image background overall model make small number false negative mistake i.e. rarely miss coccinellid largest number mistake scymninae subfamily seen confusion matrix scymninae subfamily also highest percentage miss-classified instance overall coccinella septempunctata type highest detection accuracy figure show example correct prediction made different coccinellid type appearing somewhat challenging setting example image coccinellids small sometimes hard see appear various environment however model correctly identifies image multiple coccinellids one image model correctly identifies right type even overlapping image coccinellid inside stem supplementary fig show similar example correct prediction made faster r-cnn-fpn model resmet101 backbone giou loss table faster r-cnn-fpn yolov5 yolov7 result coccinellids type test subset result reported term obtained best model according development subset faster r-cnn-fpn faster model using resnet-50 r50 resnet-101 r101 base model iou giou loss respectively best result coccinellid type using model within family highlighted bold best result overall also shown italic full size table figure confusion matrix constructed comparing type predicted yolov7 manually annotated type label background corresponds coccinellid instance identified model background corresponds prediction coccinelids coccinellid original input image full size image figure example accurate yolov7 prediction different coccinellid type full size image figure example image yolov7 model correctly identifies coccinellids type identified different manually annotated type row show ground truth type specifically scymninae harmonia axyridis hippodamia convergent predicted label image shown image full size image figure example yolov7 error image show case yolov7 mistakenly detecting object coccinellid image show case yolov7 fails detect coccinellid image show case yolov7 detects two coccinellids instead one alternatively one coccinellid instead two full size image error analysis yolov7 model work well two type error detection error localization error detection error grouped several class error coccinellid identified detected type wrong shown fig similar error seen best faster r-cnn-fpn model supplementary fig error different object picture identified coccinellid shown fig error coccinellid identified model completely miss shown fig error coccinellid wing spread model detects two coccinellids instead one conversely error two coccinellids overlap image model fails detect two instance shown fig interesting see yolov7 model identify coccinellids overlap shown fig fails detect others shown fig comparing yolov7 prediction faster r-cnn-rpn prediction found yolov7 model fix error made faster r-cnn-fpn model seen supplementary fig figure localization difference example localization difference yolov7 predicted bounded box first column faster r-cnn predicted bounded box second column manually annotated bounding box third column full size image addition detection error model also make localization error particular localization error happens iou overlap predicted bounding box manually annotated bounding box doe satisfy desired threshold e.g. however extent difference bounding box could stem difference way manual annotation performed human prone error inconsistency performing annotation fig show model learn human annotation also produce bounding box enclosing object interest closely loosely thus leading difference term object localization yolov2 model tool coccinellid detection enable use best model research community make available pre-trained yolov7 model web-based application http shown supplementary fig web-based application user-friendly allows user explore model prediction using sample image available front page alternatively new image uploaded site submitted analysis underneath built-in model used detect classify coccinelids image result displayed site using annotated bounding box take approximately 4-5 second prediction made given interaction server addition web-based application doe require programming skill also make pre-trained model source code available github experienced user may need train adapt model specie datasets limitation study shown deep learning model used identify seven type common coccinellids sorghum methodology proposed study provide tremendous benefit ipm sorghum would also like point limitation emphasized error analysis coccinellids identified especially cover area image sometimes two coccinellids overlap image image type need included dataset improve performance model image similarly model make mistake term type coccinellid identified also term precise location bounding box coccinellid dataset cover seven type coccinellids includes image several coccinellids coccinellids image type clear model would perform image coccinellids different type dataset includes small set image coccinellids considered small object based size see supplementary table data needed estimate performance model detecting small coccinellids high chance appear image taken autonomous device wild big variety image used train test model image may fully representative image would potentially taken autonomous device drone additional data captured device added training set improve robustness model scenario conclusion study focus application high throughput deep learning model detect classify coccinellids commonly found sorghum specifically compared two-stage faster r-cnn-fpn one-stage detector yolov5 yolov7 task detecting classifying seven type coccinellids including coccinella septempunctata coleomegilla maculata cycloneda sanguinea harmonia axyridis hippodamia convergens olla v-nigrum scymninae first assembled annotated dataset 4,865 image based inaturalist imagery web server publishes citizen observation regarding living organism image dataset contain one eight instance coccinelids manually annotated bounding box using labelbox tool using assembled dataset split training development test subset experimented several variant faster r-cnn-fpn network base cnn either resnet-50 resnet-101 loss optimized either standard iou generalized giou also experimented several variant yolov5 yolov7 model experimental result showed standard yolov7 model give best result overall test data 0.50 high 97.31 high 74.5 specific variant competitive result relation result similar problem prior work suggest model potential make task detecting natural enemy sorghum easier integrated system automated pest management enable community make use model made available model part web-based application allows end-users identify coccinellids image