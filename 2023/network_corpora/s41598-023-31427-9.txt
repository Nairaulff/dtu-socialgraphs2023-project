introduction quantum algorithm produce statistical pattern hard manipulate classical computer turn may perhaps help recognize pattern difficult identify classically pursue basic idea huge research effort put forward speed machine learning routine exploiting unique quantum property superposition coherence entanglement within realm machine learning reinforcement learning paradigm gained attention last two decade wide range application scenario allows modeling agent able learn improve behavior reward penalty received fully known environment agent typically chooses action perform sampling probability distribution mirror expected return associated action performed conditioned state environment aim procedure maximize total reward corresponds achievement given task obtained devising stochastic strategy train agent performing series action picked given set maximizes total reward final output conditional probability distribution correlate state environment action taken agent modify state turn performance improved use quantum routine recently reviewed date various promising proposal put forward exploit quantum accelerator speed-up including e.g. speed-ups projective simulation quantum model policy quantum circuit boltzman machine application measurement-based adaptation protocol implementation photonic platform moreover context worth mentioning strategy based grover algorithm proposed generate action probability distribution learning agent suitable number action finite along line introduce novel algorithm differentiates grover algorithm-based approach mainly exploitation coordination action multiple oracle associated action subset show allows tune probability distribution subset exploration exploitation phase moreover method generalizes mentioned able approximate principle desired probability distribution thus overcoming existing limitation applying standard grover algorithm furthermore procedure doe require prior knowledge probability assign assumed previous work following classification proposed algorithm fall framework classical generating system quantum data processing device specifically work first introduce routine encode update probability distribution onto quantum register show embody q-learning based algorithm action clustered predetermined number subset class associated range minimum maximum value expected reward cardinality class evaluated due course procedure built upon well-known quantum routine i.e. quantum oracle quantum counting information obtained classical procedure run assign probability subset accordance desired distribution element within class taken equally likely allows one tune probability order assign larger chance action included range maximum value expected reward probability distribution also changed dynamically order enforce exploration first stage allowing action associated low probability chosen exploitation second stage restrict search action higher likelihood occurrence quantum routine presented allows re-evaluating value examining action admissible given state single parallel step possible due quantum superposition besides scenario approach explicitly tailored main advantageous feature routine could also exploited context one need sample probability distribution ranging swarm intelligence algorithm particle swarm optimization ant colony optimization cloud architecture objective find efficient assignment virtual machine physical server problem known np-hard presenting quantum routine detail section preparing quantum probability distribution focus use setting section improving reinforcement learning show fact tailored need large number state-action pair section additional feature algorithm give assessment advantage quantum accelerated pure classical algorithm needed quantum resource technical section follows discussing detail probability encoding routine evaluating complexity precision section detail probability distribution encoding algorithm finally draw concluding remark section conclusion preparing quantum probability distribution introduce quantum routine encodes classical probability distribution quantum register let assume random variable whose discrete domain includes different value x_j j=1 map basis state -dimensional hilbert-space goal prepare quantum state measurement probability basis reproduce random variable probability distribution x_1 x_2 quantum routine start initializing aligned =\frac k=1 x_k _a\ aligned homogeneous superposition basis state x_k ancillary qubit set state _a\ approach final state prepared encoding probability related state sequentially require j-1\ step -th step algorithm 1\le grover iteration used set amplitude x_i basis state a_i=\sqrt x_i particular apply conditional grover operator _i\otimes _i=\hat _i\ projector onto state _a\ ancilla y=0,1\ force grover unitary _i\ act component state tied unticked state _a\ ancillary qubit operator =2\left| reflection respect uniform superposition state whereas operator _i= -2\left| x_i x_i built flip sign state x_i leave state unaltered grover operator applied amplitude x_i approximates a_i\ desired precision see section detail probability distribution encoding algorithm state ancilla modified execution grover algorithm -th step end ensuring amplitude x_i modified anymore next step end tick component tying state _a\ obtained applying operator _i=\left| x_i x_i -\left| x_i x_i whose net effect aligned _i\left| x_k _a= array x_k k=i x_k otherwise array aligned not-gate 1\le 0,1\ step state system aligned j=1 a_j x_j aligned state general non-zero overlap basis state including state x_1 i-1 whose amplitude updated previously due action reflection operator output superposition basis state however doe preclude extracting value probability random variable correctly thanks ancillary qubit indeed end last step ancilla first measured logical basis outcome measurement proceed measuring rest get one first j-1\ value random variable assigned probability distribution otherwise output set x_j\ since probability getting measurement ancilla due normalization condition =a_ k=1 j-1 a_k^2\ procedure generalized encode random distribution element divided sub-interval case probability assigned separately every single element rather collectively sub-interval element belonging sub-interval assigned equal probability useful approximate random distribution number element large case operates -dimensional hilbert space grover operator used amplify one state j-1\ step example simplest case think set grover operator act basis state general case though grover operator could amplify different priori unknown number basis state case discussed following quantum routine exploited context improving reinforcement learning show algorithm introduced exploited context specifically q-learning cycle figure provides sketch emphasising part cycle involved algorithm objective context update action probability clarified rest section algorithm described term abstract agent interacting environment environment one state belong given set whereas agent allowed perform action picked set a_s\ general depends state agent chooses one allowed action according given policy action taken agent receives reward environment state change reward used agent understand whether action useful approach goal learn adapt improve behavior shortly higher value reward better choice action particular state principle behavior policy consist rule determines best action possible state algorithm aim finding optimal policy maximizes overall reward i.e. sum reward obtained action however reward fully known advance agent need act basis estimate value figure sketch q-learning cycle agent schematically represented performing q-learning cycle namely taking action solve problem getting back reward possibly changing state finally building new probability distribution using algorithm proposing next action extracted full size image among various approach designed end called q-learning algorithm adopts temporal difference method update value i.e. estimation profitable choice action agent state choosing action given step algorithm two key factor need taken account explore possible action exploit action greatest value common resort compromise exploration exploitation choosing new action random distribution defined probability choosing action state mirror example one could adopt boltzmann-like distribution a|s =e^ normalising factor parameter vary learning process large beginning order favor exploration lower experience environment acquired order exploit knowledge give chance action higher reward severe bottleneck performance training algorithm arises number action and/or state large example chess game number state 10^ fact impossible deal consequent huge number value workaround use function approximates value obtained rule whose property depend upon small set free parameter updated training approach showed effectiveness different classical approach example deep q-learning function implemented mean neural network whose parameter updated accordance experience agent quantum scenario approach turn even effective indeed possible build parameter-dependent quantum circuit implement approach adopted recent study near-term quantum device circuit allows evaluate function complete quantum parallel fashion i.e. one shot admissible action given state approach possible obtain quantum advantage process building probability distribution action using algorithm presented section preparing quantum probability distribution achieve significant quantum speed-up reduce number required quantum resource thus making algorithm suitable near term nisq processing unit assign probability every action rather aggregate action class i.e. subset according probability explained following let consider minimum maximum value let divide interval non-overlapping necessarily equal sub-interval i_j\ given state include action a\in class c_j\ i_j\ a_s c_j\ probability sub-interval determined sum -values corresponding action c_j action c_j\ considered equally probable figure quantum routine schematic representation quantum routine update classical probability distribution quantum register initialization register j-1\ update performed store value probability distribution class state show also single iteration modified grover algorithm full size image way algorithm requires j-1\ step devoted amplify action belonging one j-1\ class -th probability obtained normalization furthermore also take advantage aggregation encoding probability distribution onto case indeed use predetermined grover oracle devoted amplify logical state corresponding action belonging given c_j\ offloading distribution-update routine onto quantum processor part q-learning procedure need two qrs encode action sub-interval respectively register need log_2 log_2 qubits respectively let consider class c_j=\ a_s i_j\ goal assign action c_j\ probability p_j\ based sub-interval using routine presented section preparing quantum probability distribution distribution building process start preparing following uniform superposition aligned =\frac aligned initial state register order apply algorithm need j-1\ oracle _j\ one given i_j\ obtain oracle first necessary define operator record sub-interval j_a\ value belongs action creates correlation two register changing initial state register follows aligned j_a aligned complete construction oracle need execute two unitaries operator j_a _\mathcal _\mathcal -2\left| j_a j_a flip phase state j_a -register operator disentangles two register effective oracle operator entering algorithm described previous section defined =\hat net effect aligned _\mathcal _\mathcal array -\left| _\mathcal _\mathcal c_j _\mathcal _\mathcal otherwise array aligned eventually apply reflection average register thus completing iteration grover operator let notice whereas operator act register action act register class grover ancilla shown schematically fig cardinality c_j\ decided beginning order evaluate right number grover iteration executed need compute see section optimal number iteration grover algorithm detail number action obtained c_j\ running quantum counting algorithm associated _j\ action possible apply routine section preparing quantum probability distribution order build desired probability distribution quantum state -register obtained agent choose action measuring state according outcome environment update value classically thus changing behaviour operator summarize key step quantum enhanced algorithm box classical quantum operation denoted respectively schematic picture amplitude distribution upload circuit depicted fig show needed resource well main gate required scheme hybrid algorithm initialize start state execute cycle build sub-interval class quantum circuit oracle _i=\hat use quantum counting _i\ compute number action belonging sub-interval compute number grover iteration class build probability distribution admissible action measure obtain action execute get new state s'\ reward update additional feature algorithm quantum enhanced algorithm presented resort quantum acceleration remove bottleneck classical approach provide assessment advantage obtained case finite yet large number action one classically given state number call function increase asymptotically conversely quantum protocol number call therefore asymptotically nonetheless larger number action lower bound error 1/\sqrt see section optimal number iteration grover algorithm detail thus case quantum algorithm based grover obtained quadratic speed-up classical algorithm updating probability distribution strategy discretizing value bin affect also reinforcement learning procedure point view accuracy reproducing desired probability distribution exploitation-exploration interplay let error introduced discretization respect target probability distribution general may depend feature target distribution independent total number action bin however rough quantitative estimate take scale proportionally size bin obtaining upper bound m-m direct consequence rectangle method accuracy approximate integral fact important process definition sub-interval maximum minimum value computable advance mean well-established quantum routine increase complexity procedure discretization also direct impact number call needed update value probability distribution indeed larger number bin call grover oracle scale linearly number bin see section optimal number iteration grover algorithm detail total computational time training general strictly problem dependent depends chosen cost function well detail size bin although estimable priori yet another parameter used lower convergence time learning finally let quantify quantum resource needed order implement algorithm ideal noiseless case reported qubits needed implement strategy organized two register first one encode case action reinforcement learning protocol consequence require log_2 qubits second one instead devoted encoding class used discretize -values needing log_2 qubits moreover ancillary qubits necessary implement oracle number strictly dependent specific problem function number action conclude logarithmic scaling number required qubits realistic scenario decoherence affect operation one possibility preserve advantage resort error correction algorithm unavoidably result increase amount quantum resource algorithm sensitive part noise amplification amplitude via grover algorithm interval ref extensive analysis effect noise grover search reported author show steane code effective strategy correct error grover search algorithm allowing lower gain qbch code reduce total amount resource needed suggested ref hybrid approach considered possible compromise two method detail probability distribution encoding algorithm technical section provide detail routine presented section preparing quantum probability distribution important actual implementation specifically address problem compute optimal number iteration grover algorithm order store single instance probability distribution compute quantity needed link update value probability distribution different sub-interval one step another finally iii evaluate complexity optimal number iteration grover algorithm order compute optimal number iteration single step exploit result reported ref grover algorithm generalized case initial non-uniform distribution define following quantity aligned =\frac j=1 k_j^ =\frac n-r_ j=r_ l_j^ aligned number grover iteration already performed dimension hilbert space context total number action n=|a_s|\ k_j^ coefficient r_i\ basis state amplified grover iteration step algorithm application r_i=|c_i|\ l_j^ coefficient basis state average labeled step-counting variable let assume one basis state time amplified grover iteration namely r_i=1\ applying result ref case obtain aligned n-1 -k^ n-1 aligned w=2\arcsin 1/n first equation compute number step t_f^ needed set coefficient desired value wanted precision bring value probability distribution x_i =|b_i\ t_f^ notice need value perform calculation value extracted form global state previous step specifically last iteration grover algorithm variation quantum state within grover iteration let consider quantum state action-register plus ancilla system given iteration grover algorithm given step aligned =\sum k=1 i-1 a_k\left| x_k _a+b_i\left| aligned b_i= 1-\sum k=1 j-1 a_k^2 1/2 t=0\ beginning grover algorithm let write state form highlight decomposition three set basis state aligned =k^ x_i k=1 i-1 l_k^ x_k +\sum k=i+1 x_k aligned made explicit dependence coefficient decomposition step useful following x_i one want use encode value probability distribution current step algorithm x_j\ j\in i-1 basis state generated reflection operation around mean whose amplitude updated previous i-1\ step j\in i+1 basis state amplitude operation performed point change using expression possible derive recursive relation compute iteratively function shall see useful order compute initial i+1 i+1 i+1 next step find recursive relation let first apply grover operator onto _a\ project onto state i+1 i+2 without loss generality choose i+1 aligned t+1 i+1 _i\left| i+1 2\left| -k^ x_i +\sum k=1 i-1 l_k^ x_k k=i+1 x_k i+1 2\left -\frac +\frac n-1 x_i -\sum k=1 i-1 l_k^ x_k -\sum k=i+1 x_k n-1 -\frac -\alpha aligned using well initial value beginning grover iteration together number iteration t_f^ simple classical iterative procedure compute final value t_f^ t_f^ t_f concludes one step embedding algorithm linking two consecutive step distribution-encoding algorithm let see use t_f^ t_f^ t_f^ computed end step obtain value i+1 i+1 i+1 needed following step i+1\ first consider global state end step applying operator mark state x_i whose amplitude updated aligned t_f^ =\sum j=1 i-1 a_j\left| x_j _a+b_ t_f^ aligned aligned t_f^ =k^ t_f^ +\sum l_k t_f^ x_k aligned applying obtain initial global state seed grover iteration step i+1\ aligned =\sum k=1 i-1 a_k\left| x_k _a+a_ x_i _a+b_ i+1 i+1 aligned aligned i+1 =k^ i+1 i+1 +\sum i+1 l_k^ x_k aligned new state coefficient i+1 ensures i+1 unit looking coefficient easy see =b_ t_f^ way compare coefficient appear state _a\ ancilla corresponding component aligned i+1 i+1 _a= t_f^ -k^ t_f^ _a\\=\ l_k^ t_f^ x_k aligned follows aligned i+1 =\frac b_i i+1 l_k^ t_f^ x_k aligned finally obtain aligned i+1 =k^ i+1 =\frac b_i i+1 t_f^ i+1 =\frac i+1 l_k^ i+1 n-1 =\frac b_i i+1 i+1 l_k^ t_f^ n-1 b_i i+1 t_f^ -\frac t_f^ n-1 aligned also possible generalize result case state updated superposition one basis state let assume r_i case general relation read aligned =\bar n-r_i r_i -\bar r_i n-r_i aligned w=2\arcsin r_i/n since marked state probability conclude probability single state ^2\ moreover expression i+1 aligned i+1 =\frac b_i i+1 n-r_i t_f^ -r_ i+1 t_f^ n-r_ i+1 aligned updating rule important underline general case necessary know advance number state related oracle mentioned set beginning achieved mean quantum counting procedure complexity precision order compute complexity algorithm start observation derived ref optimal number grover iteration given step upper bounded aligned n_i^ =\frac -\arctan r_i n-r_i 1-2\frac r_i aligned expanding n_i^ leading-order working assumption obtain aligned n_i^ -\frac +\frac r_i aligned expression conclude initial condition state reduce optimal number call grover operator dealing positive amplitude worth note case want set amplitude action maximum value value determined probability distribution therefore number grover iteration typically much lower upper bound given explained section improving reinforcement learning number time grover procedure executed equal number sub-interval chosen total complexity aligned aligned took account given state n=|a_ complexity equal useful quantity compute practical implementation algorithm precision variation probability associated action two consecutive iteration amplitude amplification t+1\ used criterion stop iteration quantified follows aligned p=\ x_i _a\left| t+1 x_i _a\left| b_i^2\bigl t+1 ^2- ^2\bigl b_i^2\bigl t+1 -\cos ^2\bigl n-r_i r_i t+1 ^2-\sin n-r_i r_i t+1 -\sin 2wt aligned recalling assumed considering upper bound case r_1 expand leading-order 1/|a_ aligned b_i^2\bigl ^2\frac ^2|a_ aligned interestingly precision bounded bound obtained b_i=1\ -1/2 -1/2 aligned aligned quantity also seen minimum error probability update matter many iteration perform conclusion work presented routine based grover algorithm encode probability distribution onto quantum register quadratic speed-up improvement quantum routine find several useful application context hybrid classical-quantum workflow spirit shown exploit training q-learning strategy shown give rise quadratic quantum speed algorithm obtained inclusion quantum subroutine stage action selection workflow large finite number action effectively enables achieving trade exploration exploitation thanks intrinsic randomness embodied extraction action performed also possibility dynamically changing relationship action value thus relative probability classical case trade exploitation exploration need implemented extra control parameter typically via random variable user-defined threshold manages rate acceptance non-optimal stat-action pair finally stress procedure use grover oracle given minimum maximum range action value number interval range divided specified advance