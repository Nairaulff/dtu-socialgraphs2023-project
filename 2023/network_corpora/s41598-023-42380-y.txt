introduction background known water quality primary indicator ecosystem health aquatic community instance aquaculture quality growth aquatic product highly affected quality water concentration dissolved oxygen well-known measure water quality reflecting balance production consumption oxygen therefore important criterion water quality management variation concentration function several factor however major source photosynthetic activity aeration structure re-aeration atmosphere measuring difficult task due effect various factor like salinity temperature oxygen source etc considering dynamic nature well challenge providing measurement equipment developing predictive model great desire monitoring water quality hence non-linear method received increasing attention exploring relationship environmental key factor water discharge water temperature specific conductance among important parameter different combination considered earlier research depending data availability environmental condition popular provider hydrological time series geological survey usgs research organization provides high-quality publicly available water data different area general provided data categorized either approved publication subject revision name imply first group data reliably processed relevant staff second group received approval yet work approved data klamath river station station number used many study literature water quality prediction used usgs data especially prediction klamath river literature review recent advance computational measurement domain world science witnessed various development aiming facilitating complex problem regarding natural phenomenon instance remote sensing facility among applicable tool monitoring nature e.g. water body hydrology one field highly befitted development sense involved subject may extend precipitation analysis water quality assessment statistical machine learning method two evident example suggested model water quality analysis general sense prediction/monitoring study cover wide range scientific effort various environmental parameter advent machine learning shed new light domain provides fast reliable inexpensive solution complex prediction problem recent sophisticated method like artificial neural network ann adaptive neuro-fuzzy inference system anfis highly regarded engineer prediction different part world kisi investigated ability two popular notion anns namely radial based function rbf multi-layer perceptron neural network mlpnn analyzing concentration compared model multilinear regression mlr found rbf performs better two model liu successfully employed attention-based recurrent neural network rnn long-term short-term prediction research effectiveness anns found proved applicability support vector machine svm predicting concentration hypoxic river system reference larger correlation obtained testing phase used svm promising approach purpose huan demonstrated high efficiency svm based least-squares theory lssvm shi successfully applied clustering-based softplus extreme learning machine cselm simulating content aquaculture also shown model accurate standard elm kisi proposed intelligent model called bayesian model averaging bma estimation validated performance model five well-known model including elm classification regression tree cart ann mlr anfis based obtained rmses 1.321 bma vs. 1.439 1.809 1.504 1.742 1.447 elm cart ann mlr anfis respectively superiority bma clearly derived najah compared anfis ann modeling found result anfis accurate olyaie conducted comparison among four data-driven model including rbf linear genetic programming lgp mlpnn svm used objective referring respective coefficient determination 0.8140 0.9662 0.9169 0.9748 svm surpassed tested model feasibility so-called deep learning technique gated recurrent unit analysis fishery pond shown model also outperformed rnn long short-term memory applicability machine learning model evolving fuzzy neural network efunn radial basis function neural network rbfnn general regression neural network grnn long-short term memory lstm support vector regression svr dynamic evolving neural-fuzzy inference system denfis shown compared earlier study comparative study found earlier literature optimization regular predictive model studied many scholar recent year raheli built optimized version mlp neural network using firefly algorithm forecasting biochemical oxygen demand performance hybrid model found reliable standard mlp furthermore uncertainty analysis revealed acceptable degree uncertainty ann yaseen coupled lssvm bat algorithm approximating comparison conventional machine learning model like multivariate adaptive regression spline mar tree pointed considerably higher accuracy i.e. rmse reduction proposed hybrid three optimization technique particle swarm optimization pso biogeography‐based optimization butterfly optimization algorithm used fadaee optimizing anfis applied seasonal analysis accuracy afnis experienced nearly improvement spring summer fall winter respectively liu could enhance accuracy least-squares svr improved pso similar application pso examined chen bayram recommended use teaching–learning based optimization tlbo applied quadratic regression stream analysis comparative effort azma seven hybrid mlp biogeography-based optimization bbo sunflower optimization sfo atom search optimization aso crow search algorithm csa league championship algorithm lca shuffled frog leaping algorithm sfla slime mould algorithm sma tested prediction rock creek station usgs number around washington usa result showed higher accuracy bbo-based model also importance assessment input reflected largest lowest importance respectively motivation contribution concerning promising result obtained hybrid algorithm utilizing metaheuristic-empowered model becoming research hotspot wide range engineering domain order address latest development regard work employ tlbo along sine cosine algorithm sca water cycle algorithm wca electromagnetic field optimization efo training strategy mlpnn predict daily using five-year record main contribution four metaheuristic algorithm problem prediction lie tuning mlpnn computational variable responsible establishing relationship influential parameter hence due optimization procedure algorithm said tlbo sca wca efo optimize non-linear dependency water condition achieve reliable prediction different condition case study klamath river oregon northern california whose initial part suffers seasonal low water quality study also pursues comparing efficiency used algorithm toward achieving fast inexpensive reliable evaluative model used model optimized term hyperparameters end practical monolithic formula extracted used do-predictive equation eliminating need running computer-aided program gui hence outcome study may provide significant contribution early prediction concentration within klamath river usgs data study area figure show location study area klamath county oregon flowing southern oregon pacific ocean klamath river approximate length originates link river dam responsible regulating lake level controlling downstream flow diverting water hydropower irrigation purpose origin klamath river shallow wide reach around klamath fall town rough altitude keno dam located around downstream control river flow dominant climate area semi-arid dry summer precipitation mostly occur winter fall initial part river characterized seasonal low water quality preventing hosting aquatic issue call proper water quality assessment area figure location klamath river station image obtained google earth full size image time-series data consisting record klamath river station operated usgs station number downloaded usgs water data website http available data five-year period i.e. 2014–2019 october september considered training sample deriving relationship trained model tested using data october september called testing data figure depicts variation moreover training testing datasets statistically described table figure variation independent factor full size image table descriptive statistic used datasets full size table methodology figure show methodological flowchart study data provision klamath river station training testing datasets created model developed combining mlpnn model four metaheuristic algorithm tlbo sca wca efo model trained using training dataset predict testing period end accuracy evaluated using error correlation criterion rank performance figure methodology study full size image following description model presented mlpnn mlpnn broadly used type anns structured several unit lying three layer namely input layer hidden layer output layer figure show architecture mlpnn used work neuron mlpnn completely connected together weight network play role synapsis biological neural network figure mlp designed predicting full size image neuron input multiplied specific weight factor added bias neuron hidden layer output layer linear non-linear activation function release outcome neuron last step training mechanism mlpnn described iteratively adjusting weight bias toward accurate prediction e.g. lower error new network common algorithm responsible process levenberg–marquardt work algorithm replaced tlbo sca wca efo metaheuristic algorithm tlbo metaheuristic algorithm designed rao widely used solving various problem algorithm class student teacher simulated teacher influence learner reach proper harmony improving knowledge student take place two separate step conducted teacher student i.e. teacher phase learner phase respectively regard potential i.e. fitness individual assessed exam teacher phase calculating fitness value potent individual considered teacher next phase learner help together improve knowledge previous study detailed mathematical regulation tlbo recently developed algorithm sca mimic mathematical rule i.e. sine/cosine function algorithm proposed mirjalili generating random swarm algorithm conduct optimization two phase namely exploration exploitation first phase suitable searching area found abruptly mixing random solution several others large rate randomness second phase random solution experience change gradually several random value used sca considered variable sine/cosine function random number also play role criterion determining updating equation i.e. utilizing either sine cosine function sca mathematically described study like eskandar developed wca taking main inspiration water cycle running nature assuming algorithm commences raining raindrop may finally take form stream river sea-based fitness value designation sea capable solution provided algorithm far river also represent improved version stream individual iteratively replace find powerful sea clearly stream promising river exchange position sea likewise replaced promising river wca mentioned process repeated repeating rain process creates new raindrop hereby prevents premature optimum wca detailed earlier literature electromagnetics-based search scheme abedinpourshotorban proposed efo similar initial classification executed wca agent efo algorithm known electromagnetic particle emp first grouped one positive negative neutral field done respect fitness proposed emp iteration new emp generated brings larger fitness replaces worst existing emp producing new emp begin taking member field next step neutral emp donates position pole new particle based fact different pole attract vice versa new particle affected positive negative emps study like contain mathematical detail explained process accuracy criterion assessing capability model mean absolute error mae root mean square error rmse index employed report prediction error equation describe error calculation using mae rmse besides pearson correlation coefficient used measure correlation result equation formulates index another criterion called nash–sutcliffe efficiency nse coefficient also expressed mae do_ expected do_ predicted rmse do_ expected do_ predicted do_ predicted predicted do_ ected expected do_ predicted predicted do_ expected expected nse do_ expected do_ predicted do_ expected expected predicted expected stand modeled measured respectively respective mean predicted expected moreover signifies number processed sample equal training testing data respectively result discussion paper offer four novel model prediction model composed mlp neural network core tlbo sca wca efo training algorithm model developed implemented matlab environment optimization training proper training mlp dependent strategy employed algorithm appointed task described previous section tlbo sca wca efo section characteristic discussed format hybridization result mlp mlpnn considered basis hybrid model per section mlpnn model three layer input layer receives data neuron one output layer one neuron releasing final prediction i.e. however hidden layer various number neuron study trial-and-error effort carried determine proper number ten model tested neuron hidden layer observed give best performance hence final model structured logic activation function output hidden neuron respectively selected pureline tansig described section formula presentation next training dataset exposed selected mlpnn network relationship water condition established mean weight bias within mlpnn fig study role tuning thesis weighst bias assigned named metaheuristic algorithm purpose mlpnn configuration first transformed form mathematical equation adjustable weight bias equation shown section formula presentation training mlpnn using metaheuristic algorithm iterative effort hereupon rmse modeled measured introduced objective function tlbo sca wca efo function used monitor optimization benhavior algorithm since rmse error indicator algorithm aim minimize time improve quality weight bias designating appropriate number iteration another important step analyzing convergence behavior algorithm well referring previous similar study iteration determined tlbo sca wca efo implemented 30,000 iteration final solution used constrcuct optimized mlpnn figure illustrates optimization flowchart figure optimization flowchart model full size image furthermore algorithm implemented nine swarm size achieve best model configuration tested tlbo sca wca efo collecting obtained objective function i.e. rmses led creating convergence curve tested figure depicts convergence curve tlbo-mlpnn sca-mlpnn wca-mlpnn efo-mlpnn figure optimization curve tlbo-mlpnn sca-mlpnn wca-mlpnn efo-mlpnn full size image seen algorithm different method training mlpnn according chart tlbo-mlpnn sca-mlpnn wca-mlpnn efo-mlpnn respective attained lowest rmses mean model mlpnns trained configuration acquired promising weight bias compared eight table collect final parameter model table parameter used algorithm full size table training testing result rmse recognized elite model i.e. tlbo-mlpnn sca-mlpnn wca-mlpnn efo-mlpnn 1.3231 1.4269 1.3043 1.3210 respectively value plus maes 0.9800 1.1113 0.9624 0.9783 0.7730 0.7359 0.7794 0.7737 indicate mlp suitably trained proposed algorithm order graphically ass quality result fig generated show agreement modeled measured calculated i.e. 0.8792 0.8637 0.8828 0.8796 demonstrate large degree agreement used model moreover outcome expected predicted referred error every sample frequency value illustrated fig chart show larger frequency error value close meaning accurately predicted outnumber considerable error figure scatterplot histogram error plotted training data tlbo-mlpnn sca-mlpnn wca-mlpnn efo-mlpnn full size image evaluating testing accuracy revealed high competency used model predicting new value word model could successfully generalize pattern captured exploring data belonging 2014–2018 data fifth year example fig show modeled measured two different period including october december january march seen first period upward pattern well-followed four model also model shown high sensitivity fluctuation pattern second period figure real predicted pattern october december january march full size image figure show error obtained testing data rmse mae tlbo-mlpnn sca-mlpnn wca-mlpnn efo-mlpnn 1.2980 0.9728 1.4493 1.2078 1.3096 0.9915 1.2903 1.0002 respectively value along 0.7668 0.7092 0.7626 0.7695 imply model predicted unseen tolerable level error moreover fig present corresponding scatterplots illustrating correlation modeled measured testing phase based value 0.8785 0.8587 0.8762 0.8815 satisfying correlation seen used model figure error line scatterplot plotted testing data tlbo-mlpnn sca-mlpnn wca-mlpnn efo-mlpnn full size image efficiency comparison discussion compare efficiency employed model accurate model first determined comparing obtained accuracy indicator comparison optimization time carried table collect calculated accuracy criterion study table obtained accuracy index full size table term accuracy criterion i.e. rmse mae nse wca-mlpnn emerged reliable model training phase word wca presented highest quality training mlp followed efo tlbo sca however result testing data need discussion phase efo-mlpnn achieved smallest rmse 1.2903 largest 0.8815 largest nse 0.7695 time smallest mae 0.9728 obtained tlbo-mlpnn sca-based ensemble shown model yield poorest prediction phase additionally fig also produced compare accuracy model form boxplot taylor diagram respectively result two figure consistent comparison indicate high accordance model output target also reflect higher accuracy wca-mlpnn efo-mlpnn tlbo-mlpnn compared sca-mlpnn figure boxplots model comparison full size image figure taylor diagram model comparison full size image comparison previous literature said model attained higher accuracy prediction instance study yang three metaheuristic algorithm namely multi-verse optimizer mvo shuffled complex evolution sce black hole algorithm bha combined mlpnn model applied case study klamath river station best training performance achieved mlp-mvo respective rmse mae 1.3148 0.9687 0.8808 best testing performance achieved mlp-sce respective rmse mae 1.3085 1.0122 0.8775 per table inferred wca-mlpnn suggested study provides better training result also far testing result concerned wca-mlpnn tlbo-mlpnn outperformed model tested yang another study kisi ensemble model called bma suggested case study achieved training testing rmses 1.334 1.321 respectively see table cited paper error value higher rmses tlbo-mlpnn wca-mlpnn efo-mlpnn study consequently model outperform benchmark conventional model tested kisi i.e. elm cart ann mlr anfis logic superiority suggested hybrid model conventional model employed previous study different station klamath river inferred altogether comparison indicate study achieved considerable improvement field prediction table denotes time elapsed optimizing mlp algorithm according table efo-mlpnn despite requiring greater number iteration i.e. 30,000 efo vs. tlbo sca wca accomplishes optimization considerably shorter time relation time tlbo sca wca range 181.3 12,649.6 88.7 6095.2 83.2 4804.0 efo bounded 277.2 296.0 another difference efo proposed algorithm related two initial since viable value implementing efo two value alternatively considered table time taken performing optimum mlp training second full size table based discussion tlbo wca efo showed higher capability compared sca examining time selected configuration tlbo-mlpnn sca-mlpnn wca-mlpnn efo-mlpnn i.e. 12,649.6 5295.7 4733.0 292.6 respectively show wca need around tlbo time train mlp efo however provides fastest training apart comparison successful prediction carried four hybrid model represents compatibility mlpnn model metaheuristic science creating predictive ensemble used optimizer algorithm could nicely optimize relationship water condition i.e. klamath river station basic model mlpnn containing weight bias fig therefore algorithm provided solution composed variable iteration considering number tested iteration algorithm i.e. 30,000 iteration efo iteration wca sca tlbo nine said outstanding solution belonging efo algorithm excerpted among large number candidate 30,000 however concerning limitation work term data methodology potential idea raised future study first suggested update applied model recent hydrological data well record water quality station order enhance generalizability model moreover metaheuristic algorithm tested combination different basic model anfis svm conduct comparative study formula presentation higher efficiency wca efo term time accuracy derived previous section hereupon mlpnns constructed optimal response two algorithm mathematically presented section give two formula predicting referring fig calculation output neuron wca-mlpnn efo-mlpnn expressed respectively aligned do_ wca mlpnn 0.395328 hn1 0.193182 hn2 0.419852 hn3 0.108298 hn4 0.686191 hn5 0.801148 hn6 0.340617 aligned aligned do_ efo mlpnn 0.033882 hn1 0.737699 hn2 0.028107 hn3 0.700302 hn4 0.955481 hn5 0.757153 hn6 0.935491 aligned relationship hni hni represent outcome hidden neuron wca-mlpnn efo-mlpnn respectively given tansig -2x activation function hidden neuron hni hni calculated equation seen two parameter calculated input study i.e. array hn1 hn2 hn3 hn4 hn5 hn6 array tansig\left array 1.818573 1.750088 0.319002 0.974577 0.397608 2.316006 1.722125 1.012571 1.575044 0.000789 2.532009 0.246384 1.288887 1.724770 1.354887 0.735724 2.250890 0.929506 array array array array 2.543969 1.526381 0.508794 0.508794 1.526381 2.543969 array array hn1 hn2 hn3 hn4 hn5 hn6 array tansig\left array 1.323143 2.172674 0.023590 1.002364 0.785601 2.202243 1.705369 1.245099 1.418881 0.033210 1.681758 1.908498 1.023548 0.887137 2.153396 0.325776 1.818692 1.748715 array array array array 2.543969 1.526381 0.508794 0.508794 1.526381 2.543969 array clearly integration result wca-mlpnn formula integration result efo-mlpnn formula given excellent accuracy two model superiority previous model literature either two formula used practical estimation especially solving water quality issue within klamath river conclusion four stochastic search strategy namely teaching–learning-based optimization sine cosine algorithm water cycle algorithm electromagnetic field optimization used train artificial neural network predicting dissolved oxygen klamath river oregon designating appropriate parameter algorithm accuracy index showed four method properly train mlp grasp reliable understanding behavior due reason model could reliably predict new environmental condition hybrid model compared term accuracy complexity computation time detect efficient predictor training process deduced although efo algorithm required time iteration accomplished process far faster three algorithm also presented accurate result term rmse nse testing phase another advantage model hiring smaller number search agent find optimal response wca-mlpnn emerged second-efficient model therefore two predictive based weight bias tuned wca efo proposed last part research moreover shown outstanding model study outperform several hybrid conventional model previous study indicating improvement practical prediction would also help better solving problem poor water quality studied area