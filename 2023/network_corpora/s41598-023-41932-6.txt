introduction human action recognition play vital role distinguishing particular behavior interest video critical application including visual surveillance detection suspicious human activity prevent fatal accident automation-based driving sense predict human behavior safe navigation addition large amount non-trivial application human–machine interaction video retrieval crowd scene analysis identity recognition early day majority research human activity recognition conducted using hand-crafted method however deep learning technology evolved gained increasing recognition research community multitude new technique proposed achieving remarkable result action recognition preserve similar property image recognition since field handle visual content addition action recognition classifies still image also dynamic temporal information sequence image built intrinsic characteristic action recognition method grouped two main approach namely recurrent neural network rnn based approach 3-d convnet based approach besides main one method utilize content spatial temporal coined name two-stream 2-d convnet based approach initially action recognition viewed natural extension image recognition spatial feature still frame could extracted using convnet one efficient technique image recognition field however traditional convnets capable processing single 2-d image time expand multiple 2-d image neural network architecture need re-designed including adding extra dimension operation convolution pooling accommodate 3-d image example technique include c3d i3d r3d s3d t3d ltc among others similarly since video primarily consists temporal sequence technique sequential data recurrent neural network specifically long short term memory utilized analyze temporal information despite larger size image feature extraction often employed long-term recurrent convolutional network lrcn beyond-short-snippets among first attempt extract feature map 2-d convnets integrate lstms make video prediction work adopted bi-directional lstms composed two separate lstms explore forward backward temporal information improve performance researcher argue video usually contain repetitive frame even hard-to-classify one make computation expensive selecting relevant frame help improve action recognition performance term efficiency accuracy similar concept based attention mechanism main focus recent research boost overall performance convnet-lstm framework rnns superior field process data sequentially meaning information flow one state next hindering ability speed training parallel causing architecture become larger size issue limit application rnns longer sequence light challenge new approach transformer emerged rapid advancement action recognition recent year 3-d convnets 2-d convnets-lstm two-stream convnets recently transformer advancement brought many benefit also created critical issue previous technique unable keep rapidly changing pace although technique evolutionary computation offer crucial mechanism architecture search image recognition swarm intelligence provides straightforward method improve performance remain largely unexplored realm action recognition recent research developed dynamic particle swarm optimization pso framework image classification framework particle navigates landscape exchanging information neighboring particle current estimate geometry gradient loss function position overall goal framework create distributed collaborative algorithm improves optimization performance guiding particle best minimum loss function extend framework action recognition incorporating state-of-the-art method temporal data transformer rnn convnet module end-to-end training setup detail made following improvement compared previous publication supplemented comprehensive review literature human action recognition implemented following enhancement addition work introduced improved novel network architecture extends pso-convnet pso-convnet transformer pso-convnet rnn end-to-end fashion expanded scope collaborative learning broader concept beyond original application image classification include action recognition conducted additional experiment challenging datasets validate effectiveness modified model improvement addition contribute significantly overall strength novelty research rest article organized follows sect discus relevant approach applying deep learning swarm intelligence har addition proposed method including collaborative learning dynamic neural network convnet transformer architecture well convnet rnn model introduced sect 3.1 3.2 3.3 respectively result experiment extension experiment discussion presented sect finally conclude work sect related work recent year deep learning greatly succeed computer vision field e.g. object detection image classification action recognition one consequence success sharp increase number investment searching good neural network architecture emerging promising approach changing manual design automatic neural architecture search essential part automated machine learning automatically generates neural network led state-of-the-art result among various approach already present literature evolutionary search stand one remarkable method example beginning one layer neural network model develops competitive architecture outperforms contemporary counterpart result efficacy proposed classification system har ucf-50 dataset demonstrated initializing weight convolutional neural network classifier based solution generated genetic algorithm addition genetic algorithm particle swarm optimization—a population-based stochastic search method influenced social behavior flocking bird schooling fish—has proven efficient technique feature selection novel approach combine modified particle swarm optimization back-propagation put forth image recognition adjusting inertia weight acceleration parameter velocity fusion allows dynamic adaptive tuning parameter global local search capability promotes diversity within swarm catfish particle swarm optimization particle worst fitness introduced search space fitness global best particle improved number consecutive iteration moreover pso based multi-objective discriminative feature selection introduced enhance classification problem several effort apply swarm intelligence action recognition video one approach employ combination binary histogram harris corner point wavelet coefficient feature extracted spatiotemporal volume video sequence minimize computational complexity feature space reduced use pso multi-objective fitness function furthermore another approach combining deep learning swarm intelligence-based metaheuristics human action recognition proposed four different type feature extracted skeletal data—distance distance velocity angle angle velocity—are optimized using nature-inspired ant lion optimizer metaheuristic eliminate non-informative misleading feature decrease size feature set idea applying pure technique natural language processing computer vision seen recent year using sequence image patch transformer model perform specially well image classification task similarly approach extended har sequence frame video swin transformer image divided regular shaped window utilize transformer block one approach found outperform factorized model efficiency taking advantage inherent spatiotemporal locality video pixel closer spatiotemporal distance likely relevant study adopt different approach utilizing extracted feature convnet rather using original image choice allows reduce computational expense without compromising efficiency detailed sect 3.2 temporal correlation module tcm utilizes fast-tempo slow-tempo information adaptively enhances expressive feature temporal segment network tsn introduced improve result two-stream architecture spatiotemporal vector locally aggregated descriptor actions-st-vlad approach design aggregate relevant deep feature entire video based adaptive video feature segmentation adaptive segment feature sampling avfs-asfs key-frame feature selected moreover concept using temporal difference found work temporal difference network tdn approach proposes finer local long-range global motion information i.e. local motion modeling temporal difference consecutive frame utilized whereas global motion modeling temporal difference across segment integrated capture long-range structure spatiotemporal motion encoding stm approach proposes stm block contains channel-wise spatiotemporal module cstm present spatiotemporal feature channel-wise motion module cmm efficiently encode motion feature channel-wise convolution applied two consecutive frame subtracts obtain approximate motion representation related approach mentioned include zero-shot learning few-shot learning knowledge distillation learning zero-shot learning few-shot learning provide technique understanding domain limited data availability similar human identify similar object within category seeing example approach enable model generalize recognize unseen scarce class proposed approach introduce concept collaborative learning particle collaboratively train distributed manner despite advance field remains largely uncharted especially respect recent emerging technique proposed method collaborative dynamic neural network define set nearest neighbor particle particle time k\in predefined number particular aligned aligned i_1 i_1 i_2 i_2 i_k i_k aligned aligned i_1\ i_2 i_k\ closest particle i_k i_k ^d\ represent position velocity particle i_k\ time figure illustrates concept k=4\ particle figure demonstration neighborhood consisting position four closest particle particle shown velocity particle depicted arrow full size image given continuous function ^d\longrightarrow compact subset s\subset ^d\ define aligned =\textsf argmin y\in s\right\ aligned subset point minimize i.e. z\in w\in dynamic investigate set neural network work together decentralized manner minimize loss function training process comprised two phase individual training neural network using stochastic gradient descent combined phase sgd pso-based cooperation weight vector neural network represented position particle -dimensional phase space number weight evolution particle neural network governed update rule specified following dynamic aligned array ccl t+1 -\eta l\left t+1 +\psi t+1 t+1 n\ell t+1 c_1 -\phi t+1 c_2 p_g^ -\phi t+1 t+1 +v^ array aligned velocity vector particle time intermediate velocity computed gradient loss function intermediate position computed intermediate velocity i.i.d uniform 0,1\right randomly drawn interval 0,1\right assume sequence i.i.d ^d\ represents best position visited time particle i.e. position minimum value loss function previous position represents nearest-neighbors counterpart i.e. best position across previous position particle jointly corresponding nearest-neighbors s\le s\right time aligned array ccl t+1 argmin y=p^ t+1 argmin y=p_ k\in array aligned weight n\ell defined aligned n\ell f\left -x^ aligned euclidean norm decreasing least non-increasing function dynamic assume aligned 1+z\right aligned constant strengthens collaboration learning two particle pushing particle dynamic alternative pull back particle instead pushing direction gradient previous section assumption particle located side valley loss function however one particle opposite side valley relative rest particle pulled away minimum using first dynamic address issue introduce second dynamic dynamic pull particle back formula dynamic follows aligned array ccl t+1 j=1 1+\left| x_i -x_j ^\beta x_j x_j r\left nbest -x_ array aligned position particle time constant set experiment euclidean norm i.i.d uniform 0,1\right randomly drawn interval 0,1\right assume sequence i.i.d nbest ^d\ represents nearest-neighbors best i.e. best position across previous position particle jointly corresponding nearest-neighbors s\le s\right time convnet transformer architecture action recognition section discus hybrid convnet-transformer architecture replaces traditional convnet-rnn block temporal input classify human action video architecture composed several component including feature extraction module using convnet position embedding layer multiple transformer encoder block classification aggregation module overall diagram architecture seen fig goal architecture effectively capture temporal information present video sequence order perform accurate human action recognition hybrid convnet-transformer design leverage strength convnets transformer offering powerful solution challenging task feature extraction via convnet position embedding early day using transformer visual classification especially image frame typically divided smaller patch used primary input however feature often quite large leading high computational requirement transformer balance efficiency accuracy convnet utilized extract crucial feature image reducing size input without sacrificing performance assume frame extracted feature connet size width height feature number filter reduce size feature global average pooling applied reducing size position encoding mechanism transformer used encode position frame sequence position encoding vector size feature summed feature value computed using following formula differs sequential processing data rnn block allowing parallel handling entity sequence aligned array ccl pe_ pos,2i sin pos/ 10000^ 2i/ model pe_ pos,2i+1 pos/ 10000^ 2i/ model array aligned time step index input vector dimension positional encoding matrix model refers length position encoding vector figure rendering end-to-end convnet-transformer architecture full size image transformer encoder transformer encoder key component hybrid convnet-transformer architecture consists stack identical layer comprising multi-head self-attention position-wise fully connected feed-forward network sub-layers ensure retention important input information residual connection employed operation followed layer normalization core module multi-head self-attention mechanism composed several self-attention block mechanism similar rnn encodes sequential data determining relevance element sequence leverage inherent relationship frame video provide accurate representation furthermore self-attention operates entire sequence resulting significant improvement runtime computation parallelized using modern gpus architecture employ encoder component full transformer goal obtain classification label video action rather sequence full transformer consists encoder decoder module however case use encoder module suffices achieve desired result assuming input sequence x_1 x_2 x_n first projected onto weight matrix xw_q\ xw_k\ xw_v\ w_q\ w_k\ w_v\ three trainable weight query q_1 q_2 q_n\ key k_1 k_2 k_n\ dimension d_k\ value v_1 v_2 v_n\ dimension d_v\ output self-attention computed follows aligned array ccl attention softmax qk^t d_k array aligned name suggested multi-head attention composed several head concatenated fed another linear projection produce final output follows aligned multihead concat head_1 head_2 head_h w^o aligned aligned head_i attention qw^q_i kw^k_i vw^v_i aligned parameter matrix w^q_i\in model d_k w^k_i\in model d_k w^v_i\in model d_v w^o\in hd_v model i=1,2 denotes number head frame selection data pre-processing input video varying number frame pose challenge model requires fixed number input put simply process video sequence incorporated time distributed layer requires predetermined number frame address issue employ several strategy selecting smaller subset frame one approach shadow method maximum sequence length established video method straightforward result cutting longer video loss information particularly desired length reached second method utilize step size skip frame allowing achieve full length video reducing number frame used additionally image center-cropped create square image efficacy method evaluated experiment layer classification assuming set video s_1 s_2 s_m corresponding label y_1 y_2 y_m number sample select frame video obtain feature global average pooling 2-d layer transformer encoder generates set representation consuming output previous block transformer encoder block obtain multi-level representation h^n h^n_1 h^n_2 h^n_l representation 1-d vector length see fig block classification module incorporates traditional layer fully connected softmax also employ global max pooling reduce network size prevent overfitting include gaussian noise dropout layer design convnet-transformer model trained using stochastic gradient descent categorical cross entropy loss used optimization criterion convnet-rnn recent study explored combination convnets rnns particularly lstms take account temporal data frame feature action recognition video provide clear understanding mathematical operation performed convnets following summary relevant formulation aligned array i=1\\ =f_ i-1 1\\ =g_ array aligned aligned array =w_ i-1 i\textrm layer convolution =\boxplus i-1 i\textrm layer pool =w_ i-1 i\textrm layer array aligned represents input image output layer i\textrm indicates weight layer denotes weight operation convolution pooling layer activation function example sigmoid tanh rectified linear relu recently leaky relu symbol act convolution operation shared weight reduce expensive matrix computation window show average max pooling operation computes average max value neighbor region size feature map matrix multiplication weight layer i\textrm layer i-1 represented last layer convnet layer act classifier usually discarded purpose using transfer learning thereafter output convnet frame video sequence fed input rnn layer considering standard rnn given input sequence x_1 x_2 x_t hidden cell state updated time step follows aligned h_t=\sigma w_h t-1 +w_x x_t+b aligned w_h\ w_x\ denote weight matrix represents bias sigmoid function output value output cell ease notation defined aligned y_t=h_t aligned also shown using softmax function _t\ output y_t\ target aligned y_t =softmax w_y h_t+b_y aligned sophisticated rnn lstm includes concept forget gate expressed shown following equation aligned f_t=\sigma t-1 +w_ x_t+b_f aligned aligned i_t=\sigma t-1 +w_ x_t+b_i aligned aligned c'_t=tanh t-1 +w_ x_t+b'_c aligned aligned c_t=f_t t-1 +i_t c'_t aligned aligned o_t=\sigma t-1 +w_ x_t+b_o aligned aligned h_t=o_t tanh c_t aligned operation represents elementwise vector product forget gate input gate output gate cell state respectively information retained forget gate f_t\ becomes eliminated f_t\ set optimization purpose alternative lstms gated recurrent unit gru utilized due lower computational demand gru merges input gate forget gate single update gate mathematical representation given following equation aligned r_t=\sigma t-1 +w_ x_t+b_r aligned aligned z_t=\sigma t-1 +w_ x_t+b_z aligned aligned h'_t=tanh r_t t-1 +w_ x_t+b_z aligned aligned h_t= 1-z_t t-1 +z_t h'_t aligned finally worth noting traditional rnns consider previous information bidirectional rnns incorporate past future information computation aligned h_t=\sigma x_t+w_ t-1 +b_h aligned aligned z_t=\sigma x_t+w_ t+1 +b_z aligned aligned y_t =softmax h_t+w_ z_t+b_y aligned t-1 t+1 indicate hidden cell state previous time step t-1\ future time step t+1\ result benchmark datasets ucf-101 dataset introduced one largest annotated video datasets available expansion ucf-50 dataset comprises 13,320 realistic video clip collected youtube cover category human action punching boxing walking dataset three distinct official split rather pre-divided training set testing set final accuracy experiment calculated arithmetic average result across three split hmdb-51 released around time ucf-101 dataset contains roughly video belonging distinct action class class dataset hold least video video collected multiple source example movie online video kinetics-400 recently made available dataset consists human action class least video clip action video assembled realistic youtube clip last around total dataset contains 240k training video 20k validation video one largest well-labeled video datasets utilized action recognition downloading individual video kinetics-400 dataset pose significant challenge due large number video fact dataset provides link youtube video therefore utilize fiftyone open-source tool specifically designed constructing high-quality datasets address challenge experiment collected top-20 accuracy category according work including riding mechanical bull presenting weather forecast sled dog racing etc eventually obtained file training file validation significant number file collected video deleted changed private etc manner gathered category hmdb-51 obtained file training file validation tool provides one-split hmdb-51 document doe specify split experiment conducted using tensorflow-2.8.2 keras-2.6.0 powerful 4-gpu system geforce gtx used hiplot data visualization figure provides snapshot sample action category figure snapshot sample action ucf-101 dataset full size image evaluation metric evaluating result employ standard classification accuracy metric defined follows aligned accuracy=\frac number correct prediction total number prediction made aligned implementation training collaborative model action recognition involves building new dedicated system model require real-time information exchange best knowledge first system ever built purpose accommodate large hardware resource required model trained separate environment one training epoch model update current location previous location estimate gradient loss function relevant information broadcast neighboring model clarify concept provide diagram collaborative system provide brief description subsection system distributed pso-convnets designed based web client-server architecture depicted fig system consists two main component client side computer web browser interface server side comprises three essential service cloud service app service data service cloud service host model virtual machine app service run convnet rnn convnet transformer model information generated model managed data service stored data storage order calculate next position particle particle must wait particle finish training cycle order obtain current information system designed operated web-based interface facilitates advanced development process allows easy interaction user system figure dynamic pso-convnets system design system divided two main component client server client side accessed web browser interface server side comprises cloud app data service cloud store virtual machine environment model reside app service convnet-rnn convnet-transformer run information generated model managed saved data service particle system update position based shared information including current previous location completing training cycle full size image effectiveness proposed method table present result dynamic dynamic action recognition model experiment setting consistent previous research fair comparison shown fig consider two different convnet architecture namely densenet-201 resnet-152 select eight model inception efficientnet densenet resnet family baseline action recognition method densenet-201 rnn resnet-152 rnn densenet-201 transformer resnet-152 transformer feature first extracted convnets using transfer learning fine-tuned however proposed method model retrained end-to-end fashion pretrained weight imagenet dataset utilized enhance training speed result show improvement accuracy 1.58\ 8.72\ notably dynamic densenet-201 transformer achieves best result also report time taken run method fine-tuning take time technique lead overfitting epoch table three-fold classification accuracy ucf-101 benchmark dataset full size table experiment described conducted using setting outlined table batch size input image size number frame adjusted maximize gpu memory utilization however worth noting human activity recognition har batch size significantly reduced compared image classification video consists multiple frame regarding gradient weight higher value indicates stronger attractive force particle table hyper-parameter setting proposed method full size table table setting gradient weight full size table comparison state-of-the-art method table comparison proposed method previous method ucf-101 benchmark dataset full size table comparison method dynamic convnet transformer previous approach shown table second method transfer learning fusion train model sports-1m youtube dataset feature ucf-101 recognition however transfer learning procedure slightly different convnet architecture designed specifically action recognition may better use pretrained weight action recognition datasets weight readily available model differ also training video dataset million sample within reasonable time real challenge research center despite limitation use transformer rnn seem provide better understanding temporal characteristic compared fusion method shuffle learn try two distinct model using 2-d image alexnet 3-d image c3d essentially series 2-d image accuracy improved though 3-d convnets require much power computing 2-d counterpart also attempt redesign well-known 2-d convnet 3-d data c3d built scratch typical convnet e.g. dpc approach and/or pretrained larger datasets e.g. st-puzzle approach besides videomoco utilizes contrastive self-supervised learning csl based approach tackle unlabeled image method extends image-based moco framework video representation empowering temporal robustness encoder well modeling temporal decay key dynamic method outperforms videomoco roughly svt self-supervised method based timesformer model employ various self-attention scheme pre-trained entire kinetics-400 dataset inference ucf-101 svt achieves 90.8 93.7 linear evaluation fine-tuning setting respectively pre-trained subset kinetics-400 60,000 video accuracy reduces 84.8 moreover tsn method apply convnet achieves accuracy 84.5 using rgb image method 92.3 using combination three network rgb optical flow warped flow similarly stm approach employ two-stream network pre-trained kinetics enhances performance significantly designing two-stream network multi-stream network would require larger resource due limitation pursued approach time furthermore using optical flow pose estimation original image may improve performance technique computationally intensive time consuming especially end-to-end training concept collaborative learning hand based general formula gradient loss function could used plug-and-play module approach finally bag word method originally used baseline dataset achieved lowest recognition accuracy 44.5\ hyperparameter optimization experiment aimed find optimal setting model table present result densenet-201 transformer resnet-152 transformer using transfer learning varied maximum sequence length number frame number attention head dense size number frame represents amount frame extracted sequence calculated step=\text maximum sequence length number frame result indicate longer sequence frame lead better accuracy large number frame necessarily best strategy balanced approach yield higher accuracy furthermore discovered model performed best attention head dense size either neuron figure show result convnet rnn model using transfer learning experiment first evaluated performance eight convnets inception-v3 resnet-101 resnet-152 densenet-121 densenet-201 efficientnet-b0 efficientnet-b4 efficientnet-b7 two best performer densenet-121 resnet-152 convnet architecture selected experimentation result varying number frame showed preference longer maximum sequence length table three-fold classification accuracy result ucf-101 benchmark dataset densenet-201 transformer resnet-152 transformer transfer learning training full size table figure hyperparameter optimization result convnet rnn model transfer learning model numbered follows inception-v3 resnet-101 resnet-152 densenet-121 densenet-201 efficientnet-b0 efficientnet-b4 efficientnet-b7 abbreviation acc stand accuracy gaussian noise learning rate respectively full size image figure impact varying number frame three-fold accuracy densenet-201 rnn resnet-152 rnn using transfer learning ucf-101 benchmark dataset full size image extension table comparison collaborative learning individual learning classification accuracy full size table section extend experiment perform challenge datasets i.e. kinetics-400 hmdb-51 method convnets retrained improve accuracy performance compared transfer learning process take long time entire kinetics-400 dataset result decided obtain portion entire dataset order demonstrate concept shown table main focus study compare non-collaborative learning individual learning collaborative learning approach experiment conduct two repetition record mean accuracy best accuracy max achieved setting experiment ucf-101 dataset learning rate range obtained running scan low high learning rate consequence learning rate particle pso-1 pso-2 pso-3 set 10^ 10^ 10^ respectively whereas learning rate wilder particle pso-4 range 10^ ,10^ result show preference collaborative learning method dynamic dynamic outperform individual learning datasets e.g. improvement 0.7 seen kinetics-400 using densenet-201 transformer result obtained experiment clearly demonstrate superiority proposed collaborative learning approach video action recognition discussion performance action recognition method convnet transformer convnet rnn largely dependent various factor including number attention head number dense neuron number unit rnn learning rate among others collaborative learning effective approach improve training neural network multiple model trained simultaneously position direction determined gradient loss function shared previous research applied dynamic convnets image classification study extend concept hybrid convnet transformer convnet rnn model human action recognition sequence image first aim identify optimal setting lead highest accuracy baseline model seen table convnet transformer model perform well convnet rnn model transfer learning could due limited data available training transformer typically require data rnn-based model however proposed method incorporating dynamic end-to-end training outperforms baseline model also result convnet transformer model outperforming convnet rnn counterpart attributed additional data provided transformer model data augmentation additional noise conclusion recognizing human action video fascinating problem art recognition convolutional neural network provide powerful method image classification application har complex temporal feature play critical role study present novel video action recognition framework leverage collaborative learning dynamic approach explores hybridization convnet rnn recent advanced method transformer adapted natural language processing video sequence experiment include exploration two dynamic model dynamic dynamic result demonstrate round improvement 2–9 accuracy baseline method 8.72\ increase accuracy densenet-201 transformer using dynamic 7.26\ increase accuracy resnet-152 transformer using dynamic approach outperforms previous method offering significant improvement video action recognition summary work make three key contribution incorporate dynamic dynamic hybrid model combine convnet two popular sequence modeling techniques—rnn transformer extend distributed collaborative learning framework address task human action recognition conducted extensive experiment challenging datasets including ucf-101 dynamics-400 hmdb-51 period 2–3 month thoroughly evaluate approach validate effectiveness compared method state-of-the-art approach field