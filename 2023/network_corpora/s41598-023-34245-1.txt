introduction age-related macular degeneration amd main cause severe vision loss blindness europe prevalence due demographic shift number affected patient projected increase order meet corresponding increase demand retinal imaging analysis automatic image analysis retinal image may provide valuable support diagnosis monitoring patient important effective treatment may also enable reproducible evaluation biomarkers epidemiological study hallmark biomarker amd drusen defined deposit retinal pigment epithelium rpe bruch membrane optical coherence tomography oct method non-invasively capture three-dimensional imaging data retina using sequence equally spaced depth scan b-scans data enables accurate quantification retinal biomarkers drusen grading process time-consuming benefit automated approach improve reproducibility comparability across study reduce associated costs.therefore several conventional machine learning deep learning-based oct segmentation model exist approach problem semantic segmentation problem segmentation mask size input image predicted existing model differ architecture loss function focus segmentation different biomarkers like drusen hyperreflective focus hrf fluid retina treating localization retinal layer oct semantic segmentation problem attractive due maturity ease use corresponding neural network architecture however doe easily support end-to-end learning since final goal pixel-wise labeling rather finding correct height layer column a-scan overall slice image b-scan existing approach requires additional post-process moreover make difficult integrate helpful anatomical prior knowledge particularly concerning order different layer occur wide adoption deep learning state-of-the-art approach directly determined layer height enforced correct layer ordering direct prediction height also attempted convolutional neural network treating layer localization 2d-to-1d regression problem recently layer order considered also tried frame segmentation sequence labeling problem a-scans approach let model learn prior layer order study introduce novel cnn architecture first segment area respective layer constraint guarantee correct ordering pass intermediate segmentation result so-called layer head computes layer height used end-to-end learning retinal layer loss directly penalizes deviation correct position frequently used public oct dataset well internal dataset demonstrate strategy allows achieve state-of-the-art accuracy present ablation study illustrate relative contribution individual architectural choice subsequently demonstrate quantification drusen based result exceeds accuracy drusen volume localization compared previous state-of-the-art method automated drusen segmentation material method previous work compared different approach cnn-based drusen segmentation found first segmenting retinal pigment epithelium rpe bruch membrane detecting drusen abnormal deviation gave accurate result trying predict drusen pixel-wise classification current work strengthens strategy introducing novel neural network architecture allows replace shortest path finding post-process previously required reconstruct one-pixel thick layer two-dimensional segmentation map direct end-to-end learning permit localization sub-pixel accuracy also account additional anatomical constraint particular correct order layer allows reduction segmentation ambiguity jointly learning position ellipsoid zone finally refine previously proposed method estimating drusen layer position layer head designed model directly predicts layer height enforces correct layer order without requiring post-processing like shortest-path finding goal achieved layer head attached arbitrary semantic segmentation model turn output map height map case refer oct layer height map fig guarantee predicted layer without hole complete b-scan without post-processing used summed squared error loss explicitly lead model towards minimizing distance ground truth predicted layer figure proposed model architecture initialization block receives input data creates feature space handed refinement block built multiple dilation block integrate global context feature space self-attention block scale feature feature space access global context return output channel layer head transforms feature map representation case every output channel represents height oct layer convolution indicated kernel-size filter dilation block filter dilation-1 dilation-2 full size image main idea layer head value layer position given image column a-scan value layer height measured distance top b-scan computed column-wise sum moreover guarantee correct order multiple layer representing separate channel earlier channel corresponding higher layer taking cumulative sum along channel axis way constraining value non-negative ensures later layer never estimated earlier one clipping pixel-wise sum greater ensures layer position remain bounded image height using layer head one keep mind good prediction depend model ability determine every pixel whether searched height might require receptive field model cover whole input image base model architecture layer head work every pixel output map need clearly identified retina requires global image context common way increasing receptive field size pooling operation strided convolution however require suitable up-sampling operation achieve segmentation input resolution reason build work soullard whose architecture refer multiscalegateddensenet implement novel fully convolutional model architecture build solely dilated convolution increase receptive field size final model 393.923 parameter contrast million parameter standard u-net architecture million parameter deeplabv3 architecture reduced resolution compensated using large number channel greatly increase number parameter parameter-wise model also compare favorably especially small version u-net squeeze u-net 2.59 million parameter adopted use multiple dilated convolution block spatial dropout gating mechanism multiscalegateddensenet made several change overall architecture well individual dilated convolution block obtain model desired receptive field size improved performance since effective receptive field size smaller calculated receptive field size decided overshoot input image size guarantee global context every pixel output map final architecture receptive field size make prediction input shape pixel rationale behind base architecture create robust feature space every pixel enables classification use dilated convolution result constant size intermediate representation allows iteratively refine feature space learning residual base architecture explained next section individual block highlighted fig use swish activation function instead relu stated otherwise choice based experimental comparison different activation function showed swish activation function tends work better relu deeper model across number challenging datasets initialization block initialization block first block model stepwise increase number channel using convolution input channel dimensionality feature space want build every convolution followed swish activation function dropout layer batch normalization use dropout rate 0.1 training aim making initialization block robust noisy input data feature might locally obscured refinement block second block refine created feature space residual learning fashion sense residual network using dilated convolution block start convolution another convolution performed learned residual added feature space let choose map feature space residual computed base residual first convolution followed spatial dropout layer rate 0.1 spatial dropout switch complete feature map instead individual pixel aim making model robust missing feature image level increase receptive field dilated convolution used expanding contracting pattern integrate feature larger scale locally example first convolution dilation factor shown right fig learned residual added input feature space sum batch normalized fed next differs significantly multiscalegateddensenet output block concatenated input fed next block refinement every pixel opportunity integrate information different scale provided different dilated convolution block self-attention block third part architecture self-attention/gating mechanism multiscalegateddensenet refined feature space aim focus network information relevant final task work element-wise multiplication sigmoid swish-activated linear combination refined feature space model learn feature suppress emphasize every pixel individually based global information collected refinement step apply self-attention mechanism produce final feature point per-pixel feature capture context full image via refinement block give self-attention mechanism opportunity use global context training procedure model trained epoch exponentially decreasing learning rate start 0.001 multiplied exp 0.1 every epoch use adam optimizer clipnorm clipvalue 0.5 batch size data shuffled iteration data augmented fly random horizontal flip additionally vertical position retina image altered uniformly distributed training data therefore first center b-scan pixel average height apply random vertical shift pixel loss function use summed squared error sse put weight partially annotated b-scans mean squared error would drusen computation drusen important biomarker amd progression detected based increased distance retinal pigment epithelium rpe bruch membrane prior work segmented drusen fitting 3rd-degree polynomial rpe annotation estimate healthy rpe part area fitted healthy rpe annotated rpe passed size-based false-positive elimination marked drusen follow-up work improved initial rectification retina using experiment showed fitting 3rd-degree polynomial necessary rectification might even detrimental instead assumed healthy rpe fixed distance might vary based individual physiology image resolution estimate fixed offset make histogram rectified rpe height compute healthy rpe height average a-scans within mode histogram directly neighboring bin remove small false positive filter drusen height computed based complete volume therefore determine maximum height connected component enface drusen projection drusen removed pixel high data prior work indicates accuracy algorithm drusen segmentation depend significantly device image taken therefore report result two datasets acquired different device qualitative comparison two datasets ground truth predicted annotation shown fig illustrating difference image quality annotated layer used eyepy python package processing visualization oct data figure exemplary b-scans validation data duke bioptigen data left internal data spectralis right ground truth annotation red remaining color indicate layer position estimated model top left b-scan mean absolute error mae pixel given every layer full size image first dataset internal amd dataset expert annotation rpe centerline volume produced spectralis device heyex heidelberg engineering germany resolution study approved institutional review board university bonn approval 013/16 written informed consent obtained participant following explanation study procedure protocol followed tenet declaration helsinki split dataset training validation test set 12,886 volume b-scans respectively evaluate drusen segmentation volume test set drusen b-scans spread equal distance central third volume manually annotated independently two reader using eyelab annotation tool compare layer segmentation result wider range prior approach used public oct dataset duke university acquired bioptigen system annotation inner boundary rpe ilm control amd volume volume b-scans size annotation available diameter centered fovea selected central a-scans every b-scan annotated a-scans per layer b-scans incorrect segmentation removed training validation data came attention remove problematic b-scans test data fair comparison previous work procedure resulted 11,427 14,228 volume b-scans training validation test set respectively split ratio prior work list excluded b-scans exact data split trained model included published code study human animal performed author article existing datasets used required ethic vote well informed participant consent obtained data normalized zero mean unit variance fed model result layer segmentation internal dataset compared model predicting layer rpe one predicting additionally metric use mean absolute error mae ground truth prediction rounded integer reported mean standard deviation computed mean mae per volume model predicting layer performs slightly better model prediction 0.63 0.66 better rpe prediction 0.85 0.88 prediction 0.44 best table table mean absolute difference standard deviation pixel a-scans test dataset full size table final model outperforms three approach previously reported result public dataset duke university regard mae table segmentation result slightly better control volume amd volume part ilm segmented best worst additionally standard deviation report bootstrapped confidence interval bci mean table mean absolute difference standard deviation pixel a-scans test dataset full size table ablation study show effectiveness architectural choice performed ablation study trained variant model duke dataset model trained loss exact hyperparameters final model except ablated characteristic model remove cumulative channel sum layer head guarantee layer order model self-attention block hence output refinement block fed directly layer head model remove shortcut connection implement residual learning strategy refinement block final model worked better three alternative ablation study drusen segmentation evaluated proposed drusen segmentation build three-layer model respect two expert compared result previous method layer-based drusen segmentation metric segmentation quality dice score dsc commonly used similarity measure relates size intersection two set combined size dsc segmentation inter-reader agreement term dice score 0.67 0.19 respect reader also annotated layer training dataset proposed method achieves drusen dice score 0.71 0.16 improves upon 0.60 0.23 previous method gorgi zadeh dice score respect reader lower 0.62 0.23 instead 0.53 0.25 method still improves previous one qualitative result shown fig figure comparison automatic manual drusen segmentation previous work shown left result shown right result clearly reduce issue segmentation previous method full size image drusen volume downstream analysis drusen load obtained automatic approach required high correlation manually obtained result verify computed pearson correlation drusen volume obtained manually automatically oct volume test data table found correlation high overall model correlating better human reader prior u-net based approach inter-reader correlation falling behind comparison table pearson correlation drusen volume test set drusen volume based model higher correlation manual grading reader based previous u-net based method full size table additionally absolute volume difference human reader automatic drusen quantification small ass computed difference result method reference created averaging volume human reader fig method tend underestimate drusen volume method closer reference volume figure drusen volume difference two automated method difference computed two automatic approach mean drusen volume two human reader every volume test data datapoints volume connected black line method volume difference closer red line otherwise volume result method closer reference full size image discussion work introduced novel algorithm automated drusen segmentation oct image showed method outperforms previous method term correlation manual grading difference mean volume two human reader also showed method reproduces result independent test set annotated reader training data accurately second reader conclude method accuracy sufficient use epidemiological study believe result illustrates importance objective assessment demonstrated improved accuracy compared previous method gorgi zadeh al. already quantified drusen reliably enough find association visual function measure making prediction b-scan size took average nvidia titan pascal gpu believe method useful future epidemiological study clinical trial aim quantify drusen load thereby provides basis insight role amd important factor contributing improved performance method improved layer segmentation particular result indicate accurate rpe amd group crucial drusen segmentation among technical refinement attention mechanism residual learning ablation study show importance exploiting additional anatomical knowledge enforcing layer order result model doe require post-processing via shortest path approach generating layer height fewer parameter previous model yielding accurate result limitation current approach doe clearly indicate region layer present anatomical region without meaningful layer structure optic disc filtered restricting domain subsequent analysis filtering region without layer structure due severe atrophy would however require extension method training sufficient number example conclusion presented specialized model oct layer segmentation predicts layer height end-to-end fashion allows accurate layer-based drusen segmentation drusen volume based prediction high correlation manual grading improves upon established previous method confident model improve assessment amd-related retinal change oct large-scale epidemiological study well help clinician assessment individual patient data