introduction electron energy loss spectroscopy eel analytical technique scanning transmission electron microscopy tem yield information elemental content sample direct manner energy core-loss edge appears reveals element-specific ionization occurred eel stem yield large amount data form spectral image allow mapping spatial distribution element sample atomic scale eel spectrum recorded sufficient energy-resolution reveal fine structure core-loss edge information electronic state sample like oxidation state bonding besides qualitative study eel spectrum like element identification mapping quantitative study allows determine relative absolute quantity element sample model-based approach quantification require input elemental content spectrum therefore currently still common-practice expert perform time-consuming visual inspection eel spectrum element identification early attempt automated identification quantification core-loss edge relied use filter-based method tabulated edge property especially edge onset energy method limited success real-world application due high noise sensitivity difficulty dealing low jump-ratio edge current age artificial intelligence data-driven method especially deep learning method use neural network capable solving large number task given enough training data supplied unsupervised technique like k-means clustering non-negative matrix factorization auto-encoders extensively applied eel spectral decomposition supervised technique like support vector machine allow generic eel application like oxidation state determination zero-loss peak determination spectral deconvolution phase-transition forecasting also successfully applied many technique similar eel like x-ray diffraction vibrational spectroscopy x-ray fluorescence spectroscopy energy-dispersive x-ray spectroscopy molecular excitation spectroscopy deep learning recently applied element identification eel kong developed synthetic dataset containing core-loss edge common element simulation method relied processing experimental data core-loss edge experimental spectrum extracted multi-gaussian fitting adapted mean scaling shifting noising multiple edge background combined form synthetic spectrum main limitation approach limited amount experimental data available especially heavier element multiple element dataset like e.g represented single experimental edge dataset formation lack variation training data limit generalizing effectively facing new data furthermore simulation method allowed one fixed energy loss range severely reduces practical applicability paper proposes purely computational eel dataset consisting 736,000 spectrum based available generalised oscillator strength table dataset represents core-loss edge chemical element dataset supply ground-truth label element identification relative quantification simulated dataset flexible detector range thanks zero padding spectrum wide detector range multiple architectures—being multilayer perceptron convolutional neural network u-net residual neural network vision transformer compact convolutional transformer ensemble—are optimized evaluated term efficiency performance element identification simulated experimental data method synthetic dataset formation specimen sampling dataset-formation method based experimental data constrained limited amount labeled data especially heavier element completely computational dataset advantage allowing much broader set element edge figure show element respective edge included presented dataset excluded edge core-loss region element heavier excluded rare instead forming sample arbitrary combination element sample drawn list material material project element included dataset list sample containing least element drawn material project result approach element fulfill minimal occurrence dataset common element present dataset often occur additional element sample next query element given extreme difference natural occurrence element approach compromise biasing dataset losing prior-knowledge training set contains element sample spectrum sample test set validation set contain sample element respectively spectrum sample additional dataset simulated spectrum contains core-loss edge corresponding single element used determine pair element often confused figure element respective edge represented simulated dataset full size image spectrum simulation seen fig element dataset represented two set edge spectrum could contain either single one two set set together since single set edge sufficient order able identify element allow possibility one two set fall outside detector range random detector range chosen using constraint query element must least one set major edge within detector range ensures minimal occurrence element maintained like sample formation edge additional element sample included fall within random detector range meaning spectrum start least edge onset least beyond edge onset content spectrum thus—like doe practice—differ general content sample depending chosen detector range theory inelastic electron scattering form foundation simulation eel spectrum extensively described egerton spectrum simulation method relies publicly available table edge onset energy eel atlas calculation core-loss edge requires series parameter like microscope acceleration voltage beam convergence angle collection angle parameter randomly drawn uniform distribution individual spectrum simulation additionally random chemical shift applied onset energy edge since available table consider solid-state effect resulting core-loss edge portray fine structure calculating fine structure sample dataset extremely computationally expensive therefore generic fine structure used instead represent true fine structure given edge specific material show sufficiently similar profile generic fine structure formed sum randomly weighted gaussian peak occurring random energy loss proximity onset energy lifetime broadened width described egerton lifetime ionized atomic electron estimated inelastic mean free path =\sqrt velocity ionized electron energy loss edge onset width lifetime broadened gaussian peak determined heisenberg uncertainty principle _f\ method requires electron inelastic mean free path parameterised seah dench solid consisting one element _i= 538a\varepsilon 0.41 3/2 1/2 _i\ atomic diameter expressed nanometer since atomic diameter within sample unknown randomly sampled additional random parameter include degree fine structure i.e number contributing gaussian peak width fine structure i.e energy range edge onset fine structure occurs relative scale fine structure respect calculated core-loss edge made depend fine structure ratio positive value negative value largest allowed ratio fine structure peak amplitude edge peak amplitude simulates effect strong white line similar fine structure approach generic low-loss region simulated lorentzian zero-loss peak arbitrary width plus arbitrary number plasmon peak simulated drude model arbitrary energy width zero-loss peak plasmon peak scaled probability p_n\ electron suffers collision assumption scattering event independent corresponds poisson process p_n -\frac scattering parameter also drawn uniform distribution core-loss edge added sum convolved low-loss region simulate effect multiple scattering convolution tends significantly decrease amplitude simulated white line e_0 background added randomly drawn e_0\ starting energy spectrum also randomly drawn jump-ratio—defined ratio peak amplitude core-loss edge fine structure amplitude background edge onset—between 0.2 1.5 enforced one arbitrarily chosen edge directly determines jump-ratio edge spectrum boundlessly small large poisson noise applied signal noise ratio fully determined previous parameter background amplitude particular random instrumental shift—which practice might result misalignment drift microscope spectrometer components—is applied finally spectrum normalized zero padded spectrum required input shape table show value parameter used simulation distribution drawn figure show schematic overview simulation procedure ceo table parameter spectrum simulation full size table figure diagram simulation ceo spectrum core-loss edge calculated table given generic fine structure generic low-loss region simulated summed core-loss edge convolved generic low-loss region power law background added final spectrum normalised zero padded poisson noise applied full size image experimental dataset experimental dataset containing element occurrence spectra—which completely independent simulated training dataset—is formed using data electron energy loss data center eeldc gatan eel atlas electron energy-loss spectroscopy x-ray absorption spectroscopy database eelsdb spectrum gathered eelsdb citation information available pre-processing kept minimal possible ensure fast flow recorded spectrum enabling real-time prediction microscope pre-processing procedure shown fig experimental spectrum resampled required energy axis zero padded full energy loss range normalized figure pre-processing procedure experimental spectrum spline used resample spectrum required energy axis resulting spectrum zero padded normalized full size image figure show occurrence element simulated experimental datasets carbon occurrence experimental spectrum ambiguous due common presence sample grid expected noticeable similarity occurrence element simulated experimental datasets experimental dataset randomly split validation set spectrum test set spectrum figure occurrence element simulated training test dataset experimental dataset carbon occurrence experimental spectrum ambiguous due common presence sample grid full size image element identification model since priory unknown architecture perform best given task given dataset architecture compared term efficiency performance compared architecture multilayer perceptron mlp convolutional cnn u-net residual resnet transformer network vision transformer vit compact convolutional transformer ctt mlp known longer state-of-the-art computer vision amongst reason able learn translation invariance well cnn element identification eel limited need translation invariance contrary onset energy important form information therefore interesting still consider mlp cnn—because immense importance computer vision—come many configuration cnn chosen evaluated one dimensional version well-known vgg-11 network u-net architecture—which originally introduced image segmentation cnn—has proven successful due ability combine global local contextual information form classification prediction using u-net mlp classification head appended resnets successfully introduced tackle vanishing gradient problem deep cnn layer deep resnet evaluated kong proposed convolutional-bidirectional long short-term memory cnn-bilstm element identification eel spectrum however lstm recurrent neural network rnn issue particularly slow due constraint sequential computation rnn lstm rapidly replaced attention-based architecture like transformer transformer originally introduced natural language processing model also known great success computer vision i.a vit vit divide input patch encoded prior processed transformer encoder cct introduced increase efficiency vit replaces partitioning patch convolutional layer ctt design many similarity cnn-bilstm additionally ensemble models—which common technique used improve robustness accuracy exchange longer inference time —is compared ensemble network prediction multiple models—which could different instance either different architectures—are averaged constituent ensemble network chosen depending performance described architecture choose limit size ensemble network one calculate inside working memory nvidia geforce rtx gpu single original resnet vit architecture use global average pooling gap spatial dimension feature map passed mlp classification head append mlp classification head u-net architecture dimension reduction method must applied well gap energy axis suppresses crucial information element identification alternative gap learnable weighted sum feature used original u-net flattening high parameter cost vit also often used class token method cct introduced sequence pooling method also suppresses spatial information best approach architecture determined experimentally activation function original architecture maintained except output layer since task hand multi-class multi-label problem one use common softmax activation function instead sigmoid activation used output layer model prediction interpreted confidence element present either batch normalization layer normalization applied model figure show schematic overview used u-net vit architecture schematic remaining architecture presented additional information supplementary figure evaluated precision recall harmonic mean known _1\ -score metric weighted occurrence element dataset furthermore evaluation includes exact match rate emr measure percentage spectrum predicted content exactly match true content root mean square error rmse trained using adam optimizer custom loss function sum binary cross-entropy loss function macro soft _1\ loss function model initial learning rate optimized grid search learning rate halved plateau _1\ -score increase convergence calculating metric experimental data network prediction carbon taken account due ambiguity ground truth label since task hand multi-class multi-label problem network output must thresholded order able compute metric optimal threshold depends application preference user remains applied threshold one minimizes difference precision recall validation data figure schematic overview u-net architecture vit architecture visualization made using software adapted plotneuralnet full size image result discussion element identification threshold experimental data noticeably higher threshold simulated data likely due many core-loss edge boundlessly small jump-ratios simulated spectrum table compare _1\ -score emr rmse achieved model simulated experimental test set utilizing optimal threshold determined respectively simulated experimental validation set despite large number parameter mlp demonstrates poor performance cnn resnet exhibit good performance simulated data struggle generalize effectively experimental data potentially attributable high number trainable parameter u-net vit manage achieve _1\ -score exceeding emr least experimental data cct generalizing better ccn resnet poorer vit u-net table comparison identification model architecture full size table table show detailed evaluation vit u-net alongside evaluation ensemble network consisting two vits three u-nets note _1\ -score must precision recall weighted averaging used table evaluation vit u-net ensemble model experimental test set full size table interpretation result hindered absence comparable result accuracy human expert quantified task described kong directly comparable emr could first glance considered rather unsuccessful one forget emr demanding metric model emr interpreted model yield useful prediction time precision recall implies present element chance detected detected element chance actually present confusion matrix quantifies pair element often confused ensemble network given additional information supplementary figure figure show six example experimental spectrum prediction ensemble network example demonstrate network correctly process spectrum within wide range characteristic example ranging minimal fine structure strong white line ranging broad localised energy loss region example show two typical case mistaken prediction first edge neighbouring lanthanide often difference onset energy smaller variation due chemical instrumental shift causing confusion neighbouring lanthanide second common mistake due thresholding example correct elemental content identified high confidence plausible alternative element also end threshold tungsten example fig show correctly identified tungsten significantly higher confidence rhenium yet since rhenium confidence exceeds threshold kind prediction penalized emr must noted intrinsic knowledge threshold thresholding form post-processing replaced improved skipped depending application preference user figure example experimental spectrum prediction vit+3 u-net ensemble full size image elemental mapping two distinct way presented used order fully automate elemental mapping spectrum image one method includes directly mapping network predictions—either thresholding—for individual spectrum alternative method using globally predicted elemental content input model-based quantification model-based quantification linear combination calculated eel cross section —usually first convolved experimental low-loss spectrum—and linearized power law background model fitted spectrum prediction many spectrum likely result false positive occurrence small concentration especially spectrum noisy selection criterion considers element detected least spectrum preimposed figure summarize lamno batio srtio superlattice sample extensively described chen prediction ensemble network spectrum take approximately one minute standard desktop computer nvidia geforce rtx gpu given preimposed selection criterion detected element equal spectrum content measured energy loss region doe encompass strontium edge probe position one two four respectively srtio batio lamno region probe position three transition region batio lamno figure show prediction ensemble result model-based quantification comparison clearly predicts superlattice structure match visual inspection model-based quantification model-based quantification measure presence batio region perfectly distinguish overlapping edge figure summed intensity spectrum lamno batio srtio superlattice spectrum corresponding marked probe position vertical dashed line show expected onset energy mapping result show probability presence predicted ensemble network ref show result model-based quantification comparison full size image conclusion work computer generated core-loss eel dataset useful training neural network generalize effectively experimental data presented dataset represents distinct core-loss edge element use generic fine structure low-loss region result sufficiently realistic spectrum keeping computational cost limited zero padding spectrum allows resulting model applied experimental spectrum measuring virtually energy loss range within use data train series neural network task identify element given eel spectrum series compared architecture u-net vision transformer presented best performance applied experimental data multiple u-nets vision transformer combined ensemble network increase performance simultaneous precision recall application potential demonstrated performing fully automated elemental mapping lamno batio srtio superlattice sample work show potential rapid element identification neural network show strength creating input parameter model-based quantification process combination form basis entirely unsupervised quantification workflow urgently needed cope ever increasing amount data generated modern stem eel experiment time offer potential remove dependency tuning parameter inevitably lead experimenter bias reproducibility issue plague eel quantification method