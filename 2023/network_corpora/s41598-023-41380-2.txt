introduction deep learning used prediction classification modeling various field deep learning model demonstrated remarkable achievement area medicine autonomous driving stock market prediction uncertainty output deep learning method particularly prediction model thus situation uncertainty need output instance dataset shift occur medical image analysis autonomous driving task prediction model output uncertainty word output mean know include model based bayesian neural network gaussian process model bayesian neural network bayesian inference train stochastic random neural network extension approach include method employ variational inference dropout expectation propagation stochastic gradient markov chain monte carlo technique gaussian process-based model enable regression flexible function e.g. regression problem output confidence interval predicted value output model instance used handle data multiple level fidelity prediction model based deep ensemble bootstrapping deterministic uncertainty estimation using radial basis function also proposed alternative approach integrating uncertainty deep learning evidential deep learning edl proposed sensoy explicitly express uncertainty prediction category combining subjective logic neural network evidential deep learning employed many field including medical image analysis target recognition autonomous driving action recognition stereo matching molecular discovery however calculate uncertainty edl mean value -dimensional dirichlet multivariate probability distribution parameter number class included training data lead following two problem first edl calculates belief mass uncertainty mass uncertain class data whose class unknown network henceforth known class probability class output word output predicted class uncertainty ultimately discretion model user determine value mean result trustworthy second edl assumes input always belongs one class output consists prediction class predicting whether input belongs class uncertainty prediction true even unexpected input data doe belong known class example data outlier correctly labeled time training data labeling registered unknown time called contaminated data address problem propose modified edl m-edl model provides output predicts whether input belongs class class along probability class consequently need determine threshold user judge result uncertain moreover output predicts instance belongs certain class uncertainty prediction nevertheless available finally contrast training data edl training data m-edl include instance class several out-of-distribution ood open-set learning method add class handle uncertainty open-set recognition neal augmented dataset class counterfactual image others explicitly train classifier class ood sample near in-distribution boundary contrast study doe create entirely new unknown class attempt learn instead proposed m-edl output natural way uncertainty prediction edls naturally generate probability unknown class simple extension data including unknown class edl handle learned moreover arbitrariness threshold weak point edl resolved fact result study show potential improving performance discriminating unknown class test data without learn counterfactual ood sample existing approach require remainder paper organized follows. overview proposed model explains structure proposed m-edl prediction model compare edl additionally method calculating parameter m-edl introduced likelihood calculation method used train model explained advantage m-edl advantage m-edl modification explained. result present experimental result discussion discus result method present method used experiment overview proposed model section first review structure edl present m-edl edl describe edl using two-class example shown fig figure number class two class figure conventional edl overall structure class dirichlet distribution output full size image first input fed neural network evidence class respectively obtained output greater equal zero train neural network sensoy employed likelihood function using sum-of-squares loss stabilize neural network training likelihood calculated follows =\int =\sum_ represents probability class class beta function parameter k\in sensoy also employed kullback–leibler divergence relative entropy i-divergence term regularize predictive distribution penalizing divergence class belief mass obtained output neural network evidence class example belief mass obtained using k=\mathrm belief mass class calculated follows =\frac =\frac +1\right furthermore belief mass class calculated k=\mathrm satisfied output edl model dirichlet distribution dimension general dirichlet distribution parameter k\in given following equation =\frac k=1 similar belief mass dirichlet distribution parameter obtained evidence class neural network using +1\ parameter directly used dirichlet distribution contrast used check uncertainty used distribution however reveals dirichlet distribution parameter belief mass related follows =\frac =\frac +1\right =\frac example fig dimension shown fig probability distribution class obtained using dirichlet distribution parameter condition k=\mathrm satisfied example result obtained dirichlet distribution expected value input belongs class 20\ expected value input belongs class 80\ uncertainty overall result sum expected value i.e. satisfies condition k=\mathrm note value included sum m-edl proposed m-edl additional class added original edl represent instance belong known class section extension needed edl obtain m-edl presented obtain evidence neural network class including class likelihood calculation must extended equation extended j\in follows first =\left =\left i\mathrm used extend following aligned =\int b\left -1\right =\sum_ =\sum_ +\mathbf aligned furthermore using relationship =\mathbf +\mathrm var transformed follows =\sum_ -\mathbf +\mathrm var expected value dirichlet distribution var variance detailed calculation provided supplementary information available online proposed m-edl dirichlet distribution -dimensions output dirichlet distribution following extension required introducing =\frac k=1 =\frac =\left calculate first use s=\sum_ k=1 =\sum_ k=1 focus relationship +\sum_ k=1 =1\ relationship satisfied using subjective logic dempster–shafer theory used framework dirichlet distribution point extension class begin +\sum_ k=1 =1\ transformed using expressed follows =\frac extended class written =\frac =k+1 obtained additionally extended class based =\frac belief mass class written =\frac hence evidence class written follows =k. equation obtained extension class derived relationship s=\sum_ k=1 =\sum_ k=1 +\sum_ k=1 =1\ therefore line belief mass dempster–shafer theory subjective logic two-class example used edl structure proposed m-edl shown fig example hence defined edl input fed neural network evidence class obtained output neural network next belief mass obtained using k=\mathrm belief mass class calculated using k=\mathrm used obtain evidence class described detail probability distribution class obtained using dirichlet distribution parameter distribution parameter obtained belief mass well condition =\mathrm satisfied figure proposed m-edl overall structure class dirichlet distribution output probability density increase blue red full size image output m-edl dirichlet distribution dimension two dimension shown fig increase probability density indicated hue blue red furthermore result dirichlet distribution expected value input belongs class 50\ expected value input belongs class 30\ expected value input belongs class input said belong either class 20\ sum expected probability also satisfies =\mathrm explained supplementary information illustrated supplementary fig available online expected value satisfying k=\mathrm obtained edl also obtained example 62.5\ 37.5\ advantage m-edl two main advantage m-edl first unnecessary determine threshold model user judge result uncertain described edl edl model sensoy output expected value input data class class expected value input data class class uncertainty 20\ 80\ uncertainty respectively whereas m-edl output expected value input data class class expected value input data class class expected value input data class class input said either class 50\ 30\ 20\ respectively edl model output form input-data prediction class corresponding uncertainty class hence uncertainty threshold must set determine whether result used accuracy model change according threshold contrast m-edl output includes expected value class class probability sum therefore user simply choose class highest probability class predicted class unnecessary define uncertainty threshold first place addition even m-edl predicts certain class class uncertainty nevertheless available m-edl furthermore training data include data class explain case likelihood function used simple likelihood estimation sensoy al. edl parameter fitting neural network part edl shown fig expressed follows =\sum_ j=1 log -\mathrm log one-hot vector encoding ground-truth class observation k\ne class correct label observation meanwhile indicates parameter dirichlet distribution observation j=1 sensoy al. method assumed input data belongs one class therefore range index take contrast m-edl shown fig introduces parameter dirichlet distribution form extension applying extension likelihood function result following aligned =\sum_ log -\mathrm log =\sum_ log -\mathrm log i\mathrm log -\mathrm log i\mathrm aligned one-hot vector contains class indicating data labeled belonging class included training data m-edl implication extension follows first becomes possible learn dataset example consists handwritten digit 0–9 mnist ground truth label 0–9 mixed completely different dataset type correct label additionally learning may help determine accuracy prediction whether example input digit digit non-numeric data mixed test dataset result investigated whether m-edl performance edl comparative experiment also investigated whether m-edl advantage including class training data objective evaluation determine following whether use m-edl reduces prediction accuracy class training test data given edl m-edl model whether m-edl model learned class prediction accuracy class compared edl model learn class m-edl predicts class higher accuracy edl ratio class data included training data affect accuracy predicting class test data happens property class data blended training data test data exactly answer question several datasets model prepared condition depended whether data class included training and/or test data well model used learn data used evaluation performance comparison edl m-edl class data evaluate whether performance m-edl comparable edl situation assumed edl situation training test data belong class word training test data composed image mnist following two condition compared edl model trained tested datasets class data m-edl model trained tested datasets class data figure compare accuracy edl thin solid red line m-edl thick solid blue line line show mean value shaded area indicate standard deviation accuracy edl change respect uncertainty threshold accuracy plotted vertical axis uncertainty threshold indicated horizontal axis accuracy edl improves threshold decrease classification result model confident treated classification result figure show result used classification result m-edl uncertainty threshold used classification result m-edl result parallel horizontal axis obtained contrast fig show result converted uncertainty threshold used edl also used m-edl figure accuracy edl m-edl training test datasets contain class data result used m-edl classification result converted used m-edl classification uncertainty threshold edl full size image graph show accuracy m-edl lower edl except region uncertainty threshold 0.9 however substantial decrease accuracy observed said performance m-edl would sufficient depending application performance comparison edl m-edl class included training test data experiment property class data included training test data completely different obtained different datasets make possible confirm whether learned uncertain class feature regarded feature class rather feature class learned training first consider whether m-edl model learned class prediction accuracy class compared edl model learn class q2a consider whether determine class higher prediction accuracy q2b following two case considered edl tested data include fashion mnist data m-edl trained data include emnist data tested data include fashion mnist data figure a–c show result class rate training data respectively line different color indicate result class rate test data 1–2 percentage number mnist data additionally table present mean accuracy edl medl condition edl tested data include emnist data m-edl trained data include fashion mnist data tested data include emnist data figure d–f show result class rate training data respectively line different color indicate result class rate test data percentage number mnist data additionally table present mean accuracy edl medl condition figure accuracy comparison edl m-edl line color indicate proportion class test data top bottom plot show accuracy class data class data respectively result m-edl learned class emnist data tested fashion mnist data class mix rate training data percentage number mnist data result m-edl learned class fashion mnist data tested emnist data class mix rate training data full size image table accuracy comparison edl m-edl value mean accuracy uncertainty threshold table corresponds fig a–c full size table table accuracy comparison edl m-edl full size table two condition one-hot vector data dimension therefore element one-hot vector class emnist fashion mnist data test data set following case processing applied edl tested data including class data left plot fig a–c table avg accuracy show result class data first condition line color indicates ratio class data included test data assumed accuracy decrease mix ratio class test data increase result show accuracy m-edl respect class high robust mix rate class training test data seen left plot fig a–c m-edl model learned class compared edl model learn class equal higher accuracy respect class moreover accuracy m-edl easily affected ratio class test data well training data right plot fig a–c table avg accuracy show accuracy class data accuracy data judged know actually different data class learned far. right plot fig a–c show accuracy m-edl respect class high robust mix rate class training test data natural increase accuracy class edl ratio class increase accuracy increase ratio class increase even class randomly classified via edl figure d–f table avg accuracy show result second condition exactly first condition except emnist fashion mnist datasets switch role accuracy m-edl respect class high robust left plot fig a–c result left plot fig d–f reveal m-edl model learned class compared edl achieved equal higher accuracy respect class accuracy m-edl easily affected ratio class test training data however right plot fig d–f table avg accuracy show accuracy m-edl respect class said better edl effect ratio class included training data prediction accuracy class test dataset comparison two pattern performance comparison edl m-edl class included training test data ratio class training data affect prediction accuracy class data ratio class included training data must appropriately selected answer whether case used result performance comparison edl m-edl class included training test data fig a–c d–f training data mix ratio respectively added following two cases:1 fashion mnist included test data neither edl m-edl trained class data training data mix ratio fig emnist included test data neither edl m-edl trained class data training data mix ratio fig line different color indicate result class rate test data figure accuracy comparison edl m-edl neither edl m-edl learned class line color indicate mix rate class test data left right plot show accuracy class data class data respectively result fashion mnist data result emnist data full size image left plot fig accuracy improved class shown left plot fig a–c whereas right plot fig improvement accuracy class right plot fig a–c accuracy class improved even ratio class training data small result suggest accuracy class may improved m-edl learn even small amount class data moreover particular need data related class data test data right plot fig show m-edl lead improvement accuracy class moreover right plot fig d–f accuracy m-edl class better edl however compared result right plot fig clear accuracy m-edl class improved even ratio class training data small inferred comparison amount accuracy improvement class change depending characteristic class training test data impact nature class training test data shown performance comparison edl edl class included training test data effect ratio class included training data prediction accuracy class test dataset amount improvement accuracy class data change depending characteristic training data test data hence evaluated whether accuracy class always improves characteristic training test data exactly i.e. class data dataset following two condition considered fashion mnist included test training data fig a–c table avg accuracy emnist included test training data fig d–f table avg accuracy figure accuracy comparison edl m-edl line color indicate proportion class test data top bottom plot show accuracy class data class data respectively result m-edl learned class fashion mnist class mix rate training data percentage number mnist data result m-edl learned class emnist class mix rate training data full size image table accuracy comparison edl m-edl full size table table accuracy comparison edl m-edl full size table difference fig a–c d–f mix rate class training data respectively line different color indicate result class rate test data percentage number mnist data particular right-hand side plot fig a–f confirm accuracy m-edl higher case considered almost case class data training and/or test data different characteristic accuracy m-edl class data changed depending combination meanwhile case class data characteristic training testing hence accuracy high clear feature learning class training data contributes improvement accuracy m-edl exhibit learning class however comparison particularly m-edl trained using emnist edl m-edl tested data including fashion mnist example found accuracy improved even unknown class training test data differ therefore m-edl potential improve accuracy excluding uncertain data result learning unrelated data belong class data although depends combination class data training test data hypothesize regarding combination class datasets mixed training increase class accuracy testing hypothesis class data whose characteristic close possible class learned training class data test discriminated class long characteristic class given test different training i.e. boundary distinguish range class strictly whose characteristic close class learned via medl class easily distinguished. conversely class data training far characteristic decision boundary freely determined class data test close may incorrectly classified. test hypothesis introduced another dataset cifar-10 evaluated similarity characteristic different datasets cifar-10 dataset used image pixel similarity calculation consistent dataset grayscaled using previously proposed method table present similarity mnist emnist fashion-mnist cifar-10 structural similarity ssim determined randomly selecting 500,000 image datasets compared mean variance calculated similarity datasets table mean standard deviation value structural similarity datasets full size table distance datasets determined inverse ssim positional relationship datasets two-dimensional plane estimated via multidimensional scaling shown fig figure location dataset estimated via point represent location mnist fashion-mnist emnist cifar-10 datasets respectively distance point proportional inverse similarity number horizontal vertical dimensionless full size image shown fig emnist similar fashion-mnist emnist newly introduced cifar-10 image dataset characteristic different mnist emnist fashion-mnist hypothesis explains result presented performance comparison edl m-edl class included training test data accuracy class higher case trained emnist classified test data containing fashion mnist case trained fashion-mnist classified test data containing emnist reason accuracy class higher case characteristic emnist closer fashion-mnist mnist medl-trained emnist able identify fashion-mnist given testing distant characteristic emnist class verify hypothesis compared accuracy class case class trained cifar-10 classified test data containing emnist case hypothesis correct accuracy class decrease following order case case case table present accuracy medl class case indeed accuracy case lowest suggesting class characteristic close class training class test detected class long characteristic class given testing farther training. table comparison accuracy medl class different case full size table discussion deep learning led many remarkable advance however many scenario uncertainty model output required edl one model provide uncertainty study proposed method extends edl model proposed sensoy predict input belongs class along probability evaluated performance behavior proposed m-edl doe require user set threshold uncertainty interpret result m-edl doe require parameter accuracy model affected value additionally m-edl allows data belonging unknown class included training dataset result experiment revealed m-edl performs comparably edl instance unknown class instance unknown class m-edl performs better edl known class performance class improves depending combination unknown data training test data m-edl learn characteristic class potential predict unknown class even unknown class training data test data different property accuracy m-edl class changed depending combination class data additional analysis cifar-10 dataset indicated training class whose characteristic evaluated via ssim close possible characteristic class learned class data test determined class long characteristic class testing farther training result class mixed intentionally training increase discrimination accuracy class medl necessary characteristic mixed data close possible class study set class data mnist data future research necessary determine optimized medl exhibit superior performance various datasets method datasets mnist fashion mnist emnist used evaluation mnist used provide data class consists image handwritten digit image labeled belonging class 0–9 data class obtained either fashion mnist emnist according experiment fashion mnist dataset 60,000 grayscale image ten fashion category t-shirt/top trouser pullover dress coat sandal shirt sneaker bag ankle boot along test set 10,000 image image dataset categorized class evaluation therefore even image t-shirt dress appear training test data correct label image class emnist dataset set handwritten character digit derived nist special database converted pixel image format dataset structure directly match format mnist dataset specifically used emnist letter i.e. capital letter class categorized class therefore even image exist training test data correct label total number training data 60,000 blending class emnist and/or fashion mnist mnist data class data blended randomly selected prior blending total number test data 10,000 class blending method used training data fully coupled neural network constructed python using kera library build neural network used edl m-edl model input image grayscale normalized image two hidden layer dimension size output layer activation function relu adam used optimization mini-batch learning used batch size initial learning rate decay learning involved early stopping maximum number epoch convergence confirmed case data used validation consisted training data training testing repeated time condition evaluation mean standard deviation accuracy reported experiment run computer equipped intel core i7-7800x nvidia geforce rtx super ram window operating system