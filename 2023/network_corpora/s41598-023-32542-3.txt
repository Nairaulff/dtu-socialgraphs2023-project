introduction fake news defined story describe event real world typically mimicking convention traditional medium reportage yet known creator significantly false transmitted combined goal widely re-transmitted deceiving least audience term fake news used literature describe misinformation disinformation take place internet online social medium platform like facebook twitter reddit misinformation referring spread falsehood regardless intent disinformation characterizing deliberate falsehood spread deceive cause harm several study demonstrated state non-state actor increasingly weaponize social medium spread fake news context information-warfare operation unprecedented scale velocity negative impact society democratic process explosive growth impact fake news real-world event presidential election covid-19 pandemic raised need technique tool identify fake news mitigate spread penetration scale speed commensurate online spread combat fake news many research effort pursuing application knowledge-based perspective identify falsehood contained online content detection linguistic trait writing style format sentiment typical fake content iii detection source disseminate fake news web-sites social medium account identification falsehood often supported active citizen identify suspicious post gather evidence highlight false claim therein report fact-checking website effort identify fake news automated manner analyze large datasets genuine fake news article extract linguistic characteristic select feature useful training fake-news detection model train classification model logistic regression random forest neural network etc selected feature apply model provide best result careful feature engineering required select extract appropriate textual latent feature order build train effective efficient model elimination ineffective feature lead lighter classification model require computational resource training deployment well accurate result trained model deployed social medium platform end-user device browser application used classify article fake flag filter-out falsehood predictive power model improved taking account additional feature represent profile reputation news-media source distributor website social medium account summary key challenge automated detection fake news identification linguistic feature help differentiate fake authentic news article prior work shown text fake news characterized informal sensational affective language since ultimate goal attract attention short-term financial political gain rather build long-term relationship reader also significant deviation exist linguistic profile authentic versus fake news article however since human language use word evolve steadily time expected linguistic feature fake news also change time goal explore hypothesis investigate possible difference temporal evolution linguistic feature fake versus authentic article end develop framework extract informative linguistic feature news article classifies article various category based content iii applies novel change-point detection method detect temporal evolution linguistic feature extracted compare difference language evolution real fake news change-point detection active area statistical research feature algorithm segment data smaller homogeneous part using flexible statistical model adapt non-stationary environment due natural heterogeneity data many real-life problem novel change-point detection methodology applied wide range application area credit scoring cyber security finance paper investigate following research question linguistic characteristic mainly appear informative identifying fake news article taking account language evolving characteristic change time iii detect occurrence change address research question introduce declare novel framework retrieves article trusted suspicious domain majority conduct extensive linguistic analysis investigate informative linguistic feature detecting fake news article linguistic feature fake news article change year develop release new publicly available large dataset news article published detail found data availability section dataset consists linguistic feature time-stamped fake real news-articles feature selection process lasso regression model described detail framework section rest article organized follows related work section review previous work exploiting linguistic characteristic common fake news framework section describes proposed framework used analysis result presented discussed result conclusion section related work section summarize work focusing style-based fake news namely news article quantifiable feature represent linguistic trait writing style format sentiment help distinguish fake news content authentic news comprehensive survey approach given method focus extracting feature capture language use sentiment writing style combination thereof linguistic feature classified three category stylistic feature represent syntax textual style article headline content textual style reflected feature like frequency stop-words punctuation quote negation word appear capital letter syntax style reflected frequency part-of-speech tag text use proper noun capital word title complexity feature aim capturing overall intricacy article headline feature computed based several word-level metric include readability index vocabulary richness achieve higher classification accuracy contrast feature combination psychological feature based frequency word found dictionary associated sentiment psychological process word found dictionary like liwc curated human domain expert sentiment score computed via afinn sentiment lexicon list english term manually rated valence premise behind using psychological feature fake content shown considerably negative authentic news promising approach include multi-class logistic regression conducting stance classification graph-kernel based hybrid support vector machine classification high-order propagation pattern addition semantic feature topic sentiment combination time-series-based feature extracted evolution news along characteristic user account involved spreading news deep learning finally one important recent advance nlp dl-based bert language representation model also used fake news detection sum although several approach demonstrating importance writing-style feature detection fake news hardly study exploring linguistic characteristic change year well apply statistical change-point detection fake news trend study contribute towards understanding fake news article well improving classification model fake news detection declare framework proposed framework partitioned four different module shown fig initially article collected based given url domain trusted/untrusted feature extraction accomplished next optional step topic classification performed order select article desired topic subsequently dimensionality reduction carried extracted feature selected article finally multivariate offline change-point detection conducted data subset rest section problem overview formulated different segment work examined detail figure declare overview scheme framework full size image problem overview set article denote a_1 a_2 article a_i 1,2 vector dimensionality d+1\ first element a_i relevant value one linguistic feature employed addition news article a_i 1,2 categorized real fake hence last element vector a_i value set 0,1 denotes respective article class label value correspond class real fake respectively problem deal work study attribute accurately characterize political article identify evolve time set corresponds informative linguistic feature required therefore deciding feature article a_i 1,2 become vector reduced dimensionality next article stamped time component ... thus multivariate data sequence constructed utilizing article set information regarding construction data sequence refer change-point detection section multivariate change-point detection technique employed detect abrupt change linguistic behavior article categorized fake compared behavior categorized real distinctively process shall reveal estimated number change-points denoted estimated location sorted increasing order denoted addition every estimated change-point location _i\ 1,2 post-processing performed order determine linguistic feature set b_i\ b_i contains linguistic feature relevant change-point _i\ discernible data collection feature extraction regarding data collection process list collected article constructed crawling webarchive news article published article divided untrusted trusted one based multiple source initially used two pair domain credibility list originally formed first contains domain name usually publish fake news highly scrutinized fact-checking organization including snopes politifact others latter includes high reputation domain rarely never criticized fact-checking site list contain popular uncommon domain english content newspaper well blog since use one source could brought bias analysis label provided independent online fact-checking outlet mediabiasfactcheck mbfc also employed verify validity list mbfc specifies often domain publishes factual news employing seven label ranging low high adopted approach chen freire define untrusted domain label low low mixed trusted domain high high mostly factual thus utilizing knowledge list mbfc possibility false positive limited discarding domain discrepancy label domain classified mbfc procedure resulted untrusted trusted domain eventually crawling procedure vital resource-demanding part data collection process component responsible crawling domain inside webarchive efficiently webarchive saved billion web page time provides waybackmachine service allows traversal website time crawhigh-reputatione used scrapy python library considered one fastest web-crawling tool especially complex crawling scrapping application next step data collection process extract actual article website however extracting information various article different format coming different domain challenging procedure address issue newspaper3k library python utilized specifically newspaper3k help building article object including field like article title body publish date way doe depend orientation website execution data collection pipeline perform data wrangling remove duplicate unreadable article well fix formatting error remove html code embedded text finally order analyse text-linguistic characteristic differ real fake source extract plethora different linguistic feature gather available knowledge text end rely previous study identified feature capture stylistic complexity psychological aspect article table unveils list summarizaing subset employed feature processing result large dataset named lincfna consists total 320,960 time-stamped article fake real characterized different linguistic feature topic classification initial corpus contain label regarding topic article able select article analysis belong particular topic e.g. politics perform automated topic classification map corpus article predefined topic interest end adopt zero-shot text classification highly accurate method allows classification class used seen model training zero-shot classifier leverage pre-trained language model therefore thought instance transfer learning generally refers using model trained one task different application originally trained particularly useful situation little available labelled data original proposed textual entailment zero-shot method natural language inference nli based model ready-made zero-shot text classifier particular method convert original text data entailment data considers text sequence classification nli premise construct hypothesis candidate label instance order evaluate whether sequence topic corresponds user-defined politics class model extract corresponding label probability regarding task formulation training procedure zero-shot textual model well example created hypothesis modeling different aspect detail found approach proven remarkably effective many text classification task particularly used large pre-trained model like bart roberta work deployment nli model employ publicly available hugging face transformer library along pre-trained bart-large model developed meta formerly facebook specific model work without requiring data provided text fine-tuned multi genre natural language inference corpus mnli dataset contains ten different text category hugging face model pipeline employ pre-trained model well pre-processing procedure performed fitting stage therefore little none text preprocessing required inference time addition lemmatization stemming required either due fact model mostly trained raw text using wordpiece tokenizers extent minimal text cleaning performed prior using aforementioned pipeline removing html code fixing unicode error finally using special token embedded url phone number addition lincfna contains observation article could considered belong one category therefore follow multi-label approach specifically unlike normal classification task class label mutually exclusive multi-label classification involves predicting multiple mutually non-exclusive label label considered independent probability normalized candidate label applying softmax yes versus score way given article model produce vector independent probability value candidate label article said belong predefined candidate label long respective probability larger 0.5 work analysis focused political news article since would like study fake news around political article thus article a_i 1,2 classified part politics class kept analysis long probability a_i political article greater equal 0.75\ used 0.75\ instead model default threshold 0.5 two reason firstly since accuracy zero-shot approach could directly observed therefore bias ambiguous label could created analysis phase due non-supervised nature used larger threshold default one order discard article controversial label secondly using large value example 0.9\ led significantly fewer article classified political created problem change-point detection part requires existence observation every time point within period tested therefore chosen keep mind plethora observation selected ambiguous observation kept analysis order produce representative robust result original 320,960 observation lincfna aforementioned procedure led set article politics even though non-political ambiguously selected article limited adjusting value examined validity selected article random sample specifically since ground-truth label politics class present examine validity political label assigned sampled checked correctness total assigned political article based evaluation around 90\ article correctly assigned politics class label based set construct matrix comprises linguistic representation selected political article along validity label dimensionality reduction aim dimensionality reduction reduce size matrix pruning initial feature end-up matrix x_r d+1 lower dimensionality contains informative supportive feature reveal fruitful information credibility topic specific article matrix lower dimensionality improve substantially effectiveness upcoming change-point detection analysis fig illustrates feature reduction procedure consists two different phase first applies filtering whereas second applies embedded feature selection component based reduction technique first phase remove feature low sample variance namely attribute value nearly observation lead new reduced feature matrix x_f removed attribute lincfna along sample variance included table supplementary table section online supplement second phase instead using filtering evaluation function relies solely property feature e.g variance threshold pearson correlation coefficient apply two individual non-filtering method first one denoting jth column matrix article label also employed supervised embedded method selection important feature second approach relied component based reduction technique first approach employed classification model utilizes feature selection mechanism algorithm modelling execution mechanism generally aim inclusion predictor strongly aid generalization unseen data preventing learning algorithm overfitting training dataset embedded method perform feature selection process training usually specific given learning machine typical embedded method include various type tree based algorithm like cart c4.5 random forest tree also algorithm logistic regression variant among embedded method regularized model perform feature weighting based objective function minimize fitting error forcing predictor coefficient exactly zero method based penalization l_1\ norm lasso induce penalty feature contribute model usually work linear classifier support vector machine logistic regression even though many embedded feature selection option available specific work adopt logistic regression model penalized using l_1\ norm obtain robust classifier sparsity coefficient additionally regarding strength regularization compute regularization path grid value stratified -fold cross validation manner regularization parameter control overall strength lasso penalty choice number fold usually formal rule work different value number fold employed since trade-off choice larger value lead much higher computational complexity lower prediction error smaller value lead computationally efficient result possibly higher prediction error therefore took 25\right\ since result extremely similar term selected feature carried analysis 10\ respect since larger value hyperparameter produce solution sparsity coefficient assessing different amount feature classifier evaluated left-out fold different value procedure exploited f_1\ score evaluation metric since combine precision recall classifier single metric taking harmonic mean selected model size penalty large enough though still allows accurately classify observation respect f_1\ score metric obtained f_1\ score different regularization parameter value found figure supplementary figure section online supplement based aforementioned figure slope obtained curve regularization parameter value used chosen point x-axis absolute value slope curve minimum long point see steep drop f_1\ -scores finally approach led new reduced feature matrix lasso consists unique feature summarized table selected aforementioned lasso approach exploit sparsity input matrix x_f\ since high-dimensional data extremely fast feature selection method therefore computationally convenient employ lasso approach different setting order explore different model size informative feature could perform predicting label article apart lasso method easily interpretable also utilize component-based approach intuition behind use another dimensionality reduction method study robustness framework compare different estimated change-point location would produced two method component-based approach employed principal component analysis pca mainly perceived variable strongly correlated therefore feature reduction essential without losing critical information pca unsupervised dimensionality reduction technique ignores class label article instead pca focus capturing direction maximum variation data set defining orthogonal projection data onto lower dimensional linear space known principal subspace variance projected data maximized regarding selected number component given upcoming multivariate change-point detection module first performs data aggregation operation accumulates data point day period considerably reducing number observation number component needed order magnitude length data sequence otherwise would potentially run high-dimensionality large computational complexity issue worked taking first principal component result extremely similar due robustness proposed change-point detection algorithm information see section result therefore article present obtained result parsimonious case meaning first principal component selected ultimately approach led new reduced feature matrix pca consists feature linear combination original one result acquired used first principal component given supplementary method section online supplement change-point detection based whether full knowledge data analysed change-point detection split two main category offline detection data already obtained online detection observation arrive sequentially present respect dimensionality data change-point detection separated algorithm act univariate data suitable change-point detection multivariate possibly high-dimensional data sequence section focus offline change-point detection denoting dimensionality given data model full generality given aligned t=1 aligned time point p\times observed data underlying unknown -dimensional deterministic signal undergoes structural change certain unknown point matrix diagonal noise term random vector mean zero vector covariance identity matrix current manuscript looking change vector first order derivative word change slope univariate component data sequence fig graphically provide example three-dimensional data sequence length 400\ diagonal element matrix equal follow standard gaussian distribution i=1,2,3\ three change-points slope location r_1=106 r_2=200\ r_3=248\ precise first two component data sequence two change-points location t=106\ t=248\ location 200\ 248\ change-points figure example three dimensional data sequence piecewise-linear structure undergoes three change first derivative location r_1 r_2 200\ r_3 248\ full size image recently developed change-point detection method called multivariate isolate-detect mid applied given multivariate data sequence component data sequence related extracted feature detail given step 1–3 mid introduced generic technique detection number location multiple structural change behaviour given multivariate possibly high-dimensional data provides maximal detection power testing change-points interval contain one change-point specific isolation technique first introduced isolate-detect methodology main idea observed data sequence t=1 j=1 positive constant mid first creates two ordered set k=\lceil t/\lambda right- left-expanding interval ith right expanding interval r_i= i\lambda t\right\ ith left-expanding interval t-i\lambda +1\right\ collect interval ordered set r_1 l_1 r_2 l_2 r_k l_k\ algorithm first act interval r_1 calculating every univariate component data sequence appropriate contrast function value possible change-point candidate interval detail suitable contrast function used given section data collection feature extraction process return vector y_j j=1 length example element y_1 contrast function value related first change-point candidate r_1\ component data sequence element y_2 relevant value second candidate r_1\ next step apply y_j mean-dominant norm y_j i=1 applying y_j return vector length identify r_1 argmax _j\left\ v_j r_1 exceeds certain threshold explicitly derived r_1 taken change-point process test next interval upon detection algorithm make new start end-points expanding interval detection occurred gaussianity noise term mid proven consistent accurately estimating true number location change-points detail please see section related work however practice mid employed current multivariate framework shown robust exhibit strong performance scenario could either auto-correlated heavy-tailed noise detail robustness result please see section result conclusion purpose paper matrix lasso pca derived dimensionality reduction stage explained previous section used creating t=1,2 algorithm mid applied three main step followed given step given matrix lasso pca depending dimensionality reduction technique employed two smaller matrix first created splitting data obtained article categorised fake obtained article categorised real notation employed aforementioned two matrix y_f\ y_r\ respectively step information therefore higher detection power worked biweekly data aggregation time essential order avoid direct utilization raw misleading observation addition important achieve aggregation observation way fake real data would appear within every period regarding selected aggregation interval experimenting confirmed aggregating two-week period specifically 14-day period allowed sufficient information fake real news within every time period used change-point detection part proposed framework therefore value various feature matrix y_f\ y_r\ aggregated period day aggregation step employed sample average relevant value feature precise number feature used since period day data second step two matrix y_r^ y_f^ dimensionality created contain aggregated information article classified real fake respectively step matrix diff y_r^ y_f^ created three step completed scenario looking abrupt change trend _t\ specifically diff t=1,2 ,255\ diff row matrix diff work difference value characteristic fake real article order capture significant deviation comparative behaviour article two aforementioned category provide indication attempt unreliable news agency write article way resembles published trusted news site ethical approval author declare human participant involved study data acquisition result informative linguistic characteristic political article applying lasso approach declare framework described extract informative linguistic feature aid identifying whether political article fake table unveils list important feature informative linearly separating article fake real result support linearly informative characteristic related psychology indicates contrast fake real political article psychological factor demonstrate intention writer convince reader content realistic using certain mechanism e.g emotionally influencing reader overdramatizating certain event persuasive language extracted feaure afinn sentiment score indeed expected informative since sentiment analysis fake news article revealed fake news tends contain increased negative emotional language moreover many selected feature widely used linguistic inquiry word count liwc dictionary demonstrate fake real news differentiate term choosing word reveal psychometrics characteristic furthermore result reveal significant stylistic attribute structural feature linked title article interestingly knowledge extracted uppercase text certainly fruitful found three important feature based uppercase letter observation linked previous study around fake news fake news found dramatic copious use uppercase letter make click-bait reader finally regarding characteristic expound complexity writing style article spotted group word-level readability vocabulary richness measure helpful distinguishing fake non-fake political article concur identical finding evolution linguistic characteristic taking account established result lasso-based model showed certain characteristic differ fake non-fake political article however since time-component involved due fact language writing continuously evolving difference informative characteristic expected changing well applying mid change-point detection algorithm default parameter value following result obtained lasso-based dimensionality reduction method four change-points detected correspond following 14-day period parenthesis provide feature change apparent first change-point period 2011-03-02 2011-03-15 title_total_number_of_sentences title_ratio_uppercase second change-point period 2011-10-26 2011-11-08 liwc_negate third change-point period 2014-02-12 2014-02-25 title_total_number_of_sentences fourth change-point period 2016-09-07 2016-09-20 title_total_number_of_sentences title_ratio_uppercase title_avg_number_of_all_caps_per_sentence rid_secondary_social_behavior rid_secondary_temporal_repere lm_weak_modal sichel vocabulary richness observe two feature title_total_number_of_sentences title_ratio_uppercase seem important rest capturing important movement similarity level fake real article figure present result aforementioned two feature attempt provide possible explanation estimated change-point location looking movement estimated signal fig consecutive segment observe significant drop value slope first last change-point change slope nature indicate aforementioned two change-points distinction fake real article became apparent meaning possibly intentional successful attempt news agency produce fake article resemble writing style trusted long-established agency table informative linguistic feature extracted lasso logistic-regression full size table figure data sequence title_total_number_of_sentences bottom row title_ratio_uppercase top row estimated change-point location red vertical line fitted continuous piecewise-linear signal presented blue colored line obtained mid change-point detection algorithm full size image continuing pca-based dimensionality reduction method principal component day change-point period detected specifically four change-point location detected period 2011-01-19 2011-02-01 2012-06-06 2012-06-19 2012-10-10 2012-10-23 finally period 2016-06-15 2016-06-28 lastly highlighted since pca performs dimensionality reduction feature selection resultant component directly interpreted like lasso-based approach conclude abrupt change trend signal present four change-points detected either lasso pca based dimensionality reduction method employed estimated change-point location two dimensionality reduction method similar indicates robustness proposed framework paper described dimensionality reduction change-point detection section crucial mention even though detected location close two method discrepancy occurred mainly due fact two reduction method obviously produce different feature set furthermore since lasso based reduction method provides interpretation regarding characteristic change perceptible perceived detected period abrupt change least one stylistic feature related title article finally observed dataset included numerous article related major political event took place near date detected change-points e.g phenomenon regarding beginning syrian civil war took place march well political scandal occurred early october played important role 58th united state presidential election finding merit additional analysis discussion potential future work utilization declare framework robustness result also investigated scenario data slightly altered precise observation every time period randomly taken carried change-point detection data removal process repeated total time meaning different data set created contained approximately value initial data set change-point detection result related shrunken data set fact good specifically time get either number estimated change-points original data set smallest possible distance meaning estimate either change-points furthermore estimated change-point location close neighbourhood location obtained original data set employed analysis conclusion work initially focused establishment lincfna large open dataset consists linguistic feature time-stamped fake real news-articles due massive amount available article lincfna allows re-use discovery research community order build upon advance knowledge tool around disinformation fake-news detection furthermore paper proposes framework includes data collection topic classification dimensionality reduction change point detection procedure proposed framework permit usage specific parameter selecting desired article feature certain timeline topic analysis ultimately experiment result carried employing method political news article demonstrated linearly informative characteristic political article related psychology interestingly significant stylistic attribute structural feature linked title article moreover result application change-point detection method support fact linguistic characteristic political article evolving also indicated several time-points even informative feature article undergo significant change making fake non-fake article harder distinguish lastly observed significant change linguistic behaviour political article occurred date major real-life political phenomenon took place potential future work using declare framework finding deserve examination discussion highlighted crawling process extracting information old website domain changed ownership challenging due fact waybackmachine remove information website well-reasoned request made content creator new ownership page commenced another important challenge modern advanced generative based model used article writing even though family model generate false content may difficult identify validity content based writing style linguistic feature since model try mimic human-like writing behaviour matter deserves investigation particular application proposed framework evolution linguistic feature extracted content generation model could studied overall analytical collective method developed work proved sensitive beneficial analysis fake news article general study would like encourage researcher consider usage certain linguistic characteristic well linguistic alternation fake news due temporal component order improve methodology model engaging fake news