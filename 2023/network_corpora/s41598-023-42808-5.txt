introduction crop wild plant specie rely interaction animal pollinator reproduction pollination therefore critical ecosystem service annual market value billion threat pollinator fully understood led urgent call study aimed understanding pollinator plant-pollinator interaction change across environmental gradient pollinator initiative currently data plant-pollinator interaction acquired field observation collection pollinator contacting reproductive part flower identification pollinator time-consuming step research example typical pollination ecologist spend week field collecting observational data arthropod many week month afterwards pinning sorting identifying arthropod using microscopy dna barcoding tool particular convolutional neural network cnns image classification potential allow efficient identification plant-pollinator interaction field image training tool require vast amount annotated data met growing amount digital data citizen science platform medium platform curated taxonomic expert development application automated recognition resulted outstanding product plant identification due consolidation different machine learning method increase image data availability advance computer hardware past decade example flora incognita app currently distinguish 16,000 european plant specie image taken citizen like plant automated arthropod identification challenged vast number taxon classified complexity image background variability shooting angle fact individual taxon vary morphology individual different taxon sometimes look similar arthropod identification also challenged dealing multiple individual overlap image different lighting condition arthropod blend cluttered background individual move fast and/or hidden part plant dramatic size difference arthropod specie deep learning revolutionized computer vision many field natural science medicine remote sensing field automatic identification arthropod convolutional neural network cnn used image classification still pre-mature phase however acknowledged potential revolutionize data collection development tool arthropod classification started focus particular taxon and/or identification museum specimen homogeneous image background example picture taken arthropod wing controlled setting i.e. microscope identify several group bee butterfly syrphid fly application cnns arthropod identification range multiple taxon considers growing number image example nine tiger beetle genus image nine group arthropod nearly image ten butterfly specie nearly 18,000 image bumble bee specie nearly 90,000 image progress direction carried also citizen science private sector ongoing research mobile apps like seek obsidentify nabu insektensommer google lens recent development camera hardware image recognition applied study insect pollination typically focused single plant specie single pollinator specie example bjerge colleague use custom camera system cnns capture image classify broad group arthropod visit plant genus sedum ratnayake colleague used raspberry hardware cnns track movement individual honeybee allowing spatial monitoring behavioral analysis important pollinator specie agricultural setting several study introduced low-cost open-source camera trap system enabling efficient collection insect image field setting however need develop tool classify flower-visiting arthropod visit wide variety flower broad geographic region europe europe four order arthropod perform vast majority pollination hymenoptera bee wasp diptera fly lepidoptera butterfly moth coleoptera beetle four taxon arthropod rarely seen flower typically considered pollinator visit flower infrequently and/or deliver little pollen per visit include order orthoptera grasshopper leafhopper order hemiptera true bug order araneae spider family formicidae ant thus necessary consider eight group arthropod classify flower visitor seen fig study test whether deep learning approach allows localize classify arthropod eight group sufficient accuracy therefore evaluated performance three light-weight object detection algorithm yolo family object detection algorithm offer multiple version algorithm varying wide variety use case experimental set-up three different yolo model trained 17,000 annotated image location arthropod marked bounding box coordinate using yolo object detection provides benefit detecting several arthropod single image one reason want explicitly test well task performed additionally expected one difficult classification dipteran family syrphidae hoverflies mimicry bee wasp hymenoptera thus performed separate test see well model differentiates family fly hymenoptera annotated image hoverflies figure example image eight group dataset used classification full size image method dataset dataset cover eight group seen fig table spider araneae beetle coleoptera true fly diptera true bug hemiptera bee wasp hymenoptera ant hymenoptera formicidae moth butterfly lepidoptera cricket grasshopper orthoptera coleoptera diptera hymenoptera lepidoptera represent important pollinator group dataset four order make majority aprox arthropod visit flower ant hymenoptera family formicidae documented pollinator case study insignificant role pollination plant even detrimental likewise araneae hemiptera orthoptera might rarely seen flower play significant role pollinator detrimental predator pollinator therefore including order dataset prevents model confusing pollinator group used curated image indexed global biodiversity information facility gbif database significant proportion image 96.77 sourced citizen science platform inaturalist observation.org account 53.86 42.91 contribution respectively extracted occurrence data eight group kept occurrence data offered url image curated datasets focusing specie marked present europe order diptera coleoptera hymenoptera lepidoptera sampled known family flower visitor uneven distribution image across family within order across specie within family example within order diptera syrphidae family many image indexed gbif dipteran family within syrphidae family common widespread specie eristalis tenax overrepresented compared specie method therefore aimed capture taxonomic likely morphological diversity image capture representative range order use random sampling order avoid selection bias specifically family consisting specie randomly selected specie randomly choose one image per specie family fewer specie randomly selected multiple image per specie high variability dataset image arthropod different angle exposure focus framing size focal length also various image background artificial natural one characteristic representative found inaturalist dataset image captured using variety device professional camera mobile phone citizen science platform encourage user crop raw image arthropod appear prominent however degree applied varies among user resulting image arthropod occupy significant portion image area case smaller portion others introduces inherent variability framing crop level insect across dataset average area occupied insect expressed proportion total image area relative bounding box area 0.34 table interquartile range 0.10 0.54 thus method allow result effectively extrapolated image captured citizen scientist arthropod image manually annotated bounding box entomologist using open source via annotation program discarded image identified incorrectly showed larva pupa stage arthropod missing and/or show entire body arthropod initial dataset consisted 20,505 image discarded 2,797 image table show final sample size training validation testing split dataset group-balanced validation testing dataset used image per group testing validation remaining image training testing dataset never shown object detection architecture validation dataset used monitoring model performance training procedure determining stop training order avoid overfitting yolo ass potential three one-stage object detection model chose light-weight model intention future application require algorithm run mobile device simultaneously trade-off must made detection model must capable performing successful classification task yolo one stage object detector since integrate object classification object location one network architecture yolo object detection algorithm divide input image sxs grid grid cell responsible predicting object centered grid cell grid cell predicts number bounding box corresponding confidence score formally confidence score prediction defined indicates likelihood object show confidence prediction time regardless number box conditional probability predicted grid cell noted contribution grid cell containing object calculated original yolo version capable real time detection one biggest drawback performance small object yolov2 introduced batch normalization anchor point use higher resolution image yolov3 built upon previous model adding object score bounding box prediction added connection backbone network layer made prediction three separate level granularity improve performance smaller object yolov4 introduced improvement backbone feature aggregation head detection step furthermore set data augmentation activation function could improve result yolov5 yolov5 originally developed pytorch darknet like predecessor yolov5 offer multiple model difference trade-off size model inference time six different architecture specific yolov5 nano small medium large extra-large distinguished depth network primarily backbone network number convolutional layer yolov5 cross stage partial csp network used backbone extract feature yolov5 panet used neck get feature pyramid model head mainly used perform final detection part yolov5 applies anchor box feature generates final output vector probability objectness score bounding box yolov5 author decided use combination leaky relu sigmoid activation function yolov5 default optimization function training stochastic gradient descent sgd default loss function used binary cross entropy logits yolov7 yolov7 multiple incremental improvement made previous version extended efficient layer aggregation e-elan used computational block enables quicker back-propagation speed training inference time yolov7 scale network depth width concatenating layer together reparameterization technique involve averaging set model weight creates model robust learning pattern yolov7 author use gradient flow propagation path see module network use reparameterization strategy final prediction author use auxiliary head different level supervision settling coarse fine definition supervision passed back lead head different granularity training set-up selected three model yolov5n nano yolov5s small yolov7t tiny compare three model offer ten million trainable parameter capable real time detection even cpu low end hardware gpus model trained using input image size pixel order use batch size eight model highest value allowed available hardware decided train model scratch use pre-trained weight coco dataset provided yolo repository since result robustness model performance model trained using three epoch warmup optimizer since help faster convergence set hyper-parameters epoch see supplementary information table best model determined fitness using weighted average mean average precision various intersection union threshold evaluate model used following metric overall accuracy precision recall intersection union iou false positive rate confusion matrix formed calculate group specific metric three model provide prediction confidence level iou score threshold using finding overall accuracy best possible combination identified using grid search increment threshold see fig supplementary information report accuracy depending highest overall accuracy achieved threshold grid search computation work done using resource leipzig university computing center granted quota access compute node eight nvidia rtx2080ti table sample size dataset used training testing object detection algorithm training dataset show imbalance image count group validation testing dataset sampled evenly group full size table result discovered general three model yolov5n yolov5s yolov7t able distinguish order flower visitor image high accuracy percent result show method categorization capable finding location arthropod within picture identifying group yolov5n highest overall accuracy acheived 94.50 achieved combination confidence iou threshold yolov5s achieved 96.24 accuracy combination confidence iou threshold yolov7t achieved 95.08 accuracy combination confidence iou threshold despite modest model size million trainable parameter model yolov5n yolov5s yolov7t able recognize order flower visitor image yolov5s approximately 3.8 time larger yolov5n achieves 1.7 greater overall accuracy yolov5s yolov7t nearly size overall accuracy difference 1.2 remaining accuracy metric shown table precision indicates accurate prediction whereas recall measure proportion ground truth instance correctly identified model false positive rate fpr proportion negative case data incorrectly recorded positive note yolov5n yolov7t get comparable result exception higher recall score yolov7t iou determined true positive taking mean predicted bounding box image yolo version scored mean iou table overview metric three model yolov5n yolov5s yolov7t full size table figure confusion matrix three model yolov5n yolov5s yolov7t column show predicted value row actual label value full size image confusion matrix prediction test dataset three model shown fig matrix show eight group dataset addition background group added count false positive false negative well show confusion matrix using confidence iou threshold table scoring highest overall accuracy confusion matrix visualizes summarizes classification algorithm performance row matrix representing example actual group column representing occurrence predicted group since may many label bounding box given picture total number image row may exceed even row contains exactly image test dataset table three yolo model fig yolov5n fig yolov5s fig yolov7t fig exhibit similar behavior diagonal indicating true positive score always greater worth noting three model missed detection hemiptera hymenoptera formicidae group seen table linked small bounding box several overlapping label per picture group share noticeable smaller bounding box well higher ratio bounding box per image compared group shown first row confusion matrix fig yolov7t suffers false positive yolov5 counterpart figure figure show result yolov7t iou depending number bounding box per image nbb iou depending relative area bounding box image size bbarea count number bounding box dataset combined category nbb bbarea size color dot represents number bounding box full size image aside comparing metric yolo version also look closely outcome detecting several object single image image small bounding box label seen fig ability recognize many arthropod various type single image significant advantage employing object detection rather scene classification approach challenging situation particularly examine iou metric accuracy bounding box placement relevant indicator model performance result image grouped number label per image shown fig result prediction depending relative area bounding box fig fig iou score shown image number detection ranging one ten last group consists image ten detection fig iou score shown depending relative area bounding box relation image size higher value bbarea larger bounding box iou measurement demonstrate significant drop value number label per image increase effect observed dealing small bounding box fig compare number bounding box per image relative area bounding box shown see larger number bounding box image also corresponds lower relative bounding box size larger bounding box area typically found image one single bounding box also worth noting fig group hymenoptera formicidae responsible bulk smaller bounding box result considerable influence distribution bounding box especially noticeable fig large circle upper left corner highlight impact carried additional test compared detection result family syrphidae within diptera using yolov7t model table show accuracy metric two combination confidence iou threshold first using confidence iou used due scoring highest overall accuracy table second combination confidence iou score highest overall accuracy syrphidae dataset see supplementary information fig experiment demonstrated exceptional result argued using confidence iou slightly superior exhibited higher level overall accuracy precision false positive rate however experiment deemed highly successful correctly classified syrphidae table show confusion matrix threshold combination confidence iou confusion matrix computed using image syrphidae test whether yolov7t model misclassifies family different group specifically hymenoptera order mimic table see syrphidae classified hymenoptera highest amount misclassified detection well label bounding box recognized successful classification example seen fig table accuracy metric using yolpv7t classifying image arthropod family syrphidae appropriate group diptera using two threshold combination full size table table confusion matrix using yolov7t family syrphidae within diptera combination confidence iou threshold full size table figure prediction blue label red nine image arthropod dataset using yolov7t model full size image fig prediction made yolov7t model depicted including prediction image multiple arthropod figure show nine image seven order dataset yolov7t model correctly classifies arthropod specific group case large count small label false negative seen fig figure show yolov7t correctly differentiates diptera-syrphidae hymenoptera discussion identifying flower-visiting arthropod challenging task especially one considers trade-off must made amount processing power necessary degree accuracy must achieved order get acceptable result yolo version used study provide several option model would suited problem tested three light-weight model could deployed field setting automated pollinator monitoring yolov5 smallest size nano small yolov7 smallest size tiny found result yolov5s yolov7t quite similar parameter count yolov5s yolov7t comparable yolov5n hand much reduced size likely explains lower score found number parameter influenced accuracy metric advantage using object detection rather scene classification determining location arthropod photo also recognizing several arthropod one image important development future automated pipeline pollinator monitoring allows individual visiting flower counted identified however observed model performance drop slightly multiple arthropod image fig model faced challenge small object since image multiple arthropod typically contain smaller bounding box image single arthropod one arthropod locate image yolov5s yolov7t give similar result high accuracy model distinguishing syrphidae hymenoptera demonstrates potential model reliable tool relatively easy job distinguish morphologically distinct group study lepidoptera coleoptera however distinguishing dipteran family syrphidae hymenopteran challenging task syrphidae mimic morphological appearance bee wasp order hymenoptera high performance model task suggests great promise future development model aim classify image lowest taxonomic level expert could high accuracy major challenge understanding trend driver pollinator pollination insufficient monitoring current data geographically biased inconsistent methodology mobilizing citizen scientist one solution work well charismatic taxon easy identify butterfly indeed transects monitored butterfly year citizen throughout europe however expanding monitoring pollinating taxon difficult citizen interested learning distinguish amongst dipteran family killing arthropod observe identified expert result presented working towards future pollinator plant-pollination interaction consistently non-destructively monitored across broad spatio-temporal scale using time-lapse camera set photograph flower field using cnns classify arthropod image europe monitoring scheme could possible existing distributed network european long term ecosystem research elter network however open question well cnn model developed manuscript use gbif-indexed image perform classifying image collected time-lapse camera testing well model perform out-of-sample dataset important direction future research object detection algorithm using deep learning proven effective achieving high accuracy variety task making popular choice machine learning practitioner however complexity computational requirement incredible deep network make challenging deploy real-world application resource may limited need quick decision-making crucial given important consider deep learning model using fewer trainable parameter may level accuracy practical deployment real world deeper network still hold potential improving accuracy may necessary balance consideration practicality feasibility real-world setting study represents significant advancement field ai-assisted identification european flower visitor encompass wide range arthropod taxon training data set occur wide variety floral background complex background however see initial step progress needed automated insect identification many ecological question monitoring aim require identification lower taxonomic level entomologist specialize taxonomy would hypothesize species-level identification might possible identifying feature specie level visible field image feature genitalia placement hair leg etc however traditional convolutional neural network cnns potential surpass human-level classification detecting pollinator identifying intricate feature pattern may elude human eye thus see testing potential limit cnns family genus specie level identification insect pollinator exciting next step line research conclusion near future object detection vital component pollinator monitoring allowing ecologist near real time data pollination across broad spatial gradient correctly evaluate change plant-pollinator interaction across space time essential continue develop technology well data set utilized training model shown yolo object detection model used classify arthropod order localize arthropod bounding box localization important task consider development application pollination ecology quantifying plant-pollinator network requires also abundance information count individual arthropod chose evaluate three different light yolo model yolov5-nano yolov5-small yolov7-tiny ten million trainable parameter important future development edge application pollination ecology lighter model deployed run detection real time edge device field condition limited computational power limited energy supply yolov5-nano model selected use foundation provides lowest number parameter still delivering satisfactory compromise precision speed yolov5-small yolov7-tiny model share similar number parameter therefore differ much result result scale almost linearly number parameter therefore suitable model type selected test depending capability future low-cost hardware setup monitor pollination