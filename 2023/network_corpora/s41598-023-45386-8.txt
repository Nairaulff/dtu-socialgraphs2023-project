introduction graphical user interface gui convenient way humanâ€“computer interaction software relies simple user interface intuitive user experience attract user user interface software requires designer design gui convert front-end code front-end engineer process often consumes lot time energy addition implementation code graphical user interface software different operating system different lead need code conversion front-end engineer automated code generation significantly reduce workload front-end developer allowing focus critical aspect software development therefore automatically converting design executable code greatly improve developer work efficiency method proposed chen combine traditional image processing method non-text area detection deep learning model area classification gui text detection gui text detection use pre-trained scene text detector east non-text gui component detection two-stage design adopted region detection region classification performed sequentially region detection developed image processing method top-down coarse strategy set gui-specific image processing algorithm region classification pretrained resnet50 image classifier fine-tuned gui component image used although chen tested variety method method used method long time ago present basic process gui code generation based computer vision use computer vision technology process gui image convert front-end code according different computer vision technology adopted method divided gui code generation method based deep learning object detection method non-deep learning gui code generation method based traditional image processing image processing-based technique rely aggregation heuristic generated image feature expert knowledge deep learning object detection-based technique use cnns obtain image feature aggregation rule large amount gui image data gui graphic processing task different computer vision task natural scene graphic distinct characteristic therefore explored various model deep neural network investigated whether structure method useful research optimized conjunction image processing algorithm paper propose new method gui code generation based component detection called guicg gui component detection phase introduce several improvement enhance performance image processing algorithm deep learning target detection algorithm gui component feature additionally develop fusion design combine image processing target detection addressing high localization accuracy required gui component detection moreover consider problem text gui component restore using text detection recognition technique accomplish task divide two step first step involves detecting classifying gui component various type e.g. button image representing specific gui object using fusion target detection model deep learning-based image processing second step generate corresponding code using code generator improve deep learning target detection image processing method meet requirement gui component detection taking account unique feature gui component shape texture boundary layout gui text detection utilize fots model established end-to-end scene text detection recognition model detect recognize text component proposed fusion-based approach gui component detection achieves significant improvement performance compared current state-of-the-art method evaluation 10,000 gui image surpass existing computer vision-based image processing-based algorithm achieving score 54.32 gui component higher current state-of-the-art approach contribution paper follows conduct empirical study evaluate target detection method image processing method gui component detection providing insight effectiveness limitation serve foundation proposed method propose guicg integrated generative model combine deep neural network image processing technique overcome challenge translating gui image code extensively evaluate guicg using mainstream datasets compare current state-of-the-art method field additionally conduct ablation experiment ass impact improvement change network experimental result demonstrate guicg outperforms existing method across multiple evaluation metric effectively combining advantage image processing target detection method overall proposed guicg method significantly improves performance gui component detection gui code generation providing accurate code generation reasonable code structure related work automatically generating code gui design using deep learning technique relatively new area research process involves problem machine understanding image design extracting logical information task seen computer vision problem therefore present related work section three part gui object detection gui text recognition gui code generation respectively gui component detection first step gui image generation code task gui component detection actually similar object detection problem computer vision used detect element gui use traditional image processing method detect gui component detect gui component based deep learning method component detection based traditional target detection method requires manual feature extraction candidate box obtained sliding window traditional classifier used determine target area entire training process divided multiple step deep learning-based method end-to-end object detection performed without defining feature usually based convolutional neural network cnn target detection method based deep learning divided two type one-stage two-stage also refinedet algorithm inherits advantage two type method gui text recognition graphic recognition network recognizes segmented text area image block text content crnn currently popular graphic recognition network recognize relatively long variable text sequence feature extraction layer includes cnn blstm carry end-to-end joint training blstm connectionist temporal classification ctc network learn context relationship character image thereby effectively improving accuracy image recognition rare network relatively effective recognizing distorted image text model inference process input image pass spatial transformation network obtain corrected image corrected image enters sequence recognition network finally text prediction result obtained esir end-to-end scene text recognition consists two part one iterative text correction network sequence recognition network gui code generation pix2code screenshots application user interface corresponding dsl training data time code generation process complicated workload heavy model lstm network pix2code model need retrained different platform repeated training increase total time code generation existing method e.g. pix2code handle simple datasets well difficulty handling complex datasets require hundred code tokens.based problem front-end code generation method based multiple head attention proposed special technique known multiple head attention analyze feature vector gui screenshots generate code token link analyzing generating process sketch2code model generating code design sketch consists convolutional neural network built top retinanet object detection architecture fast time-efficient single-stage detection method however sketch image difference shooting effect light change greater impact inference efficiency model redraw data collection training process performed iteratively fully automatically time helping reduce burden developer divide task three part detection classification combined one improve efficiency model operation however redraw currently limited detecting combining specific set style detail gui image integrates cnn rnn encoder rnn decoder unified framework rnn encoder encodes spatial layout information image feature summary vector rnn decoder summary vector generate gui framework token sequence representation recently new research improved experimental methodology evaluation metric propose new modeling architecture improve framework pix2code also automatically generates platform-specific code input given gui screenshot order overcome limitation bleu domain-specific language dsl token evaluation introduce improved bleu score mbleu work developing novel code generator graphical user interface guided need address contemporary challenge software engineering challenge include proliferation unknown malware digital landscape security vulnerability arising artificial intelligence algorithm draw inspiration insight offered qiu work emphasizes importance knowledge extraction smart city landscape introduce innovative method semantic graph-based concept extraction sgcce harness semantic information enhanced concept extraction resonates objective creating intelligent gui code generator rooted effective utilization information method designed without considering unique feature gui image gui element separately without considering problem high localization accuracy necessary gui code generation task fully consider issue propose novel gui code generation model integrating image processing deep learning object detection detection stage gui element brings significant improvement accuracy recall localization precision fusing advantage method analysis component detection model code generation gui section study effectiveness general object detection image processing method applied gui component detection firstly unique characteristic gui image gui component unique requirement gui component detection task summarized problem general object detection face unique characteristic gui proposed section design exploratory experiment explore effectiveness limitation several typical gui component detection method provide effective design idea methodology section gui component detection problem analysis component gui image different object detection natural scene distance component gui image close arrangement dense gui image many difference component mixed analyzing gui image data set seen data gui component following characteristic large similarity component textview editview text box highly similar gui image class component different form component button class different form form component quite different time gui component detection task requires high component bounding box accuracy based characteristic gui image component need explore method effective gui component detection image processing-based gui component detection method usually rely edge silhouette aggregation canny edge contour map used method visual feature object natural scene aim capture fine-grained texture detail object however since gui image may contain image natural scene applying fine-grained feature gui component easily lead wrong detection result deep learning-based method effectively learn characteristic gui component correct detection faced intra-class difference component density component similarity component gui image bounding box regression method meet high accuracy requirement gui component detection article defines gui text component component textview contain text function display text although component button text click function belong category method detect text component use ocr tool tesseract ocr tool scene text model effective detecting gui text sum three research question gui component detection task analysis section follows method suitable feature detection gui component well different type method perform predicting bounding box gui component detection gui text component recognition text component handled exploratory experimental analysis gui component detection order answer question paper first conduct analytical experiment explore performance various technology gui component detection task experiment use image processing deep learning method gui component detection respectively study conducted rico dataset research involves systematic comparison two computer vision method representative method based image processing include remaui uied ui2code three different type mature deep learning objective detection method include two anchor box-based method faster rcnn two-stage model yolov4 single-stage model single-stage anchor-free model fcos gui text detection performance ocr tool tesseract scene text detector east end-to-end text detection recognition model fots compared separate detection text non-text gui component compared performance difference unified detection dateset paper rico dataset dataset exploratory experiment section information dataset shown table experiment deal commonly used component android application interface randomly divide three part proportion training validation testing worth noting gui application appear split avoid problem seen sample training validation testing 5-fold crossover performed experiment verify table statistic rico dataset full size table model training setting experiment train model iteration batch size depending method adam optimizer faster rcnn resnet-101 backbone yolov4 cspdarknet-53 backbone fcos resnext-64x4d-101-fpn backbone network ui2code remaui uied article best setting experiment section non-maximum suppression non-maximum suppression performed remove highly repetitive prediction data listed experiment table data best performance model validation dataset evaluation paper precision recall f1-score evaluate performance method gui component detection task section following definition made detected bounding box considered positive highest iou ground-truth bounding box input gui image higher predetermined iou threshold true positive case true positive detected bounding box match real bounding box false positive case detected box doe match real bounding box false negative case ground-truth bounding box match detected box precision prec calculation formula follows aligned prec tp+fp aligned formula calculating recall rate rec follows aligned rec tp+fn aligned formula calculating score follows aligned 2\times prec rec prec rec aligned calculation method iou divide intersection area two predicted bounding box union area two bounding box represents intersection area two bounding box formula follows aligned iou a+b-i aligned figure performance precision recall score six representative method remaui ui2code uied faster rcnn yolov4 fcos used performance analysis component detection model different iou threshold full size image analysis gui component detection experiment result section show performance six method remaui ui2code uied faster rcnn yolov4 fcos applied gui component detection analyze explore performance various type method gui detection task feature firstly paper want explore impact different iou threshold model performance keeping setting except iou threshold unchanged performance six method different iou threshold shown fig section every 0.05 0.5â€“0.9 selected experimental iou threshold setting iou threshold increase 0.5 0.9 score deep learning model decrease significantly faster-rcnn yolov4 fcos decrease 32.4 28.1 29.6 deep learning model able detect component bounding box precise enough i.e. deep learning method high recall rate bounding box localization accurate enough contrast score remaui ui2code decrease significantly increase iou threshold like deep learning model score much lower deep learning model show component region detected image processing-based method partly noisy localize real component detected bounding box quite accurate due advanced design uied even performs better deep learning method term accuracy score decline smoothly much higher image processing-based method table gui component detection performance typical method full size table iou bounding box detected gui component real gui component box 0.9 bounding box likely miss part component due close arrangement gui component likely include adjacent component serious impact next task therefore paper iou 0.9 acceptable bounding box prediction threshold table show overall performance six method detecting gui component threshold iou 0.9 among ui2code performed worst indicator table speed different model processing gui image full size table meanwhile section conduct experiment explore processing speed representative method shown table deep learning target detection method significantly faster image processing-based method image processing method contains many operation directly image much slower deep learning method however two-stage method separate processing candidate region proposal prediction lead large amount time two-stage method therefore single-stage method target detection method significantly faster two-stage method uied method based image processing combine text detection method speed slow remaui slowest performance analysis text component detection recognition section experiment designed verify issue section explores whether one model used reliable text component non-text component detection time therefore experiment section trained yolov4 faster rcnn fcos model non-text component training set mixed training set non-text text component explore possibility single model simultaneously detect text non-text component performance result different training scheme shown table text non-text gui component detected yolov4 still best detecting non-text component however comparable non-text component trained compared performance three model detect non-text component certain decline show mixing text non-text component training interfere model ability learn characteristic non-text component fcos best overall performance experiment fcos anchor-free model flexibly handle text component different non-text component performance detecting text non-text component similar however gap word line text component fcos often regard word sentence whole component affect performance fcos text component table performance result different training scheme full size table according experiment feasible detect text non-text gui component one model necessary study method suitable gui text component detection current work remaui ui2code simply use ocr tool tesseract uied employ scene text detector east experiment pre-trained model directly used without fine-tuning gui text shown table fots achieves 45.52 precision 79.66 recall 57.93 score significantly higher tesseract 29.4 precision 51.83 recall 37.31 score east 40.25 precision 72.03 recall 51.64 score ui2code remaui post-processing tesseract ocr result filter false positive result still significantly change performance gui text detection since east fots specially designed scene text recognition performance significantly better gui text detection using generic object detection model see table east fots detect almost text gui including text gui component time according previous definition paper text gui component considered part component rather independent text component affect accuracy east fots experiment although text incorrect result experiment task finally parsing code restoration entire gui code must guaranteed paper text result non-text component one component text property restore final code section draw following conclusion research problem text component detection recognition performance analysis text non-text component gui instrumented separately experiment detecting text component non-text component separately simultaneously shown detection two component separately achieve better overall detection performance using deep learning scene text recognition model better ocr technology detection gui text component table text component detection performance full size table experimental analysis conclusion section explores application baseline model gui component detection task two aspect model performance text detection recognition application general object detection method gui component detection analyzed three research question proposed analysis result exploratory experiment question answered concluded graphic processing method high component bounding box accuracy deep learning object detection method high recall rate detect component non-text component text component detected separately end-to-end text detection recognition method efficiently detect text component identify text within component attribute component conclusion provide important guiding significance designing new gui code generation method based component detection next section methodology section present guicg gui code generation method leverage component detection enhance overall performance begin introducing architecture guicg followed explanation image processing technique employed gui component detection subsequently describe implementation detail deep neural network model used component detection furthermore design implement algorithm integrates image processing deep neural network additionally present end-to-end approach text detection recognition lastly discus method used generate code based result gui component detection figure guicg overall architecture component detection combine traditional image processing method deep neural network method full size image overall architecture whole task divided object detection text recognition code generation architecture guicg shown fig input image gui run image processing module deep learning module text component detection recognition module parallel use gui element detection algorithm fuse deep neural network traditional image processing technology merge detection result integrate result text detection recognition module finally use parser generate corresponding code based detection result previous step use cspdarknet add spp yolo head previously extracted feature make prediction densenet performs text recognition bounding box area gui element detection algorithm based traditional image processing technique adopt strategy large block small component detect gui object region detect gui element gui object detection model integrates deep neural network traditional image processing technology architecture result high recall rate high detection accuracy finally code generator used generate code previous result image processing gui component detection image processing-based method remaui ui2code etc detect bounding box usually accurate locating gui component therefore section design image processing method gui component detection obtain component bounding box high localization accuracy current dominant image processing method use bottom-up strategy gather fine detail object e.g. edge contour object approach vulnerable complex background gui object gui component performance poor therefore paper develops novel image processing method referred guicg-ip coarse-to-fine chunk-to-small component strategy detect gui component region figure show processing flow guicg-ip figure image processing approach full size image first convert gui image grayscale image use flood filling algorithm grayscale image use shape recognition algorithm determine whether area rectangle rectangle area considered block suzuki contour tracking algorithm used calculate boundary block produce block map next method generates binary map input gui image segment detected block corresponding region binary map existing method perform binarization canny edge detection sobel edge detection method aim preserving fine texture detail natural scene image way whatever content displayed image detected imageview element therefore used simple effective binarization method effect binarization image processing shown fig element easily recognized image finally connected component labeling algorithm used identify gui element region binary block segment deep neural network gui component detection general-purpose deep learning target detection model faster rcnn fcos yolov4 require enough training data different model design require training data different size achieve stable performance moreover unlike loose definition correct detection object detection natural scene detecting gui component fine-grained recognition task requires correct detection cover full area gui component accurately possible keeping area non-gui component adjacent gui component small possible however due characteristic gui component intra-class difference inter-class similarity dense arrangement close distance component neither anchor box-based model anchor-free model achieve goal based deep learning method generate component bounding box statistical regression meet high localization accuracy requirement gui component detection therefore based yolov4 method section improves unique feature gui component proposes cspdarknet65 combined csp network structure backbone network introduces improved spp component detection algorithm guicg-od ciou loss function following various aspect guicg-od structure described detail cspnet cspnet aim solve problem increasing amount calculation caused repetition gradient information network therefore paper redesigns part structure convolutional neural network adopts cross-stage local structure basis darknet shown fig cross-stage local structure divide feature map output previous network two part two convolution kernel one part directly output without processing part input original network perform calculation concat result two part final output processing network ensures feature map information lost also greatly reduces amount calculation cspdarknet65 backbone network guicg-od cspdarknet65 shown fig based backbone network cspdarknet53 structure backbone structure designed gao cspdarknet65 performs well guis2code figure illustration backbone network rectangle includes conv mish csp denoted residual block repeated time csp structure cspdarknet65 additional residual block blue block substituted downsampling residual block green block full size image additional root block performance improved using stack convolutional filter increase convolution stride three convolution network obtain local information image large number input root stage thereby extracting useful feature shown blue block fig average pooling block average pooling block downsampling layer speed gradient propagation network shown green block fig compared downsampling block cspdarknet53 average pooling layer stride added front original convolutional layer add convolutional layer stride replace downsampling layer structural improvement avoid information loss downsampling spatial pyramid pooling guicg-od spatial pyramid pooling structure hardly reduces network speed also significantly increase network receptive field improves ability extract contextual information paper spatial pyramid pooling improved using four maximum pooling layer kernel size k\times 13\ step size process feature map cascading four output output shown fig feature pyramid network aggregate feature map extracted backbone network different level adding bottom-up feature pyramid structure fpn structure provide wide range feature detector different level fpn structure contains bottom-up top-down path lateral connection since downsampling upsampling affect accuracy object detection top-down lateral connection reconstruction layer feature map required better predict location however order achieve better support small target detection paper add bottom-up feature pyramid structure feature pyramid original structure shown fig bottom-up structure transfer rich positional information underlying feature map upper structure top-down structure transfer rich semantic information upper feature map downward therefore method guicg-od rich semantic feature gui component location feature gui component obtained time improve performance gui component detection recognition figure architecture detail darknet structure spatial pyramid pooling block fpn panet model full size image bounding box regression compared intersection union iou generalized intersection union giou distance intersection union diou complete intersection union ciou finally use ciou bounding box loss function iou defined aligned iou aligned ciou loss function defined aligned ciou =1-iou+\frac +\frac 1-iou +\upsilon aligned summary backbone network guicg-od cspdarknet65 network cross-stage local structure additional root block average pooling block time additional module spatial pyramid pooling added neck feature pyramid bottom-up structure added make better use feature information extracted backbone network finally detection head directly detection head yolov3 bounding box loss function changed advanced ciou fusion algorithm gui component detection input image run image processing method deep learning method parallel get extracted bounding box image processing deep learning method respectively finally use fusion algorithm get final box shown algorithm first step bounding box i.e ipbox obtained image processing method filtered iou ipbox bounding box i.e odbox obtained deep learning method greater certain threshold e.g 0.8 ipbox kept otherwise discarded ipbox obtained way second step odbox filtered iou odbox ipbox greater certain threshold e.g 0.8 discard odbox otherwise keep get odbox afterwards fix position odbox rule edge odbox moved nearest line constraint distance moved exceed certain threshold e.g pixel moved edge cross edge ipbox obtain modified odbox finally ensemble ipbox odbox final result algorithm fusion algorithm full size image text recognition consider text region element label text choose fots end-to-end text recognition method best text component detection performance exploratory experiment network text component detection recognition two kind text gui image one text component textview text component text button fots easily detect text component well text belonging gui component paper considers problem identifying text component text component considered part component guicg also recognizes take result text attribute component final code generation task text attribute restored final code ensure degree restoration entire gui code code generation sequence token generated previously mentioned network compiled desired target language using traditional compilation method algorithm code generator shown algorithm algorithm code generator full size image algorithm first organizes result component detection part tree data structure according location information attribute include category component class bounding box component text component transformation algorithm completes component-to-code conversion component matching graph map containing category class-code pair component use depth-first search dfs method traverse match category component map replace position text attribute code successfully matched map bounding box text write result output file entire result traversed code file output experiment dataset experiment setup use rico dataset verify guicg performance experiment information dataset shown table fifteen common gui element android platform used paper split 58,159 gui image training validation test set ratio 8:1:1 due accuracy requirement gui element detection set iou real box predicted box 0.9 0.95 following study table overall result experiment iou 0.9 full size table table overall result experiment iou 0.95 full size table guicg implemented pytorch trained four nvidia tesla gpus cudnn acceleration operating system centos7.5 cpu intel xeon e5-2640 hyperparameters set follows number training step 500,500 step decay learning rate scheduling strategy adopted initial learning rate 0.01 400,000th step 450,000th step multiplied factor 0.1 momentum weight decay set 0.9 0.0005 respectively evaluation gui element detection use precision recall score measure performance region detection contrast experiment table show overall gui element detection result iou 0.9 among four baseline model guis2code performed best non-text element deep learning-based approach 0.439 uied achieves best non-text element 0.449 element 0.524 image-processing-based approach model achieves much better non-text element 0.463 element 0.543 iou 0.95 model experience performance degradation however method integrates image processing method relatively strong element localisation accuracy therefore still relatively strong performance even strict threshold method degrades 0.062 accuracy compared 0.089 uied 0.1-0.2 method experiment guicg achieves significant advantage achieving score 0.489 element exceeds score best method uied 0.426 6.3 ablation result ablation experiment shown table guicg-ip denotes image processing gui element detection guicg-od denotes object detection gui element detection shown table compared baseline model yolov4 improved guicg-od based exceeds yolov4 three indicator precision 0.435 recall 0.562 score 0.490 two iou threshold experiment guicg-ip achieved higher accuracy guicg-od illustrates advantage image processing method accuracy gui component detection bounding box prediction however recall rate relatively lower illustrating deep learning-based object detection method able detect component gui image comparison finally guicg integrates two method maintains advantage two method precision 0.513 recall 0.576 achieves better result single method score 0.543 table ablation experiment iou 0.9 full size table table ablation experiment iou 0.95 full size table table show region classification result guicg three deep learning baseline see method output region true-positive gui element achieves higher classification accuracy 0.87 non-text element 0.94 element three deep model table region classification result region full size table discussion method guicg paper achieved good result rico dataset gui generated generated code basically original image however effect guicg still extremely limited score component detection 0.543 recognize component gui image therefore future research idea topic expanded following point current rico datasets based real application contain gui image android application lacking real datasets web interface current datasets including web interface pix2code manually created image generated interface based manually set rule quite different interface real application follow-up research screenshots website associated html code apps grabbed create datasets current neural network-based method need rely dsl file describe gui image resulting lot work creation data set future consider abandon dependence dsl improve efficiency gui automatic code generation method conclusion paper propose guicg gui code generator combine deep neural network image processing proposed method based novel fusion deep neural network image processing technique achieves state-of-the-art performance detecting gui element gui image take gui image input generates interface code suitable various platform fusion algorithm improves recognition rate gui component furthermore consider detection recognition text component employing end-to-end text recognition method simultaneously recognize text non-text component utilize text information generated code empirical evaluation demonstrates guicg outperforms current state-of-the-art method across multiple evaluation metric achieving impressive score 0.543 overall novel guicg model excels component detection code generation