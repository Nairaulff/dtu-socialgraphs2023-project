introduction machine learning algorithm increasingly deployed decision-making critical situation profound impact society human life hence important ensure decision biased toward particular group characterized sensitive attribute gender ethnicity disability etc recent year witnessed significant progress term designing method enhancing fairness well metric evaluating fairness fair classification fair ranking fair subset selection important subtasks fair classification method goal achieve high accuracy test set also fairness measured term metric demographic parity equalized odds demographic parity ensures acceptance rate i.e. probability classifier assigning positive class subgroup equalized odds requires term true positive rate tpr false positive rate fpr fair ranking fair subset selection problem involve selecting set candidate large pool overall utility maximized ensuring fairness fair ranking additionally requires obtained set ordered decreasing utility batch classification large class problem setting like recruitment college admission etc. set agent candidate selected simultaneously refer problem batch-classification paradigm different term batch-wise classification discussed paper like defined mean sample batch learned classified collectively perform task classifying ensuring fairness entire batch together test time specifically consider batch classification post-processing step entire test set provided classification need performed collectively entire test set contrary traditional classification set-up typically point-wise task element test set labelled independently element test set dnn based algorithm like rely batch-wise training however talking batchwise inference test time despite apparent similarity classification ranking subset selection batch classification doe require relevance/utility score required ranking subset selection algorithm figure proposed framework fair batch classification given text set consists subgroup s_1\ s_2\ s_3\ representing particular value certain sensitive attribute example s_1\ represent individual gender male s_2\ could represent black people etc item belong one subgroup also provided configuration representing acceptance rate corresponding subgroup s_1\ s_2\ s_3\ first step deploy classifier model obtain labeling item test set deploy linear programming based framework lpca/lpceo take input obtain another labeling achieves configuration _i\ ensure low demographic disparity would like _i\ full size image limitation existing method general notion fairness inherently assumes similar acceptance rate across group posit fairness concept bounded social condition e.g society female representation minimal law ensuring say participation woman public position considered fair progressive hence fairness-enhancing framework need independent underlying social assumption able take social constraint input best knowledge existing framework unsuited scenario goal approach consequently paper consider problem fair batch classification acceptance rate group taken input user goal come classification achieves desired acceptance rate group aim first define configuration model whereby desirable acceptance rate group provided input algorithm demonstrate two popular metric evaluating fairness demographic parity equalized odds reformulated term acceptance rate order deal configuration model consider group set develop linear programming based solution minimizes demographic parity equalized odds maintaining accuracy proposed framework also seamlessly incorporate multiple overlapping sensitive subgroup illustrate framework fig result contribution perform experiment several real-world datasets demographic parity equalized odds fairness criterion proposed framework consistently outperforms state-of-the-art fair classification ranking subset selection method across several real-world synthetic datasets beyond decent performance gain framework also adapt given configuration capable dealing multiple overlapping subgroup demonstrate wider applicability deploy framework related problem fair gerrymandering outperforms existing baseline prior related work fair classification algorithm existing literature broadly classified three group pre-processing in-processing post-processing based algorithm pre-processing goal pre-process training data classification algorithm trained data would generate unfairness-free outcome usually done generating fair representation done feldman dwork kamiran calder edward storkey madras beutel ruoss rodriguez zhao in-processing idea add constraint fairness regularizer training objective function optimization examplesâ€”calders verwer kamishima bechavod ligett bilal zafar agarwal padala gujar zhang yurochkin celis roh yang cho romano mary post-processing third final strategy consists first running standard classifier like svm logistic-regression training data using model mitigate unfairness test data approach used hardt corbett-davis agarwal narasimhan wei perspective fair ranking algorithm relevant algorithm include celis singh zehlike zehlike last one in-processing learning rank algorithm others re-ranking algorithm without train-test data fair subset selection although predominantly studied streaming setting algorithm focussed static setting like mehrotra greedy-fair algorithm mentioned paper based old paper nemhauser revisited context demographic parity halabi since fair batch classification studied per literature compare algorithm best performing fair classification algorithm fair ranking subset selection algorithm definition fair batch classification clear fair classification algorithm also fair batch classification algorithm hence consider fair classification algorithm baseline comparison contrast fair ranking subset selection algorithm need adapted make meaningful comparison batch classification algorithm distinction post-processing algorithm would like emphasize algorithm lpca lpceo despite linear program based post-processing quite different randomized post-processing algorithm like agarwal hardt apply linear constraint ensuring agarwal al. author use constant independent size training test data dimensional linear constraint space find threshold used class probability referred confidence-scores base classifier predict class overall optimization problem linear relies cost sensitive classification algorithm paradigm similar vein used hardt also low dimensional variable constraint binary sensitive attribute find threshold decide class contrast batch classification algorithm deterministic considering base classifier size number example test set total number subpopulation dataset e.g m=2\ single binary sensitive attribute use class probability base classifier test set also post-processing algorithm transform confidence score base classifier optimization problem linear make several theoretical assumption datasets finally unlike algorithm discussed result generated algorithm sensitive change distribution sensitive attribute training data method fairness evaluation metric first provide brief overview two fairness metric demographic parity equalized odds use study two widely used metric literature represent two different category fairness metric namely independence separation also formally introduce configuration model reformulate term configuration model demographic parity demographic parity originally defined considering positive group selection rate refer acceptance rate need across two group binary sensitive attribute measure also referred statistical parity literature let population size case single binary sensitive attribute set subpopulation corresponding sensitive value represented s_1 s_2\ s_1 s_2 s_1 s_2 represents inferred label demographic disparity ddp single accordingly defined aligned ddp_s= 1|s=s_2 s=s_1 aligned system deemed demographic parity value close zero refers probability selected positive group definition extended multi-attribute multivalued case let attribute attribute assuming m_i\ value i=1 m_i\ total number sensitive value population assume correspondingly s_1 s_2 s_m\ set subpopulation representing sensitive value unlike previous case subpopulation mutually exclusive demographic disparity ddp multiple defined aligned ddp_m= 1|s=s_j 1|s=s_j aligned equalized odds hardt propose notion equalized odds single binary sensitive attribute s=\ s_1 s_2\ ground-truth labeling y=\ based define difference equalized odds deo single follows aligned deo_s y=1 s=s_1 y=1 s=s_2 y=0 s=s_1 y=0 s=s_2 aligned definition essentially stipulates true positive rate tpr_i\ y=1 s=s_i false positive rate fpr_i\ y=0 s=s_i across subpopulation s_1 s_2\ given sensitive attribute generalize definition difference equalized odds multiple sensitive attribute define difference equalized odds deo multiple multiple sensitive attribute follows aligned deo_m= tpr_j tpr_j\right fpr_j fpr_j\right aligned let dtpr_m tpr_j tpr_j difference tpr dfpr_m fpr_j fpr_j difference fpr deo_m dtpr_m dfpr_m\ easily observe trivial solution achieve zero deo_m\ simply assign label record trivial solution may lead low accuracy similarly uniformly random 0/1 labelling also lead zero deo_m\ expectation instead looking labellings lead low deo_m\ high accuracy configuration model configuration config short refers acceptance rate corresponding subpopulation normally assumed acceptance rate sub-population however real life may case many case policymakers may decide different acceptance rate different subpopulation connection demographic parity assume desirable taken input algorithm algorithm output assume desirable taken input algorithm algorithm output achieved demographic disparity configuration setting defined aligned ddp_c .\end aligned equation measure much deviation particular configuration gone w.r.t desirable condition certain constraint one establish relation ddp_m\ ddp_c\ lemma given configuration acceptance rate across subpopulation equal one show ddp_m\ ddp_c\ '_1 '_2 '_m\ arbitrary configuration '_j '_j proof condition write ddp_m ddp_c connection equalized odds one dissect definition equalized odds notion configuration inbuilt definition according configuration model defined s=s_j using bayes rule conditional probability show dependence tpr_j\ fpr_j\ _j\ aligned y=1 s=s_j s=s_j y=0 s=s_j s=s_j aligned s=s_j y=1 s=s_j y=0 similarly write fpr_j\ term _j\ well hence write deo_m\ aligned deo_m= aligned linking configuration deo_m\ allows compare two competing algorithm whereby measure deo_m\ accuracy achieved two algorithm configuration formulation unlike ddp use _j\ tool compare baseline wherein use particular configuration measure corresponding deo accuracy hence address issue input output algorithm configuration assume note fixing configuration minimizing deo_m\ necessarily mean trying satisfy criterion together otherwise known incompatible batch classification objective given test set collection s=\ s_1 s_2 s_m\ subset representing subpopulation across sensitive attribute configuration obtain labeling item configuration could realized possibly overlapping subset acceptance rate directly map demographic parity lemma deo additional constraint tpr fpr subset provided input need satisfied along configuration decidability problem first step investigate simpler decidability version objective formally decision problem corresponding demographic disparity equalized odds defined problem demographic disparity let universal set given collection s_1 s_2 s_m\ subset set subpopulation across sensitive attribute configuration decide whether exists 0/1 labelling element universal set configuration realized possibly overlapping set problem equalized odds let universal set element tag 0,1\ given collection s_1 s_2 s_m\ subset set subpopulation across sensitive attribute configuration tpr fpr decide whether exists 0/1 labelling element configuration realized given tpr fpr set w.r.t given tag certain formulation problem ensuring fairness posed ranking set-selection problem problem known -hard due possibly non-polynomial time solution problem proceed devise practical solution original objective obtaining labeling element test set achieves provided configuration well satisfying additional fairness constraint linear programming based solution section step-by-step propose solution first assume data untagged i.e without ground truth label propose reduce ddp used reduce deo criterion inherently need data tagged next consider data tagged ground truth label write used reduce ddp deo ensuring high accuracy batch classification item without tag setting consider setting ground-truth label element classified known formally given test dataset item set subpopulation belonging sensitive attribute s_1 s_2 s_m\ find 0/1 labelling item positive label fraction subpopulation given configuration propose lp-solution solve problem lpc lpc inear rogramming framework onfiguration represents labelling item feasible ensure acceptance rate value sensitive attribute according notation 0,1\ function treat variable linear program per configuration model _m\ input lpc '_1 '_2 '_m output represents ddp_c\ formulation deploy standard solver pulp obtain solution i.e. labeling element satisfies configuration constraint batch classification item tag lpc achieves provided configuration realistic setting element tagged ground-truth class model need satisfy additional performance fairness constraint based ground-truth formally given test dataset item x_i\ associated ground-truth x_i classifier prediction x_i set subpopulation belonging sensitive attribute s_1 s_2 s_m\ find 0/1 labeling item ensuring accuracy x_i x_i maximized given configuration achieved tpr_j\ fpr_j\ w.r.t subpopulation s_j deo constraint following describe based solution problem describe detail three constraint ensured propose lpca inear rogramming framework onfiguration ccuracy lpceo inear rogramming framework onfiguration qualized presented fig try satisfy two constraint case ddp equalized odds constraint case deo note achieving acceptance rate subpopulation equivalent achieving ddp make ddp special case configuration model basic structure lpca lpceo given lpca linear program contain constraint corresponding tpr fpr variable add constraint involve variable tpr fpr obtain lpceo used ensure equalized odds fairness constraint proposed considered generalization relaxation studied mehrotra maximizing accuracy element set assigned binary label hence attain higher accuracy choosing member one group say female primarily member acceptance tag x_i need chosen however note ground truth known selection made tag estimated predicted using classifier better classifier better estimation classifier besides inferring class tag point also return confidence value leverage understanding classification error would minimize one chooses item classified higher confidence value maximize accuracy specifically derive weight confidence value rank every item test data depends subpopulation like male black etc minimize j=1 put i.e rank descending order confidence value predicted classifier subpopulation element bring uniformity normalized size group hence hyperparameter number element present group achieving desired configuration provide hard constraint along small value relaxation experimental result show case output deviation smaller note unlike lpc lpca lpceo put single sided error represents two-sided phenomenon assume equal achieving low deo_m\ lpceo variable tpr_i fpr_i\ correspond tpr fpr subpopulation s_i\ s_i s'_i approximate number test data subpopulation s_i\ based classifier prediction since access use tag returned chosen classifier proxy _2\ tunable parameter control deo_m\ output configuration _\chi specifically deo_m _2\ accuracy lpca lpceo depends performance underlying classifier paper assume base classifier random forest provide result according confidence score similar result obtained logistic regression svm dnn based classifier result comparison certain baseline made obtained using fixed train test split datasets show robustness result deploy pulp obtain solution time complexity mentioned batch processing algorithm post-processing hence involve two step classifier training step post processing step thus overall convergence time algorithm written classifier classifier running time chosen classifier complexity batch processing step overall sub-populations size test set lpca lpceo using best known theoretical solver lead convergence time classifier m^2 hide polylogarithmic factor since practical scenario number subpopulation small constant convergence time rewritten classifier thus running time algorithm dominated classifier training time figure proposed framework lpca dotted line defined test record input target configuration zero disparity initial configuration _i^ initial fairness tuning parameter weight derived confidence score test data sensitive subpopulation s_i\ test set variable entire linear program lpceo additional input classifier label test data number positive negative population s_j\ according classifier s_i s_i error allowed tpr fpr variable tpr_i fpr_i\ also user defined full size image result experimental setup section describe experimental setup includes description various datasets baseline performance metric configuration generation compare baseline datasets study used four real datasets namely adult bank compas propublica recidivism german synthetic dataset evaluating performance algorithm number instance class attribute written within bracket first describe real world datasets follows adult 48,842 example task predict whether someone make 50k per year gender race protected attribute bank 41,188 example example feature target variable whether client subscribed term deposit service taken age group marital status sensitive attribute propublica recidivism 7,918 example propublica compas recidivism data task predict recidivism someone criminal history jail prison time demographic compas risk score race gender protected attribute german 1,000 example german credit dataset contains attribute personal status sex credit score credit amount housing status etc used study gender inequality credit-related issue sensitive attribute gender age synthetic datasets 8,000 example generate datasets using python function called sklearn.datasets.make_classification n_samples =8000 n_features =20 n_classes use last feature sensitive attribute varied converting 0/1 based condition natural positive rate vary across group produce non-zero ddp sensitive feature baseline compare proposed method existing fair classification fair ranking fair subset selection method specific consider method aim achieve demographic parity equalized odds classification ranking subset selection setting demographic parity selecting appropriate fair classification baseline particularly consider tackle multiple well multivalued sensitive attribute include agarwal zafar padala yang madras algorithm madras work single binary sensitive attribute similarly ranking deltr disparate exposure learning rank subset selection lp-relaxation studied mehrotra greedy-fair algorithm fair submodular maximization described halabi chosen baseline certain adjustment made order adopt method setting. equalized odds include classification baseline existing ranking subset selection method designed equalized odds agarwal zafar padala romano cho mary hardt performance metric besides measuring fairness metric ddp deo one standard metric used measure performance accuracy however divide performance respect group gain loss due fair batch classification process therefore important metric would precision fraction element chosen positive tag accepted set number positive tag element present accepted element similarly number element accepted total number positive tag element present one need consider recall efficacy algorithm depends upon fraction positive element accepted since definition notion tpr recall fpr turn related precision inbuilt consider precision recall comparison case given particular subset subpopulation s^+ whereby natural acceptance rate say natural _j\ subpopulation s_j s^+ _j\ likewise complementary subset subpopulation s^- would need calculate precision recall individual subpopulation set s^+ s^- however avoid generating many value propose notion weighted precision weighted recall let s^+ ~=~\ subpopulation whose population individual precision define weighted precision s^+\ analogously define notion weighted recall deriving configuration lpc lpca lpceo arbitrary configuration specified input case baseline algorithm goal achieve configuration acceptance rate subpopulation equal additionally acceptance rate achieved baseline need one specified input make fair comparison baseline ensure user flexibility propose deploy tunable parameter generate configuration let assume initial configuration initial arbitrary input provided user acceptance rate subpopulation need target configuration e.g. achieved baseline algorithm acceptance rate subpopulation deploy downward interpolate acceptance rate subpopulation acceptance initial higher vice versa lpca ddp certain written ddp_m ddp_m initial ddp_c ddp_c initial case lpceo write deo_m deo_m initial 1-\alpha depends configuration baseline similarly observe baseline algorithm tunable parameter changing generate different configuration varying ddp parameter multiplicative covariance factor 0,1 zafar difference-bound 0,1 agarwal lagrangian multiplier b_1 padala primal-dual parameter b_2 yang al. parameter divide range three equal part take end point generate four different configuration example take 0,0.33,0.66,1\ generate configuration zafar least ddp_m\ configuration attained one end-points range parameter instance attained zafar al. difference-bound agarwal etc however must reiterate input arbitrary configuration case also generate configuration equalized-odds implementation various baseline tuning parameter namely dccp parameter zafar difference-bound agarwal lagrangian multiplier padala varying random seed cho al. romano al. hardt varying epoch mary al. compare configuration-wise deo_m\ accuracy lpceo baseline discussed next section experimental evaluation demonstrate effectiveness proposed approach deploy across different datasets compare existing baseline algorithm configuration based demographic parity first investigate lpc able achieve provided configuration aim given dataset consider three different configuration however given configuration acceptance rate subpopulation chosen i.e. table report ddp_c\ minimum error i.e. deviation given configuration achieved lpc various datasets multiple sensitive attribute real-world synthetic datasets lpc achieves low value real-world datasets synthetic data observe increase number sensitive attribute increase different value feasibility larger number constraint requires larger value however still lpc achieves low even ten sensitive attribute table ddp_c\ lead feasibility lpc various datasets acceptance rate full size table comparison baseline ddp_m\ consider two setup experiment first setup minimum ddp_m\ given dataset compare minimum ddp corresponding accuracy achieved baseline algorithm lpca lpca iterate different configuration range acceptance rate subpopulation consider one accuracy maximized second setup deploy lpca across different configuration generated utilizing method proposed sect. deriving configuration allows demonstrate stability result make fairer comparison minimum ddp_m\ present comparative analysis lowest ddp_m\ value corresponding accuracy achieved baseline lpca table lowest value achieved tuning individual parameter mentioned sect. deriving configuration find lpca outperforms almost algorithm performing multiple overlapping subpopulation one two order magnitude term attaining minimum ddp_m\ among baseline yang performs best produce best result bank dataset since deltr greedy-fair implemented single binary sensitive attribute least ddp value better lpca table also case ddp_m\ framework mehrotra lpca except choice hence observe result close lpca accuracy comparable across baseline lpca performing marginally better lpca least ddp_m\ obtained corresponds 0.2 0.05 0.45\ 0.7 adult bank compas german datasets respectively different configuration baseline algorithm generated four configuration regulating tunable parameter sect. deriving configuration subsequently taking four configuration input run lpca obtain result resort arbitrary configuration generated baseline hence fair comparison result need generated feasible baseline configuration particular set four configuration also compute average difference accuracy weighted precision weighted recall show table see case lpca performs better baseline positive number two case lpca recall worse instance lpca always performs better competitor least two three metric however clearly second best showing maturity field several algorithm achieve similar performance note table indicates four configuration average acceptance rate lower higher natural acceptance rate lowest highest class noticeably algorithm fail minimize ddp_m\ keeping average acceptance rate constant would also like point ass performance algorithm clear reporting ddp_m\ needed table minimum ddp_m\ achieved various baseline along corresponding test accuracy various datasets full size table table difference average weighted precision higher acceptance class weighted recall lower acceptance class overall accuracy configuration lpca different datasets full size table comparison baseline deo_m\ perform configuration based comparison deo_m\ various baseline baseline cater equalized odds criterion fairness find configuration corresponding final output use lpceo return output configuration compare deo_m\ baseline lpceo note lpceo ensures ddp_c case consider four different configuration baseline observe none baseline except agarwal yang cater multiple overlapping sensitive attribute among chosen baseline algorithm zafar al. romano padala deal single binary sensitive attribute rest cater single sensitive attribute multiple subpopulation thus comparison use binary non-binary sensitive attribute according ability baseline table show average difference configuration deo_m\ accuracy lpceo baseline multiple overlapping subpopulation case observe agarwal achieve marginally better deo_m\ cost accuracy datasets except adult whereas lpceo performs better w.r.t deo_m\ compared yang datasets adult case single sensitive attribute multiple subpopulation mary performs better adult whereas lpceo performs better cho hardt term deo_m\ case single binary sensitive attribute lpceo performs better zafar padala romano w.r.t deo_m\ almost case lpceo performs better term test accuracy although improvement modest performance wrt ddp_m\ deo_m\ demographic parity perform experiment show way precision recall accuracy change change user tunable parameter defined sect. deriving configuration desired acceptance rate subpopulation provide idea relationship among metric parameter fig observe behavior weighted precision weighted recall accuracy varying ddp_m\ configs generated lpca vary adult dataset acceptance rate various class output classifier considered initial plot observe increase accuracy decrease precision recall ddp_m\ value increase happens ddp_m\ increase system move towards initial hence increasing accuracy since higher class begin get higher fraction allocation confident point get higher chance chosen hence dip precision fall recall explained similarly fig run lpca increasing value observe accuracy reach maximum around 0.20\ due symmetry metric w.r.t natural average acceptance rate system value change precision/ recall curve seven event point corresponding initial class wherein increase event point particular class flip participation precision recall calculation thus temporary reverse trend observed point equalized odds similar case ddp_m\ fixed =0.2\ vary generate configs various deo_m\ lpceo plot corresponding weighted precision recall accuracy fig taking initial also plot fig deo_m\ difference tpr fpr varying keeping 0.2\ varying keeping observe fixed 0.2\ vary deo_m\ dtpr_m\ general non-monotonic w.r.t ddp_m\ reach minimum particular 0,1 non-monotonic relation accuracy weighted precision recall also show oscillating behavior plotted deo_m\ although overall trend curve similar ddp_m\ plot fig value deo_m\ attains maximum 0.2\ due fact value point maximum accuracy essentially corresponds selecting lot people big population class like male populated group hence leading larger dtpr table average difference configuration deo_m\ accuracy various baseline lpceo full size table figure variation different performance metric configs generated lpca lpceo adult dataset increasing ddp_m\ fixed =0.2\ increasing deo_m\ increasing seven vertical line correspond initial configuration acceptance rate seven subpopulation fixed =0.2\ variation deo_m\ configuration generated lpceo increasing ddp_m\ varying =0.2 increasing full size image robustness investigate whether result obtained proposed algorithm sensitive train/test data split specifically table perform random 70/30 split data two type experiment report average ddp_m deo_m\ accuracy case lpca dataset fix report average ddp_m\ accuracy case lpceo dataset fix particular configuration report average deo_m\ accuracy random split general observe statistic change third digit decimal take average random split hence show result performance metric result indicate proposed algorithm robust sensitive data split table lpca average value accuracy ddp_m\ obtained random 70/30 split reported 0.2\ adult 0.17\ bank 0.47\ compas 0.84\ german full size table computational efficiency method next discus computational efficiency different algorithm term average time taken second fixed train-test split datasets different value model parameter algorithm experiment performed across algorithm handle multi-attribute case dataset result presented table zafar use parameter multiplicative covariance factor agarwal difference bound yang parameter plugin approach range value mentioned sect. deriving configuration since parameter regulate output configuration algorithm taking average give estimate effect strength fairness constraint running time baseline similarly method lpca lpceo vary target configuration 0,1 parameter lpca lpceo datasets time reported table second addition training testing time experiment performed intel xeon cpu 2.2 ghz 13gb ram overall lpca lpceo achieve comparable performance term computational cost respect baseline method table average running time second baseline cater multiple sensitive attribute datasets full size table fair gerrymandering problem fair gerrymandering proposed kearns demonstrates could large hidden subgroup particular data fairness may naturally flow even overall system fair problem although mentioned zafar explored detail yang construct gerrymandering subgroup realize low ddp_m\ case two sensitive attribute case datasets s_1\ s_2\ containing k_1\ k_2\ subpopulation respectively number gerrymandering group according definition yang k_1 k_2 k_1 k_2\ thus gerrymandering group adult bank compas german datasets respectively considered adult bank datasets respectively due small size group regulating tunable parameter algorithm able generate several configuration varying ddp_m\ configuration considered input lpceo deployed lpceo able realize configuration compare performance lpceo term accuracy deo_m\ yang present result table find ddp_m\ lpceo lpca much better accuracy deo_m\ result evenly distributed lpceo performing particularly well compas table comparison test accuracy deo_m\ yang lpceo averaged four configuration generated yang various datasets full size table dependence training distribution batch-wise post-processing framework lpca lpceo additional advantage invariant training distribution sensitive attribute also allows dealing situation sensitive attribute noisy often case real-world scenario like online social medium sensitive attribute provided user voluntarily illustrate consider adult dataset modify sex race attribute training data randomly assigning value every element training data keeping dimensions/attributes unchanged also ensure accuracy base classifier say randomforest largely remains unchanged noticeably algorithm mostly achieve similar level accuracy test dataset none maintain ddp_m\ deo_m\ training set modified unlike lpca lpceo algorithm assume distribution sensitive attribute training test data hence sensitive attribute information training set significant impact classification result test data detailed result reported table deltr algorithm prediction done based ranking function learnt training set also affected modification albeit extent cater single binary sensitive attribute case deo algorithm like agarwal hardt affected experiment post-process handle multiple subpopulation whereas in-processing algorithm like yang al. padala al. zafar etc dealing single binary sensitive case affected table test accuracy ddp_m\ deo_m\ various baseline adult dataset change sex race attribute training data keeping test data unchanged full size table conclusion primary contribution paper identifying presence special widespread batch-admission-like situation batch classification natural operation decoding apparently obvious real-world setting help design simple lp-based algorithm able compete perform better sophisticated classification algorithm carefully generalize definition demographic parity equalized odds multiple sensitive attribute analyze theoretical computational complexity definition help develop framework enables generation desired configuration expressed term demographic disparity average acceptance rate simple externally defined distribution acceptance rate additional advantage configuration based framework includes ability deal multiple overlapping subpopulation invariance change sensitive attribute distribution training data iii applicability related problem fair gerrymandering future would interesting see framework applied notion fairness like counterfactual fairness calibration etc quite different independence separation based notion fairness supplementary information