introduction driven successful advance deep generative model past year scientific data generation become one essential topic scientific research field novel computational approach based deep generative model developed generate scientific data experimental simulation datasets deep generative model stand deep neural network designed generate synthetic data approximating complicated high-dimensional data distribution two representative deep generative model variational autoencoder vae generative adversarial network gan extensively used scientific research data generation example vaes used new physic mining large hadron collider molecular designing whereas gans used weather prediction image augmentation condensed matter physic magnetic system representative system deep learning technique actively applied unique physical characteristic appear due competition several complicated magnetic interaction also several toy model based magnetic system ising heisenberg model generally used analyze physical phenomenon observed various research field among deep learning technique vae-based model widely adapted various magnetic system investigating phase transition behavior characterizing crystal structure interpolating extrapolating magnetic structure searching optimal magnetic structure estimating effective field finding ground state despite successful application sampling data topological spin structure using vae still certain limitation originated representative disadvantage vae called latent space smoothness usual training process vae latent space formed follow simple prior distribution e.g. gaussian distribution mean complicated target data distribution may accurately represented simple continuous latent space vae lead difficulty capturing intricate relationship data point also case sampling data topological spin structure spin structure distinctly separated high energy barrier induced topological property vae learn detail topological difference spin structure consequently allows generation non-plausible spin structure topological defect including nodal point previous study address issue using prior scientific knowledge target system adding energy generated spin configuration cost function polishing generated sample lower energy however prior knowledge often absent datasets thus additional study needed generating topological data avoiding topological defect without prior knowledge hand various deep generative model based gans also applied generate scientifically plausible data various research field condensed matter physic usual gan model discriminator network learns distinguish real fake sample generator network trained produce sample realistic enough deceive discriminator network adversarial relationship discriminator generator gan-based model shown greater capability photo-realistic data generation compared vae analogously expected gan-based model produce realistic spin structure fewer nodal point however problem gan-based model diversity generated sample poorer vae-based model secure high plausibility gan-based model high diversity vae-based model simultaneously recently hybrid model vae gan intensively studied applied various research field goal study implement generator produce physically topologically reliable magnetic structure achieve goal build hybrid model two representative deep generative model vae gan train two-dimensional spin structure exhibit strength topological structure generator result compared standalone vae gan trained model quantitatively evaluated coverage energy metric measure diversity fidelity generated sample respectively visualize latent space manifold trained model analyze underlying reason topological defect appeared generated sample additionally suggest discriminator-driven latent sampling ddls method applied improve plausibility generated sample eliminating topological defect strategy vae-gan hybrid model hybrid model combine training workflow vae gan comparative investigation train three model vae gan hybrid model vae built two neural network encoder generator decoder shown fig encoder convert training data latent code generator decodes hand gan consists generator discriminator shown fig random latent code sampled prior distribution becomes fake data via generator real data fake data classified discriminator hybrid model three neural network encoder generator discriminator figure illustrates overall training workflow hybrid model note reconstructed data also fed discriminator fake data therefore unlike standalone gan number fake sample twice number real sample figure illustration training workflow vae gan hybrid model denote encoder generator decoder discriminator respectively schematic description standard sampling vae gan hybrid model schematic description ddls sampling dashed arrow indicates gradient backpropagation denotes gradient step size full size image loss function hybrid model also contains component vae gan loss loss function vae vae shown dimensionality input feature 128\times 128\times coefficient regularization term z|x\right posterior distribution encoder term denote expectation value kullback–leibler divergence respectively vae first term measure well vae reconstruct input data second term enforces trained latent space vae close prior distribution z\right gaussian distribution study gan loss function use non-saturating loss shown gan gan denote loss function discriminator generator respectively gathered gan d\left d\left gan d\left gathered discriminator learns classify real fake data gan loss function discriminator first term log d\left represents expectation negative log probability discriminator assigns real data denoted real second term log 1-d\left represents expectation negative log probability discriminator assigns data produced generator denoted fake mean discriminator learns classify real fake data hand loss function generator log d\left represents negative log probability discriminator assigns fake data real finally entire loss function hybrid model shown coefficient gan loss gathered hybrid vae hybrid d\left d\left d\left hybrid vae d\left d\left gathered loss function separately used train encoder discriminator generator detailed training condition hyperparameters described experimental section discriminator-driven latent sampling standard sampling method deep generative model including vae gan sampling random latent code prior distribution e.g. standard normal distribution feeding generator network shown fig gan-based model another approach generate new sample called discriminator-driven latent sampling ddls end training gan adversarial game generator discriminator generally doe converge generator ground truth generating extremely realistic data completely deceiving discriminator thus discriminator still watch implausibility generated data based fact previous study proposed various ddls method rejecting unrealistic sample polishing implausible factor generated sample using monte carlo method via discriminator evaluation implement simple ddls algorithm shown fig use improve topological plausibility generated sample algorithm latent code initially sampled prior distribution iteratively updated using gradient descent method maximize evaluation trained discriminator d\left g\left z\right since discriminator trained return value one real data zero fake data process maximizing discriminator evaluation expected evolve generated spin configuration g\left z\right become realistic without topological defect result ddls presented later result section dataset train vae gan hybrid model two-dimensional metastable spin structure various labyrinth pattern dataset generated simulated annealing process implemented monte carlo method suppose heisenberg model hamiltonian =-j square lattice 128\ grid site periodic boundary condition denote exchange interaction parameter dzyaloshinskii-moriya interaction vector heisenberg spin -th grid site respectively parameter fixed 1.0 0.3 respectively system spin configuration determined spontaneous symmetry-breaking process generate countless different metastable state fixed condition generate total 40,000 spin configuration divided 30,000 training datasets 10,000 test datasets metric goal evaluate diversity fidelity data generation strategy based vae gan hybrid model without ddls unfortunately many representative metric inception score fréchet inception distance evaluate generative model without discerning diversity fidelity furthermore metric properly available model trained imagenet dataset need reference model pre-trained dataset embed generated sample feature space reference model reason measure diversity using coverage metric count mass real data covered model distribution implied generator network evaluate fidelity generated spin configuration simply measure energy using hamiltonian spin configuration dataset result simulated annealing process energetically stabilized result comparison vae gan hybrid model hybrid model shown fig trained dataset loss discussed strategy section standalone vae gan also trained condition compared hybrid model figure a–d show comparison ground truth sample spin configuration test dataset spin configuration generated trained model spin configuration generated trained vae model exhibit lot nodal point indicated red circle contrast spin configuration generated trained gan hybrid model show smaller number nodal point comparison vae model nodal point implausible structure topological defect magnetic system thus appear ground truth spin configuration addition nodal point energetically unstable energy density map high-energy peak bright point position nodal point exist mean measure plausibility fidelity generated spin configuration energy number nodal point strongly related fact one check fidelity gan hybrid model surpasses vae model figure sample spin configuration test dataset energy density map spin configuration generated trained vae gan hybrid model energy density map color black/white contrast spin configuration indicate in-plane out-of-plane direction local spin respectively red circle highlight position nodal point coverage energy metric value trained model scatter point indicates result independent trial full size image quantitatively investigate coverage energy metric value independently perform training process five time generate 10,000 sample trained model shown fig higher coverage value indicate better diversity lower energy value indicate better plausibility upper left part graph fig indicates better result mentioned confirm gan hybrid model produce lower energy sample compared vae consistent conventional understanding usual gan-based generative model advantage generate realistic sample vae-based model hand coverage vae hybrid model around 0.92 0.90 average respectively whereas coverage gan 0.80 average consequently confirm hybrid model take advantage high coverage vae high fidelity gan simultaneously another advantage hybrid model stable standalone gan observed fact coverage energy metric value five independent trial hybrid model show dispersion compared standalone gans latent space analysis investigate underlying characteristic deep generative model trained topological magnetic structure dataset analyze latent space manifold model shown fig display high-dimensional latent space model arbitrarily select two total n=128\ dimensionality latent space sample various latent code scanning specific region chosen two-dimensional latent space n-2\ component latent code fixed random number sampled standard normal distribution prior distribution model verified choice doe make significant difference discussion section sampled latent code decoded spin configuration trained decoder generator vae gan hybrid model calculating energy discriminator logits plot calculated value chosen two-dimensional latent space use heatmap representation shown fig energy discriminator logits latent space region figure latent space visualization heatmaps representation energy value discriminator logits along two within range brighter darker color indicates higher lower energy value real-like fake-like sample perspective discriminator respectively trained model discriminator vae spin configuration decoded latent code position red circle highlighting changing structure full size image interesting feature fig compared blurred energy heatmap vae energy heatmaps gan hybrid model include several narrow line flat region surrounded line interesting feature also shown heatmaps discriminator logits gan hybrid model fig considering spin configuration dataset distinctly separated topological property high energy barrier latent space partitioned several flat region narrow line may imply gan hybrid model properly learn topological property dataset specifically narrow line supposed indicating specific region latent space decoded high energy state emerging implausible topological defect implying boundary energetically stabilized topologically different spin configuration figure directly support narrow line closely related emergence implausible topological defect vae gan hybrid model three spin configuration decoded latent code three different latent position marked fig within latent space represent two separate flat region boundary line indicated red circle shown fig spin configuration exhibit topologically distinct local spin structure spin configuration includes nodal point consequently confirm latent space formed training topological data composed multiple latent domain flat region latent domain wall boundary latent domain strongly related topological property implied dataset addition also confirmed latent domain latent domain wall clearly distinguished latent space gan hybrid model whereas latent space vae blurred overall model data generation using ddls discussed previous section gan hybrid model considered study advantage generating plausible data narrowing latent region decoded implausible data however still possibility latent code sampled narrow region generate new sample without implausible defect apply ddls algorithm shown fig using generator discriminator trained hybrid model figure show result ddls algorithm ddls progress initial spin configuration becomes energetically stabilized removing several nodal point example nodal point within local spin structure highlighted red box initial spin configuration removed first iteration iteration step initial spin configuration evolves new spin configuration without implausible topological defect figure data generation process using ddls algorithm change spin configuration iterative process ddls algorithm red square initial spin configuration highlight nodal point region magnified view highlighted region grad-cam spin configuration red color indicates important area discriminator predict spin configuration fake full size image offer insight ddls algorithm eliminate nodal point initial spin configuration plot gradient-based class activation map grad-cam shown fig demonstrate role discriminator ddls algorithm grad-cam explanation method convolutional neural network classifier including discriminator gan hybrid model show specific region input data significantly influence decision classifier obviously grad-cam result initial spin configuration highlight position nodal point indicating nodal point crucial factor discriminator determine spin configuration fake data nodal point gradually disappear ddls progress level highlighting reduced mean becomes challenging discriminator determine spin configuration fake data consequently confirmed crucial factor discriminator classify spin configuration real fake data existence nodal point implausible topological defect target system using discriminator utilize ddls algorithm generate topologically plausible data removing implausible defect shown fig application hybrid model trained hybrid model capable generating plausible data also applicable various purpose section demonstrate two application example first example searching optimal solution various objective including maximizing out-of-plane magnetization minimizing minimizing energy spin configuration utilizing well-trained generator hybrid model various optimization algorithm implemented within latent space specifically search optimal solution according defined objective obtaining corresponding latent code employ genetic algorithm conventional optimization algorithm inspired biological evolution process second example investigating intermediate state optimal spin configuration also performed latent space hybrid model interpolating latent code corresponding optimal solution figure schematically illustrates location optimized latent code interpolation line iii represent latent code obtained maximizing minimizing minimizing respectively result optimizing either maximizing minimizing skyrmion lattice highlighted within red square left right side fig minimizing result well-aligned stripe structure highlighted within red square right side fig value optimal solution 0.211 0.204 respectively represent extreme value compared distribution training dataset mean 0.000 standard deviation 0.016 see fig optimized value 0.0442 significantly lower training dataset mean 0.0423 standard deviation 0.0002 see fig optimal solution skyrmion lattice well-aligned stripe structure physically reliable magnetic system controlled applying out-of-plain external field numerous study reported labyrinth structure become skyrmion structure external field applied well-aligned stripe structure also observed ground state system previous study figure application trained hybrid model schematic illustration interpolation latent space three dot iii represent optimized latent code obtained maximizing minimizing minimizing respectively spin configuration obtained linear interpolation iii iii red square indicate optimal spin configuration distribution test dataset value optimal solution indicated arrow distribution test dataset value optimal solution iii full size image optimization process using trained model completed short period time study take approximately min whereas impossible achieve goal reasonable time frame conventional micromagnetic simulation notably ground state system characterized well-aligned stripe structure remains elusive conventional micromagnetic simulation due existence numerous metastable state computational efficiency optimization using hybrid model attributed dimensionality reduction achieved trained generative model original system dimension latent space model 128-dimensional substantially narrow target space search optimal solution realm optimization higher dimension dramatically increase complexity problem constrain efficiency algorithm applied hybrid model effectively reduces dimensionality facilitates successful application genetic algorithm within dimensionally reduced latent space model believe optimization strategy applied wide range system objective designing molecule material approach also adaptable conventional optimization algorithm including gradient-based method monte carlo method important highlight mentioned optimized solution generated hybrid model absent training dataset time physically reliable displaying node point indicates hybrid model capable generating new physically reliable sample extending beyond training dataset confirm hybrid model generate wide variety sample high diversity high fidelity central area fig b–d illustrate result linear interpolation within latent space latent code iii iii interpolated structure transition smoothly one optimal state another exhibiting node point maintaining physically appropriate configuration varying out-of-plane magnetization energy reliability interpolated structure ascribed adversarial training contrasting increased number node point observed interpolation performed within latent space standalone vae model confirm hybrid model posse advantage including capability generate diverse new physically reliable sample potential application across various domain conclusion investigate performance vae-gan hybrid model generator data topological property generate dataset composed various spin configuration simulated two-dimensional magnetic system use train simple vae-gan hybrid model performance trained hybrid model evaluated aspect diversity fidelity compared standalone vae gan model confirmed hybrid model exhibit high diversity high fidelity simultaneously incorporating strength standalone vae gan model latent space visualization find latent space built model partitioned numerous latent domain latent domain wall closely related topological property implied dataset show even topologically implausible structure appears generated sample ddls algorithm improve plausibility sample removing appearing topological defect finally demonstrate two application example trained hybrid model searching optimal solution various objective investigating intermediate state believe hybrid model great potential generator topological data offering numerous versatile application experimental section neural network structure neural network pre-activation residual building block resblocks batch-normalization leaky-relu activation function used shown fig figure b–d show generator discriminator encoder architecture periodic padding applied convolution periodic boundary condition dataset spectral normalization applied discriminator layer thus batch normalization layer removed discriminator network force generator output pixel heisenberg spin normalized pixel pixel normalized end generator sampling 2\times applied upsizing generator whereas downsizing discriminator encoder implemented convolutional layer stride size kernel size 4\times figure neural network used study schematic illustration pre-activation residual block discriminator batch normalization layer removed network architecture generator discriminator encoder lrelu denote batch normalization leaky-relu activation respectively full size image hyperparameters coefficient regularization loss term vae loss chosen 0.001\ coefficient gan loss component generator hybrid model chosen 0.001 training use adam optimizers learning rate 0.0002 0.0 0.9 respectively training dataset contains 30,000 sample batch size number total training step epoch