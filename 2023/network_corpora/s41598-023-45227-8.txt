introduction supply chain management scm play critical role ensuring smooth flow good service manufacturer end consumer context accurate prediction backorders refers unfulfilled customer order due temporary stockouts paramount importance supply chain backorder prediction scbp enables proactive inventory management efficient resource allocation enhanced customer satisfaction assist mitigating negative impact stockouts lost sale decreased customer loyalty disrupted production schedule predicting backorders product future challenging mainly demand particular product fluctuate unexpectedly develop accurate predictive model crucial adequate amount training data derived inventory tracking system data allows model learn pattern indicate whether product likely backordered however significant challenge building model inherent imbalance dataset number sample product backordered much lower product backordered class imbalance creates skewed dataset negatively impact model performance need research available product backordering specifically addressing challenge class imbalance however extensive work conducted past optimize inventory management inventory manager encounter various challenge faced material shortage result complete backlog lost order previous literature categorized material backordering fixed partial time-weighted backorders customer willingness wait replenished stock depends factor supplier reputation recency backorder placement waiting time customer may patient wait others may seek alternative option due impatience case supplier experience sale loss missed revenue opportunity leading customer dissatisfaction potential doubt supplier inventory management capability traditional prediction model predominantly based classical machine learning cml algorithm widely utilized backorder prediction however model face several challenge dealing large-scale datasets typically encountered supply chain application traditional model often need help handling datasets complexity dimensionality leading suboptimal performance limited scalability moreover ability capture intricate pattern dependency within data crucial accurate prediction remains challenge conventional approach despite widespread use cml model tuning million hyperparameters training cml model like dnns requires significant computing power fast-rising data volume required training particularly post-moore law era exceeds limit semiconductor production technology limit field advancement hand quantum computing proven effective solving issue insurmountable conventional computer factoring big number unstructured database search nevertheless noise produced quantum gate absence quantum error correction noisy intermediate scale quantum nisq device substantial circuit depth face significant difficulty creating quantum algorithm reasonable level noise-resistant circuit depth would fundamental relevance performance cml model outperformed quantum machine learning qml based variational quantum circuit vastly decreased number model parameter one key advantage variational quantum model classical counterpart result variational quantum model reduce overfitting issue related cml moreover circumstance may learn quickly attain better test accuracy compared conventional counterpart variational quantum model play vital role quantum component modern qml architecture circuit parameter updated classical computer emergence quantum-inspired technique opened new avenue addressing limitation cmls technique inspired principle leverage inherent parallelism quantum-inspired optimization algorithm enhance predictive capability qml model exhibit promising potential handling large-scale datasets capturing complex pattern improving prediction accuracy various domain scbp benefit enhanced model performance improved accuracy efficient resource allocation harnessing power quantum-inspired technique utilization qml algorithm enable identification intricate relationship variable facilitating accurate prediction backorder occurrence consequently technique potential optimize scm minimize stockouts reduce cost enhance customer satisfaction field inventory management research numerous study delved enhancing forecasting decision-making regarding backorders multitude study explored various mathematical algorithmic approach markov decision process reinforcement learning fuzzy model technique however conspicuous research gap exists come effectively handling short imbalanced datasets common real-world scenario acquiring extensive data often impractical ensemble forecasting model demonstrated superiority method computational efficiency becomes limiting factor particularly large warehouse datasets thus restricting practical applicability light limitation traditional model potential advantage offered quantum-inspired technique research aim develop novel hybrid quantum-classical kera neural network tailored scbp bridge research gap proposed model combine flexibility interpretability kera nns quantum-inspired optimization algorithm overcome limitation classical approach integrating quantum-inspired technique prediction process anticipate achieving improved accuracy robustness scalability scbp novelty research lie application benchmarking qml technique classical technique field scbp short imbalanced datasets extensive literature review analysis confirm study represents first known instance qml implementation context scbp introducing qml domain objective unlock new possibility harness potential advantage quantum-inspired technique offer field scm research contributes field scm exploring potential qml technique accurate efficient backorder prediction novel hybrid quantum-classical neural network q-cnn developed part study combining strength parallel-processed computing quantum physic hybrid classical-quantum computing computational paradigm combine classical infrastructure quantum computer address specific problem domain approach classical computer play crucial role pre-processing data controlling quantum machine computation post-processing result obtained quantum computation harnessing quantum phenomenon entanglement superposition quantum computer posse ability perform parallel processing manner unprecedented classical computer leveraging strength classical quantum computing hybrid system enable utilization quantum resource utilizing classical algorithm technique enhance overall computational performance synergistic combination allows efficient utilization quantum resource effective integration classical quantum computing capability tackle complex problem hybrid algorithm employed study outperformed classical counterpart leveraging quantum classical computing capability light consideration research provides novel thorough methodology anticipating inventory backorders goal maximize profit minimizing cost related product backorders maintaining good relationship supplier customer preventing sale lost customer business alike profit precise projection future backorders individual product help well-developed predictive model current topic research simplification quantum algorithm usage nisq computer quantum algorithm scale well may efficiently executed computer use photon superconductors trapped ion particularly exciting qml compatibility current nisq design predicting product backorders example requires access massive amount data strength traditional algorithm reason research introduces novel q-cnn model deal data imbalance even trained small dataset nisq device effective running shallow-depth algorithm requiring qubits given specific difficulty prerequisite product backordering prediction becomes sensitive take advantage qml run nisq device mean scbp dataset classification inspection test small-size datasets made possible searching quantum advantage classifier open-access kaggle dataset used research gathered 8-week inventory management system unfortunately shown fig dataset need balanced number backordered item disproportionately high 137:1 figure show dataset heatmap indicating high feature correlation required increasing difficulty working dataset issue made complicated fact prediction model need help dealing imbalanced datasets gradient boosting model gbm random forest logistic regression traditional method presented similar job past also common practice use undersampling oversampling strategy rectify grossly unbalanced business statistic figure barplots showing distribution null value dataset removal top bar show number sample present feature full size image research present innovative approach scbp incorporates effective preprocessing method resulting novel quantum-classical ml-based prediction model various step methodological flowchart first preprocess sku feature using seven possible combination method benchmark preprocessed dataset applying model select effective preprocessing technique based accuracy selected preprocessing task involve converting categorical feature numerical feature handling missing value log transforming numerical feature normalizing feature value within specific range dropping redundant numerical feature using variation inflation factor vif treatment classification problem substantially fewer positive sample backordered negative sample non-backordered consequently address issue class imbalance employing undersampling technique called nearmiss choose undersampling instead oversampling qml model struggle train large datasets compared cml model furthermore utilize principal component analysis pca extract four input principal component preprocessed dataset component capture significant feature prediction finally propose hybrid q-cnn model named qamplifynet incorporates key aspect architecture mnemonic name signifies utilization principle highlighting model quantum component amplify represents concept amplifying information model layer lastly net refers nature model incorporating classical qml component performance evaluation model compare eight commonly used cml model one deep model five quantum nns three quantum-classical stacked ensemble comprehensive comparison aim demonstrate superiority robustness proposed qamplifynet model scbp short datasets despite excellent accuracy cml model complete dataset proposed qamplifynet model hold significant value showcase remarkable performance short imbalanced data common challenge inventory management additionally application qml domain represents pioneering effort making first-ever qml application inventory management field using benchmark scbp dataset titled predict product backorder run test utilizing proposed model experimental finding demonstrate higher performance technique scbp evaluated accuracy area receiver operating characteristic roc curve moreover compare model well-known classification model come conclusion strategy performs noticeably better comparable model figure spearman correlation heatmap analyze relationship target feature went_on_backorder preprocessed input feature scbp dataset generated using python 3.10 seaborn 0.13.0 full size image summary paper make eight-fold contribution study represents pioneering application scm domain introduce novel theoretical framework predicting inventory backorders present comprehensive data preprocessing technique combine log transformation normalization vif treatment nearmiss undersampling address imbalanced nature dataset rare scm domain propose hybrid quantum-classical kera nn-based technique forecasting product backorders enhancing supplier overall efficiency demonstrate hybrid q-cnn model overcomes challenge limited availability large scm datasets showcasing enhanced performance compared cml qml model short datasets feature enhance interpretability proposed model implementing explainable artificial intelligence xai method specifically shap lime novel methodology significantly improves prediction accuracy reducing misclassification error especially false positive false negative ultimately increasing enterprise profitability lastly discus proposed methodology applied homogeneously supervised binary classification domain predicting credit card default paper break current literature scbp cml model quantum-inspired model rl-based technique reviewed related work section draw attention unanswered question proposed model seek answer method section introduces proposed hybrid q-cnn-based backorder prediction system address class imbalance short dataset describes selected preprocessing step followed architecture working principle model used paper result section use experimental data robustness test evaluate compare verify effectiveness proposed model discussion section conclude make comparison proposed model alternative method possible real-world scm implementation suggested method also discussed report finish summary main finding main contribution conclusion future work section future research direction scbp employing quantum-inspired approach also presented related work field scientific research inventory management various study conducted improve forecasting decision-making related backorders mart proposed solution based markov decision process define inventory backorder strategy treated production system yield stochastic process examined stock inventory system incorporating periodic review partial backorder forecast developed framework considering distribution demand factor ass uncertainty inventory system prak teunter analyzed estimating error derived inventory model predicted lead time demand distribution distribution could used optimize inventory management chaharsooghi determined ordering policy inventory system using viewed scm multi-agent system utilized q-learning technique solve model abdul-jalbar combined n-retailer problem overall cost consideration develop objective function ordering storing backordering single inventory optimized three decision jointly lot sizing routing distribution replenishment brahimi aouam developed integrated multi-item manufacturing routing problem model considering constrained warehousing manufacturing capability optimal lot-sizing routing distribution replenishment factored penalty cost backordered product van foreest highlighted significance accurately calculating backorder level enhance fill rate reduce total cost ghiami beullens considered partial backordering discount backordered product production-inventory system maximize net present value ganesh kumar uthayakumar emphasized importance incorporating backorder decision cost ideal inventory policy noting previous model often overlooked scbp björk introduced fuzzy number-based optimization model account uncertain demand lead time outperforming conventional method kazemi presented fuzzy model included human reasoning backorders lin taleizadeh constructed economic ordering quantity model various factor special sale pricing poor quality partial backordering quantity discount kim proposed integrated inventory model optimized multiple decision simultaneously including lead time lot size number shipment safety factor fuzzy condition kazemi analyzed warehouse model incorporating backorders using fuzzy number graded mean integration model guo optimized spare component allocation decision serviceable standalone system dependent backorders feng devised approach forecasting order line-replaceable unit component backorders highlighting need consider dynamic feature factor shin proposed framework reduce overall cost anticipated risk cost backorder replenishment plan using bayesian belief network wang tang investigated dynamic rationing scheme considered demand dynamic bao used markov decision support system determine best rationing level across category demand trapero developed non-parametric parametric prediction model kernel density garch algorithm predict safety stock reduce long lead time santis proposed ensemble-based machine learning algorithm gbm paired undersampling scbp hajek abedin discussed benefit limitation ensemble prediction method undersampling dealing noisy data improving prediction accuracy liu improved scbp use conditional wasserstein generative adversarial network cwgan model along randomized undersampling initially majority non-backorder sample reduced using second cwgan used technique oversampling provide superior backorder sample ultimately implemented predict backorders class imbalance problem successfully addressed shajalal densely linked dnns combined smote randomized undersampling experimental outcome indicate better prediction performance predicted profit thorough product backordering dataset proving proposed model superiority existing approach handling noisy data minimizing overfitting ensemble forecasting model shown superiority non-parametric parametric forecasting method however computational efficiency becomes limitation analyzing large warehouse datasets real time limiting practical utility hand undersampling technique enhance computational performance may also exclude potentially valuable training data compromise prediction accuracy address challenge propose hybrid q-cnn applied short backorder dataset preprocessing approach involves several step firstly apply log transform data followed standard scaling normalize feature also address multicollinearity issue implementing variable inflation factor vif treatment training dataset unbalanced employ nearmiss undersampling method involves deliberately reducing majority class occurrence choice hybrid q-cnn analyzing short dataset driven unique advantage primarily rooted challenging nature scbp limited data real-world scm acquiring extensive datasets formidable task due hesitance company disclose internal data collecting vast data often infeasible considering significant time effort required given constraint approach focus developing qamplifynet model specifically designed predict backorders accurately even trained relatively short datasets balanced shortened preprocessed dataset using nearmiss algorithm selecting optimal preprocessing technique accomplish despite inherent challenge associated short datasets hybrid q-cnn demonstrates remarkable predictive accuracy offering insight aim elucidate unique advantage approach dealing inherent limitation short scbp datasets combining classical technique approach harness power quantum algorithm specific task leveraging robustness versatility cml framework like kera exploiting quantum principle like superposition entanglement use quantum-inspired algorithm inside classical framework result efficient accurate calculation compared purely classical purely quantum model hybrid q-cnn anticipated outperform several aspect firstly combination classical quantum technique enables powerful computation leading increased accuracy backorder prediction utilization quantum-inspired algorithm within classical framework allows efficient exploration solution space better identification pattern trend data hybrid approach offer practical advantage pure quantum model quantum computer still early stage development availability scalability may pose limitation real-world application cml model often grapple scalability issue handling extensive datasets resulting computational bottleneck hinder practicality intricate relationship dynamic nature data constrain real-time prediction capability limitation become particularly evident striving timely scbps research highlight imperative need advanced solution quantum-inspired technique qamplifynet model transcend constraint ultimately enhancing accuracy efficiency real-time prediction addressing scalability challenge inherent pure classical pure quantum model hybrid model leverage existing computational resource infrastructure integrating cml framework like kera making accessible practical implementation real-world environment integration allows accurate prediction improved decision-making better inventory control making promising approach addressing challenge backorder management real-world context study focused analyzing short imbalanced dataset obtained undersampling larger dataset aimed benchmark proposed hybrid q-cnn cml qml model working short imbalanced dataset hybrid model showcased strength outperformed cml qml model essential emphasize hybrid model superior performance particular short imbalanced dataset highlight effectiveness addressing specific challenge associated data characteristic milestone underscore practicality utility hybrid q-cnn real-world scenario acquiring large datasets may difficult yet accurate prediction crucial finding implication domain similar short imbalanced datasets success proposed model indicates practicality usefulness situation obtaining extensive datasets challenging accurate prediction paramount importance method data collection used benchmarking dataset called predict product backorder obtained kaggle data repository conduct extensive experiment proposed hybrid q-cnn-based prediction model data gathered kaggle repository many order various product included dataset total feature characterize eight-week trajectory order target binary feature denotes corresponding product backorder table summarizes feature one significant challenge working dataset inherent class imbalance related product backorders notably backorder instance relatively uncommon real-world scenario dataset total 1,929,935 order 13,981 order approximately 0.72 classified delayed experiencing backorder conversely vast majority 1,915,954 order 99.28 categorized negative case indicating product subject backorders figure show dataset class distribution substantial class imbalance pose notable challenge predictive modeling imbalance ratio approximately 1:137 dataset heavily skewed toward negative class making highly unbalanced imbalance significantly impact performance model may tend favor majority class resulting suboptimal predictive accuracy minority class address challenge ensure rigorous evaluation proposed model adopted stratified k-fold cross-validation approach five split ensuring class distribution maintained fold training testing set additionally chose shuffle dataset process preserving integrity class distribution figure class distribution imbalanced dataset used study full size image figure methodological framework illustrating data source data collection splitting data preprocessing proposed q-cnn model development scbp full size image table description dataset feature particular product order full size table data preprocessing data preprocessing crucial step enhancing performance model preprocessing approach initially focused identifying addressing irrelevant data point instance observed variable like perf_6_month_avg perf_12_month_avg contained negative value deemed inconsistent removed encountered feature included symbol indicating missing value also eliminated furthermore transformed categorical feature binary numerical representation facilitate analysis separating original dataset subsequent processing analysis instance value certain feature containing either yes converted binary respectively tried seven different combination preprocessing step tested preprocessed data evaluate choose best preprocessing step model development seven alternative technique follows iflof removed anomaly dataset using isolation forest local outlier factor iflof method combine isolation forest algorithm local outlier factor algorithm iflof identifies outlier constructing ensemble isolation tree measuring local outlier factor data point provides measure abnormality instance dataset iflof vif preprocessing step combine iflof outlier detection vif vif measure multicollinearity ass correlation predictor variable regression model applying iflof identify outlier using vif identify highly correlated variable help address outlier detection multicollinearity issue iqr vif applied interquartile range iqr statistical dispersion measure identify outlier applied vif detect remove multicollinearity vif applied vif method without using log transformation standard scaling anomaly detection algorithm log transform vif preprocessing step involves applying vif dataset without performing log transform variable method allows detection multicollinearity without influence log transformation robscaler vif alternative tried robscaler method used robust feature scaling dataset using vif detect multicollinearity robscaler particularly useful dealing data contains outlier scale feature removing median scaling according interquartile range log transform standardscaler vif proposed preprocessing step involves three stage first log transform applied variable help normalize skewed data handle nonlinear relationship removed infinity value resulting data standardscaler used feature scaling ensures variable mean standard deviation respectively finally vif threshold applied detect multicollinearity transformed scaled dataset method aim handle skewness standardize data identify multicollinearity simultaneously selected subset feature x1–x4 x10–x13 x15 x16 x17–x20 dataset technique made selection excluding remaining feature due existence multicollinearity among choose best preprocessing method undersampled dataset make balanced maintaining majority-to-minority ratio 3:1 using nearmiss algorithm compared approach log transform standardscaler vif produce best roc-auc model see table chosen specifically evaluate performance different preprocessing method widely used well-established classification algorithm applying various preprocessing method evaluating effect performance gain valuable insight technique effective improving predictive capability selecting best preprocessing technique finally balanced shortened preprocessed dataset using nearmiss algorithm fed input data model used study input training data sample 1:1 majority-to-minority class ratio test data intentionally made imbalanced using undersampling majority-to-minority ratio 3:1 sample among went backorder rest table performance evaluation model undersampled data different preprocessing technique compared study full size table classical model implemented cml model using scikit-learn library provides comprehensive set tool task python additionally parallel-computing library dask utilized enhance efficiency scalability algorithm enabled distribution execution computation across multiple processor machine allowing faster processing performed hyperparameter tuning using gridsearchcv three-fold cross-validation identify optimal hyperparameters cml shown table table best hyperparameters selected gridsearchcv cml model full size table cml model used include categorical boosting catboost light gradient boosting machine lgbm random forest extreme gradient boosting xgboost artificial neural network ann k-nearest neighbor knn support vector machine svm decision tree classical ann architecture employed study consists input layer neuron followed two dense layer neuron respectively stacked ensemble model using qiskit qiskit_machine_learning module explore following classically-stacked quantum ensemble algorithm base classifier trained using provided training data trained base classifier used make prediction train test datasets output label generated base classifier training testing data appended additional feature original training testing datasets next meta-classifier trained using updated train data performance evaluated updated testing data obtain final prediction value qsvm lgbm initialize two base classifier namely quantum support vector machine qsvm lgbm qsvm classifier utilize zzfeaturemap calculate kernel matrix computation kernel matrix performed using following equation aligned x_i x_j ^\dagger x_j x_i aligned x_i x_j training dataset represents feature map simulate result quantum computer employ state vector simulator substituted backend hardware result consider two base classifier second one lgbm ensemble construction utilize meta-classifier combine prediction two base classifier vqc qsvm used zzfeaturemap define feature map variational quantum classifier vqc base classifier qsvm meta-classifier input data mapped higher-dimensional quantum space using feature map vqc chose twolocal ansatz involved use r_y\ r_z\ gate parameterized rotation gate entanglement aligned bmatrix bmatrix aligned ansatz repeated two iteration cobyla optimizer quantuminstance statevector_simulator backend configured qsvm kernel initialized using quantumkernel employed chosen feature map quantuminstance statevector_simulator backend vqc lgbm utilized previously mentioned initialization technique vqc lgbm model employing base meta classifier model integrated stacking ensemble framework prediction base classifier combined used feature meta-classifier lgbm quantum neural network qnn model used pennylane dependency developing qnn model pennylane employed simulate quantum circuit conduct quantum experiment facilitating development program mera-vqc scheme ansatz based tensor network named multi-scale entanglement renormalization ansatz mera variable designed amplitude embedded one layer tensor network initialized device backend qubits using pennylane qml library entanglement structure mera circuit implemented using cnot gate qubits two rotation gate r_y\ applied qubit using specified weight number block wire parameter per block total number block parameterized mera quantum circuit quantum circuit implemented using defined mera structure process training data defined vqc classifier utilized previously constructed quantum circuit classifier took weight bias classical data input produced prediction based output circuit implemented square loss function measure difference predicted true label accuracy function ass model performance defined cost function used optimize weight bias parameter enable model learn training dataset quantifying overall loss prediction true label ry-cnot-vqc ry-cnot-vqc 6-layered classifier highlight use r_y\ cnot gate circuit structure providing detailed information model architecture employed 2-qubit simulator translate classical vector quantum state amplitude circuit encoded using method described mottonen also following work nielsen chuang break controlled y-axis rotation simpler circuit quantum state preparation process defined using quantum gate r_y\ rotation around y-axis controlled-not cnot pauli-x\ gate primary quantum circuit incorporates state preparation process applying multiple rotation layer based given weight function applies rotation gate qubits performs cnot operation quantum circuit evaluated test input applying state preparation process estimating expectation value pauli-z\ operator qubit classical encoder qnn suggested hybrid model made classical encoder circuit qnn two qumodes make quantum circuit vector entry used parameter available quantum gate encode classical data quantum state two 10-neuron hidden layer elu activation function 14-neuron output layer comprise classical entry classical output vector sent squeezer interferometer displacement gate kerr gate input parameter kerr gate interferometer-1 interferometer-2 squeezer displacement gate employed qnn four-step sequence using pauli-x\ gate _k|x|\phi expectation value final state qumode two-element vector _0|x|\phi _1|x|\phi constructed roc value model 71.09 closest threshold optimal roc deep reinforcement learning model used tensorflow 2.3+ agent 0.6+ implement double deep q-network ddqn treating classification problem imbalanced classification markov decision process ddqn predicts episode end agent misclassifies sample minority-class majority-class sample training process involved 100,000 episode replay memory used length matching number warmup step mini-batch training performed batch size q-network updated using step data collected episode policy updated every step soft update strategy employed blending factor update target q-network every step model architecture consisted three dense layer unit relu activation followed dropout layer rate 0.2 final layer directly outputted q-values adam optimization applied learning rate 0.00025 future reward discounted exploration rate decayed 1.0 min_epsilon total episode minimum final chance choosing random action set 0.5 proposed qamplifynet model provided fig present overview proposed methodological framework first phase framework gathering baseline information may include supplier efficiency lead time inventory level product sale information sale supplier efficiency inventory level lead time supplier gathered wide variety data source data combined grouped weekly time interval order dataset subsequently divided training testing set collected data undergoes preprocessing using suggested log transformation standard scaling vif treatment method address common anomaly found manufacturing industrial sensor data involves eliminating inconsistent data point managing null value scaling normalizing data within specified range applied pca train test datasets prepare input 2-qubit amplitude encoder resulting feature dimensionality choice aligns model requirement operates yield 2-dimensional classical data input aggregated data prepared predictive analytics employing hybrid q-cnn named qamplifynet core component proposed framework classical layer process input data quantum layer performs quantum computation encoded data comprehensive framework enables effectively leverage collected data utilize hybrid model analysis prediction purpose figure model architecture qamplifynet model full size image implementation leveraged capability pennylane convert qnodes kera layer integration allowed combine quantum layer diverse set classical layer available kera enabling creation genuinely hybrid model figure explains proposed architecture qamplifynet consists kera sequential model consisting input layer three classical hidden layer one quantum layer classical output layer explanation layer input layer input layer accepts input feature comprises neuron hidden layer dense layer unit relu activation function receives input input layer dimension set non-trainable serving purpose embedding input data hidden layer second dense layer unit relu activation function receives input previous layer non-trainable hidden layer dense layer unit relu activation function take input previous layer non-trainable pass 4-dimensional output next quantum layer qnn keraslayer next layer incorporates 2-qubit quantum node qnode weight shape represents quantum part hybrid model take input previous dense layer receives four-dimensional classical data input convert four amplitude representing quantum state two qubits output layer final output probability generated via softmax activation function output dense layer two possible class need classified hence layer unit softmax activation function characterized follows aligned =\frac j=1 aligned softmax function input vector standard exponential function input vector class count multi-classifier using learning rate 0.01 loss function binary_crossentropy employed adam optimizer qamplifynet mode implemented distinct classical quantum part work together form overall architecture let delve detail part classical part classical part model primarily consists classical layer operate classical data specific implementation used classical dense layer various activation function e.g. relu configuration classical layer process input data using classical computation performing operation like linear transformation nonlinear activation model three classical dense layer dense layer dense layer dense layer layer receive input previous layer set non-trainable indicated trainable false parameter classical part culminates dense layer two unit employ softmax activation function generating final output probability quantum part quantum part model integrated classical part using qml.qnn.keraslayer pennylane part includes qnode represents quantum circuit weight shape define structure quantum operation implementation qnode defined consists quantum operation pennylane template amplitude embedding strongly entangling layer sel classical data item must embedded quantum state qubits processing quantum computer due quantum nature computer operation circuit state preparation component responsible encoding classical data onto two data qubits key advantage ability handle significantly large amount information relatively small number qubits amplitude encoding number amplitude available practically limitless allowing encoding significant amount data notably number qubits required encoding given number feature follows logarithmic relationship log_2 meaning number data feature increase logarithmic increase number qubits needed scalability enables encoding vast amount information additional qubit making amplitude encoding powerful approach handling complex datasets composed parameterized quantum circuit comprising embedding circuit variational circuit see fig embedding circuit incorporates amplitude encoder designed encode maximum 2^n\ data feature amplitude quantum state consisting qubits alternatively vector containing number feature encoded using qubits amplitude quantum state qubits thought representation normalized classical datapoint dimension aligned i=1 aligned given equation equal 2^n\ x_i\ represents -th element variable refers -th state computational basis nevertheless x_i\ float integer vector must normalized according definition aligned i=1 aligned figure quantum circuit representation qamplifynet featuring two qubits labeled circuit comprises variational layer utilizing sel approach two qubits depth one layer initial blue line depict embedding feature quantum state amplitude two r_y\ -gates see introduce rotation qubits subsequently two rotation gate involving r_z\ r_y\ r_z\ see single-qubit rotation optimized training blue cnot see entangling gate connect qubits reinforcing entanglement circular topology measurement layer includes two pauli-z\ operator graphic generated using pennylane-qiskit full size image number feature encode power remaining amplitude filled constant value technique transforms feature obtained classical component amplitude quantum state qubits aligned r_y bmatrix -\sin bmatrix aligned aligned r_z bmatrix -i\psi i\psi bmatrix aligned aligned cnot= bmatrix bmatrix aligned variational stage number sel variable sel consists generic trainable rotational gate rot implemented qubits set cnot gate used connect adjacent qubit pair last qubit regarded neighbor first number sel -qubit circuit modified tune complexity circuit model precisely 3\times number trainable parameter sel utilizes circuit-centric approach design approach individual qubit denoted represented 2\times unitary matrix shown equation aligned bmatrix i\phi i\psi -e^ -i\psi -i\phi bmatrix aligned due lack support reversible differentiation method sel pennylane automatically chooses suitable differentiation method available state two qubits measured using pauli-z\ operator upon measurement qubits collapse specific state matrix representation pauli-z\ operator illustrated aligned bmatrix bmatrix aligned measurement first qubit pauli-z\ operator denoted expectation value subsequently utilized determine probability involved backorder backorder backorder backorder state respectively aligned backorder +1\right aligned aligned backorder 1-\left\langle backorder aligned quantum operation help encode input feature quantum state perform quantum computation qnode calculates pauli-z\ operator expectation value quantum circuit qubit qnode output input subsequent classical layer combining classical quantum part classical quantum part model seamlessly integrated within sequential framework kera classical layer process data certain point output fed quantum layer keraslayer incorporates qnode challenge lie necessity 4-neuron dense layer preceding 2-qubit quantum layer serf pas essential 4-dimensional input feature quantum layer rendering removal replacement unfeasible adam optimizer utilized train parameter model include weight bias model optimized training based binary cross-entropy loss function training step involve iteratively updating parameter improve model performance accuracy also enabled earlystopping mechanism training process ensuring model stop desired metric stop improving helped prevent overfitting saved training time ensured model primary goal generalize effectively new unseen data confirmed testing although validation loss remained higher model achieved good balance fitting training data generalizing new instance use earlystopping added robustness convergence analysis preventing overfitting training training procedure took place kaggle kernel environment equipped cpu core ram nvidia tesla gpus model parameter carefully selected multiple trial run optimize accuracy training process concluded epoch using batch size loss curve fig indicates model ability minimize error training validation phase loss curve aid evaluating model learning progress generalization capability potential effective prediction new instance figure left right curve represent roc loss evolution versus epoch qamplifynet model curve provide insight model ability classify backorder instance accurately overall predictive performance training progress full size image figure confusion matrix classification report left right qamplifynet model full size image result evaluation metric order ass effectiveness predictive model employed study various performance metric utilized context scbp true positive refers number correctly classified instance backorder occurrence true negative represents number correctly classified instance non-backorder occurrence false positive indicates number backorder instance mistakenly classified false negative signifies number misclassified non-backorder instance significant higher result missed opportunity potential customer leading increased opportunity cost hand higher lead increased inventory holding cost greater risk product obsolescence due long-term accumulation unnecessary inventory definition equation performance metric used evaluate model accuracy accuracy metric evaluates overall accuracy prediction determining ratio correct prediction total number prediction made aligned accuracy aligned precision precision metric evaluates accuracy positive prediction made model represents proportion correctly identified positive instance instance predicted positive metric help ass model capability minimize false positive prediction providing insight precision reliability identifying positive case accurately aligned precision aligned recall true positive rate recall metric quantifies model effectiveness correctly identifying positive instance among actual positive instance provides insight well model detect capture positive case dataset aligned recall aligned f1-measure f1-measure metric combine precision recall single value giving equal importance serf balanced measure particularly beneficial dealing imbalanced datasets considering precision recall measure provides comprehensive evaluation model performance considering ability correctly identify positive instance precision capture positive instance recall make valuable metric uneven class distribution scenario like scbp dataset offer balanced assessment model effectiveness aligned f1-measure precision recall precision recall aligned specificity true negative rate specificity metric quantifies accuracy model correctly identifying negative instance among actual negative instance provides insight model capability detect classify negative instance accurately aligned specificity aligned gmean gmean metric represented aim achieve balance maximizing take account minimizing adverse effect caused imbalanced class distribution crucial acknowledge gmean metric doe offer insight specific contribution made class towards overall index consequently various combination result identical gmean value aligned gmean aligned iba iba measure estimate performance binary classifier imbalanced datasets using following equation aligned iba gmean dominance aligned dominance refers absolute difference utilized gauge relationship two measure substituting dominance gmean equation gain valuable insight iba balance trade-off dominance gmean auc-roc index auc metric evaluates overall performance model considering ability differentiate positive negative instance various classification threshold represented graphically roc curve auc serf indicator model discriminative power capacity classify different instance accurately performance metric relevant scbp problem provide insight model accuracy precision recall ability handle imbalanced datasets help ass model effectiveness correctly identifying backorder non-backorder instance result analysis result presented table demonstrate performance comparison different algorithm task hand proposed qamplifynet algorithm achieves highest accuracy score outperforming model used study among qnn model mera 4-layered classical encoder qnn ry-cnot 6-layered exhibit respectable accuracy score respectively nevertheless choosing algorithm vital take account factor beyond accuracy sole criterion consideration algorithm ability generalize well unseen data interpretability providing understandable insight computational efficiency also taken consideration scenario two class represents backorder represents backorder different model demonstrate better performance either precision recall essential consider measure assessing f1-score qamplifynet achieves best macro-average f1-score predicting class predicting class given imbalanced nature dataset employed imblearn module scikit-learn gain insight specificity gmean iba value qamplifynet yield highest gmean iba score class class outperforming model furthermore qamplifynet achieved auc-roc value 79.85 indicating model exhibit stronger discriminatory power model auc-roc analysis allows ass model overall ability rank instance correctly provides insight predictive capability qamplifynet achieves highest macro-average precision recall score respectively regarding class qamplifynet achieves precision see fig indicating instance predicted class correctly classified recall signifies model successfully identifies true class instance specificity suggests model accurately identifies true class instance class concerning class precision reveals instance predicted class classified correctly nevertheless recall signifies model manages identify actual instance belonging class hand specificity implies instance belonging class accurately classified class qamplifynet demonstrated significant outperformance compared model achieving macro-average specificity indicates qamplifynet excelled correctly identifying negative instance surpassing performance model term distinguishing non-backorder case accurately notably qamplifynet consistently demonstrates superior performance across evaluation metric accuracy auc-roc precision recall f1-score specificity gmean iba macro-average 59.50 contrast model exhibit inconsistent performance across metric comparison confusion matrix component namely various model scbp depicted provided fig upon analyzing result becomes evident qamplifynet outperforms model term predictive performance qamplifynet achieved rate 14.98 rate 74.91 demonstrating ability classify positive negative instance accurately significantly achieved notable rate signifying complete absence incorrect prediction labeling non-backorder instance backorders furthermore qamplifynet exhibited relatively low rate 10.11 implying minimal number missed positive prediction contrast several model displayed higher rate erroneously identifying actual non-backorders backorders similarly model demonstrated higher rate misclassifying backorder case achievement particularly significant given imbalanced nature scbp problem instance mera 4-layered ry-cnot 6-layered model achieved rate expense higher rate 22.10 25.09 respectively additionally rate lower qamplifynet figure bar plot illustrating rate various model used paper scbp obtained value derived confusion matrix model offering valuable information regarding ability accurately classify instance either positive negative full size image comparatively cml model exhibited significantly higher average rate 47.99 relatively lower average rate 26.92 similarly stacked ensemble model demonstrated rate 53.18 rate 21.72 classical encoder qnn 15.73 higher rate 15.73 lower rate compared qamplifynet worth noting ddqn achieved high rate 24.34 cost substantial rate 50.56 conversely qamplifynet achieved competitive rate maintaining significantly lower rate underscoring robustness minimizing false positive prediction comparison qamplifynet model highlight superiority achieving balanced trade-off rate resulting accurate scbp minimal prediction substantiates qamplifynet potential enhancing reliability robustness scbp system table performance comparison model used study qamplifynet short scbp dataset full size table xai interpretation using lime shap gain insight interpretability qamplifynet applied two popular xai technique local interpretable model-agnostic explanation lime shapley additive explanation shap python programming language employing method able gain insight model prediction provide explanation identifying specific contribution individual feature lime lime local interpretability method provides explanation individual prediction approximating model behavior around specific instance introducing perturbation input data tracking hybrid model prediction changed able utilize lime provide potential explanation model behavior process allowed identify significant feature understand influence model decision-making lime achieves generating local surrogate model around particular instance interest surrogate model simpler interpretable linear decision tree model capture local behavior complex model lime examines significance influence individual aspect model decision-making process perturbation input feature evaluating ensuing change prediction equation lime expressed follows aligned aligned loss function quantifies similarity original sophisticated model interpretable model family interpretable model denoted _x\ represents closeness instance evaluated specific instance term indicates significance importance assigned model involve additional weighting importance factor lime aim find interpretable model minimizes loss function adequately capture complex model behavior considering proximity criticality aspect family interpretable model denoted _x\ represents closeness instance evaluated specific instance term indicates significance importance assigned model involve additional weighting importance factor limetabularexplainer specific implementation lime designed tabular data leverage idea perturbation generating perturbed instance around instance interest limetabularexplainer construct local surrogate model fitting weighted linear model perturbed instance weight assigned perturbed instance reflect similarity original instance model prediction instance used approximate feature importance figure show lime-based feature importance bar plot showcasing explanation specific instance prediction plot visualizes individual feature contribution towards classifying instance backorder backorder category figure depicts lime-generated explanation plot another instance depicting feature importance contribution prediction feature pc1 pc2 pc3 pc4 considered predicted probability obtained using model figure figure comprises two subfigure illustrating lime explanation different instance classification task display bar plot depicting feature importance specific instance exhibit lime-generated explanation plot another instance highlight contribution feature pc1 pc2 pc3 pc4 towards prediction providing insight classification process model full size image shap shap another popular xai technique provides global interpretability attributing model prediction individual feature across entire dataset therefore contribution feature prediction computed visualized using shap python library utilizing shap value cooperative game theory shap quantifies feature influence prediction provide quantitative assessment much feature contributes overall prediction denoted defined follows aligned x_1 x_2 x_m\ x_j\ val x_j\ val aligned represents shapley value feature x_j\ x_j\ denotes specific feature value feature subset model denoted parameter represents total number feature model term val represents projection feature value set equation calculates shapley value summing possible subset considering cardinality difference valuation subset including x_j\ valuation subset excluding x_j\ division factorial account different permutation combination subset figure shap force plot selected instance using kernelexplainer shap decision plot showing feature contribution misclassifications qamplifynet model full size image applied shap hybrid model understand importance influence different feature determining model output shap value explain model expected base output denoted transition actual output denoted specific feature known value quantify feature contribution prediction indicate pattern connection feature target variable shap value feature close substantially impact prediction data point hand shap value close feature indicates importance making prediction figure display impact prediction specific test instance shap decision plot provide insight model reach decision especially numerous significant feature play line corresponds prediction plot interacts x-axis predicted value color line reflects prediction value creating visual spectrum moving bottom top shap value feature added model baseline effectively revealing individual contribution feature overall prediction plot invaluable understanding inner working complex model highlighting feature importance showcasing impact feature final prediction figure show feature contributes shifting model output expected value statistical test conducted rigorous statistical analysis significance level set ass performance qamplifynet model model employed study research investigated following two hypothesis null hypothesis significant difference accuracy roc-auc qamplifynet tested model alternative hypothesis significant difference accuracy roc-auc qamplifynet tested model conducted ten-fold cross-validated paired t-test well-established method comparing classification model performance dataset randomly split ten subset shuffling statistical robustness cross-validation fold train model training subset evaluate accuracy corresponding test subset table display result highlighting significant difference accuracy roc-auc score qamplifynet model counterpart result reject case indicating observed difference accuracy roc-auc score statistically significant value signifies difference unlikely occurred chance providing robust evidence qamplifynet model superior performance consistently low value underscore confidence model capability table ten-fold cross-validated paired t-test model performance comparison full size table discussion scm complex critical process relies heavily accurate prediction backorders optimize inventory control reduce cost ensure customer experience research introduced groundbreaking hybrid q-cnn model called qamplifynet scbp integrates quantum-inspired technique conventional framework discussion aim comprehensively analyze proposed model benefit limitation practical implication potential application integration quantum-inspired technique proposed model offer several advantage classical hybrid model firstly utilization quantum-inspired algorithm enables model grasp intricate data pattern interdependency crucial accurate scbp parallelism inherent allows efficient solution space exploration leading improved prediction accuracy qamplifynet benefit flexibility interpretability kera framework combining quantum-inspired optimization algorithm kera well-established architecture enhances model overall performance interpretability proposed model demonstrates robustness handling short imbalanced datasets commonly encountered scm employing combination preprocessing technique undersampling principal component analysis model effectively address challenge posed limited data availability class imbalance qamplifynet offer numerous advantage important acknowledge limitation one potential limitation computational complexity associated quantum-inspired technique still nascent stage current hardware limitation noise limited qubit connectivity hinder scalability practical implementation quantum algorithm therefore proposed model may face challenge scaling larger datasets real-time application additionally training optimization quantum-inspired model require specialized knowledge expertise integration quantum classical component proposed model add complexity requiring researcher practitioner strong understanding principle traditional technique accurate scbp significant practical implication various aspect scm leveraging proposed model organization optimize inventory control reduce backorders enhance customer satisfaction ability predict backorders enables proactive management inventory level minimizing stockouts ensuring availability product meet customer demand turn lead improved customer loyalty increased revenue opportunity accurate prediction backorders allows efficient resource allocation organization optimize production schedule procurement process transportation logistics based predicted demand leading cost saving improved operational efficiency additionally accurate scbp facilitates better supplier communication coordination ensuring timely replenishment minimizing delay proposed model seamlessly integrated real-world scm system organization enhance decision-making process automate scbp incorporating qamplifynet existing inventory management software integration enables real-time monitoring inventory level proactive order fulfillment efficient allocation resource model also used identify potential bottleneck vulnerability allowing organization implement preventive measure improve overall resilience qamplifynet potential broader application beyond scm hybrid nature model make adaptable supervised binary classification task credit card default prediction fraud detection imbalanced datasets limited feature set common challenge comparative analysis shed light strength weakness model direct implication scbp qamplifynet emerges top-performing model consistently demonstrating strong performance across multiple evaluation metric including accuracy f1-score specificity gmean iba auc-roc ability achieve high accuracy f1-scores indicates effectiveness correctly predicting positive negative instance crucial efficient scm superior performance qamplifynet various metric implies effectively minimize false positive false negative addressing challenge imbalanced data scbp particularly noteworthy given significant impact fps fns inventory management customer satisfaction business may improve customer satisfaction reduce likelihood disruption maximize inventory efficiency quickly correctly detecting instance risk backorders however essential consider practical implication beyond model performance metric factor generalizability interpretability computational efficiency critical real-world implementation qamplifynet exhibit strong generalization capability evidenced robust performance validation dataset incorporation amplification technique ensures scalability computational efficiency enabling timely prediction large-scale operation interpretability also crucial factor decision-making qamplifynet performs exceptionally well term accuracy metric black-box nature may limit understanding specific prediction made address presented interpretability qamplifynet using shap lime conclusion future work research primary contribution lie development qamplifynet novel hybrid q-cnn model designed explicitly backorder prediction domain harnessing power quantum-inspired technique within well-established kera framework aimed significantly enhance accuracy backorder prediction furthermore proposed comprehensive methodological framework encompassing various stage including data source identification data collection data splitting data preprocessing implementing qamplifynet model ensure optimal performance model thoroughly explored seven different preprocessing alternative meticulously evaluated effectiveness assessing performance preprocessed dataset rigorous evaluation process allowed select suitable preprocessing technique specific application extensive experiment evaluation short scbp dataset compared performance qamplifynet eight traditional cml model three classically stacked quantum ensemble model five qnn model one deep model finding clearly demonstrate exceptional backorder prediction accuracy achieved qamplifynet surpassing model term accuracy impressive accuracy rate notably qamplifynet also achieved highest f1-score predicting backorder predicting backorder outperforming model additionally qamplifynet exhibited highest auc-roc score 79.85 validating superior predictive capability seamlessly integrating quantum-inspired technique model successfully captured complex pattern dependency within data leading significant improvement prediction accuracy significance proposed model lie ability optimize inventory control reduce backorders enhance overall scm accurate scbp enables proactive decision-making efficient resource allocation improved customer satisfaction integrating qamplifynet real-world system organization achieve cost saving increased revenue opportunity improved operational efficiency implementing xai technique specifically shap lime could successfully enhance interpretability proposed model understanding model decision-making process greatly aided xai technique shedding light significance contribution different feature predicting backorders leveraging shap lime able gain deeper understanding model arrived prediction identify key factor influencing prediction pioneering research quantum-backed backorder prediction present intriguing future prospect acknowledging certain technological limitation exclusively employed part quantum feature mapping however potential angle encoding basis encoding remains untapped awaiting exploration subsequent research due constraint current quantum hardware qamplifynet model crafted qubits yet technology progress utilization circuit larger qubit capacity hold great promise tackling complex computational task study featured vqc single layer potential increased depth capture nuanced data dependency beckons furthermore diversifying type quantum layer used beyond sel model performance fine-tuned incorporation basic entangler layer continuous-variable neural net layer random layer additionally research primarily integrated vqc fully connected dense layer however considerable potential coupling quantum model broader array neural network architecture including long short-term memory gated recurrent unit convolutional endeavor intricately linked ongoing evolution capability play vital role continued development qml diverse complex application deploying qamplifynet real-world scenario present several potential pitfall challenge must considered important acknowledge current limitation quantum hardware quantum computer still nascent stage access large-scale fault-tolerant quantum device limited restrict deployment quantum model real-world application especially handling extensive datasets requiring real-time processing however ongoing advancement quantum technology hardware limitation may gradually diminish deeper circuit may demand computational resource time potentially limiting practicality real-time application striking balance circuit depth model performance essential adoption quantum technology associated substantial cost including hardware software expertise assessing cost-effectiveness deploying quantum model real-world scenario crucial particularly organization budget constraint matures becomes accessible many challenge may addressed opening new opportunity leveraging qml diverse complex scenario several promising avenue future work field firstly improvement made proposed model exploring additional quantum-inspired technique algorithm field continues advance efficient quantum hardware algorithm expected become available could enhance performance scalability model expanding dataset used training evaluation could improve model accuracy generalizability model ability capture wider variety pattern trend might benefit incorporation extensive diversified dataset furthermore potential applying proposed model domain scm demand forecasting inventory optimization warrant exploration versatility qml model open opportunity application various aspect operation addition introducing novel strategy scbp making use hybrid q-cnn study notable first use qml field scm result stress necessity quantum-inspired method enhance prediction accuracy optimize scm future research potential change field scm stimulate breakthrough qml model continuing improve model expanding dataset exploring quantum-inspired approach