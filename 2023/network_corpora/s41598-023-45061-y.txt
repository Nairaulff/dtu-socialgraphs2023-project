introduction hydroacoustic signal primary mean long-range communication ocean ship noise identification essential analyzing signal ship-radiated noise refers signal generated ship received passive sonar system widely used ship target identification carry ship identification system autonomous underwater robot become one direction interest researcher however due complexity marine environment difficulty data collection identifying ship hydroacoustic remote sensing challenging address issue various signal processing method proposed extracting feature hydroacoustic signal including lofar spectrum meier scalar spectrogram meier cepstral coefficient mfcc hilbert-huang transform feature development deep learning feature based method used develop ship signal identification model however existing hydroacoustic datasets limited different recognition method mainly compete minor sample problem must generalizable scholar input raw audio directly neural network recognition input raw audio cnn mesh layer improve network generalization ability shen developed auditory-inspired convolutional neural network incorporating multi-scale expansion enhance generalization capability scholar used spectral feature input network research direction shifted feature enhancement small sample learning problem mishachandar vairamuthu proposed marine noise classification recognition system using mfcc input capable classifying unidentified marine sound cetacean fish marine invertebrate anthropogenic sound natural sound passive acoustic marine noise recording liu connected meier spectrum first- second-order derivative increase input bit feature used recurrent neural network recognition ibrahim introduced migration learning grouper sound classification demonstrated migration learning good recognition accuracy sun introduced convolutional neural network multi-target recognition hydroacoustic signal demonstrated using amplitude short time fourier transform stft complex-valued stft spectrum log-mel spectrum network input could effectively recognize multi-target signal computing chip autonomous underwater robot often unable withstand high arithmetic power developing simple high-performance network also become one difficulty improve effectiveness recognition network data enhancement image recognition employed paper deep learning solution based convolutional neural network proposed improve data augmentation network decision layer improve network recognition accuracy using feature fusion explore best hydroacoustic signal feature original audio signal mfcc different fused feature compared input cnn network verify generalizability network completed training network applied new dataset deepship achieving better result contribution paper summarized follows firstly unlike previous denoising method paper proposes using positive incentive noise introduce noise dataset extension extract fused feature network input experimental result demonstrate noise improve network recognition rate certain condition approach provides novel solution issue limited hydroacoustic datasets improves generalizability ship noise classification model secondly paper borrows voting mechanism random forest combine cnn add decision layer back end cnn approach improves accuracy network fusing output multiple cnn model method contributes development robust accurate ship noise classification model lastly paper compare existing algorithm proposed method verifies simple network also achieve high recognition accuracy finding significant suggests complex network structure involved adversarial learning may always necessary accurate ship noise classification section dataset setting discus dataset setup compare enhanced dataset section method describes design parameter network section experiment performs experimental comparison show method superiority dataset setting paper dataset produced based shipsear dataset dataset collect sound different vessel along spanish atlantic coast label facilitate study type ship noise one type environmental noise classified five category based classification shipsear dataset shown table network still classified according category table label full size table dataset expansion counting data five category audio dataset contained audio category audio category audio category audio category audio category avoid discarding audio slice blank audio kept increase data volume aim expand dataset efficiently improve network adopt latest proposal positive incentive noise defined follows define information task noise mi\left f\right =h\left t\right t|f mi\ mutual information information entropy define noise satisfies following condition positive incentive noise mi\left f\right inequality also equivalent h\left t\right t|f contrary noise satisfies mi\left f\right =0\ called pure noise negative noise contrast idea noise always affect network accuracy argued noise always harmful effect positive incentive noise simple neural network substantial adversarial learning area concludes stochastic resonance analysis random noise positively incentive data pure noise case mean pure noise data pure positive incentive noise inspiration led unique perspective denoising conventionally employed handle datasets plagued substantial ambient noise introducing white noise could enhance network recognition rate crucial highlight approach diverges traditional practice adding noise data primarily dataset enrichment instead process involves actively incorporating white noise boost network performance constituting somewhat distinct conceptual twist idea process ship noise classification machine learning typically involves conversion raw audio signal spectrogram extract relevant feature recognition however conversion process may result loss information original signal additionally filter used creating spectrogram may selectively retain certain signal feature based frequency address issue novel approach proposed paper involves introducing random noise original audio signal prior spectrogram conversion hypothesis added noise enhance retained feature filtering without affecting feature extraction process filter effectively remove extraneous noise hypothesis verified simple experiment expand dataset efficiently improve feature extraction random noise added original slice new dataset formed audio without added noise resulting dataset twice size original data important note number class data significantly larger four class amount ambient noise data belong class limited address issue new dataset called deepship introduced deepship open source github http comprises four category ship cargo passenger tanker tugboat deepship part audio sliced plus noise processing according classification shipsear obtain balanced dataset finally ambient noise data expanded simulation obtain final dataset comparison experiment positive incentive noise experiment proposed focus image recognition add random noise original audio experimental comparison experimental parameter set follows study raw audio uniformly converted stft-spectrum extracted feature input cnn network recognition consisted two convolutional layer two maximum pooling layer additional average pooling layer fully connected layer front output layer activation function set common relu function optimizer adam network trained epoch straightforward cnn network used experiment verify noise improvement training result experimental result shown fig figure recognition rate original noise-added data set full size image experiment show recognition accuracy original unnoticed dataset recognition accuracy dataset random noise added reach 80.2 prof positive incentive noise also effective audio recognition method traditional way underwater target identification human ear method requires operator extensive experience skilled hydrophone operation skill operator capture suspicious sound adjusts volume filter remove background noise analyzes timbre rhythm acoustic characteristic identify target based experience although manual identification method high accuracy required time economic cost expensive machine learning neural network represented cnn enables dimensionality feature learn different acoustic target feature deepening number layer original audio spectral filtering extract acoustic feature example meier spectrum similar human ear low-frequency sensitivity retain acoustic feature however different spectrum extracting feature must lose feature simultaneously propose using different feature extraction method feature fusion input network recognition framework follows firstly different feature extracted original audio feature fused fed deep convolutional network back-end decision effectively improve recognition accuracy use convolutional network feature extraction fused feature feeding multiple neural network parallel training adding voting decision mechanism back end detailed process shown fig figure overall framework full size image feature extraction mel cepstral coefficient mfcc feature widely used speech signal recognition introduced davis mermelstein 1980s mel scale describes nonlinear property human ear frequency related linear frequency mel\left f\right =2595\mathrm 1+f/700 frequency specific step mfcc feature extraction basis shown step pre-emphasis boosting high-frequency part stabilize feature since high-frequency part signal attenuates much low frequency underwater propagation high-frequency part signal ignored feature extraction performed directly therefore pre-emphasis effectively extract stable signal feature h\left z\right =1-\mu pre-emphasized signal original signal pre-emphasis coefficient generally considered 0.9 step take number data point frame sub-frame sampled noise sequence order avoid much variation two adjacent frame generally overlap two adjacent frame containing sampling point taken paper step adding window multiplying hamming window frame increase continuity left right side frame multiplying hamming window speech signal n\right expressed ^\prime n\right w\left n\right =\left\ array 0.54-0.45\times 2\pi n-1 ,0\le n\le n-1\\ other\end array step fourier transform fourier transform signal framing signal spectrum modulo squared obtain signal power spectrum fast fourier transform signal x\left k\right =\sum_ n=0 n-1 -2j\pi x\left k\right amplitude spectrum input signal denotes number fourier transform point step mel filter bank filtering transferring frequency domain mel domain signal processing array k-f\left m-1\right f\left m\right -f\left m-1\right m-1 k=f f\left m+1\right f\left m+1\right -f\left m\right k\le m+1 other\end array 0\le m\le l\right. m=0 m-1 k\right =1\ denotes filter parameter denotes center frequency triangular filter number meier filter bandpass filter output d\left m\right =\sum_ k=0 n-1 k\right total number signal point frame step mfcc parameter obtained taking logarithm performing discrete cosine transform c\left n\right =\sum_ k=1 d\left m\right k-0.5\right n=\mathrm 1,2 mfcc order another commonly used feature extraction method stft spectrum basic idea stft add window signal perform fourier transform window function translated throughout time axis according change time spectrum near moment localized using window function thus constituting two-dimensional time–frequency spectrum signal analyzed stft=\left -\infty +\infty t-\tau -i\omega time duration window function center frequency window function principle various type feature extraction method seen method occurs partial loss signal feature want enhance extracted feature preserving feature much possible figure show spectrum various feature extraction method five type noise figure example feature row original audio wav row magnitude stft spectrogram row log-mel spectrogram full size image paper librosa software package used data processing feature extraction referring idea mel spectrum connected first second-order derivative used liu extracting stft spectrum logging mel spectrum connected form four-dimensional feature input cnn network convolution cnn parameter study drawing inspiration widely acclaimed cnn architecture resnet aimed construct streamlined cnn network could attain exceptional recognition accuracy accomplish crafted straightforward cnn network drawing influence alternative network structure known densenet cnn network automatically extract feature raw data learn high-level abstract feature data task classification recognition operation convolution pooling diverging complexity network convolutional recurrent neural network crnn cnn network two convolution one-dimensional stratification pool output layer used study detailed structure shown table figure illustrates three cnn structure parameter network differ network network network identical network network applied comparison experiment iii table cnn1 full size table table cnn3 full size table original data divided different subset subset used train cnn model k-fold cross-validation used divide data copy using k-1 copy time training data remaining copy test data approach effectively reduces overfitting provides better generalization ability study two cnn network parameter shown fig combined set fused feature extracted previous section used cnn network input hyperbolic tangent function tanh chosen activation function two layer convolution pooling classification probability category output fully connected softmax layer contrast vgg16 network often used image classification task includes convolutional layer three fully connected layer vgg network initially proposed solve large data set simple network structure may practical small sample problem like ship noise parameter fast model convergence experiment different feature extracted fusion input cnn1 experiment aim verify whether feature retained feature fusion could effectively improve recognition accuracy network change made network structure experiment recognition accuracy complex network compared simple network proposed paper aim verify conjecture simple network could achieve comparable even better performance complex network voting mechanism addition using cnns also considered feasibility random forest decision-making approach hydroacoustic remote sensing random forest integrated learning algorithm improves prediction accuracy integrating multiple decision tree decision tree unlike cnns random forest suitable processing structured data require manual feature selection extraction familiar combination strategy integrated learning averaging voting random forest typical integrated learning algorithm combination strategy voting method relies voting choice decision tree random forest determine final classification result outset research primary focus studying random forest algorithm however consistently observed unsatisfactory recognition accuracy applying random forest hydroacoustic signal recognition demonstrated experiment refer experimental result delved deeper random forest algorithm uncovered final decision layer typically employ voting mechanism moreover noted substantial impact weighted soft-voting mechanism enhancing performance deep learning model consequently integrated weighted soft voting mechanism designed network enhance algorithm performance standard voting method hard voting soft voting hard voting simple mechanism multiple model prediction voted category vote ultimately selected prediction result soft voting probability-based voting mechanism known weighted average probability voting prediction result multiple model considered probability distribution final prediction result weighted average prediction probability model figure show flow soft voting mechanism figure visualizes difference soft voting hard voting figure soft voting picture show difference soft hard voting prediction highest number vote final result full size image due small sample problem ship noise classification using simple network parameter weighted soft voting chosen back-end decision mechanism study experiment compare random forest neural network training result experiment iii comparing past study present method experiment verifying generalization ability method paper experiment evaluation metric ship noise classification multi-class classification problem since number data varies greatly various type data dataset using macro-averaged score evaluate classifier performance score calculated follows f1=2\frac precision recall precision+recall precision represents proportion true positive sample among sample predicted positive recall represents proportion true positive sample correctly predicted positive calculation formula follows precision=\frac tp+fp recall=\frac tp+fn macro-averaged score averaged calculating score category without considering difference number sample category i.e. weight category macro =\frac i=1 also average precision selected area precision-recall curve coordinate evaluate algorithm performance ap= precision recall recall experiment experiment use data set training testing worth noting class ship data partitioned training set testing set approach aid mitigating imbalance training outcome resulting variation data volume among different class contrast random data split different feature fed network cnn1 comparison figure show identified feature accuracy recall macro-average score figure partial result different input feature full size image original audio signal experiment 71.24 recognition accuracy achieved test set accuracy reach using single spectrum feature input trying fuse multiple feature extraction method find fusion mel spectrum first second-order derivative achieves recognition accuracy using stft log-mel fusion slightly outperforms 3d-mel 95.34 recognition accuracy table show result experiment table recognition result different feature full size table experiment experiment idea using random forest classify recognize ship noise validated feature stft log-mel fed random forest training comparison cnn network two model used random forest parameter setting first random forest parameter change contained decision tree second random forest bayesian optimization automatically found optimal hyperparameters model approach multiple model trained parallel hard voting decision experimental result shown table table comparison random forest cnn network training result full size table experimental result found random forest model performs poorly ship noise classification problem adding voting mechanism also improve recognition accuracy model certain extent provides new idea adding voting decision mechanism cnn network finding optimal hyperparameters random forest requires higher arithmetic power experiment found random forest model take much longer train simple network model paper experiment iii experiment iii proposed method paper compared previous study used various type feature adversarial learning network replicating previous study achieved 92.91 accuracy using mfcc input cnn network 95.64 accuracy using 3d-mel feature however network performance decreased stft spectrum used feature input pa-per migration learning also performed using resnet recognition accuracy curve method shown fig figure accuracy curve method full size image table show network structure experimental result type method table training result method full size table convolutional neural network cnn outperformed convolutional recurrent neural network crnn using mel-frequency cepstral coefficient mfcc input recognition accuracy 92.91 various cnn network parameter addition cnns rectified linear unit relu activation function performed slightly worse cnns hyperbolic tangent tanh activation function however 3d-mel used network input recognition accuracy significantly improved 2.43 simple network consisting fine-tuned resnet50 weight trained imagenet dataset produce satisfactory recognition result contrast adversarial learning network gan achieved impressive recognition accuracy 96.84 interestingly composite cnn network voting decision differ much gan term recall score achieved higher recognition accuracy 98.44 compared previous study method paper straightforward high performance figure show precision–recall curve method paper fig show confusion matrix better demonstrate recognition result type noise figure precision–recall curve class full size image figure confusion matrix mussel boat sailboat passenger tugboat dredger natural ambient noise motorboat roro fishboat ocean liner trawler pilot ship full size image curve different type noise show proposed method paper tends achieve average precision value close 1.00 indicating high precision recall value however due imbalanced data volume certain type noise noise category relatively lower value overall curve demonstrate effectiveness proposed method accurately classifying ship noise particularly presence various type noise figure show noise data tends better training result lead false recognition noise fewer data experiment noteworthy experiment experiment training validation set separated due limited data volume evaluate generalizability approach performed additional experiment deepship datasets validation set result compared obtained using resnet50 network migration learning fig show experimental finding notably deepship dataset includes ship tanker class present shipsear dataset therefore categorized tanker class noise analysis figure identification result deepship dataset full size image proposed method paper still 94.47 recognition accuracy deepship dataset comparison migration learning experiment iii prof method good generalization since deepship dataset contains four type ship noise two type ship noise described paper included impact test result discussion experimental result demonstrate choice feature used network input ship noise classification play decisive role recognition accuracy complex network structure may always lead im-proved accuracy various feature extraction method cause information loss fused feature tend exhibit exemplary performance confusion matrix fig show data size still impact recognition result network study weighted soft voting used back-end decision-making method generally voting method used different model maximize performance model however case complex net-works always applicable using network decision-making may appropriate although training set used study separated test set unlike previous study method generalizability explored applying completed training model deepship dataset important highlight dataset utilized study constructed extension original dataset noteworthy addition introduction white noise positive incentive noise enhance network performance furthermore crucial acknowledge dataset lacked ambient noise data ambient noise level significantly vary across different sea area distinct sea condition consequently outcome ambient noise identification may hold strong practical significance future research endeavor focus expanding dataset encompass diverse data source additionally plan incorporate real data obtained measurement upcoming study conclusion paper present novel approach ship noise remote sensing classification using simple cnn network structure paper introduces concept positive incentive noise addition noise improve recognition accuracy network additionally use fused feature network input lead better performance single feature alone proposed method also utilizes voting method integrated learning improve network performance without increasing complexity experimental result show network achieves recognition accuracy 98.44 demonstrates better generalization ability compared previous study furthermore proposed method validated new dataset highlighting effectiveness using simple network future research focus developing method accurately identify specific vessel