introduction cardiovascular disease cvd leading cause human mortality worldwide burden cvd healthcare professional exacerbated population aging increasing number patient considering estimated cvd case preventable growing need effective early diagnosis cvd recent year machine learning revolutionized computer vision image processing within medical domain various solution proposed automate image diagnosis disease detection characterization pathological feature image clinical decision support system triage medical data abundantly available hospital often shared large datasets research purpose however limited availability labeled data remains key challenge utilizing large-scaled datasets train deep neural network labeling medical data labor-intensive process requires involvement trained healthcare professional may limited time address research consequently labeling sufficient amount medical data become bottleneck effective development deployment deep learning system medical imaging analysis active learning semi-supervised method aim reduce required number labeled sample required machine learning active learning model learns querying unlabeled sample large dataset requesting user label training selecting informative sample consecutive training theorized model achieve adequate performance relying considerably fewer labeled data sample current state-of-the-art active learning technique commonly utilize fixed scheduling training querying step however rate timing model learning plateau may vary set labeled training-data consequently determining optimal timing fixed scheduler becomes critical hyperparameter may chosen arbitrarily necessitate additional experiment optimal selection conducting training round model learning already plateaued result inefficiency conversely fixed time query short process may undergone sufficient amount iteration effectively extract underlying pattern available training data interrupted select new data sample next training round study propose dynamic querying strategy optimize scheduling demonstrate strategy implementation active learning using dataset short-axis cardiac magnetic resonance cmr scan primary aim research evaluate efficiency applying active learning medical image ass dynamic querying reduces learning time performance proposed model compared model trained utilizing fully-supervised training method effectiveness active learning approach assessed based dataset size requirement loss rate task hand classify whether presented image scan slice cross widest point left pulmonary artery orthogonally method study population biobank prospective cohort study conducted united kingdom half million participant age community-based population recruited study received ethical approval north west multi-centre research ethic committee rec reference 16/nw/0274 participant biobank provided informed consent study method comply relevant guideline regulation research utilized biobank resource application number cmr scan individual biobank included current study scan stored dicom medium format comprising pixel data metadata orientation position participant within scanner data labeling dataset consists two-dimensional short-axis cardiac scan see fig right image labeled either class label included excluded manual labeling performed human annotator inspected full three-dimensional scan volume corresponding scan slice annotator received supervision two trained medical imaging professional labeling decision discussed extensively figure example short-axis scan right yellow border corresponding long-axis scan left purple border left yellow line long-axis scan slice render projection short-axis scan acquired perpendicularly long-axis scan center orientation location plane presented schematically also relation orientation heart yellow line long-axis scan left indicates location short-axis scan right obtained since perpendicular long-axis view needed determine exact scan location scan required ass whether short-axis scan usable annotation making selection process arduous error prone task model classify scan using information present short-axis scan slice full size image image labeled included segmentation pulmonary artery intersected left pulmonary artery orthogonally widest point required scan acquired appropriate orientation positioned correctly within participant ass acquisition position annotator observed short-axis scan fig right relation corresponding long-axis scan fig center left position short-axis scan perpendicular long-axis scan indicated yellow line projected onto long-axis scan fig left example scan labeled included presented fig image classified excluded criterion met human labeler could clearly classify due factor poor image quality example scan labeled excluded displayed fig figure example scan two class left four example included class presented right four example excluded class displayed although clear blur deformation present excluded image excluded images—e.g left-bottom—show strong resemblance included image therefore human observer classify image inclusion without long-axis scan including yellow projection line short-axis image fig left full size image splitting two class disjoint meaning image scan exist element class additionally class present dataset evaluate model performance training subset data withheld exposed model training validation dataset created randomly selecting equal number scan class ensure balanced representation half smaller class selected maximum scan per class approach ensured validation set excessively large allowed adequate number pseudo-unlabeled sample queried training set consisted remaining image scan excluding validation dataset labeled dataset constructed initially populating preprocessed batch image scan randomly sampled training data active learning method employed paper size set allowing network select informative sample right initialization contrast fully supervised learning data point labeled used train model p\left card\left system pre-labeled data point effectively enabling fully supervised training hand active learning employed case data point remained included could queried model learning process software data analysis creation visualization plot model training evaluation performed python version 3.74 fully supervised active learning neural network trained using pytorch deep learning platform version 1.4.0 pixel data metadata extraction dicom medium file carried using python package pydicom version 1.0 plot generated using python package matplotlib version 3.1.1 detail regarding use python package respective version provided throughout paper relevant image preprocessing preprocessing pipeline applied transform raw image feature representation accelerate model training process since raw pulmonary artery scan image large predictive region interest presumed located approximate heart region cropping performed cropping area empirically determined horizontal axis vertical axis cropping reduced data throughput model also eliminated potentially irrelevant information task hand subsequently image resized pixel using bilinear interpolation finally image transformed greyscale resulting one-channel encoding normalized value exploratory analysis gain insight difficulty classification task calculated principal component cropped imaging data using method described tipping bishop subsequently applied two-dimensional t-distributed stochastic neighbor embedding t-sne create visual representation class distribution principal component analysis t-sne visualization utilized scikit-learn python package version 0.21.3 augmentation mitigate risk overfitting data augmentation employed increase size training data reduce likelihood overfitting image augmentation utilized torchvision python library version 0.5.0 study performed affine transformation preserved potentially predictive parallel spatial pattern image data augmentation process involved randomly rotating image clockwise counterclockwise scaling random factor horizontally shearing random number pixel within range 0,5 transformation effectively increased number training sample generating slightly different image retaining relevant feature additionally applied two color value transformation jittering brightness contrast image factor metadata processing dicom medium file contain metadata—often referred dicom header —providing information scan including scan dimension color depth acquisition hardware detail scan metadata extracted stored information participant orientation position relative scan plane scan hypothesized information would provide meaningful insight location short-axis scan relation accompanying long-axis scan fig extracted metadata value fed model alongside corresponding image pixel data value comprised cartesian coordinate proper euler angle two orientation vector scalar value indicate relative position image slice full scan additionally scout scan metadata—a initial scan performed operating technician localization purposes—the participant position orientation used yield combined information scan placement metadate value normalized using standard logistic function described s\left neural network model architecture model utilized study deep neural network consisting successive interconnected layer pixel data image fed trainable resnet18 model pre-trained imagenet dataset transfer learning applied natural medical image assuming similarity low-level feature edge shape pre-trained resnet18 model trained image data study metadata concatenated resnet18 output resulting vector fed two dense layer node respectively softmax function transformed logits class probability vector compared true label one-hot vector calculate minibatch loss full architecture neural network model illustrated supplementary fig loss softmax equation transformed network output class probability vector ensuring probability summed cross-entropy loss calculated probability vector true class vector represented one-hot vector corresponding image scan label binary cross-entropy loss ranging indicates dissimilarity two vector optimizer stochastic gradient descent nesterov momentum employed optimizer function training model function update parameter negative direction gradient estimate incorporates additional momentum value 0.95 stabilize gradient direction accumulating current previous gradient particularly useful handling high curvature loss function prevent overfitting regularization method employed weight decay—also known parameter norm penalty ridge regression tikhonov regularization —was vital regularization method training model adding penalty equal square magnitude coefficient reducing model effective capacity study penalty value used learning rate scheduler learning rate regulates learning speed network parameter requires careful scheduling study learning rate initialized decreased factor 0.9 whenever loss training minibatches appeared plateau least epoch help precise convergence model relatively low-error subspace within full solution space evaluation classification performance model performance measured using accuracy metric representing percentage correctly classified validation image accuracy estimate reported confidence interval based model prediction validation holdout dataset active learning querying active learning framework image labeled training process via query querying process involves asking oracle user general automated process study label appropriate image set unlabeled image initial image randomly selected since absence label unlabeled dataset seems preclude elaborate querying strategy auto-labeling emulate active learning scenario system utilized pseudo-unlabeled data whose label remained concealed image scan selected querying approach simulated process human annotation request system enabling learning process proceed without actual human involvement labeling sample experiment querying strategy adopted state-of-the-art querying strategy field active learning specifically entropy-based querying strategy fall umbrella uncertainty sampling entropy-based sampling leverage concept entropy quantify uncertainty model prediction unlabeled sample preprocessing pipeline augmentation applied resulting sample fed neural network obtain class probability vector denoted entropy vector denoted measure distribution different class predicted model class predicted equal probability entropy value maximal i.e. conversely class probability vector one-hot vector indicating high certainty prediction entropy value minimal i.e. sample high-class entropy value informative model point training system query calculated entropy random selection unlabeled sample selection queried sample highest entropy parameter configurable hyperparameters allowing flexibility querying strategy instance setting would effectively disable entropy test setting would lead querying sample absolute highest entropy cost increased computational power dealing larger unlabeled datasets h\left querying scheduler active learning determining appropriate interval querying new sample queried crucial achieve desired model performance querying frequently counteract benefit active learning goal achieve high performance utilizing minimal number labeled sample hand querying sparsely lead overfitting poor generalization address challenge propose query scheduler called dynamic querying aimed striking balance extremity primary objective query scheduler select new data point labeling whenever model learning available labeled sample became insufficient process governed two precondition new sample queried either following condition met simple moving average training loss recent epoch dipped predefined fixed threshold least epoch passed since previous query training loss plateauing defined loss plateaued mean loss recent epoch since last query higher half mean loss preceding epoch condition implemented prevent drastic overfitting avoid memorizing training data condition hand prompted system select new data point training loss decrease rapidly anymore leading model explore beyond local optimum solution space likely approach allowed model explore new region data distribution improve overall performance evaluate effectiveness dynamic querying conducted comparative analysis model performance measured accuracy relation number image used training round compared metric model trained utilizing dynamic scheduling approach model trained using fixed querying schedule epoch interval set hyperparameter sweep model training process involved several hyperparameters including learning rate gamma learning rate decay factor weight decay batch size nesterov momentum term network hyperparameters used fully supervised active learning scenario managing large list hyperparameters complex time consuming requires training comparing multiple model varying setting address employed hyperparameter sweep automating search optimal hyperparameter combination reducing arbitrary choice model design hyperparameter sweep conducted follows linear search performed hyperparameter exploring range value logarithmically scaled default setting best-performing value hyperparameter saved process repeated three time weight decay initial learning rate grid search performed evaluating combination two range logarithmically scaled value best performing combination selected resulting hyperparameters result population dataset comprised total image image labeled included image labeled excluded randomly selected validation dataset remaining image formed training dataset image labeled excluded labeled included exploratory analysis gain insight dataset characteristic ass separability performed principal component analysis subsequent t-sne visualization preprocessed data fig show data comprised two weakly distinguished cluster indicating moderate classification performance could achievable dataset figure pca t-sne dimensionality reduction two pulmonary artery data class kullback–leibler divergence 0.73 full size image model performance fully-supervised method achieved accuracy 74.5–89.5 complete training dataset image considered empirical upper bound task given current dataset contrast active learning achieved accuracy 63.0–77.5 using sample epoch 601–1387 active learning scenario naturally resulted lower accuracy due use fewer labeled sample demonstrated adequate performance requiring significantly reduced labeling requirement presented supplementary fig result fully-supervised active learning training run presented fig supplementary fig supplementary fig illustrates trade-off maximum validation accuracy number queried sample employing active learning figure training validation loss mean per minibatch training loss indicated blue dotted line validation loss indicated orange solid line left loss active learning training run training loss decrease sharply sample queried—indicated vertical grey bars—after spike back oscillation level loss slowly increase validation loss follows inverse pattern right loss fully-supervised training run training loss decrease sharply level validation loss slightly decrease plateau full size image comparison dynamic querying approach conducted four run fixed querying schedule querying epoch ensure fair comparison run limited query select sample run achieved maximum accuracy 56.0–75.1 epoch 672–1144 run achieved maximum accuracy 65.9–77.1 epoch 530–1213 run achieved maximum accuracy 61.1.y–84.6 epoch 813–1263 run achieved maximum accuracy 59.4.y–76.7 epoch 938–1208 analyze misclassifications trained model table list four statistical measure notably number false positive false negative approximately equal although balance might preferred medical setting table additional metric fully supervised model obtained mean value included excluded validation scan full size table discussion application deep active learning medical datasets promising direction research deep learning remains relatively unexplored study focused investigation query scheduling aspect active learning received attention compared query selection strategy dynamic querying warrant investigation including exploring potential combination existing query selection strategy query-by committee expected model change historically querying strategy dominated active learning research classical machine learning timing sample selection crucial may contributed relative lack attention given query scheduling dynamic querying fixed querying schedule hyperparameter experiment confirmed optimum likely exists hence investigating different fixed schedule extensively necessity applying fixed scheduling achieve appropriate result dynamic querying approach surpass performance best fixed querying approach demonstrated comparable result outperformed majority fixed querying run hold number epoch required train model using dynamic scheduling additionally dynamic querying exhibited greater stability result compared fixed querying schedule despite achieving absolute best performance dynamic querying offer significant advantage enabling active learning without need extensively investigate fine-tune querying schedule still delivering near-optimal performance translated future study dynamic querying posse self-optimizing characteristic greatly accelerate initiation active learning project however important note study focused solely application dynamic querying specific tailored dataset specific purpose therefore definite conclusion drawn experiment regarding performance dynamic querying imaging modality data type different problem domain fully understand generalizability dynamic querying essential evaluate effectiveness across various data type imaging modality thereby providing deeper insight potential impact diverse research topic important observation experiment accuracy dropped initial query round active learning strategy phenomenon consistent across different approach line previous finding entropy-based querying indicating need improvement initial sample selection active learning algorithm additionally noticed initial validation accuracy varied among different active learning strategy employed finding underscore importance refining sample selection process enhance performance stability active learning algorithm enlarging initialization minibatch could potentially provide better predictable initial selection unlabeled dataset however would require human labeling would move system towards ordinary supervised learning alternatively method representativeness-based approach adaptive method balancing uncertainty-based representativeness-based selection previously proposed could explored sample first image approach might bootstrap model general case querying uncertain sample importantly offer opportunity follow-up study investigate effectiveness dynamic querying combination balanced selection strategy larger unlabeled datasets hypothetically achieve better active learning result using entropy method queried sample likely near decision boundary study initially trained active learning system dataset of—up to—1017 scan achieve initial accuracy approximately 61.0–79.0 plan continue training complete uk-biobank imaging dataset order magnitude larger entropy-based querying strategy proved effective many case potential effect outlier noisy data explored detail possible high-entropy data may include outlier corrupted sample confound model training process known concern uncertainty sampling selection strategy may prone incorrect estimation regarding true decision boundary partially due outlier implementing quality control preprocessing task detect exclude outlier could enhance overall performance regarding model selection opted resnet18 architecture seemingly difficult classification task three-dimensional context image slice inferred slice decision based resnet18 well-established performance natural image classification suggested prior research employing pretrained imagenet architecture medical domain may suboptimal others assert opposite study demonstrates considerable potential employing active learning transfer learning resnet18 architecture analysis medical imaging scan utilizing small number labeled image strength limitation key strength work lie introduction dynamic query scheduler optimizing active learning process efficiently timing query additional labeled data approach minimizes queried training data time maintaining model accuracy however limitation consider firstly dataset used study labeled single annotator potentially introducing observer bias could model reported performance mitigate risk annotator supervised two trained medical imaging expert involving multiple annotator label dataset independently could reduce observer bias enhance model performance secondly complexity classification problem may pose limitation even trained professional classifying short-axis scan without considering relation corresponding long-axis image challenging reason model might learned classify based solely criterion orthogonality scan slice respect pulmonary artery without considering whether sliced widest point addressed limitation including extra metadata parameter however improve classification accuracy incorporating adjacent short-axis scan slice corresponding long-axis scan voxels encompassing pulmonary artery region might necessary addition could enhance model performance would also increase input dimension resnet18 potentially complicating model training necessitating larger-scaled training dataset thirdly relatively small dataset image may limited model optimal performance however common constraint medical domain study aimed demonstrate efficient training approach circumstance rather achieving best possible performance conclusion conclusion study involved training two deep neural network selection short-axis cmr image suitable pulmonary artery annotation one model trained using fully supervised learning entire dataset second model trained minimum image employing active learning introduced novel query timing strategy optimize model performance minimal labeled sample although fully supervised method achieved higher accuracy compared active learning latter approach demonstrated promising result reaching peak performance significantly fewer labeled sample without necessity prior tuning query scheduling hyperparameter suggests active learning dynamic query scheduling hold great potential enhancing practicality applicability deep neural cardiovascular imaging research particularly scenario limited availability labeled imaging data