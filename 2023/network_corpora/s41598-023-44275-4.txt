introduction crop spraying one fundamental process agriculture carried apply herbicide pesticide fertilizer necessary chemical crop key problem current crop spraying system small percent spray stick crop intended due plant hydrophobic property spray pattern large portion sprayed chemical bounce plant land ground become part chemical runoff flow stream river often causing serious pollution researcher discovered pesticide detected 90\ agricultural stream 50\ well 33\ deep aquifer sampled across u.s. study related chemical runoff problem pattern spray emitted nozzle agricultural nozzle effectiveness determined many different factor among important droplet size velocity spray pattern earlier work developed tool measuring droplet size velocity thus critical need precise measurement spray pattern study efficacy sprayer system retention agricultural spray adjust spray pattern achieve optimal retention hence minimize chemical runoff pollutes soil-water-plant system motivation scope paper focus extracting two critical characteristic agricultural sprayer system given input image segmentation spray region estimation spray cone angle successful segmentation determine spray region given image provide useful information spray pattern spray pattern perform expected lead under-spraying chemical causing unnecessary waste chemical therefore measuring spray pattern essential understanding overall effectiveness spray similarly spray cone angle crucial estimating reach spray theory end-user choose nozzle system satisfies desired characteristic spray accordance system specification example flat-fan nozzle supposed generate spray cone angle degree operating rated pressure psi discharge rate 0.5 gallon per minute specialized instrument patternators used lab environment understand study spray pattern example investigating performance different hand-held sprayer type researcher manually measured spray angle following iso 5682-1 standard using dedicated testbed however specification theoretical value may change drastically environmental factor come play even sprayer system rated degree spray cone angle produce different actual angle value actual system pressure varies along flow spray angle also influenced dimension liquid characteristic density ambient liquid sprayed tested different nozzle noticed spray angle difference 10\ compared manufacture-rated nozzle spray angle importantly technique developed paper facilitate automated recognition measurement spray pattern angle given spray image method much economical manual measurement spray pattern human operator approach discussed work employed feedback mechanism control adjust spray pattern field achieve desirable spray efficacy addition research lay foundation integrated early phase nozzle design investigation lab setting scope work develop advanced ai-enable tool recognize measure quantify spray pattern agricultural nozzle achieve goal research emphasizes importance developing machine-learning model light number parameter maintaining desired performance model fewer parameter generate output faster require memory resource addition work also clearly illustrates pathway leverage deep learning computer vision estimate spray boundary spray cone angle natural continuation work develop classification neural network take measurement generated research output quality spray interest neural network trained supervised ground-truth data labeled human expert agent also take account type crop well since spray good one crop may poor another crop hydrophobic property different plant may vary another future direction would expand research investigate effect factor like wind drift tractor motion rough terrain spray region cone angle deep learning play central role work driven fact deep-learning method recently shown impressive result computer vision machine learning example deep learning implemented successful classification detection segmentation reinforcement learning name furthermore work focus using image taken common phone camera instead expensive high-speed camera make accessible summary motivation research leverage potential deep learning computer vision address one fundamental problem precision agriculture namely measuring agricultural spray characteristic related work estimation spray cone angle majority existing work estimating spray cone angle focused primarily fuel spray system little work agricultural application particular artificial light added generate high contrast image help detection spray boundary crucial spray cone angle computation similarly black background added addition use para flash manipulating lighting condition special charged-coupled device ccd camera used collect image existing computer vision software used manually measure spray cone angle ccd camera stroboscope used capture image processed estimate spray angle better understand performance liquid rocket engine pintle injector spray angle manually measured time-averaged spray image addition using ccd camera similar use high-speed ccd camera used spray angle estimation existing study used specialized camera capture image whereas project work image recorded using common cellphone camera importantly effectiveness existing technique relies environmental lighting condition setting tuning lighting condition time-consuming requires multiple trial error iteration get desired lighting condition avoid issue designed deep neural network transform image obtained camera binary image extract spray cone angle binary image two distinct region white region represents spray everything else black represents background therefore proposed method minimizes dependence lighting condition save lot time make system accessible average user related work deep learning image segmentation determining spray pattern image achieved segmentation many branch computer vision decade lot research carried focusing image segmentation since dealing input image convolution-based segmentation natural choice seminal work regarded one early segmentation technique employ convolution-based approach though revolutionary model time many new improved model introduced address shortcoming work example parsenet developed utilize global context scene lead reduction loss scene-level semantic context another widely recognized used model segmentation u-net u-net enables precise segmentation using fewer training image addition higher number feature channel u-net allows network propagate context information higher resolution layer many variation u-net target different application example recent work implemented u-net-inspired model sea bottom detection based sonar data light model u-net called mobile-unet developed fabric defect detection addition variation called s3d-unet proposed brain tumor segmentation segmentation model paper also inspired u-net motivation choosing u-net model beside widely successful different application designed deal limited data set achieving desirable performance two different model spray pattern segmentation developed paper trained experimental data collected spray system test bed shown fig particular test bed includes raven industry hawkeye2 pulse width modulation pwm system operates 10hz maintaining constant boom pressure pwm spray system advanced technology obtain variable rate spray application without varying operative sprayer parameter addition user interface used control flow rate different spray nozzle generate different spray pattern comparative study presented compare performance new model well original u-net model key contribution work follows two new deep-learning model spray pattern segmentation training validation comparison two deep-learning model spray region segmentation u-net model showing 1\times convolution prominently used deep learning-based segmentation model training result two proposed model new technique estimating spray cone angle based upon deep-learning model output agricultural application experimental result spray cone angle determination using two new model image taken common phone camera addition performance proposed model affected environmental factor lighting contrast condition figure experimental set-up crop spray nozzle data collection full size image data processing operation given objective described last section fundamental process take input image spray process data extract critical feature define spray pattern detected figure illustrates building-block operation fundamental process operation described follows 5\times convolution followed relu activation applied input image size 572\times 572\times resultant output binary image size 568\times 568\ stacked one another resulting total data size 568\times 568\times in-depth discussion operation elaborated convolution process applying filter input image 5\times convolution mean filter size 5\times used given input stride one filter move one pixel step entire input processed example top left panel fig show result applying identity filter stride given input result applying convolution fig obtained following step first 3\times identity filter placed image patch size second element-wise multiplication done entry image patch identity filter entry resulting matrix summed mathematically written since stride next step identity filter move one pixel repeat calculation entire image processed result next patch output last patch output -1\ thus result applying convolution identity filter depicted fig fig since use different filter process result output value filter entry trained training process discussed next section activation process applying function entry given input rectified linear unit relu one activation function employed work since relu defined relu max negative value converted value zero example bottom left panel fig show result applying relu activation input addition relu also use sigmoid sigmoid activation function matter activation function used process applying activation input remains activation function essential deep learning common see activation applied output operation convolution transpose convolution also worth noting applying filter doe change size data transpose convolution process upsampling given input applying filter 2\times transpose convolution mean filter size 2\times used example bottom right panel fig show result applying transpose convolution filter size 2\times stride given input fig transpose convolution first entry input multiplied given filter similarly second third entry input multiplied filter particular example given stride intermediate output stacked get final output seen fig different stride size step might required get result 1\times convolution followed batch normalization relu activation applied output size 568\times 568\times coming last process batch normalization technique normalizing input similar applying activation function batch normalization doe alter size input data batch normalization relatively new idea field deep learning batch normalization help training deep neural network work batch normalization carried output 1\times convolution since batch normalization preserve size output size batch normalization still 568\times 568\times finally relu activation applied output batch normalization activation function also preserve size output size remains 568\times 568\times output operation contains feature map size preserve key characteristic define spray pattern feature map processed spray pattern segmentation figure input image going multiple operation eight 5\times convolution filter applied input rgb image resulting output 568\times 568\times since relu batch normalization preserve size size obtained applying convolution remain even applying operation convolution extract important feature image whereas relu activation function restricts output convolution operation certain range full size image figure illustration applying basic operation including convolution max pooling transpose convolution relu activation different input full size image neural network architecture spray pattern segmentation developed two deep-learning model namely model model whose layer architecture listed table input size output size operation carried layer layer collection operation example layer down-sampling take input image size 572\times 572\times output result size 568\times 568\times operation carried layer down-sampling written compact form follows input size 572\times 572\times convolution 5\times stride activation relu convolution 1\times stride batch normalization activation relu output size 568\times 568\times down-sampling up-sampling two different set operation elaborated follows down-sampling 2\times max pooling operation stride 5\times convolution stride followed relu activation 1\times convolution stride followed batch normalization resultant feature map passed relu activation up-sampling 2\times transpose convolution stride followed batch normalization resulting feature map pas relu activation stacking feature map 1\times convolution stride padding one pixel throughout border followed relu activation essential down-sampling process max pooling operation max pooling calculates maximum value patch given input resulting suppression value except maximum convolution patch size defined example 3\times max pooling would mean patch size 3\times top right panel fig show result applying max pooling size 3\times stride given input result max-pooling operation obtained finding maximum value patch first patch maximum value second patch maximum value proposed model refer table in-depth step convolution play vital role neural network architecture goal convolution operation case down-sampling gradually increase depth feature map contrast up-sampling depth feature map gradually decrease help transpose convolution one major operation link output down-sampling layer up-sampling layer stacking concatenate operation result obtained max-pooling operation down-sampling layer stacked result obtained transpose convolution layer up-sampling seen table operation table known stack example output feature map max-pooling operation layer down-sampling stacked output feature map transpose convolution layer up-sampling generate output size 284\times 284\times 16\ case layer output feature map max-pooling operation stacked output feature map last 1\times convolution operation layer output feature map size 14\times 14\times 256\ layer up-sampling table network architecture model model model similar color region feature size column indicates feature get stacked together full size table summary refer table in-depth step repeat down-sampling operation two convolution max-pooling five time input image size 572\times 572\times pixel obtain feature map size 14\times 14\times 128\ output obtained layer stacked result obtained applying two convolution resulting feature map size 14\times 14\times 256\ passed one convolution followed transpose convolution operation stacking followed convolution transpose convolution also repeated five time resulting feature size 572\times 572\times case model four 1\times convolution applied end obtain output image size 572\times 572\times case model two 3\times convolution applied end obtain output image size 568\times 568\times model take input image output binary mask segmentation difference among model term network architecture two new segmentation model distinct compared well-established u-net model significant difference u-net use 1\times convolution model model allowed significantly reduce total number trainable parameter proposed model seen table u-net around time parameter compared model model according work segnet another popular segmentation model around million parameter similar observation made term model total size shown table proposed model also layer deeper compared u-net general smaller number parameter take time complete segmentation task input image compared model larger number parameter thus significant advantage model fewer number parameter addition reduced number parameter emerging technique batch normalization introduced model model stage term model architecture proposed model significant advantage u-net spray pattern recognition next section elaborate training compare performance table comparison three model term network architecture full size table training organize date three distinct group training validation test image contained within training dataset provide agent large set labeled example use learn recognize spray pattern deep-learning model trained presented many example input data along corresponding correct output input analyzing processing example algorithm adjust parameter minimize difference predicted output actual output via optimization scheme validation dataset enables gain insight overall performance model processing image previously used training model compute loss validation dataset epoch learn data parameter deep-learning model remain fixed validation loss computation evaluating model performance data model trained purpose test dataset evaluate model performance image model never encountered addition represents real-world scenario different spray nozzle varying lighting condition experimental setting produce variety spray pattern image augmentation pipeline used increase number image reduce data over-fitting image augmentation pipeline involved using one following operation resizing original image height width central crop window size 572\times 572\ resizing size 572\times 572\ horizontal flip three augmentation operation one randomly selected input desired output generate desired output region around spray drawn image database used generate binary mask mask one-channel image white pixel representing spray black pixel representing background stage input image corresponding mask size 572\times 572\ using input image mask database built containing image model take input size 572\ output single channel image different size seen table based model mask resized necessary fit model desired size example model output image height width whereas u-net output image height width addition output model value sigmoid function last layer result ground truth also scaled value computing loss function binary cross-entropy used loss function defined aligned l_x i=1 j=1 log 1-y log aligned l_x\ loss value given input image desired output image generated image output model pixel value row column output image height width lowest bound log function equation set -100\ avoid singularity loss function defined stochastic gradient descent sgd algorithm momentum used minimize loss function value training process train model database divided two group 80\ image mask used training purpose remaining 20\ used validation let _t\ set containing image used training model _v\ set containing image used validation training loss defined l_t l_x x\in _t\ validation loss defined l_v l_x x\in _v\ representing total number element given set hyperparameter value used training process reported table though work doe explore systematic way achieve optimal value hyperparameters currently selected value random either key driving factor selecting value listed table follows higher value batch size used preserve memory lower value batch size lead lot oscillation training loss larger learning rate lead high oscillation validation loss lower value explored model would take time converge weight decay used way introduce regularization model making model robust above-selected value three model model model u-net trained using pytorch framework training process training loss l_t\ validation loss l_v\ computed every epoch seen fig figure left training loss three model right validation loss three model full size image difference model term training time performance training employed high-performance computing facility intel xeon gold 2.4 ghz 14nm cpu nvidia tesla p100 gpu three model trained using database discussed hyperparameters table training hardware also kept constant training progress made model time seen table result presented table show u-net model take approximately hour train compared model model addition u-net model doe perform better compared model model term training loss validation loss indicated fig beside binary cross-entropy loss model performance measured using additional metric threshold applied output model pixel value greater 0.5 replaced everywhere else following metric ground truth validation set computed true positive number pixel model correctly predicts pixel value compared ground truth true negative number pixel model correctly predicts value compared ground truth false positive number pixel model predicts value ground truth value pixel false negative number pixel model predicts value ground truth value pixel defined commonly used segmentation metric computed mean accuracy mean dice coefficient mdc mean intersection union miou table training parameter full size table table training performance three model full size table mean accuracy computes mean pixel accuracy ground truth output model defined aligned i=1 total number image aligned mean dice coefficient mdc computes similarity model-generated output image ground truth defined aligned mdc i=1 total number image aligned mean intersection union iou computes overlap ground truth prediction defined follows aligned miou i=1 total number image aligned performance metric defined validation dataset used understand model overall performance untrained image even though model computes loss validation dataset every epoch never learns validation loss word weight model frozen validation loss computation addition validation dataset test dataset also introduced evaluate trained model performance novel data adding test data evaluate performance trained model common practice performance metric computed validation test data shown fig see model performance improves number epoch increase however performance test dataset decrease compared validation dataset expected model training contained data collected single setup shown fig one direction future work would increase training data size capture different setup spray different environment lab setting nonetheless performance proposed model still better u-net model figure performance metric computed validation dataset top row test dataset bottom row every epoch full size image inference point clearly illustrated proposed model model model fewer training parameter smaller model size take time train compared u-net therefore compelling motivation pick either proposed model model model spray pattern recognition model model share lot similarity term network architecture model size training time compared model model lower value training validation loss furthermore model performs better term mean accuracy mean dice coefficient mean intersection union comparison model validation dataset model also performs better test dataset compared model see fig highlight efficacy model accurately predicting target outcome underscore potential robust model spray boundary detection thus model selected model analysis result also clearly show 1\times convolution used efficiently within model task image segmentation seen close value training loss l_t\ validation loss l_v\ shown fig figure depicts typical result model segmenting spray image detect spray pattern even though model recognize region spray given image deep-learning model loss remains training case training validation loss 0.1 ability segment region spray given image next step would estimate spray cone angle figure input image left column output binary mask obtained model middle column superimposing boundary output mask input image right column full size image estimation spray cone angle section discus post-processing carried fit standard geometry detected spray pattern post-processing algorithm consists following step binary threshold one channel output image pixel value inclusive obtained model scaled gray-scale image pixel value spray cone angle estimation classical computer vision library opencv opencv library function expect pixel value threshold applied gray-scale image technique work assigning pixel either value based following equation aligned i_b i=1 j=1 i_b array i_b threshold else array aligned i_b\ output image applying model given input image width height respectively image i_b\ threshold value chosen user value selected case binary thresholding operation region spray represented white color pixel value everything else black pixel value figure post processing estimate spray cone angle output deep-neural network segmentation output boundary detection output cropping output image thinning output line fitting output line refinement angle computation full size image spray boundary detection spray region detected next step detect edge/boundary detected spray region spray boundary detected using edge detection technique edge boundary extraction contour extracted technique enables establish topological relationship spray boundary surroundings topological structure helpful remove false detection spot inside sprayer pattern output step shown fig iii cropping next step would focus nozzle region liquid exit nozzle image obtained applying step cropped center contain 80\ total pixel particular 20\ pixel surrounding image boundary removed resulting image size 342\times 342\ cropped image referred i_c\ output step shown fig cropping window seen fig dotted rectangle image thinning module redundant pixel value representing edge spray removed via image thinning process main idea behind image thinning reduce foreground region remnant original connectivity preserved specifically operation remove redundant white pixel white pixel represent edge spray thinning algorithm represented using equation aligned i_e i_e i_c f_1 i_c i_c f_2 i_c aligned f_1\ erosion followed dilation f_2\ erosion operation morphological operation 3\times structural element used operation bit-wise operation initially i_e\ one-channel image pixel value zero i_c\ initially cropped image image i_e\ i_c\ repeatedly updated operation defined eqaution repeated unless pixel value i_c\ zero output step shown fig line fitting output step provides rudimentary pixel representing boundary spray pattern using hough line transformation technique line represented polar coordinate fitted output image condition line fit image requires least continuous boundary pixel form line value chosen detect many line possible based observation significant impact choosing different value range fitted line represent left side spray boundary right side spray boundary filtered left right edge defined spray cone angle following logic applied detected line line satisfy logic selected aligned accept detected line array 20^\circ 85^\circ 95^\circ 160^\circ array aligned angle image width direction perpendicular line detected line depicted fig accepted line grouped two set q_1\ q_2\ q_1\ contains line slope 20^\circ\ 85^\circ\ set q_2\ contains line 95^\circ\ 160^\circ\ figure spray cone angle estimation using computer vision full size image line refinement angle computation spray cone angle obtained computing angle left boundary right boundary previous step could multiple line set q_1\ q_2\ let average slope value stored set q_1\ average slope value stored set q_2\ hence lead two line one represents left boundary represents right boundary spray region refer fig visual representation finally spray cone angle degree computed validation given spray image model used compute binary spray pattern using approach spray cone angle estimated binary spray pattern image spray cone angle computed step compared manual measurement obtain manual measurement image processed model loaded imagej image processing software developed national institute health laboratory optical computational instrumentation image widely used validation spray angle different application spray angle obtained using imagej referred manual measurement current state art result obtained proposed method referred estimated value illustrated fig ten image randomly selected result shown table table validation verification unit degree full size table seen table proposed method result align manual measurement within relative error 3.3\ validation step reassures effectiveness proposed method thus pipeline developed used estimate spray cone angle place manual measurement using imagej conclusion work lay foundation deep-learning technique better understand sprayer system characteristic well address problem agriculture demonstrates 1\times convolution play significant role detection spray pattern lead model fewer parameter higher efficiency trained model also demonstrates excellent capability segmenting spray region output trained model used estimate spray cone angle data analysis robust lighting condition also remove need using special camera estimate spray cone angle additional benefit using deep learning approach model trained additional data image different resolution different outdoor setting image taken different camera make model general reliable though work doe detail actual implementation overall algorithm system field application always motivational factor successful field test require processing capability high frame rate since environment substantially dynamic compared controlled environment lab current paper code written python post-processing task trained model run using old computer 2.9 ghz dual-core intel core gpu mhz ddr3 memory intel iris graphic card device able segment region spray also estimate spray cone angle rate frame per second future field test coding lower-level programming language like c/c++ powerful computer optimized code lead higher processing frame rate future research develop deep-learning algorithm segmenting spray pattern dynamic influence wind also plan validate proposed algorithm field test