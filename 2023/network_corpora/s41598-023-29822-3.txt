introduction information resource due advance expansion digitalization control however programing explicit algorithm good performance may become unfeasible due vertiginous growth amount available information classical algorithm deal inherent difficulty finding efficient algorithm specific problem limit current capability information processing task two alternative approach would contest limitation machine learning quantum computing one hand machine learning branch artificial intelligence statistical technique give computer ability progressively learn input data without explicitly programmed based generation hypothesis optimized sample input re-used generate new prediction thus algorithm learn data overcome static program instruction making data-driven decision sample input among distinct hypothesis model neural network extended due blooming deep learning artificial neural network organized layer layer learns new behavior pattern computational power artificial neural network relies architecture neuron layer feed signal neuron allowing parallel-processed computing manner several calculation performed time large computational problem often divided smaller one solved simultaneously versatility neural network classify complex data relies universal approximation theorem lead artificial neural network capacity approximate function result span broad range application speech object recognition spam filter vehicle control trajectory prediction decision making game-playing automated trading system hand quantum computing represents different paradigm classical information processing based alternative information encoding exploit quantum property matter system encompass several quantum bit qubits exponentially hard simulate classical device showing quantum system seem obey church thesis consequently polynomially equivalent classical system quantum system harnessed computational device might dramatically powerful classical system universality quantum computing expands broad range application illustrative example linear system solver molecule simulator combinatorial optimizers black-box factorization problem hamiltonian simulation although set single n=1\ two-qubit n=2\ gate universal approximator larger multi-qubit gate may offer computational advantage reduces complexity existing algorithm quantum machine learning aim symbiosis paradigm mutual reinforcement achieve improvement machine learning protocol leveraging quantum resource comparison classical counterpart goal future hand universality artificial network may enhance accuracy efficiency quantum protocol making analogy classical neural network quantum neural network qnn consists quantum perceptrons neuron possessing nonlinear activation function different layer network hidden layer qnn intermediate one composed quantum perceptrons qubit encoded ising hamiltonian measuring excitation probability reduced eigenstate hamiltonian one get nonlinear activation function work propose extension universal qnn enabling multi-qubit interaction lead reduction network depth keeping approximation power result achieving simplification existing protocol requires shorter operation time may also introduce accumulation error due reduction amount requested gate article structured follows firstly define quantum perceptron single-output quantum neuron multi-qubit interaction connecting several-input quantum neuron without hidden layer result nesting several quantum perceptrons qnn show quantum perceptron multi-qubit interaction xor gate prime number search bit improving performance approximation power compared classical counterpart well compared standard qnns i.e qnns include nested perceptrons without multi-qubit interaction show quantum gate cnot toffoli fredkin implemented qnn involving quantum perceptrons multi-qubit interaction thus reducing circuit depth needed add hidden layer result quantum perceptrons multi-qubit potential quantum perceptron quantum neuron basic building block qnn constructed qubit present nonlinear response input potential _j\ excitation probability written following quantum gate acting qubit encodes quantum perceptron aligned 1-f aligned aligned 1+\frac 1+x^2 aligned corresponds nonlinear function transformation engineered e.g. evolving adiabatically qubit hamiltonian aligned ^z_j _j^x\right aligned _j\ potential exerted neuron perceptron applied external field lead tunable energy gap dressed-state qubit basis ^x_j|\pm typically i=1 ^z_i b_j\ implies perceptron coupled number neuron labelled previous/input layer via standard spin-spin interaction hamiltonian following reduced eigenstate i.e degree freedom neuron traced-out aligned x_j/ x_j x_j ~~~~ aligned excitation probability form specifically accomplish one use hadamard gate firstly get transformation finally obtain x_j/ t_f certain time t_f\ evolving system adiabatically hamiltonian fixed trajectory always along instantaneous eigenstate hamiltonian one deduce external driving fast quasi-adiabatic passage manner nonlinear activation function quantum perceptron encoded probability excited state p_j x_j 1+\langle _j^z adiabatic evolution order speed operation perceptron one also use inverse engineering technique directly impose condition wave function evolution initial final time instant resulting nonlinear response quantum perceptron correspondingly smoother control easily implemented experimentally also found addition accelerated activation mechanism inverse engineering quantum neuron would reduce decoherence variation input potential induced neuron previous layer leading enhanced performance introduce different type potential rely possibility implement multi-qubit interaction particular consider potential kind aligned i=1 ^z_i l_1 l_n b_j aligned multi-qubit coefficient marked subscript l_p namely term involving several pauli matrix includes product arbitrary number neuron previous input sake simplicity presentation single multi-qubit term however include several product distinct neuron input layer i.e additional multi-qubit term later provide specific example interaction associated definite problem following show multi-qubit potential enables task constructing xor gate perceptron level searching prime number iii encoding quantum gate implemented without hidden layer and/or ancillary qubits thus showing significant role multi-qubit potential simplification qnns xor gate classical perceptron linear separator nonlinear logic gate well-known xor problem i.e. exclusive boolean function requires least one hidden layer implemented classical neural network show quantum perceptron multi-qubit interaction neural potential nonlinear classifier particular illustrate construction xor gate single quantum perceptron multi-qubit interaction also show lack hidden layer prevents classical neural network standard qnns achieve task figure order encode xor gate search prime number among integer show value cost function different epoch using multi-qubit interaction perceptron solid blue classical perceptron dotted red latter equivalent quantum perceptron two-qubit term shown comparison weight bias training process see learning rate 1.5\ transfer function used case quantum perceptron function indicates system evolves adiabatically full size image value output neuron separated linearly classical perceptron two input one output i.e without hidden layer fails solve xor gate show use standard gradient descent algorithm train simple classical perceptron sigmoidal activation potential see x_j=\sum i=i ^kw_ s_i+b_j\ classical input s_i 0,1\ whose cost function form mean square value aligned c=\frac n=1 -t^ aligned however besides sigmoid function neuron form nonlinear activation function relu function also create neural network learn xor gate n=4\ determines four possible example output target respectively example simplicity subscript labelling one perceptron neglected following text training parameter classical perceptron updated epoch aligned _i= w_i w_i w_i n=1 s_i -\eta i=1 aligned learning rate nonlinear function similar applied train perceptron order obtain approximation power shown fig cost function value classical perceptron stucks c=0.125\ dotted-red line superimposed diamond better identification classical perceptron converge linearly separable data able imitate xor function order complete xor hidden layer two neuron needed two neuron regarded perform nand gate implement xor gate quantum perceptron without multi-qubit term using potential w_1 _1^z w_2 _2^z +b\ one follow procedure described ref encode xor gate neural potential derived four basis state play role four example input xor gate namely case input value xor gate bit one transform measurement value ^z\ input qubits perceptron i.e 1+\langle therefore input value refer input state ground state -1\ excited state =1\ respectively quantum perceptron without hidden layer two-qubit interaction equivalent classical perceptron point view following training process aiming training gradient descent method one update weight bias aligned _i= w_i n=1 w_i i=1 aligned aligned aligned solution schr√∂dinger equation driven hamiltonian w_1 _1^z w_2 _2^z +b\ previous equation see weight bias obtained way classical counterpart one compare provided w_i =\hat _i^z s_i\ indicates single quantum perceptron two-qubit interaction basis state input equivalent classical perceptron order implement xor gate quantum perceptron one would need perform two adiabatic passage different control well use different neural potential passage appropriately changing weight bias equivalently one could also xor gate including one hidden layer two additional quantum neuron application single worth mentioning hold quantum perceptron instead qnn hidden layer qnn layer one need measure output qubit value aligned y=p 1+\langle ^z_ aligned instead intermediate one i.e. tot tot j=1 _j\ total number quantum perceptrons qnn otherwise shot noise introduced measuring neuron hidden layer procedure xor gate simplified considering quantum perceptron multi-qubit interaction find output quantum perceptron using unitary transformation implemented quantum perceptron gate heisenberg picture aligned ^\dag 1-2f 1-f aligned lead y=1\ 1/2\ y=0\ 1/2\ particular explore following multi-qubit potential aligned w_1 _1^z w_2 _2^z _1^z _2^z aligned case weight w_1\ w_2\ updated updating formula weight _1^z _2^z\ term aligned n=1 ^z_1 ^z_2 aligned considering construction xor gate equation aligned 0\times w_1 w_2 aligned aligned 0\times w_1 w_2 w_2 aligned aligned 1\times w_1 w_2 w_1 aligned aligned 1\times w_1 w_2 -w_1 w_2 aligned find contradictory mutli-qubit interaction term doe exist however one always find approprint value satisfy inequality existence _1^z _2^z\ neural potential enables quantum perceptron construct xor gate nonlinear separator test cost function value see quantum perceptron find occurs epoch =197\ shown fig solid-blue line square numerical calcluation see cost function value continues decrease contrary classical qubit-qubit interaction perceptron able produce xor gate see plateau behavior cost function dotted-red remains constant epoch 50\ searching prime number ref specific example two three four perceptrons per layer illustrated detect prime number 2^i -1\ range i=3\ i=7\ bit particular shown qnn two perceptrons ‚Äìone hidden layer one output‚Äì classify prime number bit exemplifies better performance qnns compared classical one hidden layer two neuron necessary accomplish task scheme network bit input shown figure fig detail regarding qnn-training search prime number method figure schematic configuration classical neural network one hidden layer two neuron task search prime number input number a_1 a_2 a_3 bit well trained network give output y=q task achieved qnn multi-qubit interaction neural potential red junction involving second third neuron without hidden layer truth table prime-number search input bit qnn input value a_1 a_2 a_3 binary number integer output value prime number non-prime one full size image introduce multi-qubit term neural potential find task achieved qnn without hidden layer i.e single quantum perceptron level search prime number bit truth table listed fig using single quantum perceptron consider potential aligned w_1 _1^z w_2 _2^z w_3 _3^z w_\text _2^z _3^z aligned demonstrate later adding multi-qubit term w_\text _2^z _3^z\ enough fulfill prime number searching task respect one include additional multi-qubit term neural potential however use simplest example simplify network training process note input quantum perceptron present two-qubit interaction basis state equivalent classical perceptron shown reason compare cost function classical perceptron cost function quantum perceptron using potential specific purpose searching prime number shown fig quantum perceptron achieves epoch solid-blue square value saturates 0.126 classical counterpart dotted-red diamond indicates perceptron achieves searching task without hidden layer also verified ability quantum perceptron minimizing cost function acceptable error searching prime number bit potential aligned w_1 _1^z w_2 _2^z w_3 _3^z w_4 _4^z w_\text _2^z _3^z aligned bit aligned w_1 _1^z w_2 _2^z w_3 _3^z w_4 _4^z w_5 _5^z w_\text _2^z _3^z aligned multi-qubit term two neural potential bit chosen due fact cost function result epoch =1692\ epoch =1698\ consideration adopting minimal number multi-qubit term training quantum perceptrons present value continue decrease proving success achieve task quantum gate show one use qnn multi-qubit interaction construct quantum gate cnot toffoli fredkin gate without necessity hidden layer comparison one demonstrate qnn two-qubit interaction construct mentioned quantum gate condition shown later quantum gate reversible number input output qubits quantum gate equal hence number neuron input equal output correspondingly cost function changed aligned c=\frac 2nk n=1 i=1 y_i^ -t_i^ aligned number quantum perceptrons cnot gate k=2\ truth table schematic configuration qnn shown fig respectively perceptron output neuron give output value 1+\langle first perceptron value first input neuron second one aim achieve value xor output two input neuron i.e ^z_ out,2 _1^z _2^z\ neural potential second perceptron aligned _1^z _2^z b_2 _1^z\hat _2^z aligned first perceptron two-qubit interaction term find concise choice requires least connectivity obtain cost function value using epoch =116\ c\rightarrow larger epoch shown fig solid-blue square indicating satisfaction train cnot gate well contrary training cnot gate qnn two-qubit interaction term lead tending 0.0625 large epoch see fig indicates standard qnn encode cnot without hidden layer figure truth table cnot gate constructed qnn illustrated schematic configuration multi-qubit interaction term _1^z _2^z\ full size image figure cost function different epoch qnn multi-qubit term qnn ony two-qubit interaction particular solid-blue line cost function obtained construct cnot gate toffoli gate dashed-red line fredkin gate dotted-black line illustrated inset cost function value reach 116th 140th 162th epoch three quantum gate respectively indicating gate constructed qnns multi-qubit interaction without hidden layer contrast value respective plateau quantum perceptrons two-qubit interaction full size image figure truth table toffoli gate constructed qnn illustrated schematic configuration multi-qubit interaction term _1^z\hat _2^z _3^z\ full size image qnn multi-qubit term also work constructing toffoli gate without hidden layer truth table qnn toffoli shown fig known controlled-controlled-not gate toffoli gate 3-qubit input output qnn output first two qubits value input ^z_i\ output third qubit aim out,3 _3^z ^z_1 ^z_2\ case propose following neural potential third perceptron aligned _3= _1^z _2^z _3^z b_3 w_\text _1^z _2^z _3^z aligned minimal number multi-qubit term demonstrated fig value dashed-red line cross occurs epoch =140\ large epoch training toffoli gate close similarity previous case standard qnn without hidden layer fails achieve toffoli gate saturates 0.0238 another example successfully constructed qnns including multi-qubit interaction without hidden layer fredkin gate also known controlled-swap gate whose truth table schematic configuration fig case adopted potential third perceptron aligned _3= _1^z _2^z _3^z aligned aligned b_3 w_\text _2^z _3^z aligned according numerical calculation cost function value tends zero shown fig dotted-black line asterisk indicating gate constructed quantum perceptrons without hidden layer saturates value 0.0417 large epoch standard qnn without hidden layer see fig figure truth table fredkin gate constructed qnn illustrated schematic configuration multi-qubit interaction term _2^z\hat _3^z\ full size image discussion shown different application qnns posse multi-qubit interaction meanwhile performance enhanced compared topology qnn without multi-qubit interaction multi-qubit interaction term induce connectivity among quantum perceptrons deviate current network paradigm additive activation due multi-qubit term potential one avoid presence hidden layer without sacrificing approximative power architecture allows address connectivity challenge scaling qnns moreover simple configuration help control efficiency training process training process example shown activation function based adiabatic evolution system used instead one may use shortcut adiabaticity accelerate formation activation function physical register hamiltonian perceptron given neural potential expressed corresponds linear ising hamiltonian higher order interaction model present distinct quantum platform experimentally theoretically although development different platform vary optical ising machine hosting adjustable four-body interaction all-to-all connection large number spin experimentally demonstrated ref moreover four-body interaction designed realized via superconducting quantum interference device squid single shot method executing i-toffoli gate three-qubit gate two control one target qubits proposed ref application currently existing superconducting hardware using resonant microwave-mediated interaction distant electron spin implement multi-qubit potential mark important milestone all-to-all qubit connectivity scalability silicon-based quantum circuit quantum evolution governed term involving six-qubit interaction already implemented trapped-ion system value qubit-qubit interaction tuned allowing architecture used implement different type gate leading variety quantum gate system example considered corresponds particular case multi-qubit interaction physical implementation would depend specific considered platform development quantum hardware highlight potential practical implementation multi-qubit potential qnns promotion quantum hardware qnn protocol respective field boost mutual development method hamiltonian training neural network article propose qnn multi-qubit interaction hamiltonian one perceptron neural potential expressed preparation qnn demonstrate advantage comparison classical counterpart need develop concept improve scalability qnns controlling network depth becomes crucial one main objective develop qnn therefore minimize depth without sacrificing approximative power end explore deviation current network paradigm additive activation include multi-qubit interaction neural potential leading reduction network depth calculation use standard gradient descent train neural network cost function correspondingly weight multi-qubit interaction term l_1 ^z\cdots l_n ^z\ neural potential updated aligned n=1 ^z_ l_1 ^z_ l_n aligned training prime number search train qnn task searching prime number set 2^i\ pair bit containing input output value 2^i n=1 taken input binary number a_1 a_2 a_i corresponding integer belonging set ,2^i -1\ target 0,1\ output network y^n input number prime