introduction spontaneous retinal venous pulsation svp rhythmic change central retinal vein visible adjacent optic disc frequency also closely matched cardiac frequency svps originated result complicated interplay systemic blood pressure intraocular pressure cerebrospinal fluid pressure also known intracranial pressure icp vessel structure stiffness diameter due interaction intraocular intracranial space svps hold clinically significant information relevant range eye brain disease glaucoma intracranial hypertension visual impairment intracranial pressure viip despite clinical significance svp monitoring autonomous objective method svp assessment currently available svps monitored subjectively expert clinician eye svp assessment recognized important marker glaucoma onset progression previous study shown svps evident glaucoma glaucoma suspect healthy individual morgan show svp visible glaucoma case glaucoma suspect healthy instance legler jonas showed svp presence 64.1 glaucoma subject 75.3 healthy case several factor suggested svps reduced glaucoma glaucoma suspect include alteration ocular perfusion pressure fluctuation translaminar pressure gradient downstream increased vascular resistance brain cerebrospinal fluid csf come contact central retinal vein via optic nerve sheath result fluctuation csf directly transverse central retinal vein leading change svp amplitude increase csf pressure aka icp characteristic several neurological condition trauma intracranial mass lesion idiopathic intracranial hypertension hydrocephalus stroke viip experienced astronaut previous study shown svps reduced increasing icp may re-established raising iop icp 5â€“10 collectively presence absence svps clinical indicator normal abnormal level icp respectively statistical structural image analysis model proposed quantify svps mchugh used spectralis optical coherence tomography device record infrared video length retina centered optic disc presence svps assessed subjectively using grading system suggested hedge principal component analysis pca applied moret sequential retinal image detect svp found vital pulsatile sign hidden first component shariflou applied custom-written algorithm based contrast-limited adaptive histogram equalization clahe method proposed fischer measure svp amplitude approach enabled objective measurement svps heavily resource-intensive despite previous attempt best knowledge autonomous method detect svps using fundus video doe exist study developed deep neural network trained retinal fundus video autonomously detect presence absence svps material method dataset retinal image used study obtained publicly available repository retinal video study performed accordance guideline tenet declaration helsinki approved university technology sydney human research ethic committee eth17-1392 informed consent obtained participant following explanation nature study two distinct set fundus video image used develop test performance proposed model fundus video total collected participant attending marsden eye clinic participant recruited subject following inclusion/exclusion criterion inclusion criterion adult i.e. year age normal fundus ophthalmoscopy visible vascular change clear ocular medium visual acuity better 6/12 exclusion criterion persistent vision loss blurred vision floater history laser treatment retina injection either eye history retinal surgery anomaly ocular medium would preclude accurate imaging participant contraindicated imaging fundus imaging system used study e.g hypersensitive light medication cause photosensitivity participant dilated fundoscopy minimum 3-second recording frame per second 46/60 degree field view retina 2.2 image magnification centered optic disc fig co-authors smg reviewed video marked svps present absent occurrence svps assessed within one-disc diameter optic nerve head co-author adjudicated disagreement assessment two grader fundus image used drions-db database public dataset containing fundus image annotated ground truth training optic disc localization model fig figure sample svp drions-db datasets full size image svp classification classify svps developed end-to-end deep model called u3d-net figure show overall structure model u3d-net receives fundus video input classifies svps present absent u3d-net consists two main block optic disc localizer classifier since svp occurs adjacent optic disc u3d-net tuned focus optic disc purpose u3d-net accurate fast localizer process individual video frame locates optic disc image order frame due synchronization cardiac frequency also essential factor taken account design localizer feed sequential frame classifier therefore svps classified based batch sequential frame figure overall structure u3d-net full size image optic disc localizer svps mainly observable central retinal vein located adjacent optic disc therefore prior analyzing retinal video presence absence svps developed model could localize optic disc image purpose study attention mechanism recurrent residual convolutional layer depth-wise separable used depth-wise separable layer decrease computational cost network process includes depth-wise spatial convolution operated separately across every input data channel following supported pointwise 1\times kernel convolution obtain outcome channel o_1 o_2 o_3 o_4 convolution kernel k_1 k_2 k_3 k_4 convolved one input channel i_1 i_2 i_3 i_4 ultimately outcome different kernel fused one output i-th\ kernel o_i\ defined aligned o_i k_i l_i aligned k_i\ o_i\ convolution kernel outcome channel convolution kernel outcome channel respectively figure proposed optic disc localizer number filter depth-wise convolutional layer shown full size image equation establishes number convolution operation needed depth-wise separable layer proposed architecture optic disc localizer fig contains recurrent residual layer attention mechanism architecture eliminated modified original u-net copying cropping block employed concatenation operation resulting highly developed structure improved proficiency fundamental idea recurrent connection reuse map weight keep data output depth-wise separable convolution layer return layer input passing next layer also residual unit assist avoiding vanishing gradient problem training hence feature extraction recurrent residual convolutional layer ensures compelling feature representation enabling design accurate optic disc localizer localizer model trained attention gate thoroughly learns ignore unnecessary area input image focus distinctive feature valuable optic disc detection mixed recurrent residual convolutional layer minimum computational cost improving model accuracy figure display proposed attention value computed pixel assumed represented u_l\ g_l\ respectively gating signal g_l\ specifies attention region per pixel additive attention utilized acquire attention coefficient achieve higher accuracy additive formula present follows aligned q_l w_u u_l w_g g_l b_g q_l aligned weight _1\ _2\ represent activation function relu sigmoid respectively b_\psi denote bias parameter updated trained based backpropagation technique rather utilizing sampling-based update process finally result multiplication attention coefficient feature map shown follows aligned c_l^ u_1 aligned figure detail rrl block attention gate used optic disc localizer model full size image construction rrl block illustrated fig localization optic disc encompasses contracting expansive path input localization block individual video frame initially passed depth-wise separable convolutional layer filter recurrent convolutional layer utilized final output recurrent convolution layer passed residual layer applied time step second indicating one forward convolution layer supported one recurrent convolutional layer next relu activation function max-pooling operation applied reducing input width height image resolution reduced passing image sequence layer multiple time convolution layer setting used expansive side up-sampling layer lead increased image resolution information obtained contracting path utilized attention gate remove noisy unnecessary response skip connection implemented directly concatenation process merge relevant important activation optic disc localizer model input video frame output segmentation map optic disc shown fig calculating coordinate area optic disc white pixel segmentation map region optic disc characterized finally applying function frame video optic disc region cropped sequence form part drions-db dataset used training validation remaining testing localizer model initial learning rate 0.003 used batch size epoch training order update weight network iteratively rmsprop algorithm used order train evaluate optic disc localization model dice loss function selected since commonly used medical image segmentation learning effective feature representation weight parameter model learned locate optic disc fundus image accurately figure optic disc localization step video frame extraction creating segmentation map u-net localizing optic disc using segmentation map building cropped optic disc video full size image classifier following localization optic disc sequential frame input video passed classifier block u3d-net video frame resized pixel converted grayscale decrease computational time complexity different deep learning network paper evaluated inception dense-resnet resnet long-term recurrent convolutional network lrcn convlstm network chosen used widely medical image video application task network comprise layer convolutional layer pooling layer fully connected layer make label input data also final performance network analyzed next part two characteristic essential video classification spatial static feature within frame temporal dynamic feature sequential frame evaluate performance classifier model classifying svps increase number variety fundus video data augmentation using degree rotation original video used also remove bias due chosen set k-fold cross-validation used svp dataset indiscriminately divided five equal-sized fold partition procedure single fold chosen serve test set rest four fold combined form training set process repeated five time fold serving test set rotating test set fold guarantee algorithm assessed various subset data finally average result calculated enables reliable estimation performance generalization capability structure classifier model based different deep learning structure detail presented follows inception one classifier model used includes inception module pooling convolution layer extract spatial-temporal feature input video real-time shown fig inception-based classifier block consists different layer including input inception module combination convolution batch normalization relu activation function output merge single vector create input next layer max-pooling layer support alternating convolutional layer also dropout layer applied regularization operation limit overfitting finally fully connected layer linked output layer classifies svp status dense-resnet paper use iterative advancement property resnets make densely connected residual network classifying svp call dense-resnet densenets convolution layer densely connected dense-resnet apply dense connectivity resnets module therefore dense-resnet model executes iterative advancement representation step single resnet utilizes dense connectivity get refined multi-scale feature representation hence combining fc-densenets fc-resnets single model merges advantage architecture brings architecture use advantage dense connectivity residual pattern namely iterative refinement representation gradient flow multi-scale feature combination deep supervision connectivity pattern dense-resnet shown fig first input processed conv3d convolution followed max-pooling operation output fed dense block organized residual block based resnets figure classifier model used detect svp full size image number kernel convolution process cnn equal input map used input also provide output feature map layer outcome add bias term procedure repeated various kernel get desired number output feature map convolution layer followed batch normalization rectified linear unit relu set decrease number input feature map output global-average-pooling dense layer followed final output resnet proposed resnet network based resnets structure resnets present shortcut connection skip signal one layer another layer connection transfer gradient flow model later layer earlier layer leading facilitating training process deep model structure proposed resnet shown fig first input processed conv3d convolution followed max-pooling batch-normalization rectified linear unit relu decrease number input feature map output output fed residual block organized skip connection provide output feature map layer outcome add bias term number kernel conv3d layer residual block first layer conv3d layer resnet kernel size finally global-average-pooling dense layer followed final output long-term recurrent convolutional network lrcn another method utilized detection svp cnn model lstm model trained individually extract spatial feature frame video cnn network used goal pre-trained model employed fine-tuned issue lstm network use feature extracted previous model predict absence presence svp video another method known long-term recurrent convolutional network lrcn used integrates cnn lstm layer single network fig convolutional layer utilized spatial feature extraction video frame spatial feature fed lstm layer time-steps process temporal sequence modeling model directly learns spatiotemporal feature robust end-to-end model also timedistributed wrapper layer utilized provides usage layer every frame video separately creates layer potential take input shape num frame width height num channel layer input shape width height num channel advantageous authorizes input whole video network single shot training proposed lrcn model time-distributed conv2d layer used followed dropout layer maxpooling2d layer conv2d layer extract feature flattened using flatten layer output fed lstm layer dense layer activation softmax apply final result lstm layer model size kernel size conv2d layer pooling size maxpooling2d convlstm approach proposed detecting presence absence svp combination convlstm cell convelstm cell kind lstm model includes convolution function model lstm convolution infixed network make apt identify spatial feature data considering temporal relation method effectively catch spatial connection individual frame temporal connection across various frame video classification consequently convlstm take width height num channel input convolution network whereas simple lstm take input figure structure convolutional lstm convlstm cell full size image overall structure proposed convlstm cell shown fig sigmoid function presented weight layer bias x_t\ input time step hyperbolic tangent function represented tanh also hadamard product operator shown f_t\ forget gate c_t\ cell state i_t\ input gate o_t\ output gate value obtained taking sigmoid function getting x_t\ t-1 equal value forget gate sends range sigmoid function output information previous cell forgotten output value information previous cell wholly memorized also i_t g_t\ gate holding current information catch t-1 x_t\ sigmoid function value take hadamard product operation hyperbolic tangent tanh function sent input gate range g_t\ i_t\ represents direction intensity storing current information formula convlstm cell shown follows aligned f_t= x_t +w_ t-1 t-1 b_f aligned aligned i_t= x_t +w_ t-1 t-1 aligned aligned g_t= x_t +w_ t-1 h-g aligned aligned c_t= f_t t-1 i_t aligned aligned o_t= x_t +w_ t-1 h-o aligned aligned h_t= o_t aligned cell state input gate output gate cell output cell input forget gate tensor original lstm element vector also matrix multiplication considered operation convolution show number presented weight cell original lstm proposed model convlstm used kera layer also convlstm layer catch number kernel filter size needed using convolutional process outcome layer end flattened fed dense layer softmax activation also maxpooling layer used decrease size frame avoid unneeded calculation dropout layer control overfitting proposed model architecture simple number trainable parameter small overall structure proposed method based convlstm shown fig kernel size convlstm hyperbolic tangent tanh activation function applied convlstm2d layer convlstm2d layer maxpooling3d layer pooling size batch normalization layer applied final result passed flatten dense layer analyze best performance every classifier model ran several different experiment modifying number epoch batch size learning rate table summarizes characteristic proposed classifier table characteristic u3d-net classifier full size table result interpreting performance every model various metric utilized include parameter parameter refer true positive true negative false positive false negative respectively accuracy precision recall specificity f1-score negative predictive value npv dice score intersection-over-union iou used evaluating proposed model u3d-net localizer result evaluate proposed optic disc localizer model dice score iou used dice score applied statistical validation factor measure similarity manual segmentation map final segmentation map model iou factor utilized define area overlap two region greater region overlapping brings greater iou factor iou dice factor utilize different method calculate matching image segmentation algorithm outcome ground truth segmentation map figure segmentation map created optic disc localizer versus ground truth one full size image figure sample comparison optic disc segmentation map extracted model ground truth localizer model able achieve dice score 0.95 iou 0.91 table also regard partial evaluation localization performance actual dataset randomly selected number sample dataset average dice iou score given sample 0.87 0.84 respectively table comparison proposed model existing model optic disc localization using drions-db dataset full size table u3d-net classifier result table summarizes sensitivity specificity precision accuracy f-1 score negative predictive value attained classifier model utilizing abovementioned parameter evaluating classifier model k-fold cross-validation used typically result biased model compared technique every observation dataset opportunity come view training test set result demonstrate inception achieved better result table general performance comparison proposed classifier model existing research full size table fig compared area receiver operating characteristic roc curve ass model performance separating presence absence svp figure receiver operating characteristic roc curve different classifier full size image discussion study developed model based recurrent residual u-net utilizes attention mechanism autonomously objectively classify svps present absent fundus video best knowledge first study use deep neural network svp assessment result finding set first benchmark svp assessment using approach previous attempt use computer-aided analysis quantifying svp amplitude resource-intensive require post-video capture analysis solution overcomes shortfall providing approach called u3d-net readily analyze fundus video provide binary classification svp status i.e. present absent svps particularly visible optic disc area ablation u3d-net model i.e. optic disc localizer significantly decreased performance overall model due fact network considered entire region fundus image without specific focus optic disc physiological svps known occur proposed deep learning model based u-net detect optic disc image segmented optic disc fed another time-series deep learning model classify svps fundus video order select best model highest performance classification task trained different time series model including inception dense-resnet resnet lrcn convlstm comparing model performance table inception model outperformed others achieving sensitivity classifying svps comparable recent clinical study reported sensitivity 84.7 76.8 two expert clinician subjectively classified svps present absent model achieved specificity comparable aforementioned study expert clinician scored 89.2 68.6 specificity respectively finally accuracy model comparison 73.1 86.7 accuracy achieved expert clinician study collectively despite relatively low sample size used train evaluate model demonstrated possible develop deep learning framework achieve sensitivity specificity accuracy comparable expert clinician room improvement larger sample size used svp analysis provide significant clinical insight hemodynamic status optic nerve head due anatomical location svps observed central retinal vein direct result hemodynamic interaction intraocular intracranial pressure accordingly svp analysis reveal blood flow dysfunction due ocular neurological condition traditionally svps assessed ophthalmologist clinic using 78d 90d ophthalmic lens however major limitation approach subjectively ass svp subtle vein pulsation easily missed evident previous study reported varying degree svp presence normal glaucoma patient however study used computer-aided analysis retinal video demonstrated svps identifiable almost population pulse amplitude vary nonexistent i.e. diameter expansion clinical evidence i.e. diameter expansion study limitation first used relatively small sample size train evaluate deep learning model despite model performance comparable expert clinician grading second used subjective grading ground truth exact svp amplitude produced computer-aided image analysis program could used study purposely decided use subjective grading ground truth mainly two reason subjective assessment established method clinic thus finding directly translated clinical setting compare finding available subjective study finally used binary classification svp analysis multi-tier grading svps inform enhanced clinical decision-making binary classification svps lay foundation future work area whilst providing evidence overall hemodynamic status optic nerve head conclusion conclusion developed deep learning model named u3d-net objectively analyze retinal fundus video readily provide autonomous classification svp presence absence highest performance model achieved sensitivity specificity accuracy classifying svps serf initial benchmark similar study may carried future significant increase imaging technology model integrated portable fundus ophthalmoscope used scan svp presence however study larger heterogeneous sample size well multi-class labeling needed fully exploit clinical benefit autonomous svp classification