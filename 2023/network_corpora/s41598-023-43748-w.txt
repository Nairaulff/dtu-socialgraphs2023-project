introduction object detection remains challenging research area within computer vision encompassing localization classification object within scene successful advancement computer vision significantly improved accuracy object detection play pivotal role various application traditional approach v–j detector histogram oriented gradient hog local binary pattern lbp deformable part model dpm demonstrated good result term accuracy speed relying handcrafted object feature like edge key point template however limited diversity manual design element make challenging meet high-precision requirement complex object detection task diverse target property recent year object detection method based convolutional neural network cnns gained significant attention outperformed traditional approach leveraging feature automatically extracted cnns instead handcrafted feature breakthrough cnns came alexnet ignited interest neural network deep learning propelling forefront artificial intelligence research subsequent approach overfeat region-based cnn r-cnn introduced alexnet-based categorization positioning detection refined object proposal technique based cnns respectively development led deep learning-based object detection method becoming prominent research area fast r-cnn faster r-cnn subsequently introduced enhance speed r-cnn series method employing selective search regional proposal network rpn instead sliding window search simplifying region proposal generation improving object detection time typically object detection network based sliding window rpn framework consist two stage candidate-region generation classification however two-stage process often hinders real-time performance due inherent low speed look yolo method representative one-stage approach address issue treating object identification regression problem generating prediction boundary box category simultaneously inputting image neural network unlike two-stage method yolo directly train single convolutional network candidate generation end-to-end classification resulting real-time object detection performance subsequently one-stage approach single-shot detection ssd retinanet proposed improving speed accuracy object detection among various one-stage detector yolo classical one-stage object detection algorithm gained popularity industrial detection due remarkable speed high accuracy yolo application evolved time yolov2 yolo9000 yolov3 significantly enhancing object detection accuracy speed compared original yolo approach several enhancement technique based yolo continually improved effectiveness also found application various domain uav-based traffic monitoring approach achieved favorable outcome enhancing yolo different perspective yolov4 improved backbone network structure introduced feature fusion mechanism enhance interaction target feature resulting efficient accurate model high mean average precision map however yolov4 algorithm bounding box prediction strategy predicts center coordinate width height box limitation dealing object whose distinctive feature centered within bounding box target significant asymmetric characteristic rigid bounding box prediction method fails fully exploit object asymmetric property thereby limiting detection accuracy improvement address limitation propose object detection approach called kr–al–yolo keypoint regression angle loss based yolov4 kr–al–yolo optimizes bounding box regression network model introducing keypoint regression strategy additionally novel angle loss function designed adapt new regression strategy effectively updating network model parameter enhancing algorithm accuracy improved feature fusion technique also introduced reinforce original feature fusion yolov4 progression time numerous improved version yolo series algorithm proposed yolov5 yolov6 yolov7 yolov8 method shown significant advancement accuracy speed object detection compared yolov4 instance yolov5 refined network architecture based yolov4 replacing activation function leaky relu transitioning cbm cbl structure incorporating focus module enhance receptive field convolution process yolov6 focused lightweighting model industrial application resulting improved speed yolov7 made substantial improvement model structure csp elan convolutional strategy conv repconv label assignment method leading notable performance enhancement yolov8 drew inspiration yolov7 elan structure substituted structure c2f replaced head section decoupled head structure regression approach also shifted anchor-based anchor-free loss computation introduced taskalignedassigner positive sample allocation strategy advancement collectively position yolov8 one cutting-edge method available however yolov4 remains widely utilized practical project thus objective revolves around validating incorporating proposed technique within yolov4 framework paper present kr–al–yolo approach improves upon yolov4 introducing keypoint regression strategy instead center point regression model trained regress prediction box flexible format leveraging asymmetry left right feature well upper lower feature target object regard location inside object bounding box positive keypoint four offset detect object design native angle-loss function refine network model parameter improving algorithm accuracy furthermore condidering effectiveness bifpn feature fusion handling diverse object scale successful integration state-of-the-art object detection model introduce enhanced feature fusion method bolster yolov4 capability proposed kr–al–yolo approach achieves higher map yolov4 maintaining real-time detection speed main contribution paper follows introduce kr–al–yolo novel approach within yolov4 framework incorporates keypoint regression strategy angle loss mechanism capitalizing inherent asymmetry object feature model excels regressing prediction box adaptable output format enhancing object localization capability develop original angle-loss function effectively update model network parameter innovative loss function contributes significantly refining algorithm precision thereby leading improved detection accuracy introduce integrate enhanced feature fusion bifpn technique yolov4 architecture technique serve bolster model overall performance augmenting ability extract meaningful object representation proposed kr–al–yolo method seamlessly incorporates advancement resulting substantial enhancement baseline yolov4 model detection capability rest paper organized follows related work section provides brief review related work method section explains proposed approach detail experiment section present experimental result discussion finally conclusion section concludes paper related work object detection witnessed significant advancement two general category cnn-based approach anchor-based anchor-free method section provide overview approach anchor-based object detector anchor-based detector utilize predefined anchor box various size predict bounding box girshick introduced r-cnn first object detection method leverage cnns feature extraction employed cnns perform convolutional operation candidate region updated weight using gradient descent automatic feature selection however method suffered large number redundant candidate box impacting speed accuracy address proposed sppnet spatial pyramid pooling network shared computation across multiple region within cnn forward pas thereby accelerating r-cnn subsequent method fast r-cnn faster r-cnn introduced selective search region proposal network rpn respectively simplify region proposal generation enhance detection speed liu proposed ssd achieved good performance small object independently detecting object multiple feature map yolo algorithm variant including yolov2 yolov3 yolov4 yolo-based variant gained significant popularity yolov2 removed constraint grid cell anticipate single object predicted offset desired center point relative grid yolov3 introduced multi-scale fusion feature pyramid network fpn yolov4 optimized calculation efficiency incorporating mosaic data enhancement improved feature fusion using technique spp panet furthermore certain yolo-based approach rsod innovated upon yolo methodology distinct perspective method applied diverse domain yielded promising outcome advancement yolo series method made popular choice one-stage object detection due state-of-the-art accuracy real-time performance anchor-free object detector anchor-free method typically consider object center point pre-defined/self-learned keypoints define positive sample predict bounding box yolov1 instance divide image grid grid cell containing object center predict bounding box densebox focus filled circle object center identification directly predicts bounding box cornernet predicts top-left bottom-right corner object defining bounding box based keypoints however distinguishing corner dense object becomes challenging centernet address employing cascade corner pooling center pooling collect information corner central region respectively resulting improved precision recall fcos analyzes difference anchor-based anchor-free detector introduces adaptive training sample selection bridge gap zhang propose learning-to-match ltm method enables flexible anchor matching formulating detector training within maximum likelihood estimation framework extending anchor-free paradigm additionally transformer-based approach detr vidt introduced object detection simplifying pipeline directly predicting set object eliminating non-maximum suppression anchor generation step vidt approach introduces reconconfigured attention module enhancing feature extraction capability also employ lightweight neck-free architecture reduce computational cost additionally introduces novel concept token matching knowledge distillation leading improved model performance make vidt one top-performing method object detection currently method paper propose enhanced object detection approach called kr–al–yolo method build upon yolov4 introducing flexible bounding box regression strategy specifically keypoint regression also propose novel angle-loss function improved fusion method integrating multiscale feature object kr–al–yolo model constructed trained achieve accurate object detection original yolov4 network predicts four coordinate bounding box convert coordinate center point width height using predefined formula however object often posse uneven feature distinctive characteristic may align geometric center standard bounding box regression approach assumes equal distance center boundary may suitable object asymmetric feature instead using geometric center bounding box redefine center point network prediction arbitrary keypoint within feature map yolov4 approach selected yolov4 baseline due simplicity high performance yolov4 utilizes cspdarknet53 backbone network panet feature fusion network yolo head prediction employ three feature map different scale detect object input image size 512\ processed cspdarknet53 network extract image feature spp spatial pyramid pooling module enhances receptive field position feature map panet feature fusion network combine top–down transmission semantic feature bottom-up transmission robust localization feature parameter aggregation performed different backbone network various detector level shown fig input image several convolutional layer obtain feature map three scale downsampling factor respectively lower-resolution feature map larger receptive field responsible detecting large object higher-resolution feature map smaller receptive field suitable detecting smaller target yolo divide image grid grid cell predicts target center point object fall within three anchor box assigned grid characterized dimension dimension include center box relative grid cell width height relative entire image confidence prediction object class coco dataset confidence indicates likelihood predicted box contains object figure network architecture kr–al–yolo propose simple yet effective bounding box regression strategy make regression flexible followed reported default network parameter backbone number computed 512\times 512\ input full size image keypoint regression strategy yolo model generates prediction target dimension format represent offset predicted box center point coordinate width height offset predicted object confidence prediction number object category coco dataset respectively four predicted value transformed target center point coordinate width height using yolo position prediction decoding formula yolov4 bounding box regression distance center point left right boundary well upper lower boundary bounding box assumed equal however rigid regression method fails account object prominent asymmetric characteristic resulting low intersection union iou score prediction ground truth moreover significant feature object may necessarily align geometric center feature map instead center gravity within feature map may better capture feature distribution considering gravity center crucial keypoint refining prediction propose straightforward yet effective strategy called keypoint regression introduce flexibility regression process regard location inside object bounding box positive keypoint four offset detect object depicted fig replace four value bounding box center point offset t_x\ t_y\ bounding box size offset t_w\ t_h\ six value keypoint information t^a_ t^a_ distance keypoint boundary bounding box t_l t_t t_r\ t_b\ following yolov4 approach detect object various size different level feature map specifically utilize three level feature map generated cspdarknet53 backbone followed upsampling cbl convolution normalization leaky rectified linear unit module consequently network predicts six coordinate bounding box scale six value converted final prediction output b_l b_t b_r\ b_b\ using following equation aligned array b_x t^a_x c_x b_y t^a_y c_y b_l t_l b_r t_r b_t t_t b_b t_b array aligned aligned =\frac 1+e^ aligned represents sigmoid function denote coordinate top-left corner grid responsible predicting object correspond width height corresponding anchor relative output layer respectively figure simple schematic diagram bounding box prediction method full size image network output dimension scale change n\times n\times 3\times 85\ n\times n\times 3\times 87\ minimum maximum value b_x-b_l\ b_x+b_r\ b_y-b_t\ b_y+b_b\ direction respectively six coordinate determine prediction box enable generation high-quality bounding box thus improving recall precision angle loss figure angle formation diagram full size image keypoint regression method refines localization predicted bounding box incorporating keypoint location distance keypoint boundary coordinated parameter collectively determine position prediction case b_l b_r\ b_t b_b\ keypoint center bounding box coincide resulting angle vector originating top-left corner bottom-right corner towards keypoint fig motivated cosine similarity study introduces novel angle-loss function included overall loss computation backpropagation process total adopted loss function defined aligned loc +l_ conf +l_ prob +l_ angle aligned loc conf prob represent complete iou regression loss confidence loss multi-class cross-entropy classification loss respectively loss component correspond utilized yolov4 angle denotes proposed angle loss measure cosine angle two vector c_a c_a c_a\ represent keypoint top-left bottom-right point respectively fig angle loss value range indicating vector pointing direction indicating orthogonality i.e. perpendicularity vector thus angle loss formulated follows aligned angle 1/n -\cos aligned denotes batch size represents angle two vector _i\ denotes ground truth angle i-th sample _i\ denotes predicted angle i-th sample represents scaling factor control magnitude logits angle calculated based six coordinate b_x b_y b_l b_t b_r\ b_b\ value range -90 aligned aligned _y+\nu ^2+ ^2+ aligned aligned -b_l\ -b_t\ denote coordinate b_r\ b_b\ denote coordinate respectively bifpn feature fusion context object detection task integration low-level physical feature high-level semantic feature commonly employed skip connection hypercolumns enhance overall performance high-level feature capture abstract object semantics low-level feature provide detailed object description however presence substantial semantic gap different level often fails provide robust feature support multiscale visual recognition task objective neck component object detection algorithm aggregate target feature information comprehensively possible aggregation occurs prior feeding object feature information extracted backbone network back detection head approach aim mitigate loss fine-grained information feature information small object lower level interacts semantic information higher level abstraction feature fusion method employed yolov4 panet fpn feature pyramid network efficient feature fusion technique propagates high-level semantic feature top bottom thereby strengthening entire feature pyramid however unidirectional information flow solely enhances semantic information doe transmit positional information fpn transmits shallow feature bottom top shallow feature information becomes attenuated due numerous convolutional layer applied reaching topmost level address issue panet introduces additional path facilitates bidirectional transmission low-level localization feature enabling pairwise aggregation parameter figure network structure diagram changing yolov4 feature fusion mode bifpn full size image study adopts bidirectional feature pyramid network bifpn fusion method enhance yolov4 algorithm achieve comprehensive fusion feature extracted backbone network figure illustrates modified neck section yolov4 compared panet bifpn offer superior feature fusion capability efficient cross-scale connection bifpn streamlines bidirectional network eliminating node one input edge contribute overall feature network furthermore bifpn achieves enhanced feature fusion introducing additional edge original input output node repeating bidirectional path multiple time layer improvement lead effective feature fusion without significant increase computational cost employed bifpn connection mechanism node facilitate improved outcome yolov4 experiment experimental setup implementation datasets ass effectiveness kr–al–yolo approach comparison object detection method particularly yolov4 conducted experiment coco dataset coco2017 dataset utilized object detection experiment comprised 100,000 image encompassing object category specifically coco training dataset consisting 11,726 image employed model training coco validation dataset utilized evaluate performance kr–al–yolo model training experiment conducted gtx titan v100 12g gpu cuda 10.0 cudnn implementation carried using pytorch deep learning framework within python programming language utilizing pycharm platform adopted default network parameter number iteration specified literature baseline result approach introduces regression strategy angle-loss function bifpn feature fusion technique keeping original backbone intact lightweight computational method method hardly impose additional computational burden training inference process result model training inference time remain nearly identical original yolov4 model consistent object detection approach like yolov4 set iou_ pred truth 0.5 initial learning rate set 0.01 cosine-annealing decay learning rate schedule employed adjustment training batch size set total number iteration epoch experiment coco dataset table comparison improvement component proposed method coco test-val2017 full size table table result coco test-val2017 full size table figure object detection using kr–al–yolo coco testing dataset full size image object detection result kr–al–yolo coco test-val2017 dataset presented table well fig table provides comparison performance improvement achieved component kr–al–yolo table compare detection accuracy kr–al–yolo state-of-the-art approach evaluation metric used consistent yolov4 reported result table demonstrates kr–al–yolo yolov4 baseline achieves 0.1 increase average precision 0.4 increase ap_ addition keypoint regression alone notably proposed method exhibit significant improvement detection accuracy small object ap_s\ yolo+al surpasses yolov4 3.2 however accuracy detecting large object lower compared yolov4 due higher sensitivity iou rate bounding box offset small object even slight deviation substantial impact overall position bounding box small object angle-loss function imposes heavier penalty small target model training since deviation lead larger angle small target box table present comparison proposed method state-of-the-art object detection algorithm coco test-val2017 dataset leveraging robust baseline yolov4 employing various training technique proposed detector achieves high detection accuracy surpassing yolov4 efficientdet 0.5 0.4 ap_ respectively approach outperforms vidt-tiny method yolov8-s method across multiple metric however compared vidt-base yolov8-l method approach fall slightly behind various indicator vidt-base yolov8-l method indeed stand advanced object detection technique present primary reason disparity approach built upon yolov4 framework lack integration additional optimization technique enhance algorithmic performance additionally seen table approach doe perform well detecting small object compared state-of-the-art sota method believe certain sota method specifically designed optimizing small object detection rsod likely achieve better result coco dataset come detecting small object rsod method utilizes shallow feature map construct feature pyramid network enhancing extraction fine-grained image feature integrates improved spatial pyramid pooling layer lateral connection feature pyramid network fpn enhance extraction local global image feature employing adaptive weight allocation effectively enhances valuable information suppressing irrelevant detail technique like fine-grained feature pyramid construction adaptive weight allocation potential significantly improve accuracy small object detection providing valuable insight future research endeavor detection result proposed method coco testing dataset visualized fig conclusion paper present kr–al–yolo object detection approach enhances bounding box regression strategy yolov4 kr–al–yolo introduces keypoint regression strategy angle loss improve recall rate overall detection performance additionally feature fusion method employed effectively gather concatenate multiscale feature facilitating comprehensive object feature learning experimental result coco2017 datasets validate superiority kr–al–yolo yolov4 particularly accurate detection small object