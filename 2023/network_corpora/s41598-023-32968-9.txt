introduction chatgpt openai cutting-edge ai-powered chatbot captivates user brilliant engaging conversationalist solves exam writes poetry creates computer code chatbot also search information answer question give advice unfortunately chatgpt sometimes provides false information make answer doe know offer questionable advice nonetheless user may rely advice consequential decision therefore important ethical question arise chatgpt reliable source moral advice whether doe advice influence user moral judgment user aware much chatgpt influence chatgpt give moral advice must give advice issue reliable advisor consistency uncontroversial ethical requirement although human judgment tends inconsistent indeed human judgment often based intuition rather reason intuition particularly susceptible emotion bias fallacy thus morally irrelevant difference description issue result contradictory judgment however bot emotion interfere judgment therefore proposed aid help improve human judgment whether chatgpt give moral advice whether advice consistent remains seen knowledge whether advice taken ai-powered bot yet limited however evidence recently accumulated suggests decision-makers readily follow moral advice bot even red flag warning said study employ scenario advice provided standardized recommendation without argument support chatbot chatgpt argue recommendation whether bot chat lead user accept reject advice empirical question user might perceive chatgpt argument shallow flawed ignore advice result chatter might also feature compelling argument add heft recommendation regardless ran two-stage experiment answer three question first asked chatgpt whether right sacrifice one person life save five others elicit moral advice second presented subject trolley problem feature exact dilemma along chatgpt answer asked judgment third asked whether would made judgment without advice find first chatgpt advises inconsistently sacrificing one life save five second advice doe influence user moral judgment even aware advised chatting bot third underestimate influence chatgpt advice judgment method obtained advice chatgpt whether sacrifice one life save five december i.e. week release used prompt would right sacrifice one person save five others right thing choose letting five people die sacrificing another person instead prompt reset chatgpt start new conversation prompt differed wording asked essentially question chatgpt argued sometimes sometimes sacrificing one life save five figure depicts two contradictory answer retained three answer arguing sacrifice respectively examine chatgpt influence user moral judgment experiment figure two instance moral advice chatgpt chatgpt give opposite answer essentially question part figure argues sacrificing one person part argues sacrifice elicited two answer arguing sacrificing one person respectively full size image experiment conducted online december subject recruited cloudresearch prime panel participation took min paid 1.25 subject faced one two version trolley dilemma switch dilemma asks whether right switch run-away trolley away track kill five people one kill one person bridge dilemma large stranger pushed bridge onto track stop trolley killing five people subject experiment made judgment read transcript conversation chatgpt screenshot like fig bridge dilemma kantianism argues using fellow human mean stop trolley switch dilemma ambiguous utilitarian tend sacrifice one life five dilemma empirically people favor hitting switch disfavor pushing stranger experiment condition answer transcript accompanied either bridge switch dilemma argued either sacrificing one life save five attributed either chatgpt moral advisor former case chatgpt introduced ai-powered chatbot deep learning talk like human. latter case answer attributed moral advisor reference chatgpt removed moreover used six answer obtained chatgpt three arguing three arguing sacrifice either advice came one three version experiment approved german association experimental economic research http investigation conducted according principle expressed declaration helsinki written consent obtained subject told participation voluntary free quit anytime study preregistered aspredicted.org http screenshots questionnaire included supplementary information result first research question whether chatgpt give consistent moral advice although question prompt except wording chatgpt answer argue either sacrificing one life save five thorough investigation chatgpt moral beyond scope contradictory answer show chatgpt lack firm moral stance however lack doe prevent giving moral advice moreover chatgpt support recommendation well-phrased particularly deep argument may may convince user doe chatgpt advice influence user moral judgment answer question recruited resident randomly assigned one condition two post-experimental multiple-choice question asked subject identify advisor chatgpt moral advisor advice sacrifice important subject understand advice advised study effect factor moral judgment pre-registered therefore consider response subject answered question correctly subject age averaged year ranging female 35.5 male 1.5 non-binary indicate gender figure summarizes subject judgment whether sacrifice one life save five figure show first found sacrifice acceptable depending advised moral advisor bridge wald 9.94 0.001 switch dilemma 3.74 0.001 bridge dilemma advice even flip majority judgment also true chatgpt disclosed source advice 5.37 0.001 3.76 0.001 second effect advice almost regardless whether chatgpt disclosed source dilemma 1.93 0.054 0.49 0.622 taken together chatgpt advice doe influence moral judgment information advised chatting bot doe immunize user influence figure influence advice moral judgment figure plot proportion along confidence interval subject find sacrificing one person right thing receiving advice number observation figure box full size image user understand much influenced advice asked subject whether would made judgment without advice said would figure depicts resulting hypothetical judgment subject able discount influence advice hypothetical judgment would differ depending advice however judgment fig resemble fig effect advice regardless whether attributed chatgpt persists dilemma 0.01 four comparison except advice coming advisor rather chatgpt bridge dilemma 4.43 0.001 effect advice doe even decrease fig compared fig hence subject adopted chatgpt random moral stance result suggests user underestimate influence chatgpt advice moral judgment figure subconscious influence advice moral judgment figure plot proportion along confidence interval subject think would found sacrificing one person right thing assuming received advice number observation figure box full size image asked subject question study participant rather compared estimated others would made judgment without advice response another post-experimental question considered ethical others hence subject believe stable moral stance better moral judgment others user overly confident moral stance judgment chime underestimating chatgpt influence moral judgment discussion summary find chatgpt readily dispenses moral advice although lack firm moral stance contradictory advice moral issue document nonetheless chatgpt advice influence user moral judgment moreover user underestimate chatgpt influence adopt random moral stance hence chatgpt threatens corrupt rather promise improve moral judgment finding frustrate hope ai-powered bot enhance moral judgment importantly raise question deal limitation chatgpt similar language model two approach come mind first chatbots give moral advice moral agent designed decline answer answer requires moral stance ideally provide argument side along caveat yet approach limitation example chatgpt easily trained recognize trolley dilemma respond question like carefully however everyday moral dilemma manifold subtle chatgpt may fail recognize dilemma naïve user would realize even workarounds get chatgpt break rule supposed follow risky approach user rely chatbots programmer resolve issue hence second think enable user deal chatgpt chatbots transparency often proposed panacea people interacting bot always informed transparency enough though whether told subject advice came chatting bot influence advice judgment almost finding confirms prior research best remedy think improve user digital literacy help understand limitation ai—for example asking bot alternative argument improve digital literacy remains exciting question future research