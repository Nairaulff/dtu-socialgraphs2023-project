introduction ability predict binding affinity potential drug target protein important fundamental level also crucial success drug discovery early stage drug design theoretical computation binding affinity still need development experimental determination large number small molecule target time-consuming expensive result alternative machine learning method make accurate prediction greatly welcomed widely used field traditional method physics-based meaning rely biophysical model proteins-ligand structure estimate binding affinity various strategy exist within realm physics-based method instance all-atom molecular dynamic method simulate temporal behavior drug-protein complex estimate binding affinity unfortunately rigorous method computationally expensive often require lot expert knowledge domain expertise quantum mechanical calculation encompassing semiempirical density-functional theory coupled-cluster approach also employed binding affinity prediction although method tend offer high accuracy applicability hindered size complexity protein–ligand structure making impractical study larger molecule finally force-field scoring function also used evaluate energy associated complex formed ligand protein scoring function considers bonded non-bonded interaction ligand protein including electrostatic interaction van der waals interaction bonding term method time-consuming compared previous approach sacrifice accuracy prediction machine learning technique specifically deep learning method recently attracted attention ability improve upon traditional physics-based method traditional method need adapted every single protein–ligand pair requiring long computation domain expertise every single binding affinity prediction recent available big datasets making individual prediction longer worth hand data-based method machine learning require one-time training process enabling provide prediction indefinitely minimal computational cost therefore development efficient accurate data-based method crucial development drug design unlike traditional machine learning method deep learning learn directly atomic structure protein–ligand pair without relying hand-curated manually-extracted feature data commonly-used deep learning approach binding affinity prediction three-dimensional convolutional neural network cnn network represent atom property space taking account local molecular structure relationship atom representation used input cnn high-dimensional matrix since million parameter required describe one data sample high dimensionality complex deep learning model required uncover hidden pattern help predict binding affinity training model mean finding optimal value parameter minimize suitable loss function complex model training parameter require longer execution time limit exploration different architecture hyperparameters training process heavily accelerated using powerful gpus however size datasets continues grow crucial scale computational resource like gpus also enhance efficiency algorithm meet demand larger datasets therefore pressing need discover efficient training approach network would enable exploration novel network architecture innovative pre-processing technique advancement hold promise developing highly accurate model accelerate drug design process also instil greater confidence reliability computational method complexity machine learning model also affect generalisation capacity according hoeffding theorem highly complex machine learning model require large amount data reduce variance model prediction stated hoeffding inequality aligned sample aligned error test set error training set measure complexity model sample number data sample least comparable complexity model guarantee low error prediction new data case test data similar enough training data smaller training set still allow good performance nonetheless increasing complexity model always increase chance producing overfitting thus convenient resort simpler machine learning model quantum machine learning method potential solve numerical problem exponentially faster classical method although fault-tolerant quantum computer still available new trend quantum algorithm called noisy intermediate-scale quantum nisq era devoted designing quantum algorithm provide quantum advantage quantum computer available today exponential growth scaling hilbert space dimension quantum computer process large amount data qubits reason combining quantum algorithm machine learning allows reducing complexity classical machine learning method maintaining accuracy managing large datasets crucial field drug design considering remarkable growth available data computational study illustration pdbbind dataset utilized study refer data section included mere complex general set back however number risen approximately sample current version comprises 14,000 sample anticipated grow year consequently imperative develop efficient machine learning model capable handling vast datasets effectively address data revolution hybrid quantum-classical machine learning model emerged promising approach may hold key designing efficient model capable effectively working large amount data paper propose hybrid quantum-classical cnn replacing first convolutional layer quantum circuit effectively reduces number training parameter model result show long quantum circuit properly designed hybrid cnn maintains performance corresponding classical cnn moreover hybrid cnn requires fewer training parameter training time reduced 20–40 depending hardware used training extensively investigate various architecture quantum layer hybrid cnn revealing design quantum layer play crucial role achieving optimal performance therefore study offer optimal strategy designing hybrid cnns excel machine learning task providing valuable insight future advancement field worth noting quantum circuit used work executed using quantum simulation due current limitation quantum hardware quantum layer modified optimized run effectively gpu classical cnn specifically quantum circuit within quantum layer correspond quantum unitary transformation constructed using pytorch tensor design choice enables integrated neural network computational graph facilitating efficient optimization gpu even though training done classical resource additionally provide performance benchmark considering different noise model error probability model result show error probability lower p=0.01\ circuit gate common error mitigation algorithm namely data regression error mitigation accurately mitigate error produced quantum hardware finding clearly indicate hybrid quantum-classical machine learning method potential speed training process classical machine learning method reduce computational resource needed train figure error metric evaluated validation set function training epoch classical cnn left hybrid cnn gate right model seen converge epoch full size image result section present result obtained classical cnn different variation hybrid cnn see classical cnn hybrid quantum-classical cnn section detail performance model evaluated core set pdbbind dataset see data section training validation step done refined set separated training validation set model reduce overfitting training data use early stopping procedure finishing training step performance validation set converged evaluate convergence training process five error metric considered root mean squared error rmse mean absolute error mae coefficient determination squared proportion variation dependent variable binding affinity predictable independent variable prediction model pearson correlation coefficient pearson linear correlation two variable binding affinity prediction model range -1\ +1\ spearman coefficient monotonic correlation coefficient range -1\ +1\ spearman correlation +1\ -1\ occurs variable perfect monotone function figure show evolution five error metric validation set classical cnn hybrid cnn quantum gate see case error metric stabilize epoch training model data could lead overfitting training data thus decreasing generalization capacity reason training model stopped epoch result fig also show pearson spearman coefficient oscillate error metric even training converged reason conclude case rmse mae better measure model convergence figure evaluation five error metric core set comparison hybrid cnn model constructed ising model family 20,50,100,200,300,400,500 gate together classical cnn result horizontal dashed orange line additionally performance smaller classical cnn model number training parameter hybrid cnn given horizontal dotted purple line model trained refined set full size image model trained evaluate performance test set figure show result obtained five error metric evaluated test set model studied work compare performance hybrid model 20–600 quantum gate histogram performance classical cnn horizontal dashed orange line result show general performance hybrid cnn model increase number quantum gate roughly performance classical cnn reached quantum gate point model gate oscillate around classical performance significantly improve number quantum gate therefore conclude number quantum gate doe affect performance model shallow quantum circuit stabilizes quantum circuit achieve certain depth minimal number gate needed achieve classical performance case around quantum gate thus certain choice quantum circuit decreasing complexity cnn doe decrease predictive performance validate claim fig contains performance downsized classical cnn modified model initial convolutional layer entirely omitted despite equivalent number training parameter hybrid cnn model performance core set evaluated using five error metric consideration fall notably short achieved standard classical cnn effective hybrid cnn model hence merely reducing size classical cnn model doe suffice preserve predictive capability achieving optimal performance reducing training time necessitates incorporation additional quantum layer figure also show performance hybrid model constructed ising model bit worse one optimal hybrid model table training time number training parameter classical hybrid cnn trained refined set pdbbind dataset full size table main motivation designing hybrid cnn model reduce complexity thus training time neural network measure complexity doe depend hardware model trained number training parameter table show training parameter classical cnn hybrid cnn model used work seen classical cnn around million parameter hybrid cnns use around million parameter demonstrating reduction model complexity notice number quantum gate quantum layer doe affect number training parameter network since parameter quantum circuit carefully selected fixed training precisely one advantage using quantum reservoir quantum transformation hand training time depend hardware training executed table show training cnns cpu requires much longer execution time using gpus highly accelerates training process thus reducing training time many day hour experiment model trained using cpu two type gpus detail used hardware shown table table hardware specification different device used train classical hybrid cnns full size table seen table improvement training time hybrid model classical varies using powerful gpus reduces difference training time hardware also expensive difference training time case limited difference training parameter hardware-agnostic measure complexity figure fig trained general set full size image analyzing result model trained refined set repeated experiment training model general set general set almost three time data refined set thus training take time computational resource observed model required epoch performance converge validation set performance metric evaluated test set displayed fig see performance result equivalent one model trained refined set performance hybrid model increase number quantum gate converges around gate performance oscillates around classical performance ising model suboptimal performance compared classical cnn hybrid cnn gate result conclude training model general set lead equivalent result training model refined set requires longer training time computational resource cnns widely used model learn data time series image volumetric representation goal unravel hidden pattern input data use predict target thus complexity cnn model highly depends complexity data hybrid quantum-classical cnn model help reduce number parameter neural network maintaining prediction capacity one natural question arises reduction training parameter scale size data let consider sample size number feature size volume side reduction model complexity corresponds number parameter first layer network therefore reduction training parameter scale linearly number feature number training parameter doe explicitly depend since filter applied locally portion data many time needed cover whole sample however dimensionality data increase usually filter needed cnn converge data complexity increase complex model needed learn useful information figure example output quantum circuit used quantum convolutional layer three noise model different error rate easier visualization first output displayed figure full size image figure example output quantum circuit used quantum convolutional layer three noise model error rate p=0.01\ together output error mitigation algorithm easier visualization first output displayed figure full size image table performance error mitigation algorithm evaluated using mean squared error mse tendency accuracy different noise model error rate full size table analyzing result noiseless quantum circuit perform noisy simulation three different quantum channel analyze corresponding performance example output quantum circuit different noise model different error probability shown fig see three noise model reduce probability amplitude circuit output main difference behavior noise model phase damping channel reduces probability amplitude slower two model case error probability reach p=0.03\ quantum information lost since amplitude peak longer distinguished hand error rate smaller p=0.03\ drer algorithm successfully mitigate noisy output example performance drer algorithm p=0.01\ shown fig even though noise quantum device significantly reduces amplitude distribution drer algorithm recover original amplitude significant accuracy every noise model error rate performed hyperparameter optimization obtain best linear model mitigate quantum error result shown table addition evaluating mean squared error mse also evaluate tendency accuracy fraction time drer algorithm modifies output correct direction let noisy noiseless mitigated noisy noiseless mitigated count respectively tendency accuracy measure proportion time mitigated noiseless noisy noiseless table show 0.01\ mse mitigated circuit smaller mse noisy circuit hand p=0.03\ mse mitigated circuit similar even larger mse noisy circuit tendency accuracy barely better random guessing result agrees result fig since noisy simulation p=0.03\ basically constant value table also show tendency accuracy increase error probability decrease depolarizing quantum channel tendency accuracy reach value 0.8 p=0.008\ increase 0.89 p=0.001\ amplitude damping noise seems hardest mitigate since tendency accuracy increase slower tendency accuracy noise model amplitude damping channel introduces non-zero count apart mitigating amplitude noiseless simulation hand tendency accuracy increase faster phase damping channel reach value 0.81 p=0.01\ result show long error rate smaller p=0.01\ drer algorithm successfully mitigate error introduced quantum device quantum convolutional layer gate conclusion understanding binding affinity drug candidate provide valuable insight potential efficacy help identify potential side effect additionally predicting binding affinity help design new molecule bind strongly target protein especially important drug development process dealing new treatment work previously unexplored biological mechanism reason designing efficient computational method accurately predict binding affinity molecule target protein essential speed drug discovery process deep learning method cnns provide promising result aspect since learn directly atomic structure protein–ligand pair unfortunately one biggest challenge deep learning method high complexity network require learning million training parameter fact make training process long costly limiting exploration different network architecture quantum machine learning field seek leverage advantage quantum computing improve machine learning algorithm exponential scaling hilbert space quantum computer handle large high-dimensional datasets speed machine learning algorithm paper present hybrid quantum-classical cnn reduces complexity classical cnn maintaining optimal prediction performance proper design quantum circuit hybrid cnn reduces number training parameter implies reduction training time -40 depending hardware algorithm executed apart testing performance algorithm classical hardware work also prof potential effectiveness method noisy real hardware aided relevant error mitigation technique result show error probability smaller 0.01 commonly-used error mitigation technique accurately recover noiseless output quantum circuit work show quantum machine learning offer potential reduce complexity long training time classical neural network leveraging advantage quantum computing handle large high-dimensional datasets speed machine learning algorithm method section provides overview classical quantum machine learning algorithm used study start discussing pdbbind dataset per-processing method used neural network model architecture classical cnn described processing algorithm architecture classical cnn one ref support reproducible comparable pipeline finally design hybrid quantum-classical cnn described detail data data used study sourced pdbbind database curated subset protein data bank pdb contains collection protein–ligand biomolecular complex manually collected associated publication protein–ligand complex data file contain information morphology type bond constituent atom together protein–ligand binding affinity binding affinity experimentally obtained measuring equilibrium dissociation constant protein–ligand k_d\ inhibition constant k_i\ binding affinity defined -\log k_d/k_i completeness extension pdbbind dataset recently become common benchmark binding affinity prediction biophysics-based machine learning method pdbbind dataset come already split two non-overlapping set general refined set refined set compiled order contain higher-quality complex based several filter regarding binding data e.g complex ic_ k_i\ k_d\ measurement crystal structure e.g low crystal resolution missing fragment complex well nature complex e.g ligand-protein covalent bond binding segregated subset refined set called core set provides small high-quality data collection testing purpose version pdbbind dataset used study general set excluding refined set contains 14,127 complex refined set contains complex core set significantly smaller data sample data processing order train classical hybrid cnns raw pdbbind data transformed first appropriate input format convolutional layer reshaping data appropriate format common processing protocol applied following process ref hydrogen added protein–ligand complex according atom valence partial charge bond solved using ucsf chimera default setting protocol convert pdb file mol2 file molecular file store information atom bond molecular property spatial representation used represent feature data method volume grid capture atomic relationship voxelized space data sample size size dimension space number feature extracted protein–ligand pair use volume space size 48å voxel size size allows covering pocket region without large input size cnn model set dimension space following feature extracted protein–ligand pair c=19\ atom type one-hot encoding element halogen metal atom hybridization give information number bond i.e geometry connecting particular atom neighboring atom take value ^2\ ^3\ hybridization respectively number heavy atom bond heavy atom number bond heteroatoms heteroatoms atom different structural property one-hot encoding hydrophobic aromatic acceptor donor ring property partial charge distribution charge atom result chemical environment molecule type indicates whether protein ligand atom respectively feature extraction process done openbabel tool version 3.1.1.1 van der waals radius used determine size atom voxelized space way atom could occupy one voxels depending van der waals radius atom overlap feature added element-wise resulting representation feature resulted sparse matrix may make training neural network harder since input sample similar zero-valued sample therefore neural network difficulty differentiating useful information noise reason gaussian blur amplitude =1\ applied voxelized feature populating neighbouring atom thus reducing number zero-value voxels figure show representation initial protein–ligand pair two main processing step notice volume representation high-dimensional since million real number needed represent one data sample reason large amount data sample complex neural network model needed make accurate prediction without overfitting training data data processing done independently datasets considered study apart general refined core set partitioned general refined set training validation set split done maintain probability distribution binding affinity training validation set reason binding affinity separated quintiles quintile randomly selected data validation set kept rest training set way obtained training validation set general refined set figure example data sample processing pdbbind dataset protein–ligand pair corresponds 1br6 sample refined set left first step processing feature extraction feature voxelized space middle gaussian blur applied produce dense representation data right full size image classical cnn cnns provided successful result deep learning application type network specialised processing high-dimensional data form spatial array time series image volume name stem fact instead general matrix multiplication employ mathematical convolution least one layer output convolution another array represents information present initial array subtle way way filter convolutional neural network responsible detecting one feature network input kernel matrix free parameter must learned perform optimal feature extraction convolutional operation followed nonlinear activation function add non-linearity system following convolutional layer pooling layer added progressively reduce spatial size array series convolutional pooling layer flattening layer feed-forward layer used combine extracted feature predict final output representation layer cnn shown fig top cnns used multiple application volume image segmentation medical imaging classification human action recognition diagram classical cnn used work shown fig bottom architecture one proposed ref comparison purpose network contains five convolutional layer 64,64,64,128 filter respectively kernel size layer except last one kernel cnn contains two residual connection proposed resnet allow passing gradient next layer without nonlinear activation function batch normalization used convolutional layer use rectified linear unit relu activation function network contains two pooling layer two fully-connected layer neuron respectively figure schematic representation component convolutional neural network top architecture cnn used study bottom proposed ref citeatom full size image hybrid quantum-classical cnn paper propose hybrid quantum-classical cnn designed reduce complexity classical cnn maintaining prediction performance hybrid cnns replace one convolutional layer quantum convolutional layer classical convolutional filter replaced quantum circuit act quantum filter quantum circuit significantly fewer training parameter classical convolutional layer order reduce overall complexity network quantum circuit divided two block data encoding map input data quantum circuit quantum transformation quantum operation applied retrieve information encoded data case hybrid cnn replaces first classical convolutional layer quantum convolutional layer final architecture hybrid cnn depicted fig processed protein–ligand data fed classical quantum convolutional layer output aggregated using residual connection fed subsequent classical convolutional pooling layer rest network classical version architecture first convolutional layer replaced quantum counterpart leaving rest network unchanged figure schematic representation hybrid quantum-classical cnn original data processed classical convolutional layer quantum convolutional layer output layer aggregated result fed set convolutional pooling layer following architecture classical cnn full size image data encoding quantum convolutional layer aim extract local feature input data classical convolutional layer would reason split input data n\times block process block individually given block data encoding process convert quantum state high dimensionality data need find data encoding method minimizes number qubits resulting quantum circuit suitable encoding scale logarithmically dimension block popular data encoding mechanism fulfills property called amplitude encoding requires n^3 qubits encode block however amplitude encoding scheme normalizes block independently produce normalized quantum state therefore different block data would different normalization constant would comparable reason decided choose flexible representation quantum image frqi method normalizes whole image encoding avoiding problem n^3 qubits frqi proposed provide normalized quantum state encodes value colour pixel position image given image n-1 pixel pixel normalized 2\pi encoded state given aligned 2^n i=0 aligned i=0,1 basis computational state normalized since 2^n i=0 1.\ _i\ frqi composed two part encodes color pixel encodes position pixel image simple example 2\times image representation displayed aligned array array aligned =\frac +\sin +\sin +\sin +\sin aligned aligned number qubits needed construct frqi state increase logarithmically number pixel angle image since dimension computational basis increase exponentially number qubits hilbert space ref proven frqi state implemented simple quantum gate hadamard gate cnots r_y\ rotation number quantum gate polynomial number pixel image even though frqi designed colour image generalization block straightforward let block normalized value n^3 2\pi frqi state would given aligned n^3 i=0 n^3 aligned notice difference number angle quantum state n^3\ power i.e n^3 2^l state non-zero component state computational basis therefore choosing n^3\ power mostly exploit use hilbert space reason set n=4\ experiment figure show example scaling number qubits number gate block size number qubits needed frqi encoding n^3 scale logarithmically dimension block hand calculated number gate needed implement frqi real quantum device number gate depends value block _i\ angle value quantum circuit compressed reduce number gate ref author show frqi quantum circuit simplified minimizing boolean expression example number gate scale block size considered block data highest mean absolute sum ensure chose block highly different angle figure show number gate general frqi encoding scale linearly dimension block n^3\ recall frqi serf effective quantum encoding method tailored handling high-dimensional array image volume consequently well-suited quantum convolutional layer however dealing type neural network widespread graph neural network different quantum circuit configuration need considered figure example scaling flexible representation quantum image frqi number qubits scale logarithmically number gate quantum circuit scale linearly dimension block n^3\ full size image quantum transformation data encoded quantum circuit set quantum gate applied perform quantum transformation followed set measurement convert data back classical representation see quantum circuit fig quantum convolutional layer quantum transformation usually parameterized quantum circuit pqc optimal parameter circuit need learned however challenge represented high dimensionality data many quantum complex circuit needed process single data sample splitting image block quantum circuit required span whole sample current hardware limitation number qubits quantum gate also number quantum circuit executed reason possible train whole neural network model current hardware another option would run pqc quantum simulation however case even though quantum layer would still fewer training parameter classical convolutional layer training quantum neural network prepared run gpus compared classical convolutional layer reason even though hybrid model pqcs lower complexity experiment training time longer classical cnn another good alternative using quantum reservoir qrs emerging approach quantum machine learning provided excellent result multiple task exploit quantumness physical system extract useful property data used feed machine learning model gate-based quantum computation random quantum circuit applied initial state encodes input data followed measurement local operator measurement feature extracted model fed classical machine learning algorithm predict desired output main advantage using qrs low complexity model thus easy training strategy instead using pqc finding optimal parameter qrs use carefully selected quantum system training parameter transform input data qrs used temporal task quantum reservoir computing also predict excited property molecular data case design random quantum circuit crucial determine performance quantum machine learning model complex quantum circuit one better exploit quantum property system thus provide useful feature learning target recent work shown majorization principle good indicator complexity performance qrs higher complexity according majorization principle one give better result quantum machine learning task particular seven family quantum circuit different complexity used qrs given family quantum circuit built adding fixed number random quantum gate family g3= cnot family cnot controlled-not gate stand hadamard phase gate provided best result training algorithm moreover performance increased number gate circuit performance reached optimal value remained constant even number gate increased role noise computation also taken account ref paper quantum transformation consists quantum circuit randomly generated gate family qubits measured computational basis providing output quantum convolutional layer hybrid cnn trained qrs quantum gate way evaluate depth influence performance model figure show example output quantum convolutional layer see low number gate quantum layer extract simpler quantum feature higher number gate figure example output quantum convolutional layer different number random gate family together input quantum convolutional layer composed frqi encoding layer followed quantum transformation generated random quantum circuit different number gate taken family full size image another widely used transverse-field ising model case quantum circuit performs time evolution quantum state random transverse-field ising hamiltonian aligned ising j=0 n-1 z_iz_j n-1 x_i aligned x_i\ z_j\ pauli operator acting site -th qubit coefficient h_i\ chosen according ref provides state-of-the-art method select optimal parameter ising model quantum reservoir computing case sampled uniform distribution -j_s/2 j_s/2 h_i constant optimal parameter fulfill h/j_s 0.1\ system evolved time t=10\ compare performance hybrid cnns trained qrs generated family well performance model qrs generated ising model since current quantum computer limited availability high access queue time limit number iterative run training hybrid cnns run using quantum simulation classical hardware code optimized using qiskit pytorch adapted could trained gpus like classical cnn error mitigation one biggest challenge current quantum device presence noise perform noisy quantum operation limited coherence time affect performance quantum algorithm even though quantum circuit used study run using quantum simulation also evaluated corresponding performance noisy quantum circuit using three different noise model small set sample first noise model amplitude damping channel reproduces effect energy dissipation loss energy quantum state environment second noise model described phase damping channel model loss quantum information without loss energy last error model described depolarizing channel case pauli error occurs probability information error model see ref perform noisy simulation error probability p=0.03 0.01 0.008 0.005 0.003 0.001\ error mitigation method aim reduce noise output quantum algorithm executed work data regression error mitigation drer algorithm used mitigate noise quantum circuit drer algorithm train machine learning model correct error noisy quantum circuit obtain training set random quantum circuit gate sampled family executed noisy noiseless simulation thus training set consists pair x_i y_i x_i\ contains count noisy distribution y_i\ contains count noiseless distribution case machine learning model used ridge regression regularized linear model minimizes mean squared error aligned mse n_s i=0 n_s x_i y_i aligned n_s\ number sample training set matrix linear model regularization parameter l^2\ norm drer trained sample derived quantum layer output generated data sourced refined set subsequently performance evaluated using noisy quantum circuit also originating quantum layer output time using data core set case volumetric space divided block size n=8\ leading quantum circuit qubits gate drer algorithm suitable task since machine learning model trained used mitigate multiple quantum circuit requiring classical computational resource make practical use large datasets