introduction delay differential equation dde play crucial role epidemiology population growth many mathematical modeling problem ddes dependent variable depends current state also specific past state one type dde time delay included state derivative called neutral delay differential equation ndde delay term classified three type discrete continuous proportional delay paper focusing proportional ddes nddes one famous example proportional delay differential equation pantograph differential equation first introduced generally exact solution delay differential equation complicated find due model complexity many ddes exact solution various numerical scheme developed year find approximate solution delay differential equation several article illustrate exact numerical method approximate solution ddes nddes artificial neural network anns utilised produce approximate solution differential equation past year neural network approach several ordinary partial differential equation first proposed lagaris approximate solution delivered artificial neural network variety advantage derived approximation solution closed analytic form generalization ability approximation excellent iii discretization derivative required many article approximation artificial neural network solution different differential equation available literature far know study obtaining approximate solution delay differential equation using artificial neural network limited little literature available solving delay differential equation using anns fang solved first-order delay differential equation single delay using ann chih-chun houe obtained approximate solution proportional delay differential equation using ann artificial neural network approach suffer common problem algorithm time-consuming therefore computationally expansive numerical optimization algorithm completely depend trial solution difficult construct higher dimensional problem recently manoj shagun obtained approximate solution differential equation using optimization-free neural network approach trained network weight using elm algorithm author solved first-order pantograph equation using optimization-free ann approach linear first-order delay differential-algebraic equation solved using legendre neural network work present orthogonal neural network extreme learning machine algorithm onn-elm obtain approximate solution higher-order delay differential equation neutral delay differential equation system multiple delay variable coefficient onn model particular functional link neural network flnn case advantage fast accurate learning entire procedure becomes much quicker traditional neural network remove high-cost iteration procedure train network weight using moore-penrose generalized inverse following benefit proposed approach single hidden layer neural network need train output layer weight randomly selecting input layer weight use unsupervised extreme learning machine algorithm train output weight optimization technique used procedure simple implement accurate compared numerical scheme mentioned literature run quickly work considers four different orthogonal polynomials-based neural network legendre neural network hermite neural network iii laguerre neural network chebyshev neural network elm solving ddes nddes system nddes multiple delay variable coefficient interest find orthogonal neural network among four produce accurate solution layout paper follows preliminary section present definition property orthogonal polynomial description considered problem orthogonal neural network section describe architecture orthogonal neural network onn extreme learning algorithm elm error analysis section discus convergence analysis error analysis methodology proposed method presented methodology section various numerical illustration presented numerical illustration section comparative study given comparative analysis section preliminary section first introduce basic definition property orthogonal polynomial throughout paper use p_n represent orthogonal polynomial order orthogonal polynomial definition orthogonal polynomial special class polynomial p_n defined follow orthogonality relation aligned p_m p_n k_n aligned kronecker delta weight function p_n dx\ remark weight function =1\ orthogonal polynomial called legendre polynomial weight function 1-x^ -\frac orthogonal polynomial called chebyshev polynomial first kind weight function =e^ -x^ orthogonal polynomial called hermite polynomial weight function =e^ orthogonal polynomial called laguerre polynomial property orthogonal polynomial following remarkable property set orthogonal polynomial polynomial p_n orthogonal polynomial degree set orthogonal polynomial p_0 p_n set orthogonal polynomial recurrence formula connects three consecutive polynomial sequence i.e. relation n+1 a_nt+b_n -c_np_ n-1 exists constant a_n b_n c_n\ depending zero orthogonal polynomial real number always zero orthogonal polynomial n+1 two zero moore-penrose generalized inverse section moore-penrose generalized inverse introduced problem obtaining solution general linear system may singular matrix may even square moore-penrose generalized inverse used solve difficulty term generalized inverse sometimes referred synonym pseudoinverse precisely define moore-penrose generalized inverse follows definition matrix order n\times moore-penrose generalized inverse matrix order m\times following hold aligned aba bab aligned a^t\ denotes transpose matrix moore-penrose generalized inverse matrix denoted a^\dagger\ definition x_0 ^n\ said minimum norm least-squares solution general linear system ^m\ aligned x_0 ax-y az-y ^n\ aligned euclidean norm word solution x_0\ smallest norm among least-squares solution considered minimum norm least-squares solution general linear system theorem let matrix minimum norm least-squares solution linear equation a^\dagger\ moore-penrose generalized inverse matrix required sufficient problem definition subsection present general form pantograph equation higher order delay differential equation higher order neutral delay differential equation system higher order delay differential equation variable coefficient multiple delay generalized pantograph equation pantograph type equation arises mathematical model study wave motion overhead supply line electric locomotive following equation give generalized form pantograph type equation multiple delay aligned i=1 j=1 aligned initial condition aligned =z_ aligned continuous function q_i t\in t_0 t_1 t_0 t_1\in higher order ddes nddes consider general form higher-order ddes multiple delay aligned =f\left ... k-1 ... aligned initial condition aligned =z_ =z_ k-1 =z_ k-1 aligned 0,1 i=\ ... denotes kth derivative consider general form higher-order nddes multiple delay aligned aligned ... k-1 k+1 k+1 k+1 aligned aligned initial condition aligned =z_ =z_ k-1 =z_ k-1 aligned 0,1 j=1 k+1\ i=1 n_j\ n_j k\in denotes kth derivative higher order system dde consider general form higher order coupled neutral delay differential equation multiple delay aligned aligned ... k-1 ... k+1 k+1 k+1 k+1 k+1 k+1 z_1 =z_ =z_ k-1 =z_ k-1 aligned aligned aligned aligned ... k-1 ... k+1 k+1 k+1 k+1 k+1 k+1 z_2 =z_ =z_ k-1 =z_ k-1 aligned aligned n_j m_j l_j h_j 0,1 j=1 k+1\ i_1=1 n_j\ i_2=1 m_j\ i_3=1 l_j\ i_4=1 h_j\ orthogonal neural network section introduce structure single-layered orthogonal neural network onn model extreme learning machine elm algorithm training network weight structure orthogonal neural network onn orthogonal neural network onn single-layered feed-forward neural network consists one input neuron one output neuron hidden layer eliminated orthogonal functional expansion block architecture orthogonal neural network depicted fig figure structure orthogonal neural network full size image consider 1-dimensional input neuron enhanced pattern obtained orthogonal functional expansion block follows aligned aligned i=0 output orthogonal neural network a_i's\ randomly selected fixed weight 's\ weight trained extreme learning machine elm algorithm given sample point t_j y_j t_j ^n\ y_j j=0,1 single-layer feed-forward neural network n+1 neuron following output aligned i=0 w_ig_i a_it_j j=0,1 aligned g_i\ activation function -th neuron hidden layer 's\ randomly selected fixed weight input layer hidden layer 's\ weight hidden layer output need trained neural network completely approximates given data i.e. output neural network actual data equal following relation hold aligned i=0 w_ig_i a_it_j =y_j.\ j=0,1 aligned equation written matrix form aligned aligned hidden layer output matrix defined follows aligned pmatrix a_0t_0 a_1t_0 a_nt_0 a_0t_1 a_1t_1 a_nt_1 a_0t_m a_1t_m a_nt_m pmatrix aligned w_0 w_1 w_n ^t\ y_0 y_1 y_m ^t\ given training point 's\in ^n\ weight 's\ matrix calculated weight 's\ calculated solving linear system theorem system =\textbf solvable following several case square matrix =\mathbf rectangular matrix =\mathbf minimal least square solution =\textbf pseudo inverse singular matrix =\mathbf +\textbf regularization coefficient set value according specific instance error analysis section discus convergence result error analysis onn-elm method solving delay neutral delay differential equation theorem let single layer feed-forward orthogonal neural network approximate solution one-dimensional neutral delay differential equation m+1\ arbitrary distinct sample point t_j y_j j=0,1 ... t_i y_i orthogonal expansion layer output matrix invertible =0\ theorem let t_0 t_m orthogonal neural network neuron hidden layer absolute error hidden neuron n\rightarrow proof taylor expansion formula give following expression t_0 t_m aligned t_0^+ t_0^+ t-t_0 +\frac t_0^+ t-t_0 ^2+ ... +\frac t-t_0 c\in t_0 t_1 aligned let define z_n =\sum i=0 n-1 z^i t_0^+ t-t_0 ^i\ get aligned -z_n t-t_0 aligned let l=span\ p_0 p_1 p_n let best approximation given =\sum i=0 n-1 w_ip_i a_it w_i\ weight obtained elm algorithm get aligned -\widehat -\bar aligned particular taking =z_n aligned aligned e_n =\vert -\widehat -z_n t-t_0 aligned aligned thus aligned aligned e_n z^n t-t_0 ^n\vert 2^n aligned aligned m=max\vert t-t_0 ^n\vert\ t\in t_0 t_m moreover deduce e_n large value show onn high representational ability approximate exact solution almost error methodology section explains method obtain approximate solution second-order ndde using onn-elm algorithm easily extended higher-order ndde higher-order dde special case higher-order ndde consider general form linear second-order ndde aligned aligned +\sum j=1 m_1 +\sum k=1 m_2 +\sum l=1 m_3 t\in aligned aligned initial condition =z_0\ =z_1\ boundary condition =z_2\ =z_3\ z_0 z_1 z_2 z_3 continuously differentiable function m_1 m_2 m_3 using onn-elm neuron approximate solution obtained form aligned =\sum i=0 aligned w_i\ output weight need trained p_i -th orthogonal polynomial since approximate solution obtained onn-elm algorithm linear combination orthogonal polynomial infinitely differentiable aligned '_n i=0 aligned aligned i=0 aligned aligned j=1 m_1 j=1 m_1 i=0 aligned aligned k=1 m_2 '_n k=1 m_2 i=0 aligned aligned l=1 m_3 l=1 m_3 i=0 aligned substituting second order neutral delay differential equation aligned aligned i=0 i=0 i=0 +\sum i=0 j=1 m_1 +\sum i=0 k=1 m_2 +\sum i=0 l=1 m_3 aligned aligned write aligned i=0 aligned aligned aligned +\sum j=1 m_1 k=1 m_2 +\sum l=1 m_3 aligned aligned using discretization interval a=t_0 t_1 t_m=b\ m\in define f_m=f t_m discretized point satisfied aligned i=0 w_ia_ t_m t_m aligned equation written system equation aligned =b_1 aligned w_0 w_1 w_n aligned a_1= pmatrix t_0 t_0 t_0 t_1 t_1 t_1 t_m t_m t_m pmatrix aligned b_1\ t_0 t_1 t_m case:1 consider initial condition following linear system obtained aligned pmatrix t_0 t_0 t_0 t_1 t_1 t_1 t_m t_m t_m pmatrix pmatrix w_0 w_1 w_n pmatrix pmatrix f_0 f_1 f_m z_0\\ z_1\\ pmatrix aligned case:2 consider boundary condition following linear system ndde obtained aligned pmatrix t_0 t_0 t_0 t_1 t_1 t_1 t_m t_m t_m pmatrix pmatrix w_0 w_1 w_n pmatrix pmatrix f_0 f_1 f_m z_2\\ z_3\\ pmatrix aligned calculate weight vector network use extreme learning algorithm aligned =a^ aligned least square solution note similar methodology used higher order neutral delay differential equation system higher order neutral delay differential equation step solving nddes using onn-elm algorithm discretize domain a=t_0 t_1 t_2 ... t_m=b\ construct approximate solution using orthogonal polynomial activation function aligned i=0 aligned a_i's\ randomly generated fixed weight discrete point substitute approximate solution derivative differential equation boundary condition obtain system equation =\textbf solve system equation =\textbf elm algorithm obtain network weight w_i's\ substitute value w_i's\ get approximate solution dde numerical illustration section considers higher order delay neutral delay differential equation multiple delay variable coefficient also consider system delay neutral delay differential equation test example use special orthogonal polynomial based neural network like legendre neural network laguerre neural network chebyshev neural network hermite neural network show reliability powerfulness presented method compare approximate solution exact solution computation carried using python 3.9.7 intel core i5-8250u cpu 1.60ghz 1.80 ghz window operating system calculate relative error defined follows aligned relative error exact solution numerical solution exact solution aligned example 6.1 consider second-order boundary valued proportional delay differential equation variable coefficient aligned aligned =0.5z +e^ 0.5t z\left -2e^ =e^ aligned aligned exact solution given equation te^ employ four onns obtain approximate solution given second-order dde variable coefficient choose ten uniformly distributed point relative error onns shown fig obtained relative error different orthogonal neural network reported table compare approximate solution exact solution fig table fig clearly show chebyshev polynomial-based onn performs best maximum relative error 5.61\times 10^ table show comparison maximum relative error example 6.1 using legendre laguerre hermite chebyshev neural network various number neuron respective computational time additionally table show four neural network satisfy theorem n=5\ four orthogonal neural network show similar accuracy however chebyshev neural network performs better n=8,11\ table relative error example 6.1 different orthogonal neural network full size table figure comparison exact solution obtained approximate solution example 6.1 full size image figure error graph different orthogonal neural network different number neuron example 6.1 full size image table comparision maximum relative error example 6.1 different number neuron full size table example 6.2 consider second-order neutral delay differential equation multiple delay aligned aligned +z\left +z'\left +0.5z aligned aligned =-t^ -t+1\ t\in 0,1 exact solution given equation =t^ equation solved using four onns architecture ten uniformly distributed training point 6,8 neuron hidden layer relative error different onns 6,8 neuron activation function reported table figure show error graph different orthogonal neural network comparison approximate solution exact solution shown fig table fig conclude given second-order neutral delay differential equation chebyshev polynomial-based onn performs best maximum relative error 7.19\times 10^ -14 additionally table show four neural network satisfy theorem table comparision maximum relative error example 6.2 different number neuron full size table figure error graph different orthogonal neural network different number neuron example 6.2 full size image figure comparison exact solution obtained approximate solution example 6.2 full size image table relative error example 6.2 different orthogonal neural network full size table example 6.3 consider second-order neutral delay differential equation variable coefficient aligned aligned =z'\left -\frac 0,1 aligned aligned exact solution given equation =t^2+1\ obtain approximate solution given equation use four onns ten uniformly distributed training point 0,1 8,9 neuron activation function hidden layer relative error different onns different number neuron reported table exact approximate solution compared fig figure show absolute relative error four special onns table fig conclude given second-order neutral delay differential equation chebyshev polynomial-based onn provides best accurate solution maximum relative error 2.29\times 10^ -15 additionally table show four neural network satisfy theorem figure error graph different orthogonal neural network different number neuron example 6.3 full size image figure comparison exact solution obtained approximate solution example 6.3 full size image table relative error example−6.3 different orthogonal neural network full size table table comparision maximum relative error example 6.3 different number neuron full size table example 6.4 consider third-order pantograph equation aligned aligned =tz -z\left +tcos +cos\left 0,1 =-1 aligned aligned exact solution given equation =cos obtain approximate solution given equation use four onns ten uniformly distributed training point 0,1 8,11,13 neuron activation function hidden layer relative error different onns different number neuron activation function reported table exact approximate solution compared fig figure show maximum relative error four special onns different number neuron table fig conclude given third-order neutral delay differential equation chebyshev polynomial-based onn provides best accurate solution maximum relative error 3.77\times 10^ -10 additionally table show four orthogonal neural network satisfy theorem table comparision maximum relative error example 6.4 different number neuron full size table figure comparison exact solution obtained approximate solution example 6.4 full size image figure error graph different orthogonal neural network different number neuron example 6.4 full size image table relative error example 6.4 different orthogonal neural network full size table comparative analysis section describes comparative study proposed approach 1st-order pantograph equation system pantograph equation neural network approach example 7.1 consider pantograph equation variable coefficient multiple delay aligned aligned =0.5z +0.5e^ 0.5t z\left +\frac tz\left aligned aligned =\frac 12sin +4e^ sin -8cos +3te^ sin exact solution given equation =sin employ four onns obtain approximate solution given pantograph equation multiple delay choose eight uniformly distributed point 5,8 neuron hidden layer relative error four onns different number neuron shown fig obtained relative error different orthogonal neural network reported table compare approximate solution exact solution fig table fig clearly show chebyshev polynomial-based onn performs best maximum relative error 3.40\times 10^ -11 maximum relative error simple feed-forward neural network fnn method 4.05\times 10^ -10 maximum relative error proposed flnn-based onn method 3.40\times 10^ -11 comparison show onn method obtain better accuracy solution simple fnn additionally table show four orthogonal neural network satisfy theorem table comparision maximum relative error example 7.1 different number neuron full size table figure comparison exact solution obtained approximate solution example 7.1 full size image figure error graph different orthogonal neural network different number neuron example 7.1 full size image example 7.2 consider system pantograph equation aligned aligned =z_ -z_ +z_ -e^ 0.5t +e^ =-z_ -z_ -z_ +e^ -0.5t +e^ aligned aligned exact solution given system pantograph equation z_1 =e^ z_2 =e^ obtain approximate solution given system ddes use four onns twelve uniformly distributed training point 0,1 5,7 neuron orthogonal functional expansion block activation function relative error different onns 5,7 neuron activation function reported table comparison exact solution approximate solution presented fig figure show absolute relative error four special onns exact solution table conclude given system delay differential equation chebyshev polynomial-based onn provides best accurate solution z_1 z_2 maximum relative error 1.60\times 10^ 5.11\times 10^ -11 respectively maximum relative error simple feed-forward neural network fnn method z_1 z_2 twelve training point 1.93\times 10^ 2.42\times 10^ respectively maximum relative error proposed flnn-based onn method z_1 z_2 twelve training point 1.60\times 10^ 5.11\times 10^ -10 respectively comparison show onn method obtain better accuracy solution simple fnn additionally table show four orthogonal neural network satisfy theorem table comparision maximum relative error z_1 example 7.2 different number neuron full size table table comparision maximum relative error z_2 example 7.2 different number neuron full size table figure comparison exact solution z_1 obtained approximate solution example 7.2 full size image figure comparison exact solution z_2 obtained approximate solution example 7.2 full size image figure error graph z_1 different orthogonal neural network different number neuron example 7.2 full size image figure error graph z_2 different orthogonal neural network different number neuron example 7.2 full size image example 7.3 consider system pantograph equation aligned aligned +z_ -2z_ =z_ 0.2t +z_ -z_ 0.3t -2z_ -z_ 0.3t +z_ 0.5 +f_1 -z_ =z_ -z_ +3z_ 0.5t -z_ 0.5t +z_ 0.3t +z_ 0.7t +f_2 -2z_ =z_ -z_ 0.8t +3z_ -z_ 0.2t +z_ 0.8t +f_3 aligned aligned =cos 0.3t -sin 0.2t -sin +e^ 0.3t -e^ 0.5t =-cos 0.3t +cos 0.5t -3sin 0.5t +cos -e^ 0.7t +e^ =-cos 0.8t +sin 0.2t -3cos -2sin +e^ 0.8t -2e^ exact solution given system pantograph equation z_1 =sin z_2 =cos z_3 =e^ obtain approximate solution given system ddes use four onns ten uniformly distributed training point 0,1 7,10 neuron orthogonal functional expansion block activation function relative error different onns 7,10 neuron activation function reported table comparison exact solution approximate solution presented fig figure show absolute relative error four special onns exact solution table conclude given system delay differential equation chebyshev polynomial-based onn provides best accurate solution z_1 z_2 z_3 maximum relative error 1.98\times 10^ -10 3.11\times 10^ -10 5.74\times 10^ respectively maximum relative error simple feed-forward neural network fnn method z_1 z_2 z_3 ten training point 8.78\times 10^ 1.42\times 10^ 1.93\times 10^ respectively maximum relative error proposed flnn-based onn method z_1 z_2 z_3 ten training point 1.98\times 10^ -10 3.11\times 10^ -10 5.74\times 10^ respectively comparison show onn method obtain better accuracy solution simple fnn additionally table show four orthogonal neural network satisfy theorem table comparision maximum relative error z_1 example 7.3 different number neuron full size table table comparision maximum relative error z_2 example 7.3 different number neuron full size table table comparision maximum relative error z_3 example 7.3 different number neuron full size table figure error graph z_1 different orthogonal neural network different number neuron example 7.3 full size image figure comparison exact solution z_1 obtained approximate solution example 7.3 full size image figure comparison exact solution z_2 obtained approximate solution example 7.3 full size image figure comparison exact solution z_3 obtained approximate solution example 7.3 full size image figure error graph z_2 different orthogonal neural network different number neuron example 7.3 full size image figure error graph z_3 different orthogonal neural network different number neuron example 7.3 full size image conclusion paper obtained approximate solution higher order nddes well system ddes multiple delay variable coefficient using four single-layer orthogonal polynomial-based neural network legendre neural network chebyshev neural network iii hermite neural network laguerre neural network training network weight elm algorithm used proved relative error exact solution approximate solution obtained onns order number neuron shown orthogonal polynomial-based neural network provide approximate solution good agreement exact solution however observed among four onns chebyshev neural network provides accurate result result section demonstrate proposed method simple implement powerful mathematical technique obtaining approximate solution higher order nddes well system ddes