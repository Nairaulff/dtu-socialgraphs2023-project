introduction colorectal cancer crc leading cause cancer mortality globally colorectal cancer evolve adenomatous polyp making early detection removal polyp critical crc prevention treatment colonoscopy gold standard detecting removing polyp develop crc however accurately identifying segmenting polyp colonoscopy complex task due diversity polyp term shape size texture lead missed misdiagnosed polyp seriously harm patient health machine learning algorithm particularly convolutional neural network cnns shown promising result medical image segmentation applied polyp detection segmentation deep learning algorithm achieve high precision typically require large amount labeled data costly time-consuming obtain effort improve accuracy efficiency polyp segmentation researcher developed various deep learning architecture employ different technique address complex task example architecture used polyp segmentation include u-net fcn variant u-net++ modified u-net mu-net resunet++ h-denseunet method achieve precise segmentation result performance may robust faced wide range polyp characteristic study present novel supervised convolutional neural network architecture image segmentation encoder-decoder structure u-net architecture significant difference key feature architecture combination custom-designed convolutional block residual downsampling convolutional block enables model accurately locate predict border polyp small margin error incorporating residual downsampling model utilize initial image information resolution level encoder segment improving performance also used deeplabv3 atrous convolution capturing spacial information residual block resunet++ enhanced feature extraction main contribution paper custom-built convolutional block duck deep understanding convolutional kernel allows in-depth feature selection enabling model locate polyp target accurately correctly predict border method residual downsampling allows use initial image information resolution level encoder segment way network always original field view alongside processed input image model doe use external module trained target dataset pre-training kind method accurately identifies polyp regardless number shape size texture extensive experiment prove method achieves good performance lead existing method several benchmark datasets related work convolutional neural network automatic polyp segmentation crucial clinical practice reduce cancer mortality rate medical image segmentation task usually employ convolutional neural network several widely utilized architecture applied problem one architecture u-net encoder-decoder model developed initially biomedical image segmentation u-net exhibit advantage relatively simple efficient still achieving good performance various medical image segmentation task however may struggle complex varied input image alternative method may suitable case pranet cnn architecture specifically designed automatic polyp segmentation colonoscopy image employ parallel partial decoder extract high-level feature image generate global map initial guidance following processing step furthermore utilizes reverse attention module mine boundary cue help establish relationship different region image boundary pranet also incorporates recurrent cooperation mechanism correct misaligned prediction improve segmentation accuracy result evaluation indicate pranet significantly improves segmentation accuracy advantage term real-time processing efficiency reaching speed frame per second deeplabv3 extension deeplabv3 architecture semantic image segmentation employ atrous convolution allow dilated field view extraction feature multiple scale improve capture long-range contextual dependency approach enables accurate segmentation object complex shape large-scale variation also requires computation may slower train infer hrnetv2 cnn architecture human pose estimation utilizes fully connected style-like architecture share multi-scale information layer different resolution architecture improve performance small blurry object may prone overfitting require data achieve good performance cnns designed explicitly automatic polyp segmentation include resunet incorporates residual block enhance location information polyp hardnet-dfus combine custom-built encoder block called hardblock decoder lawin transformer improve accuracy inference speed resunet leverage powerful expressive capacity residual block may require data computation achieve good performance hardnet-dfus designed real-time prediction mind may sacrifice accuracy favor faster inference colonformer utilizes attention mechanism encoder includes refinement module attention axis different resolution achieve refined output maintaining decoder similar classical u-net attention mechanism effective handling large complex input image may require computation challenging optimize method msrf-net cnn architecture specifically designed medical image segmentation utilizes unique dual-scale dense fusion dsdf block exchange multi-scale feature varying receptive field allowing preservation resolution improved information flow msrf sub-network employ series dsdf block perform multi-scale fusion enabling propagation high-level low-level feature accurate segmentation however one limitation method may perform well low-contrast image transformer previously mentioned method achieved good result automatic polyp segmentation approach utilize transformer encoder perform particularly well task model typically use pre-trained vision transformer encoder trained large dataset imagenet extract relevant feature input image feature fed decoder process multi-scale feature combine single final output example approach include fcn-transformer ssformer-l achieved state-of-the-art sota performance kvasir segmentation dataset time release use transformer gained traction field computer vision past year widely used field natural language processing nlp shown spectacular result retaining global context subject hand vision-transformers vit like nlp counterpart make use mechanism called attention aggregate global context extract relevant information large image patch vits seem perform well field traditional cnn method like efficientnetv2 outperformed popular image classification datasets imagenet cifar-10 proving efficient cnn method still developed proposed method explores benefit traditional cnns vit-based architecture biomedical image segmentation still yield substantial improvement accuracy metric overall field active area research various approach proposed evaluated thus research needed determine model optimal design training strategy essential carefully consider trade-off accuracy computational efficiency performance metric selecting method specific application methodology proposed polyp segmentation solution consists two novel main component first novel convolutional block called duck six variation convolutional block parallel allow network train whichever deems best novel convolutional block allows network train critical part precisely one drawback crush fine detail subsequent layer second novel contribution keep low-level detail adding secondary u-net downscaling layer doe process image keep low-level detail intact present detail explaining high-level architecture convolutional block model architecture proposed architecture fig encoder-decoder formula u-net architecture three significant difference figure duck-net architecture full size image firstly replace pair convolutional block classically used u-net novel duck block step except last one allows model capture detail step sacrificing finer low-level detail exact detail block explanation behind work detailed last downsampling part chose four residual block image size downscaled five time smaller largest simulated kernel size duck thus would able take full advantage small scale secondly address issue caused novel block losing fine detail implemented secondary downscaling layer doe implement convolutional processing output step layer fed main downscaling layer using addition employ convolution stride downscale image behaves better max pooling model learn essential part keep lastly used addition instead concatenation every time combined two output similar linknet observed produce better result using memory computational resource also mean step need half number parameter upscaling part match output size downscaling part study utilized parameter filter size modify depth convolutional layer comprehensive experimentation determined model incorporating filter serf optimal representation smaller model model incorporating filter represents larger model effectively block component residual block fig first introduced resunet++ paper first component novel duck purpose understand small detail make polyp using multiple small convolution usually good idea many mean network difficulty training understanding feature look use combination one two three residual block simulate kernel size figure residual block full size image novel midscope fig widescope fig block use dilated convolution reduce parameter needed simulate larger kernel allowing network understand higher-level feature better work spreading nine cell would typically kernel larger area two block aim learn prominent feature require little attention detail dilation effect side effect losing information midscope cell simulates kernel size widescope simulates kernel size figure midscope block full size image figure widescope block full size image separated block fig third way simulating big kernel main idea behind combining kernel kernel result behavior similar kernel however method encounter drawback related concept known diagonality essentially diagonality implies capacity convolutional layer capture sustain spatial detail linked diagonal pattern image feature intrinsic structure conventional convolutional kernel retains diagonal element owing bidimensional characteristic enabling capture spatial connection vertical horizontal direction also encompasses diagonal aspect yet distinctive processing approach separable convolution followed filter operate one dimension time potentially obstructs capacity efficiently encode diagonal feature lead so-called loss diagonality diagonal relationship prove useful detecting specific intricate pattern shape within image hence block designed compensate figure separated block full size image duck fig novel convolutional block combine previously mentioned block used parallel network use behavior deems best step idea behind wide variety kernel size simulated three different way mean network decide compensate drawback one way simulate kernel another variety kernel size mean find general area target also finding edge correctly incorporated one–two–three combination residual block based empirical observation suggesting significant performance gain multiple instance midscope widescope separable block essentially computational resource required addition justify marginal improvement result result novel block search low-level high-level feature simultaneously auspicious result figure duck block full size image model evaluation accurate evaluation crucial determining effectiveness various neural network architecture several metric proposed purpose chosen focus five widely used dice coefficient jaccard index precision recall accuracy dice coefficient also known score measure overlap two set range value indicates perfect overlap indicates overlap jaccard index similar dice coefficient measure overlap two set expressed ratio size intersection size union set precision measure positive predictive value classifier proportion true positive prediction among positive prediction recall also known sensitivity true positive rate measure proportion true positive prediction among actual positive instance accuracy overall correct classification rate proportion correct prediction made classifier prediction made dice\ coefficient 2tp 2tp jaccard\ index precision recall accuracy dice loss loss function commonly used medical image segmentation task dice coefficient measure overlap two set context image segmentation dice loss used penalize model incorrect incomplete segmentation object image using dice loss medical image segmentation several benefit dice coefficient widely used evaluate performance image segmentation model using dice loss help optimize model metric dice loss handle class imbalance often concern medical image segmentation class may much prevalent others dice loss differentiable allows used conjunction gradient-based optimization algorithm dice loss calculated follows dice\ loss dice\ coefficient experiment implementation detail ensure fairness reproducibility comparison used identical training validation testing set model evaluated study specifically dataset randomly split three subset training validation testing 80:10:10 percent ratio motivation behind choosing random data split ensure selection process unbiased comparison across different model fair possible provide split datasets data availability section result easily reproducible designed experimental setup validate model state-of-the-art performance unseen data showcasing ability generalize across different context first conducted test dataset independently compared model performance method prove generalization capability model trained model one dataset tested another namely kvasir-seg cvc-clinicdb datasets vice versa way could effectively gauge adaptability predictive accuracy novel unseen data cross-dataset testing yielded strong result emphasizing model generalization capability even absence extra pre-training data trained model predict binary segmentation map rgb image reduce computational cost image rescaled pixel convention set several published paper due aliasing issue rescaling image used lanczos filter preserve quality used rmsprop optimizer learning rate 0.0001 trained model batch size epoch used tensorflow framework implement architecture trained model using nvidia a100 gpu data augmentation implemented data augmentation training set significantly improving model generalization capability point regularization technique dropout unnecessary library used implement augmentation albumenations involved randomly applying transformation training image resulting significantly different variation original image helping model better generalize unseen data epoch randomly augmented training input using augmentation inspired previous work modified fit specific need model augmentation technique used horizontal vertical flip color jitter brightness factor uniformly sampled 0.6 1.6 contrast 0.2 saturation factor 0.1 hue factor 0.01 affine transforms rotation angle sampled uniformly 180° 180° horizontal vertical translation magnitude sampled uniformly 0.125 0.125 scaling magnitude sampled uniformly 0.5 1.5 shearing angle sampled uniformly 22.5° 22° augmentation color jitter applied image rest applied consistently image corresponding segmentation map datasets perform experiment popular four datasets polyp segmentation kvasir-seg cvc-clinicdb cvc-colondb etis-laribpolypdb kvasir-seg dataset contains polyp image corresponding ground truth different resolution ranging pixel cvc-clinicdb dataset contains polyp image corresponding ground truth resolution pixel etis-laribpolypdb dataset contains polyp image corresponding ground truth resolution pixel cvc-colondb dataset contains polyp image corresponding ground truth resolution pixel result table show comparison different method using mean dice jaccard index precision recall accuracy metric also included calculation standard deviation analysis strengthen evaluation model performance measure provides insight variability used metric among different model thus giving understanding potential range performance employing method statistical perspective complement raw performance figure offering comprehensive view model performance consistency reliability ensure fair comparison utilized image augmentation base u-net model augmentation consistent used model also provide clearer understanding result included information table regarding method pre-trained ablation study part goal ass efficiency proposed duck block compared standard convolutional block controlled like-for-like test setup table provides comprehensive summary result derived ablation study conducted performance novel duck block compared simple convolutional block context duck-net architecture using kvasir-seg dataset shown table duck block consistently outperformed simple convolutional block across tested performance metric advantage evident filter size model finding indicate duck block significantly enhances duck-net performance leading precise accurate result analysis support utility integrating duck block within duck-net architecture application demand high-performing convolutional block discussion supervised learning proven effective many task medical image domain classification detection segmentation advance field crucial improving medical care developing high-performing model played central role advancement hence developing method require minimal annotated data great benefit clinical community work present state-of-the-art sota model automatic polyp segmentation colonoscopy image experiment demonstrate model outperforms existing model various benchmark particularly generalizability handling polyp varying shape size texture contributed automated processing colonoscopy image aid medical staff lesion detection classification model combine strength wide information extraction deeplabv3+ atrous convolution rich information extraction large yet efficient kernel separable module localize target polyp accurately table show experimental result sota polyp segmentation datasets kvasir-seg cvc-clinicdb etis-laribpolypdb cvc-colondb model outperforms architecture highlighting ability learn key polyp feature small amount data time table show capacity generalize one dataset apply different one kvasir-seg cvc-clinicdb even though show excellent result doe achieve sota result fcn-transformer advantage extra training data pre-training help generalize feature dataset-specific way furthermore model capacity handle real-world scenario demonstrated use multiple datasets containing image vary significantly one another datasets include image international patient different background representing wide range scenario model could encounter real-world application table segmentation accuracy dice coefficient jaccard index accuracy recall precision kvasir-seg dataset full size table table segmentation accuracy dice coefficient jaccard index accuracy recall precision cvc-clinicdb dataset full size table table segmentation accuracy dice coefficient jaccard index accuracy recall precision etis-laribpolypdb dataset full size table table segmentation accuracy dice coefficient jaccard index accuracy recall precision cvc-colondb dataset full size table table segmentation accuracy dice coefficient jaccard index accuracy recall precision cvc-clinicdb dataset model trained kvasir-seg dataset full size table table segmentation accuracy dice coefficient jaccard index accuracy recall precision kvasir-seg dataset model trained cvc-clinicdb dataset full size table table show result ablation study conducted proposed duck block consistent outperformance compared simple convolutional block support hypothesis novel structure enhances effectiveness image segmentation task future research might build foundation exploring duck block performs architecture task validate leverage advantage table ablation study result dice coefficient jaccard index accuracy recall precision kvasir-seg dataset full size table fig show three example polyp image kvasir-seg test set compare prediction novel architecture duck-net evaluated across different model size filter size existing architecture fcb-transformer hardnet-dfus hrnetv2 msrf-net pranet u-net figure comparison predicted polyp mask full size image regarding computational complexity implication integrating additional convolutional block within duck block structure consider two main factor computational cost memory usage new block mean network operation instance conventional convolutional layer kernel size nxn computational complexity furthermore residual block duck would require network perform addition operation potentially non-linear operation sigmoid activation hand memory usage also grows addition convolutional block every layer within deep learning model must store weight gradient neuron activation meaning block added model requires memory store quantity training inference complexity consideration optimization like dilated convolution separable convolution used provide similar representational power standard convolution fewer parameter thus computational cost ultimately using block duck lead computational complexity advantage allows network capture feature different scale compensate drawback different type convolution could improve model performance complex task nevertheless benefit must balanced increased resource requirement particularly deploying model resource-constrained environment model generally exhibit high level prediction accuracy observed limitation performance dealing polyp whose color blend background resulting indistinct border investigation needed address issue enhance model ability locate predict border polyp accurately conclusion based result presented paper duck-net supervised convolutional neural network architecture achieve state-of-the-art performance polyp segmentation task colonoscopy image model encoder-decoder structure residual downsampling mechanism custom convolutional block allows capture process image information multiple resolution effectively time data augmentation technique help improve overall performance duck-net model demonstrates strong generalization capability achieve excellent result even limited training data overall duck-net architecture show great potential use various segmentation task warrant investigation