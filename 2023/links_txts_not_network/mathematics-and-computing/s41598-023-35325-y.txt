Introduction Artificial intelligence (AI) has been gradually changing medicine throughout the last few years. As exhibited by Bohr & Memarzadeh 1 , it can impact all areas of healthcare by enabling more precise disease detection, image analysis, patient monitoring, more efficient self-administration medication among others 2 . Combining AI with health monitoring devices can significantly decrease healthcare costs 1 . In particular, deep learning (DL) can help find hidden correlations and patterns using advanced machine-learning algorithms, including artificial neural networks (ANN) 3 , 4 . Thereby, deep machine learning can be used to achieve earlier recognition of complex patterns in a patient’s data in order to detect anomalies and correlate symptoms & diseases. This new branch of medicine can make it more accessible and affordable 5 , 6 . Exploiting machine learning, we seek to demonstrate that combinations of lower-cost & lower-precision sensors can potentially become as precise as any cutting-edge healthcare technology, reducing costs and providing a more universal access to healthcare 1 . Building on this philosophy, this report establishes how a deep learning approach can yield more accurate data predictions from an ultra low-cost temperature sensors array. Temperature sensors Temperature sensors come in many designs and materials, according to their target application. Beyond cost, the key features to consider are reliability, response time, accuracy, sensitivity, temperature range and, for skin temperature, wearability 7 . They can include thermocouples, resistance temperature detectors (RTDs), thermistors and semiconductor sensors, each with their own advantages and disadvantages 8 , 9 , 10 . Detailed specifications for these sensors are found in the literature 7 , 9 . For this project, we use negative temperature coefficient (NTC) thermistors and semiconductor-based integrated circuits (ICs). The NTC sensors measure change in resistance. The temperature is then computed with the Steinhart-Hart equation given as 11 , $$\begin{aligned} \frac{1}{T} = A + B\ln {R} + C(\ln {R})^{3} \end{aligned}$$ (1) where T is temperature in Kelvin, R is the thermistor resistance and A,B,C are constants specific to the sensor device, usually provided by manufacturers 11 . These are analog sensors where the output is a continuous electric signal that is converted to temperature. In contrast, integrated circuits (IC)-based sensors use bipolar transistors to do the measurements. The specific IC sensor chosen for this work also includes an analog-to-digital converter. As such, the output signal from the sensor is a non-continuous temperature reading. Temperature in medicine Body temperature is one of the key vital signs for health assessment. The normal temperature may slightly vary between individuals, but is considered normal when at \(37\;^\circ \hbox {C}\) 12 . However, the temperature will be different depending on the part of the body where it is measured, the ambient temperature and the subject’s activities. Extremities tend to be colder 13 . The human body has built-in temperature regulation mechanisms in order to maintain its temperature at \(37\;\;^\circ \hbox {C}\) . These mechanisms can be cold-activated like shivering, hunger and goosebumps, or they can be heat-activated like sweating and accelerated breathing 13 . As such, temperature measurements are especially useful to detect infections and inflammations, but more generally for immune response detection. Bacterial discharge and virus load cause fever and can also be detected through a temperature increase 12 , 14 . Using wearable devices, it is now possible to continuously monitor several health indicators and vital signs outside the clinics 14 , 15 . For example, temperature imaging can be used to verify blood flow in order to detect small temperature changes on patients with vascular disorders 16 . Another application is to monitor disease and treatment evolution through temperature, for example in pneumonia patients 17 or high-risk diabetic patients afflicted with foot ulcerations 18 . Furthermore, temperature can be used to distinguish between superficial and deep skin burns, but also to monitor and predict the skin regeneration and healing processes 19 . It is also used for the monitoring of infected wounds 20 , 21 . Currently, thermal imaging is almost exclusively used in clinical settings. Although it offers many advantages as a simple non-invasive approach, its main disadvantage is that it works better directly on the skin 17 . This can cause accessibility, comfort and privacy issues, depending on the affected area. Furthermore, it can only be done in a medical environment. In contrast, temperature sensors can be easily implemented in wearable devices such as watches 14 , patches 22 and even face masks 23 to be even less intrusive and allow to monitor the patients continuously. Although this can bring calibration and accuracy issues, we intend for our DL model to improve wearable devices and learn to make-up for these intrinsic issues. Machine learning The lower accuracies and precisions of low-cost printed sensors usually stem from less reliable designs, coupled with cheaper materials and fabrication techniques. As such, an interesting idea would be to exploit machine learning algorithms on a statistically-significant number of those low-cost sensors (array) in order to potentially learn to compensate for those design and fabrication flaws. So far, only a handful of research groups have reported significant progress in this exciting new approach to further enhance the performances of inkjet printed sensors beyond their physical limits. In 2019, an array of 20 printed sensors coupled with a two-stage machine learning approach produced an artificial nose used for food classification 24 . There, a featurized-random forest or k-nearest neighbor classification (with similar accuracy) is first used for classification into food categories (ex: cheese, liquor, oil). Then, a combinatorial selector scan is used to class the specific food item within its category (ex: rum, vodka, whiskey, gin, and tequila as liquors) 24 . In 2020, researchers achieved sign-to-speech translation using machine-learning-assisted stretchable sensor arrays 25 . Meanwhile, biomolecular & protein sensing 26 , 27 , as well as gases & pollutant mixtures detection 28 , 29 were also demonstrated using low-cost printed sensors with machine learning treatment. In 2020, a multi-disciplinary team developed a smartphone-based DNA diagnostic tool for malaria used in rural Uganda in order to also improve connectivity between such communities and centralized medical facilities 30 . They used low-cost paper-based microfluidic diagnostic test and had a disease detection accuracy over 98% 30 . In all those cases, the idea was ultimately to equip these low-cost sensor arrays with some intelligence in order to perform a certain classification task 24 , 25 , 26 , 27 , 28 , 29 , 31 . Low-cost sensors usually lead to low-precision and low-accuracy results due to equipment quality. This work demonstrates that low-cost temperature sensors used in combination with deep machine learning frameworks yield better precision and accuracy. This opens a wide range of applications, especially in the medical field, where cheaper sensors could be placed on different body parts, but still predict the body temperature. Materials and methods Data collection Materials In order to create our sensor array, we chose two types of low-cost temperature sensors. We used 16 digital temperature sensors and 16 analog temperature sensors, all with accuracies between 0.5 to 2.0 \(^{\circ }\) C. To collect the data from our sensors, we use an Arduino Mega2650 32 and Arduino’s IDE. The Mega2650 offers 54 digital inputs and 16 analog inputs, which is sufficient to connect all our sensors to the microcontroller. It operates at 5V and 16 MHz frequency. Methods The sensors are mounted on an IKA C-MAG HS 7 control hotplate 33 with thermal paste to ensure conductivity and fixed with thermally-conductive tape, using the configurations shown in Figs. 1 & 2 . The sensors are placed in a 4x8 array, covering the center of the plate as indicated in Fig. 1 a. Two (2) rows consist of the digital sensors and two (2) rows for the analog sensors. This specific configuraton is only chosen to facilitate wire-management and data-collection. Using two types of sensors helps diversify our dataset, while providing enough data for a meaningful distribution (see Supplementary Information section to compare both sensor types). All 32 sensors are connected through wires to the Arduino microcontroller as shown in Fig. 1 . There, Fig. 1 a shows a representation of the experimental setup condition. The approximate placement of the 32 low-cost temperature sensors is schematically represented atop a thermal image of the hotplate when set at \(50\;^\circ \hbox {C}\) . From the thermal image acquired using a FLIR-One infrared camera, it is clear that the temperature is not uniform everywhere on the hotplate. This configuration was chosen on purpose to represent the human body, where the temperature can fluctuate quite a bit from one location to another. We cycled the hotplate’s set-temperature from 30 to \(45\;^\circ \hbox {C}\) , with increments of \(1\;^\circ \hbox {C}\) as a staircase signal. The heating plate’s accuracy is \(\pm 0.15\;^\circ \hbox {C}\) according to specifications. As the temperature varies quite significantly over the surface, this parameter isn’t really meaningful in this study. Instead, we want our model to learn to predict the hotplate’s set temperature with the highest precision. Similarly, the body temperature can also vary significantly from one point to another. When measured orally, this temperature is established as true, whereas elsewhere it may be different. Thus, we want our model learn to predict the established temperature of the plate, even if it is changing wildly depending on the position of the sensors on the hotplate. Fig. 1 b shows the circuit on the Arduino Mega2650. For each degree measurement, we waited for two minutes to make sure that the hotplate’s temperature is stable before collecting the sensors’ readings each 1.5 seconds for four minutes using the Arduino. Afterwards, 50 random vectors were chosen from the entire sample. Thus, our dataset consists of 50 vectors of 32 components for each temperature degree, for a total of 800 vectors. All vectors are then labeled according to the plate’s set temperature and accuracy. Figure 1 ( a ) Placement of the 32 low-cost temperature sensors schematically represented atop a thermal image of the hotplate when set at \({50}^\circ {{\textbf{C}}}\) . The two rows bounded in the black box are analog sensors, where as the green box contains digital sensors. ( b ) Schematic of our circuit. Only four sensors of each type are shown to simplify the figure. Generated with Fritzing v0.9.10 ( https://fritzing.org ). Full size image Neural network Methods A feed-forward artificial neural network is a deep learning algorithm generally using large quantities of data to learn to recognize hidden patterns in order to make more accurate predictions 34 . In this case, we designed a regression model, which predicts an output based off the data you feed it. The architecture of an artificial neural network is composed of interconnected neuron layers. It also contains an input layer, which forwards the data to the hidden layers for computational purpose. The information is then spread to the output layer, making a final prediction. Here, we used a supervised training method 35 . To do so, the data set is randomly split in two subsets using Numpy’s random module. 80% went to the training set, while the remaining 20% composed the validation set. A verification was performed to validate that the entire temperature range was covered equally in the training set for it to be unbiased and complete. (See Supplementary Information for the distribution.) To design our model, we use TensorFlow’s module Keras 36 . We chose a three-layer deep neural network (DNN) shown in Fig. 3 . Its hidden layer has 20 neurons and all are activated with an hyperbolic tangent function \((\tanh (x)=\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}})\) . We chose the Adam optimizer with a 0.01 learning rate. The computed loss function for our regression is the mean squared error \((MSE =\frac{1}{n} \sum _{j=1}^n (Y_{j}-\hat{Y}_{j})^2 )\) . We obtained a minimal loss by training the data set with 300 epochs. All these choices were made according to tests and grid search’s results obtained with Python’s Scikit-Learn module. (See Table S1 in Supplementary Information for optimization details on the algorithm and grid search results.) Figure 2 Optimized deep neural network (DNN) architecture used to learn to predict the (set) temperature from the read-out data of our 4 x 8 array of low-cost and low-accuracy temperature sensors. Full size image In this project, the model trains itself with 640 temperature vectors composed from the readings of the 32 sensors and labelled with the set temperature of the hotplate. Using this training set, the model learns to predict the set temperature of the hotplate (labels) from the patterns and features of the array. Once the model is trained, we evaluate its performances using the test vectors and evaluate its set-temperature predictions from the sensors’ data. The predictions according to the set temperature and compared with the sensors’ readings are shown in Fig. 4 . Results and discussion As seen in Fig. 3 , the recorded temperatures fluctuate wildly from one sensor to another and the averaged sensor readings tend to increasingly underestimate the actual (set) temperature as the temperature is increased. For a set temperature of \(45\;^\circ \hbox {C}\) , some sensors read temperatures as low as \(33\;^\circ \hbox {C}\) . After only a few iterations of training, we observe that the DNN model architecture shown in Fig. 3 can predict the actual (set) temperature with a \(0.12\;\;^\circ \hbox {C}\) accuracy using extremely low-quality sensing devices. These results suggest that the DNN learns to compensate extremely well for the poor sensors’ precision and accuracy, as well as for the non-homogeneous temperature profile of the plate. Figure 3 Individual temperature readings from each of the 32 sensors, mean value of all readings and the model’s predictions as a function of the hotplate’s set temperature. The dashed blue line indicates the target (set) temperature value. Full size image Results from Fig. 3 clearly highlight the sensors’ large margin for error. The red vertical dotted lines indicate each sensors’ readings according to each set temperature. As the set temperature increases, it is clear that lower temperature readings tend to move further from the actual set temperature than the maximal one. As such, the mean value extracted from the 32 sensors increasingly underestimates the set temperature. This increasing margin of error as the temperature rises can be explained by (1) the sensors’ low-precision and (2) the non-uniformity of the hotplate’s thermal profile for higher temperatures. The blue data points show the model’s prediction, which accurately follows the set temperature. The sensors’ readings’ mean rather follows a logarithmic regression. We computed a 0.998 coefficient of determination ( \(\hbox {R}^{2}\) ) between prediction and set temperature, as well as a 0.999 cosine similarity. Even if the hotplate’s thermal profile becomes non-uniform as the temperature rises, our algorithm still performs very well. This is because the model also learns the behavior of each sensor according to its placement. Figure 4 shows a 3D representation of our 4x8 sensor array as the temperature increases on the hotplate (heatmap) from two (2) different viewpoints. Just like the thermal image of Fig. 1 , it is clear that some sensors are subjected to different temperatures locally. At \(30^\circ\) , the whole array is red (lower temperatures), and it then becomes increasingly yellow (higher temperatures) at different rates. It is clear from these results that the temperature is not uniform everywhere on the hotplate. Indeed, this experimental system was selected on purpose in order to accurately mimic the non-uniform temperatures experienced across the human body. As mentioned earlier, the body temperature can vary significantly depending on where the measurement is taken, just like the sensors in our work. However, our model still manages to predict accurately the hotplate’s reference (set) temperature, which would be the core body temperature in a clinical setting. Thus, we could place sensors over a patient’s body and be able to know the core body temperature. This could also be helpful in creating a heat map of the patient’s body. For instance, becomes possible to accurately predict the temperature at point A from a reading at point B, as shown in Fig. 5 , where the algorithm could predict the oral temperature from the wrist sensor. But most importantly, it helps to get more accurate temperature readings from low-cost sensors. Even though these timely results present an appealing proof-of-concept, this study also represents a strong foundation for future investigations. For example, one could try different types of sensors an/or modify the positioning and shape of the array. We already did a first try of data augmentation and randomized the test set to get an idea of the effect’s on the prediction, as discussed in the Ablation Study below. The chosen temperature range for this project is convenient for skin temperature measurements, but we could also try to expand it and accommodate the model’s behavior in order to target other applications. Figure 4 3D heatmaps of our individual sensors’ readings with increasing temperature in the black arrow’s direction from two (2) different viewpoints. Each dotted line represents the evolution of one sensor. Axes going from 1 to 4 (row) and 1-8 (column) indicate the sensors’ individual placement. Generated with Mathematica Online v13.1 ( https://www.wolfram.com/mathematica/online/ ). Full size image Ablation study In order to develop the best model for this project, we tried different parameters for the algorithm. This section describes the model’s optimization process. Loss and activation functions We compared the results using different loss functions for our regression model. We tried the mean absolute error (Fig. 6 a) and the mean squared logarithmic error and the root mean squared error (Fig. 6 b) resulting in loss values of 2.79x10 \(^{-2}\) and 4.57x10 \(^{-2}\) respectively. As shown in Fig. 6 c, the mean squared error yields significantly better results. Furthermore, the combination of the hyperbolic tangent activation function for both layers results in the best precision. Figure 5 Representation of our model’s transition onto the human body. Full size image Figure 6 Results for different loss functions used to optimize our model in a logarithmic scale. ( a ) mean absolute error (MAE), ( b ) root mean squared error (RMSE) and ( c ) mean squared error (MSE), all with hyperbolic tangent activation function. Full size image Indeed, this precise combination of hyperparameters provides the best restults : a 1.47x10 \(^{-4}\) loss on the training set and 1.22x10 \(^{-4}\) on the test set. As such, we can conclude that the framework has great generalization ability, since it performs just as well on the test set on unseen data than in its training. This ability depends mostly of the variance-bias tradeoff. In this case, the model has a low variance (0.03) and bias (0.002), which is the optimal case for machine learning models 37 . Randomized vectors If we shuffle the components of the testing vectors, the algorithm doesn’t perform as well. This is because part of the algorithm is also learning the heat profile of the hotplate, as it is intended. For instance, a shuffled test set fed into our model achieves a MSE of 6.58x10 \(^{-3}\) , which is roughly a factor thirty (30 \(\times\) Figure 7 ( a ) MSE loss function on logarithmic scale for our model ( b ) MSE loss function on logarithmic scale for a model trained using a completely randomized data set. Full size image ) larger than our best MSE result. This is due to the fact that when shuffling the components of each vector, we mix the heat map of our dataset. Therefore, the model can’t rely on that specific property to predict the temperature, and that’s why it becomes a bit less precise. As a result, we also tried to train our model using randomly-shuffled vectors. Each one was randomly shuffled so that the mapping aspect is completely eliminated. The same model computed a 6.97x10 \(^{-4}\) of the test set, which is only a factor five (5 \(\times\) ) higher than our best MSE results. Comparison for both models is shown in Fig. 7 . However, we also tried to predict the temperature from a new heatmap. Instead of randomly shuffling each vector separately, we shuffled the sensors’ placement to create a different thermal profile as a test set. We did not retrain the model with this placement, so this allows us to assess the generalization ability for our model. Indeed, the new heatmap fed into the model achieves a MSE of 1.50x10 \(^{-3}\) , which is only a factor ten (10 \(\times\) ) higher than the loss for the specific heatmap the model was initially trained on (1.22x10 \(^{-4}\) ). In this current work, the goal is for the model to learn the heatmap and placement of sensors. Indeed, if the sensors were placed on a human body, we would want the model to be able to correlate the sensors to their placement on the patient. Thus, the focus can be fixed on a particular heatmap only. Conclusion While it is important to continue to improve materials and fabrication processes to improve sensors, the impact that artificial intelligence can also have should not be overlooked. This paper clearly demonstrates that machine learning algorithms are a powerful way to rapidly enhance readily-available low-cost sensor performances and to generate heatmaps from low-cost sensor arrays. Research is currently oriented towards implementing some intelligence onto sensor arrays in order to perform classification tasks. We show that applying such deep learning algorithms to low-cost sensor arrays can also improve their performances. In the future, it will be interesting to try this approach to identify the best designs to measure body temperatures. To do so, researchers will need to consider the sensor’s biocompatibility with skin 38 . This system has a great potential for medical applications for non-invasive temperature measurements. As it is currently done with biomarkers 20 , such sensor arrays could also be used to monitor inflammatory responses or recovery in burned and wounded patients. The advantage our sensors is that they require no chemical reactions and aren’t disposable. Furthermore, the thermal map generated by our model could be helpful to monitor the evolution of wounds and injuries, at much lower costs than current methods.