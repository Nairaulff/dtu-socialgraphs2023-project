Introduction The very first studies on the peculiar properties of entangled photons from spontaneous parametric down-conversion (SPDC) 1 , 2 led to the discovery of quite counter-intuitive correlation imaging modalities 1 , 3 , 4 , and to the development of so-called quantum imaging. In this context, spatio-temporal correlations of light have been exploited both toward novel imaging schemes and to overcome the limits of traditional imaging (e.g., in terms of resolution, spectral range, contrast, signal-to-noise ratio) 5 , 6 , 7 . On the one hand, quantum correlated photons have been employed to achieve otherwise unattainable quantum effects, such as imaging with undetected photons 8 and sub-shot-noise imaging 9 , 10 , 11 , 12 . On the other hand, it was discovered that specific correlation imaging tasks could still be achieved when replacing SPDC photons with chaotic light sources, such as thermal and pseudo-thermal 13 , 14 , 15 , 16 , 17 . Such classically correlated sources typically entails a worse signal-to-noise ratio (SNR) than expected with entangled photons 18 , 19 , but also brings in several practical advantages: light sources are simpler and more feasible (potentially, any available incoherent source could serve the purpose 20 , 21 ), the image acquisition time can be significantly reduced by avoiding the low production rate of entangled photons, and protocols are potentially insensitive to the deleterious effects of decoherence. A wide range of quantum-inspired imaging protocols based on chaotic light correlations have been demonstrated so far, in different application scenarios: imaging of objects hidden to the main sensor 22 , 23 , dual wavelength imaging 24 , 25 (analogous to the implementation with entangled photons 26 , 27 ), detection of objects surrounded by turbulence 28 , 29 , 30 , 3D imaging through computational ghost imaging 31 , refocusing and 3D imaging through correlation plenotpic imaging and microscopy 32 , 33 , 34 , 35 , 36 , 37 , 38 . However, the variety of advantages entailed by the spatio-temporal correlation properties of light clashes with the most relevant challenge of correlation imaging methods: reducing the acquisition time to make them effectively competitive with the corresponding state-of-the-art traditional techniques. Such a challenge is intrinsic to this approach, since evaluating correlation functions requires sampling a high enough number of statistical realizations. The use of high-resolution CCD and CMOS cameras in correlation imaging setups 6 , 7 , 13 , 16 , 34 , 38 , 39 has enabled to overcome the extremely time-consuming mechanical scanning of the image plane, as performed in pioneering correlation imaging experiments 3 , 14 , 17 . There are two time scales that one must consider when dealing with the speed of correlation imaging with a camera 7 . First, if \(N_t\) camera frames are required, the total acquisition time is equal to \(T_{\textrm{image}}= N_t / R\) , with R the frame rate; its inverse \(T_{\textrm{image}}^{-1}\) is the rate at which correlation images can be acquired. The acquisition rate can be reduced by i) maximizing R , as in high-speed sensors, and ii) optimizing the trade-off between number of frames and SNR, with the latter expected to depend on \(\sqrt{N_t}\) 18 , 40 , 41 , 42 , 43 . The other crucial time scale to be considered is the gating time , namely, the effective sensitivity window in which a single frame is acquired: if it is larger than the source coherence time, intensity fluctuations in each frame are partially erased 44 , making it more difficult to reconstruct their correlations, and thus increasing the required \(N_t\) . An innovative class of detectors, made of an array of single-photon avalanche photodiodes (SPAD) 45 , 46 , 47 , 48 , provides one of the most interesting solutions available to take on both temporal issues. SPAD arrays ensure at once fast acquisition rates of up to about \(10^5\) fps, sub-10 ns gating time, and low noise: SPAD arrays are characterized by the absence of readout noise, whereas dark counts are limited to less than 10 counts per second per pixel. The reduced noise is essential for high-quality sampling of the light statistics with fewer frames. SPAD arrays have thus been extensively employed for correlation measurements, and yet more rarely for correlated-photon imaging (see Ref. 48 for a wide review and detailed bibliography). In this context, despite the development of high-resolution SPAD arrays has permitted to largely cut the acquisition time by exploiting multiple pair coincidences within a single frame, the acquisition times attained in entangled-based high-resolution 2D imaging remain larger than one second 49 , 50 . In fact, even neglecting the data bandwidth limitation of state-of-the-art high-resolution SPAD arrays, which currently prevents large arrays from being used at full speed for extended periods, the long acquisition time needed by entanglement-based correlation imaging is essentially determined by the low production rate of SPDC. In this work, we shall demonstrate correlated-photon imaging at a rate of 10 volumetric images per second, with a field of view of 256 × 256 pixels. The key for achieving such performances is the use of: (1) SwissSPAD2 45 , 46 , 47 , 51 , a SPAD array operated at a 512 × 256-pixel resolution, and capable of acquiring up to \(10^5\) frames per second; (2) chaotic light illumination, which enables to avoid the low speed related with the low production rates of parametric down-conversion; (3) the principles of correlation plenoptic imaging (CPI) 32 , 35 , 36 , 37 , 52 , a technique that enables to acquire information about both the spatial distribution of light and its propagation direction; such a richness of information is used, during data processing, to reconstruct three-dimensional snapshots of the scene of interest. In traditional light-field imaging devices 53 , 54 , 55 , 56 , based on the insertion of an array of micro-lenses before the sensor, directional resolution can be gained only at the expense of spatial resolution 57 . Nonetheless, aided by additional post-processing algorithms 58 , 59 , 60 , they find applications in the most diverse fields, such as photography 61 and microscopy 62 . Plenoptic or light-field cameras based on intensity measurement can currently operate at the essentially same rates of a standard camera, which evidently outperforms any correlation imaging technique (whether volumetric or not) at similar resolutions. However, many interesting applications of light-field imaging in science, including the neuronal activity detection accomplished in Refs. 63 , 64 , are performed at image rates ranging between 10 and \(100\,\textrm{Hz}\) 64 , 65 . The results presented in this paper thus demonstrate the competitiveness of correlated-photon imaging in these tasks: CPI based on correlated photons from chaotic sources brings a net advantage with respect to state-of-the-art light-field cameras, combining similar time performances with an improved volumetric resolution at analogous numerical aperture 36 , 66 . To the best of our knowledge, the presented CPI setup is indeed the first case of a feasible light-field device employing a single lens. The article is organized as follows. In the “ Results ” section, we summarize the working principle of the novel CPI device and show the possibility to obtain light-field images with a \(0.1\,\textrm{s}\) acquisition time. In the “ Discussion ” section, we highlight the relevance of our results along with their implications for practical applications, and discuss both the current limitations of our experiment and the foreseen future developments. In the “ Materials and methods ” section, we present details about the experimental setup. The Supplementary Information document further details on the measured correlation functions and the refocusing process, as well as complementary results on the interdependence between the number of collected frames (hence, the image acquisition time) and the SNR. Results Figure 1 Working principle of the developed CPI protocol. \(\textrm{O}_a\) and \(\textrm{O}_b\) are the two conjugate planes of the high-resolution sensors \(\textrm{D}_a\) and \(\textrm{D}_b\) ; they are placed at the generic distances \(z_a\) and \(z_b\) from the lens, respectively. BS is a beam splitter sending light from the lens toward the two sensors. Pixel-by-pixel correlations between photon number fluctuations are evaluated by software and employed to reconstruct the volumetric image of the scene. See “ Materials and methods ” for the detailed experimental setup. Full size image Figure 2 ( a ) Comparison between the images directly retrieved by the sensors, through their average intensity (left panels), and the images refocused by means of CPI (central panel); the plots in the right panel are obtained by integrating the highlighted rectangles in the corresponding average intensities (gray) and refocused images (blue) along the slit direction. All the reported data have been obtained by acquiring \(N_t=9.8\times 10^{3}\) frames, at full resolution, at \(\sim 9.8\times 10^{4}\) frames per second, resulting in an overall acquisition speed of 10 volumetric images per second. ( b ) Comparison of the resolution achieved by conventional imaging (orange for \(\textrm{D}_b\) , green for \(\textrm{D}_a\) ) and CPI (blue) as a function of the axial distance from the lens. ( A ) ( \(z=275\) mm), ( B ) ( \(z=319\) mm) and ( C ) ( \(z=373\) mm) indicate the three different masks shown in panels ( a ); the plot shows their axial position and the distances between neighboring slits within the masks. Full size image The working principle of the CPI camera is reported in Fig. 1 36 . Two planes \(\textrm{O}_a\) and \(\textrm{O}_b\) , chosen arbitrarily within the three-dimensional scene of interest, are focused on two high-resolution sensors, \(\textrm{D}_a\) and \(\textrm{D}_b\) . Unlike a conventional light-field camera, involving both the usual camera lens and a micro-lens array, our CPI device is realized with a single lens, collecting light from both chosen planes, and focusing them on the two sensors. Light from the scene is chaotic; hence, by computing the equal-time pixel-by-pixel correlation between the number of photons ( \(N_a\) and \(N_b\) ) detected by the sensors \(\textrm{D}_a\) and \(\textrm{D}_b\) , we obtain the correlation function: $$\begin{aligned} \Gamma (\varvec{\rho }_a,\varvec{\rho }_b) = \langle N_a (\varvec{\rho }_a) N_b (\varvec{\rho }_b) \rangle - \langle N_a (\varvec{\rho }_a) \rangle \langle N_b (\varvec{\rho }_b) \rangle , \end{aligned}$$ (1) where \(\langle \dots \rangle\) indicates the averaging process, while \(\varvec{\rho }_a\) and \(\varvec{\rho }_b\) are the coordinates identifying pixel positions on the sensors. The correlation function in Eq. ( 1 ) contains plenoptic information, and thus enables reconstructing features of a 3D object that can be placed both between and beyond the two planes \(\textrm{O}_a\) and \(\textrm{O}_b\) imaged on the detectors 35 , 67 . As explained in detail in the Supplementary Information, \(\Gamma (\varvec{\rho }_a,\varvec{\rho }_b)\) encodes a collection of multi-perspective volumetric images; proper processing of these volumetric images provides the refocused image of a specific transverse plane in the scene. Adopting chaotic light illumination entails that the magnitude of the correlation function ( 1 ) scales like the product on the mean number of photons 44 , thus being crucial in ensuring that correlation measurements provide analogous results both in the case of high-intensity, as in Ref. 38 , and in the single-photon regime, as in the present work. However, a key requirement in this sense, is that the SPAD array works in the linear regime (namely, the probability to detect a photon is proportional to the intensity of the impinging field), far from saturation. Experimental results are reported in Fig. 2 : Both sensors acquire blurred images of three different planar test targets (A,B, and C); the plenoptic information contained in the measured correlation function enables reconstructing the object details, in all three cases. In the panel on the left, we report the out-of-focus images of the test target, which is placed either within (case B) or outside (cases A and C) the volume defined by the two conjugate planes of the detectors; the effective refocusing enabled by CPI is shown in the center panels. The recovery in visibility deriving from refocusing is demonstrated in the right panels: here, we compare the linear images related with both average intensity and CPI, which are obtained by integration along the slit direction. CPI also enables over \(10\times\) depth of field (DOF) enhancement at a resolution of 250 \(\mu\) m, and \(12\times\) at 160 \(\mu\) m, with respect to a conventional imaging system with the same numerical aperture (NA). This can be seen by considering the curves reported in panel (b) of Fig. 2 , together with the axial position and the distance between neighboring slits on the three test targets (A,B, and C) reported in panel (a). The plot shows the expected resolution limit of the refocused images (blue line), with varying axial position z , compared with the analogous limits associated with the conventional images focused on \(\textrm{D}_a\) (green line) and \(\textrm{D}_b\) (orange line). In particular, the blue line indicates the object detail size (i.e., the resolution) that can be refocused by our CPI device with 10% visibility, as a function of the longitudinal distance ( z ) of the object from the lens. The green and red lines represent the natural DOF (as determined by the circle of confusion) of the images separately observed on the two sensors D \(_a\) and D \(_b\) , at the given resolution. The images reported in Fig. 2 have been obtained at an overall acquisition speed of 10 volumetric images per second. This is an unprecedented result in the field of correlation imaging, and indicates the feasibility of correlated-photon imaging at video rate. The noise analysis reported in the Supplementary Information shows the robustness of the developed technique: when the acquisition speed is reduced to 1 image per second by increasing the number of acquired frames by 1 order of magnitude, the SNR increases by nearly 35%, and reaches its maximum value. A comparison between the CPI images acquired at the speed of 1 and 10 volumetric images per second is reported in Fig. S3 of the Supplementary Information. Discussion We have presented a quantum-inspired imaging system capable of collecting 10 plenoptic images per second. Since plenoptic images are a collection of multi-perspective volumetric images, they enable changing, in post-processing, the focusing plane within the entire axial range enclosed by the blue curve in Fig. 2 b. This result entails a large reduction of the gap in time-performance between CPI and conventional light-field imaging, that is generally performed at a speed between 10 and 100 Hz, in scientific applications 64 , 65 , but with a significant loss of resolution due to microlens array and intensity measurement. The key element to achieve such a critical improvement in the acquisition time is the integration of the SwissSPAD2 sensor in a chaotic-light based correlaton plenoptic imaging setup. This SPAD array enables to collect, with single-photon sensitivity, all the frames that contribute to the plenoptic correlation image, at a rate of almost 100.000 frames per second. Such a fast rate is combined with both a resolution comparable to that of ordinary detectors and low noise (see Refs. 46 , 47 , 51 for a detailed description of the sensor). The low noise of the detector is a key aspect for keeping as low as possible the number of frames \(N_t\) required for reconstructing light statistics and correlations. Our SwissSPAD2 sensor has an on-board DDR3 memory bank (2 GB) that can be filled with a maximum of \(131\,072\) measured binary frames. By saving the acquired data on the internal memory instead of streaming to an external disk, we were able to exploit the maximum speed of 97.7 kHz at full resolution. However, the limited capacity of the memory has bound us to single-image acquisitions instead of videos. In the future, we shall employ a new generation of SwissSPAD2 capable of streaming data from a \(512 \times 512\) sensor to a workstation at full speed. The new generation of SwissSPAD2 also provides a relevant improvement in the gating time, which can be reduced down to about 10 ns. This represents an extremely important parameter in correlation imaging based on chaotic light, since reconstruction of light statistics is optimal when the detector exposure time matches the coherence time of light 44 . The possibility to match coherence times as small as hundreds of ps would open the way to CPI with broadband sources, thus leading the way toward passive quantum imaging devices. It is reasonable to expect the achieved acquisition speed to be further increased through computational techniques enabling to use less frames to achieve a comparable SNR; examples are compressive sensing 68 , 69 , quantum tomography 70 , and machine learning 71 . All these techniques are currently being developed in the framework of CPI, and we plan to integrate them with our refocusing algorithm 51 . To further increase the SNR while reducing the acquired number of frames, we are also working toward employing, within the data analysis, the statistical properties of the correlation function, in a similar fashion as in Ref. 72 . It is interesting to emphasize, however, that all data presented in this work have not been treated with any denoising algorithm, or post-processing method, other than the refocusing algorithm described in the Supplementary Information. The novelty of the implemented CPI setup also stands in the fact that two arbitrary planes are focused on the two sensors 36 , as opposed to conventional approaches involving imaging of the main lens for retrieving directional information. This approach enables: (i) parallel acquisition of two diffraction limited images within the three-dimensional scene of interest, (ii) single-lens light-field imaging , which is quite significant considering the disadvantages and physical limitations connected with the use of micro-lenses (i.e., resolution loss and reduced 3D imaging capability), (iii) a DOF enhancement by over 1 order of magnitude, without sacrificing diffraction-limited resolution. Materials and methods Figure 3 Technical scheme of the developed CPI setup. The chaotic source is made of a diode laser illuminating a rotating ground glass disk. Two planes, \(\textrm{O}_a\) and \(\textrm{O}_b\) , arbitrarily chosen in the surrounding of the scene of interest, are imaged by a unique lens onto two disjoint high-resolution detectors \(\textrm{D}_a\) and \(\textrm{D}_b\) , which are practically implemented by using two halves of the same SwissSPAD2 sensor. Two optical paths, one for each detector, are realized by means of two polarizing beams splitters (PBS), two quarter-wave plates (QWP) and four mirrors; each pair of QWP and mirror is mounted on a translation stage, which offers flexibility in the choice of the two planes \(\textrm{O}_a\) and \(\textrm{O}_b\) , when preparing the acquisition. Full size image The optical system is aimed at maximizing speed of acquisition and performance in terms of resolution versus DOF trade-off, while guaranteeing flexibility in the focusing capability. The design of the employed CPI setup is oriented to the acquisition of generally demagnified images, as in an ordinary camera. The lack of two synchronized SPAD arrays has imposed using two halves of a single SPAD array as the two sensors \(\textrm{D}_a\) and \(\textrm{D}_b\) . This entails some constraints to the setup design: demagnified images can only be obtained if the two CPI paths are separated upstream of the lens, rather than downstream (as reported in Fig. 1 , and originally proposed in Ref. 35 ). The experimental setup thus consists of two main parts (Fig. 3 ): 1. The ultra-fast imaging device, made of a camera lens (Navitar MVL75M1, of focal length \(75\,\textrm{mm}\) and focal ratio 2.8) mounted on the SPAD array sensor; 2. A “CPI adapter”, represented in Fig. 3 by the dashed gray rectangle. The CPI adapter endeavors the ultra-fast camera with plenoptic properties by first creating (through the first polarizing beam-splitter) and then recombining (through the second polarizing beam-splitter) two optical paths, which we shall indicate as a (depicted in green) and b (depicted in red). Each optical path contains a delay line, offering the required flexibility for choosing the two arbitrary planes \(\textrm{O}_a\) and \(\textrm{O}_b\) , when preparing the acquisition. In our setup the distances between the planes \(\textrm{O}_{a,b}\) and the lens are \(z_a=345\) mm and \(z_b=293\) mm, respectively. The delay lines are made by the combined system (QM \(_{a,b}\) ) of a quarter-wave plate (QWP) and a mirror. This combined system converts light from H-polarized to V-polarized, and viceversa, so that the beam that is back-reflected by QM \(_{a,b}\) is then reflected/transmitted by the corresponding PBS toward the camera lens. Changing the optical path in arms a and b defines the specific plane to be imaged on sensor \(\textrm{D}_a\) and \(\textrm{D}_b\) , respectively. In fact, given the lens focal length f and the fixed lens-to-sensor distance \(z_i\) , the distance \(z_o\) of the object plane from the lens is uniquely defined by the thin lens equation. Hence, the two planes \(\textrm{O}_a\) and \(\textrm{O}_b\) , imaged on \(\textrm{D}_a\) and \(\textrm{D}_b\) , respectively, are both placed at an optical distance \(z_o\) from the lens; however, the actual planes that are imaged on two disjoint halves of the sensor, are determined by length of the delay lines, which enable to arbitrarily choose the distances \(z_a\) and \(z_b\) , associated with two different planes within the volume of interest. We should specify that the versatility in choosing the two planes is a useful feature when setting up the acquisition, since it allows the experimenter both to select the planes to be focused and to define the volume that can be refocused (as defined by the blue curve in Fig. 2 b); the specific choice, however, plays no role during the acquisition itself. Both delay lines are characterized by the same magnifications \(M=-z_i/z_o\) , numerical aperture (NA), and resolution at focus, as defined by the camera lens. The clear aperture of both the polarizing beam splitter, PBS (45 mm), and the optics (2 inches) in the delay lines have been chosen to enable fully exploiting the NA of the camera lens. In order to maximize its fill factor, the SwissSPAD2 sensor is equipped with a microlens array; its NA \(\approx 0.25\) is larger than the lens NA on the image side ( \(\text {NA}_i=\text {NA}_o/|M| = 0.13\) ) and does not limit the NA of the CPI device. However, the pixel size of the sensor is larger than the achievable diffraction limited resolution; hence, the setup has a pixel limited resolution of 95 \(\mu\) m. In the present experiment, the CPI device was employed to image transmissive planar test targets placed out of focus, as shown in Fig. 2 . The targets are illuminated by a chaotic light source of controllable polarization, intensity, and coherence time, made by a green diode laser (Thorlabs CPS532, \(\lambda =532\) nm) scattered by a rotating ground glass disk (GGD). At the maximum rotation speed of the GGD (30 Hz), the measured coherence time of the source is \(t_\text {ch}\simeq 15 \,\mu \textrm{s}\) . SwissSPAD2 employs a design that provides one of the largest resolutions ( \(512 \times 512\) photodiodes operating in Geiger mode) as well as one of the highest sensitivity (50% photon detection probability at 520 nm) and lowest dark count rate ( \(0.26\text { cps}/\mu \text {m}^2\) , equivalent to a median value of less than 10 cps per pixel) combinations among SPADs which are built with standard CMOS-process technologies. Its 10.5% native fill factor is improved by 4-5 times, for collimated light, by means of the use of a microlens array. The output of each frame consists of a binary matrix identifying the pixels that have been triggered by at least one photon. Due to the binary nature of the signal, it is of utmost importance for the reconstruction of intensity correlations to work close to the linear regime 45 , 73 , in which the probability to detect a photon is proportional to the intensity of the impinging electromagnetic field.