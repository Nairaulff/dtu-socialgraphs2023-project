Introduction As of 25 September 2022, 612 million confirmed cases and 6.5 million deaths due to COVID-19 have been reported globally (WHO, 2022) 1 . Even after vaccination, the peaks in the incidence of COVID-19 have arisen as new variants challenge former immunization 2 . Assessing the risk of COVID-19 fatality can guide clinical decision-making by healthcare professionals 3 . Many studies have investigated the predictors of COVID-19 death and severity and proposed risk stratification tools 4 . Machine learning (ML), as a novel approach, can improve policy-making, forecasting, screening, drug development, and risk stratification. Artificial intelligence (AI) can result in fair decision-making by minimizing interobserver variability and filling the gap between healthcare resources and human workload 5 . Although many ML algorithms have strived to help physicians, ML tools face several obstacles to implementation in clinical practice. For instance, the clinicians' hardship in using and interpreting computational models may hinder the further progress of ML. Thereby, creating a reproducible easy-to-use model is vital, which can be achieved with healthcare professionals’ assistance in model development. Moreover, training a generalizable ML needs precise data collection and population selection. In this fashion, the ML training data set will represent the actual population using the model in the future 6 . Risk stratification of patients can indicate the most vulnerable groups and is crucial for resource allocation and follow-up of patients 5 . Table 1 summarizes previous studies on the prediction of COVID-19 mortality. A systematic review of prediction models for COVID-19 mortality showed that 70 out of 79 articles faced a high or unclear risk of bias 7 . Even among the nine articles with a low risk of bias, external validation was not considered in six 7 . Therefore, the reproducibility of ML experiments on this matter can be in question. In addition, collecting a large set of predictors is time-consuming, and many studies with a large number of clinical and laboratory predictors tend to have a limited patient population (Table 1 ). On the other hand, reducing the number of collected features may compromise a precise interpretation of the disease and its severity since COVID-19 is a multi-organ disease 8 . Table 1 Studies with or without external validation aiming to predict prognosis of COVID-19 using clinical and laboratory features (retrieved from review articles and search in PubMed and Scopus databases 7 , 9 ). Full size table This study aims to propose an on-admission mortality risk prediction model and investigate its external validation to assess the generalization of the tool. In order to increase the ease of implementation, we gather feedback from clinicians involved in COVID-19 practice. This study is part of an observational, retrospective, multicentric research project to investigate the epidemiological characteristics of COVID-19 patients 27 . Material and methods Data collection We used data set of 5320 confirmed COVID-19 patients admitted to three general hospitals in Tehran, Iran, from March 2020 to March 2021. A Medical team reviewed patients' medical records and gathered patients' demographics, symptoms, comorbidities, admission vital signs, and outcomes. Laboratory results were collected for all patients on the first day of admission through the hospital information system. Confirmation of cases was based on real-time polymerase chain reaction (RT-PCR) for SARS-CoV-2 of nasal or oropharyngeal swab samples on the first days of hospitalization. The outcome of current study was death versus discharge from the hospital. We previously explored the epidemiology of the cohort used in this study in detail 27 . Data cleaning and imputation Patients with any missing categorical variable or missing more than two numerical features were removed from the dataset. Out of 88 features collected from cohort patients, including 52 categorical features and 29 continuous features, none of the categorical features contained missing data. Conversely, seven numerical features were dropped due to a proportion of missing values greater than 5%. Other missing values were imputed using Python's Sci-kit learn iterative imputer. Feature selection Feature selection can prevent overfitting, a sinficant problem in ML models, by eliminating redundant collinear features. We recognized the most predictive values using the least absolute shrinkage and selection operator (LASSO) regression and Boruta feature selection methods. LASSO confirmed 37 features containing 25 categorical and 12 nominal features, and Boruta selected 24 features, all of which were nominal. We used these groups separately as our training data features and compared the performances. Model development Six ML classification models were trained and fine-tuned, including support vector machine (SVM) with Radial Basis Function (RBF) as kernel and the degree set to 3, logistic regression (LR), k-nearest neighbors (KNN) with number of neighbors set to 5 and weights to uniform, random forest (RF) with the number of estimators set to 100 and criterion set to Gini, gradient boosting decision tree (GBDT) with the number of estimators set to 100, learning rate set to 0.1, and loss set to log_loss, and deep neural network (DNN) to calculate the risk of mortality in admitted covid patients. SVM and LR were regularized using the L2-regularization (Ridge regression) method. After fine-tuning, the neural network contained two hidden layers with 128 and 64 units for the first and second hidden layers, respectively. Moreover, all layers were activated using rectified linear unit (ReLU) activation function, and the output layer contained a unit with a sigmoid activation function. All layers except the output layer had 60% dropout. A DNN compiled with binary cross-entropy as loss function and stochastic gradient descent with learning rate, decay, momentum, and Nesterov set to 0.01, 1e−7, 0.9, and true as optimizer, respectively. The ML pipeline of the proposed DNN model and its implementation are depicted in Fig. 1 . Figure 1 Proposed deep neural network model structure and implementation ( LASSO least absolute shrinkage and selection operator, DM diabetes, COPD chronic obstructive pulmonary disease, IHD ischemic heart disease, CVA cerebrovascular accident, CHF chronic heart failure, RA rheumatoid arthritis, GI gastrointestinal, LOC loss of consciousness, RR respiratory rate, Hb hemoglobin, WBC white blood cell, Neut neutrophil count, Cr creatinine, Mg magnesium, K potassium, INR international normalization ratio of prothrombin time, DNNL deep neural network, ICUL intensive care unit). Full size image Model training and evaluation Two data sets were created using features confirmed by each feature selection method. Then datasets were randomly split into training and validation sets in a ratio of 7:3 while preserving the same proportion of mortality in all datasets due to the small percentage of mortality in datasets. Using accuracy for evaluating model performance was inappropriate due to the skewness of the data. Precision, recall, F1-Score, sensitivity, specificity, and area under the curve (AUC) of the receiver operating characteristic (ROC) score were calculated to evaluate model performance on validation datasets. Additionally, the ROC curve visualized model performance. After each iteration of model training and validation, we fine-tuned model parameters, including the number of layers, number of neurons in each layer, learning rate, regularization method, and perceptron connection dropout rate for the ANN models. Also, we tuned parameters like the number of estimators for gradient boosted classifier, the maximum depth for the RF model, and the regularization method for SVM and LR models. These fine-parameter changes were used to maximize the accuracy and generalizability of our AI models. Finally, we tested our trained models' performances on an external dataset from another tertiary hospital in a different province of Iran to evaluate the generalizability of our models. Effect of using iterative imputer on models' performances One of the most critical issues that every ML and deep learning project on tabular data must overcome is dealing with missing data. There are several ways to solve this problem, including filling with median, mean, arbitrary value, previous/next value, using the most common value, and imputing the missing values using ML models. In this study, we used an iterative multivariate imputer, which estimates the missing values in each feature using all other features in the dataset. This is one of the most commonly used ML strategies for missing values. We evaluated the effect of the iterative imputer on ML models' performances and compared it with models trained on datasets without missing values. For this comparison, we randomly removed 20% of the numerical values in our training datasets and trained the same ML models with the same hyperparameters on these datasets. Then we evaluated the performance metrics of these models on the primary testing dataset to compare their performances. Optimal cutoff point Expert opinions of an emergency medicine professor, an internist, and two general practitioners were collected on optimal cutoff points of the proposed model. Two systems with binary (high risk, low risk) and ternary (very high risk, high risk, low risk) classifications were suggested. The ternary classifications can help physicians during peaks of the disease to find the most susceptible patients and allocate hospital beds properly. The optimal cutoff scores were selected based on the optimal point of ROC and the clinician's opinion after reviewing the probability graph. A confusion matrix was used to visualize the performance of cutoff scores in a randomly selected sample from the external validation dataset with 100 survived and 100 deceased cases. Statistical analysis Data analysis and visualization were performed using the R program. The Kolmogorov–Smirnov normality test was used to evaluate the normal distribution of a variable. The Fisher exact test was used to determine the significance of categorical features, and the Mann–Whitney U test was used to evaluate the significance difference of non-parametric numerical variables. An Independent t-test was used to find the significant difference in parametric numerical features. Cox proportional hazards model was used to find the odds ratio (OR) of time-to-death. The categorical variables are presented as numbers and percentage, and numerical variables are presented as mean and standard deviation (SD). Ethical approval All methods were performed in accordance to Helsinki protocol. The Institutional Review Board (IRB) at the Shahid Beheshti University of Medical Science approved the study and waived informed consent gathering (IR.SBMU.RIGLD.REC.1400.014). Data were anonymized before analysis, and patient confidentiality and data security were concerned. Results Basic characteristics After excluding 1703 patients due to missing categorical variables or missing more than two nominal variables, 5320 hospitalized COVID-19 patients were enrolled in the study with a mean ± SD age of 61.6 ± 17.6 years. The fatality rate in the enrolled cohort was 17.24% (N = 917). Patients who died due to covid-19 were significantly older than those who survived (70.3 ± 15.1 versus 58.6 ± 17.1, P < 0.001). The basic characteristics of survived and mortality cohort is presented in Supplementary Table S1 . Factors associated with mortality As depicted in Supplementary Table S2 , on-admission factors associated with mortality in cox proportional hazards model were age, history of myalgia, loss of consciousness, vertigo and vomiting, skin lesions, alcohol consumption, history of gastrointestinal problems, rheumatoid arthritis, Neurologic disorders, leukocytosis, thrombocytopenia, low hemoglobin level, high CRP, low HCO 3 , high CPK level, low oxygen saturation, pulse rate, and respiratory rate. The most important features associated with mortality were alcohol consumption (OR 2.6) and loss of consciousness (OR 1.5). Table 2 shows the mean difference and hazard ratio of selected features. Table 2 Mean comparison and Cox regression of selected variables for inclusion in the model. Full size table Feature selection methods and variable importance LASSO and Brouta feature selection methods were used for variable importance, and results are visualized in Supplementary Figures S1 and S2 . Twenty-four features out of 81 were confirmed by the Boruta method, mainly consisting of laboratory tests (Supplementary Figure S1 ). The most important features are oxygen saturation at admission, age, neutrophil count, serum level of creatinine, troponin, and loss of consciousness. Thirty-seven features were confirmed by the LASSO regression method, including 25 categorical features and 12 continuous variables (Supplementary Figure S2 ). Among these, 23 features were positively associated with mortality, and 14 were negatively correlated with covid patients' mortality. Internal and external validation The details of the model's performance in the test datasets are summarized in Table 3 , and Fig. 2 shows the ROC curve of the models. Most of the trained models showed promising performance for internal validation (AUC score > 80%) except KNN, which had the lowest AUC score among all selected models in both datasets. DNN showed the best performance, with an AUC score of 83.4% in the LASSO-selected validation dataset and 82.6% in the Boruta dataset. Table 3 Model internal and external validation; and validation of imputer model for 2 out of 10 missing lab value. Full size table Figure 2 Receiver operator curve of models using two different feature selection. Full size image The multivariate imputation showed a promising performance on the primary test set when 2 out of 10 laboratory variables were missing. The change in model performance ranged from -1.4% (GBDT with LASSO features) to 4.2% (KNN with LASSO variables), and the performance of the DNN model with LASSO features decreased by 1.6% when imputing two missing laboratories. The generalized performance of the DNN model using LASSO variables was confirmed in the external validation (83.4–82.8%), and the model performance change ranged between 0.7% increase (GDBT with LASSO features) to 11.9% decrease (SVM with Brouta features) in AUC. The confusion matrix of the proposed model (DNN using LASSO features) in the external validation dataset is presented in Fig. 3 using binary and ternary classification (using cutoff points offered by an expert clinician). Figure 3 Probability graph and risk of mortality ( a ), binary confusion matrix ( b ), and ternary confusion matrix ( c ) of external validation dataset using cutoff scores suggested by clinicians. Full size image Discussion As of March 2022, different strains of the SARS-CoV-2 virus have caused five global surges in the number of cases and deaths from COVID-19. It is critical to potentiate the health system struggling with managing the resources during disease surge. The high capabilities of AI and ML algorithms in information processing can help us improve patient management. In this study, we worked intimately with healthcare professionals to provide a tool that can solve real-world needs. We developed a model to predict the mortality risk of COVID-19 inpatients at admission using clinical and laboratory data. In addition, a set of 27 clinical and ten affordable, widely available laboratories was selected in our model. Furthermore, an imputation tool is used to impute the missing labs, and a ternary outcome classification (low, high, and very high risk) was proposed as healthcare experts' suggestion. Several studies have developed ML models to predict COVID-19 patients' mortality risk. However, as demonstrated in Table 1 , models with high AUC scores are most likely trained on a small dataset or the data gathered from a single medical center. Consequently, these models may ungeneralizable, and their performance can drop in a dataset from a different center 11 , 14 , 15 , 16 , 18 . Furthermore, our model performed relatively better or the same as models trained on a large multicentral datasets. This higher performance may be due to the large number of input features, which can simultaneously analyze different aspects of a patient's health 10 , 12 , 13 , 17 . COVID-19 can affect multiple organs, including the kidney, heart, lungs, brain, and blood. Hence, it can cause death by several different organ failures 8 . We should consider markers from several organs of the human body in order to predict the risk of mortality. Thus, as a novel approach, we collected and analyzed more than 80 on-admission features representing the function of different organs. We used a relatively large dataset to train our ML and DNN models and selected the input features using feature selection methods to eliminate collinearity. Nevertheless, overfitting of models, especially ANN, was a substantial problem in this study due to the large number of selected features for models’ input. One of the most important parameters that we added to prevent them from overfitting was L2 regularization, which resulted in a good performance in the validation dataset. Also, adding kernel regularization and 60% dropout for each layer, as well as limiting the number of neurons and hidden layers in ANN, brought about a robust and generalizable model by preventing overfitting. We selected a DNN model trained on features determined by the LASSO regression method as our proposed model. Other studies also used LASSO method for their feature selection 12 , 13 , 14 , 24 or prediction 23 . Despite the susceptibility of neural networks to overfitting, our DNN model performed well on the external validation due to feature selection method, large sample sizes, and layer regularization. Among 10 studies with external validation, various ML methods were used for mortality prediction, including logistic regression 15 , 19 , random forest 11 , regression coefficient 13 , XGBosst 14 , 17 , 18 , CatBoost 11 , neural network, and DNN 15 . Although decision tree was the most common architecture in previous studies, even largescale ones, we found higher precision for DNN. This may be due to the high number of input features and the complex interaction of predictors. In a similar study, Gao et al. used data from 1500 patients in two centers and developed an ensembled model called MRPMC. MROMC is composed of four ML methods of logistic regression, support vector machine, gradient-boosted decision tree, and neural network 16 . However, the AUC in external validation of MRPMC, logistic regression, and neural network were fairly equal (91.8%, 91.3%, and 91.1%, respectively). Similarly, we find the neural network and logistic regression methods better for generalizable use. However, we avoided ensemble architecture to prevent overfitting since 37 input features were selected, while Gao et al. had eight. Also, ensemble models require longer prediction time, more computation power, and hard work for tuning. The application of ML models in the clinic depends on the input features and prediction accuracy. Ease of access to input features, along with high accuracy and generalization of prediction, can increase acceptance of ML tools by healthcare workers. Selected features in the present study include 18 factors at the time of admission. Previous studies included many of our selected features for prognosis prediction, which can imply the accuracy of our feature importance method 10 , 11 , 12 , 14 , 15 . Laboratory markers, patient demographics, medical history, and vital signs have been used as effective features in predicting the mortality of patients with COVID-19, similar to this study 10 , 11 , 28 , 29 , 30 , 31 , 32 , 33 . However, we excluded some variables, such as inflammatory cytokines, while others found them predictive 34 , 35 , 36 , 37 . Since we excluded some features with collinearity, the other included feature represents the effect of this predictor on mortality. The results of this study are applicable to managing COVID-19 inpatients with the current and upcoming COVID-19 surges. First, validation with 20% missing data indicates the approved potential of our model when the patient's data is unreachable and needs imputation. Second, the model's generalization was investigated using data from a fourth hospital in a different province. The AUC of 82.8% was achieved in external validation, which confirmed the model performance for global application. Third, we proposed ternary severity classification as per clinician’s opinion to show the most susceptible patients with very high severity. Our model can facilitate clinical decision-making, resource allocation, and evaluation of drug’s effectiveness by risk stratifying mortality in COVID-19 inpatients. Nonetheless, there are some limitations to this work that should be noted. First, even though we had a relatively large patient population, our study was retrospective. Prospective validation of our study is required to ascertain the results. The hospitals in our study are all in a developing country (Iran). The scarcity of medical resources in Iranian hospitals may bring about inadequate service allocated to patients. This condition can thereby increase the mortality rate in such countries in contrast to countries with effective medical systems. Additionally, the current model does not encompass imaging, microbiological, and histological data, which could contribute to a more precise prognosis prediction despite the inconvenience. Socioeconomic and racial differences, which were investigated in some studies 38 , 39 , might as well play a role in prognosis. In conclusion, this study shows that ML methods can predict the mortality risk of COVID-19 patients on admission. This approves the potential of ML methods for use in clinical practice as a decision-support system. However, effective ML models should satisfy the real-world needs of healthcare experts to increase the chance of implementation in practice. Further studies are suggested to investigate and overcome the current barriers to applying ML in medical practice.